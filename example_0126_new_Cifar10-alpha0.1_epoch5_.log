2022-01-26 22:16:36:INFO:-------------Round number: 0-------------
2022-01-26 22:16:36:INFO:-------------Sending models-------------
2022-01-26 22:16:36:INFO:-------------Evaluating models-------------
2022-01-26 22:16:37:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:16:37:INFO:Accuracy = [0.9000333222259247, 0.09963345551482838, 0.09983338887037654, 0.09996667777407531, 0.8760413195601466, 0.8805731422859047, 0.10003332222592469, 0.09983338887037654, 0.8994335221592802, 0.8993668777074308]
2022-01-26 22:16:37:INFO:Loss = [0.6656853142558475, 0.7252704504886018, 0.7189109772334532, 0.7331650955682594, 0.6908818278460453, 0.6900989621490369, 0.7395622698516299, 0.703261496920619, 0.6848333545940314, 0.6385443350069923]
2022-01-26 22:16:37:INFO:-------------Training local models-------------
2022-01-26 22:24:56:INFO:-------------Aggregating local models-------------
2022-01-26 22:24:59:INFO:-------------Round number: 1-------------
2022-01-26 22:24:59:INFO:-------------Sending models-------------
2022-01-26 22:24:59:INFO:-------------Evaluating models-------------
2022-01-26 22:25:00:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:25:00:INFO:Accuracy = [0.9311562812395868, 0.9532822392535821, 0.9848050649783405, 0.9288903698767078, 0.915028323892036, 0.9574141952682439, 0.9844051982672443, 0.9824725091636122, 0.9480173275574808, 0.9299566811062979]
2022-01-26 22:25:00:INFO:Loss = [0.14414273469954958, 0.13201070199815215, 0.05645278125378511, 0.15609371457236512, 0.1856694453727033, 0.11484641811460683, 0.0767225537697081, 0.07977664749479739, 0.11727464884644953, 0.15502967551977165]
2022-01-26 22:25:00:INFO:-------------Training local models-------------
2022-01-26 22:33:19:INFO:-------------Aggregating local models-------------
2022-01-26 22:33:21:INFO:-------------Round number: 2-------------
2022-01-26 22:33:21:INFO:-------------Sending models-------------
2022-01-26 22:33:21:INFO:-------------Evaluating models-------------
2022-01-26 22:33:22:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:33:22:INFO:Accuracy = [0.9562812395868044, 0.9532822392535821, 0.9848050649783405, 0.9317560813062312, 0.9325558147284239, 0.9736087970676441, 0.9844051982672443, 0.9824725091636122, 0.9714095301566145, 0.9394868377207597]
2022-01-26 22:33:22:INFO:Loss = [0.10574394698482552, 0.10903740787383799, 0.04256797325997547, 0.13749422921215845, 0.16295356659368562, 0.07186456607263356, 0.04499307206120579, 0.05865733797084112, 0.07538946745838841, 0.13017998461773564]
2022-01-26 22:33:22:INFO:-------------Training local models-------------
2022-01-26 22:41:42:INFO:-------------Aggregating local models-------------
2022-01-26 22:41:45:INFO:-------------Round number: 3-------------
2022-01-26 22:41:45:INFO:-------------Sending models-------------
2022-01-26 22:41:45:INFO:-------------Evaluating models-------------
2022-01-26 22:41:46:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:41:46:INFO:Accuracy = [0.9683438853715428, 0.9532822392535821, 0.9848050649783405, 0.9454848383872043, 0.9436854381872709, 0.9770076641119627, 0.9844051982672443, 0.9824725091636122, 0.9726757747417527, 0.9457514161946018]
2022-01-26 22:41:46:INFO:Loss = [0.08658849323215413, 0.10636228247850489, 0.04104600335342232, 0.12597638465166502, 0.15001131265838646, 0.06015591832503623, 0.0402498836402624, 0.05552312317774862, 0.06606931145686529, 0.12138724148789248]
2022-01-26 22:41:46:INFO:-------------Training local models-------------
2022-01-26 22:50:04:INFO:-------------Aggregating local models-------------
2022-01-26 22:50:07:INFO:-------------Round number: 4-------------
2022-01-26 22:50:07:INFO:-------------Sending models-------------
2022-01-26 22:50:07:INFO:-------------Evaluating models-------------
2022-01-26 22:50:07:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:50:07:INFO:Accuracy = [0.9708763745418194, 0.9532822392535821, 0.9848050649783405, 0.947350883038987, 0.947350883038987, 0.977940686437854, 0.9844051982672443, 0.9824725091636122, 0.9734755081639453, 0.9464178607130956]
2022-01-26 22:50:07:INFO:Loss = [0.07710502259581456, 0.10419926243533248, 0.040339251259876856, 0.11874569873754956, 0.13964743497519608, 0.05699557515392834, 0.03733398002246193, 0.05401179152465218, 0.06272172939466944, 0.11406509356166061]
2022-01-26 22:50:07:INFO:-------------Training local models-------------
2022-01-26 22:58:26:INFO:-------------Aggregating local models-------------
2022-01-26 22:58:28:INFO:-------------Round number: 5-------------
2022-01-26 22:58:28:INFO:-------------Sending models-------------
2022-01-26 22:58:29:INFO:-------------Evaluating models-------------
2022-01-26 22:58:29:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:58:29:INFO:Accuracy = [0.9724758413862046, 0.9532822392535821, 0.9848050649783405, 0.9484838387204265, 0.9477507497500833, 0.9777407530823059, 0.985738087304232, 0.9824725091636122, 0.9740753082305899, 0.9475508163945352]
2022-01-26 22:58:29:INFO:Loss = [0.07313210041918107, 0.10176961182852352, 0.03993460547383574, 0.11529483558796362, 0.13495745629326122, 0.05584491023814221, 0.03505238577977127, 0.05297665445345112, 0.06081476297073739, 0.11031242681940538]
2022-01-26 22:58:29:INFO:-------------Training local models-------------
2022-01-26 23:06:47:INFO:-------------Aggregating local models-------------
2022-01-26 23:06:49:INFO:-------------Round number: 6-------------
2022-01-26 23:06:49:INFO:-------------Sending models-------------
2022-01-26 23:06:49:INFO:-------------Evaluating models-------------
2022-01-26 23:06:50:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 23:06:50:INFO:Accuracy = [0.9732089303565478, 0.9532822392535821, 0.9848050649783405, 0.9497500833055648, 0.9483505498167277, 0.977940686437854, 0.987137620793069, 0.9824725091636122, 0.9746751082972342, 0.9490169943352216]
2022-01-26 23:06:50:INFO:Loss = [0.0708499838524639, 0.09910337703877557, 0.03966027016861095, 0.11350970287631634, 0.13177351971747972, 0.05516126540025773, 0.03339993860879035, 0.0521672953758284, 0.05958426186152295, 0.1074833451515556]
2022-01-26 23:06:50:INFO:-------------Training local models-------------
2022-01-26 23:15:01:INFO:-------------Aggregating local models-------------
2022-01-26 23:15:04:INFO:-------------Round number: 7-------------
2022-01-26 23:15:04:INFO:-------------Sending models-------------
2022-01-26 23:15:04:INFO:-------------Evaluating models-------------
2022-01-26 23:15:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 23:15:05:INFO:Accuracy = [0.9740753082305899, 0.9558813728757081, 0.9848050649783405, 0.9503498833722093, 0.9488170609796734, 0.9778740419860047, 0.9878040653115628, 0.9824725091636122, 0.9746084638453849, 0.9506164611796069]
2022-01-26 23:15:05:INFO:Loss = [0.06920299949294753, 0.09577614361121885, 0.03942746637741956, 0.1121166972792688, 0.12897166228985718, 0.054396498624948546, 0.03194166104384246, 0.05148981375086493, 0.05858939887142468, 0.10391796800362123]
2022-01-26 23:15:05:INFO:-------------Training local models-------------
2022-01-26 23:23:15:INFO:-------------Aggregating local models-------------
2022-01-26 23:23:18:INFO:-------------Round number: 8-------------
2022-01-26 23:23:18:INFO:-------------Sending models-------------
2022-01-26 23:23:18:INFO:-------------Evaluating models-------------
2022-01-26 23:23:18:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 23:23:18:INFO:Accuracy = [0.9747417527490836, 0.9599466844385205, 0.9848050649783405, 0.9517494168610463, 0.9494168610463178, 0.9781406197934022, 0.9886037987337554, 0.9824725091636122, 0.974808397200933, 0.9533488837054315]
2022-01-26 23:23:18:INFO:Loss = [0.06805129711667025, 0.09095303839436766, 0.03917532616943875, 0.11077857036328968, 0.12633020797505937, 0.053913016701135776, 0.030144621239879977, 0.05090092517287481, 0.05777742366198603, 0.09921782818022656]
2022-01-26 23:23:18:INFO:-------------Training local models-------------
2022-01-26 23:31:29:INFO:-------------Aggregating local models-------------
2022-01-26 23:31:32:INFO:-------------Round number: 9-------------
2022-01-26 23:31:32:INFO:-------------Sending models-------------
2022-01-26 23:31:32:INFO:-------------Evaluating models-------------
2022-01-26 23:31:33:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 23:31:33:INFO:Accuracy = [0.9744751749416861, 0.9627457514161946, 0.9851382872375875, 0.9545484838387204, 0.9516161279573475, 0.9785404865044985, 0.9895368210596468, 0.9824725091636122, 0.9748750416527824, 0.9557480839720093]
2022-01-26 23:31:33:INFO:Loss = [0.06744647504352869, 0.08552613219038768, 0.03897390021548117, 0.10928147879291217, 0.12385465973251977, 0.05342814467240211, 0.02887819112440168, 0.05036627906099015, 0.05698104928590088, 0.0962690133520914]
2022-01-26 23:31:33:INFO:-------------Training local models-------------
2022-01-26 23:39:43:INFO:-------------Aggregating local models-------------
2022-01-26 23:39:45:INFO:-------------Round number: 10-------------
2022-01-26 23:39:45:INFO:-------------Sending models-------------
2022-01-26 23:39:45:INFO:-------------Evaluating models-------------
2022-01-26 23:39:46:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 23:39:46:INFO:Accuracy = [0.974808397200933, 0.9634121959346884, 0.9856714428523825, 0.9558147284238587, 0.9524158613795402, 0.9784071976007997, 0.9901366211262912, 0.9824725091636122, 0.9750749750083305, 0.9555481506164611]
2022-01-26 23:39:46:INFO:Loss = [0.06707558621921952, 0.08302356161579666, 0.03870450808423109, 0.10775221313340942, 0.12164324830679248, 0.05308205427896211, 0.027676990766278633, 0.04988099666455015, 0.05621773059267428, 0.09621000301649492]
2022-01-26 23:39:46:INFO:-------------Training local models-------------
2022-01-26 23:47:57:INFO:-------------Aggregating local models-------------
2022-01-26 23:47:59:INFO:-------------Round number: 11-------------
2022-01-26 23:47:59:INFO:-------------Sending models-------------
2022-01-26 23:48:00:INFO:-------------Evaluating models-------------
2022-01-26 23:48:00:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 23:48:00:INFO:Accuracy = [0.9746084638453849, 0.9638787070976341, 0.9865378207264245, 0.9574141952682439, 0.9536821059646784, 0.9786071309563479, 0.9907364211929357, 0.9824725091636122, 0.9752749083638788, 0.9565478173942019]
2022-01-26 23:48:00:INFO:Loss = [0.06693055390152845, 0.08223694326514791, 0.03831119810210121, 0.10625886483642524, 0.11970834863501306, 0.05243695424671817, 0.027048516600859895, 0.04942566077379982, 0.055316792353363724, 0.09598913911844643]
2022-01-26 23:48:00:INFO:-------------Training local models-------------
2022-01-26 23:56:10:INFO:-------------Aggregating local models-------------
2022-01-26 23:56:13:INFO:-------------Round number: 12-------------
2022-01-26 23:56:13:INFO:-------------Sending models-------------
2022-01-26 23:56:13:INFO:-------------Evaluating models-------------
2022-01-26 23:56:14:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 23:56:14:INFO:Accuracy = [0.9746751082972342, 0.9648117294235254, 0.9872042652449183, 0.9578807064311896, 0.9537487504165278, 0.9788737087637455, 0.990803065644785, 0.9824725091636122, 0.9755414861712762, 0.9577474175274908]
2022-01-26 23:56:14:INFO:Loss = [0.06711865696150723, 0.08091302644208469, 0.03784064057879281, 0.10481745385337464, 0.11822666731860385, 0.05214685023844835, 0.026142269411272553, 0.048977219129079534, 0.05440809558032933, 0.09372117991553058]
2022-01-26 23:56:14:INFO:-------------Training local models-------------
2022-01-27 00:04:24:INFO:-------------Aggregating local models-------------
2022-01-27 00:04:27:INFO:-------------Round number: 13-------------
2022-01-27 00:04:27:INFO:-------------Sending models-------------
2022-01-27 00:04:27:INFO:-------------Evaluating models-------------
2022-01-27 00:04:28:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:04:28:INFO:Accuracy = [0.9744751749416861, 0.9652115961346218, 0.9874708430523159, 0.9586137954015328, 0.9549483505498167, 0.9792735754748417, 0.9909363545484838, 0.9824725091636122, 0.9769410196601133, 0.9593468843718761]
2022-01-27 00:04:28:INFO:Loss = [0.06741140140420303, 0.07932959000240251, 0.03739283867667771, 0.10348641338289813, 0.11685897507227651, 0.05183264425626871, 0.025150392569773736, 0.0485284216690017, 0.053471424886347, 0.0906701824668209]
2022-01-27 00:04:28:INFO:-------------Training local models-------------
2022-01-27 00:12:38:INFO:-------------Aggregating local models-------------
2022-01-27 00:12:40:INFO:-------------Round number: 14-------------
2022-01-27 00:12:40:INFO:-------------Sending models-------------
2022-01-27 00:12:41:INFO:-------------Evaluating models-------------
2022-01-27 00:12:41:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:12:41:INFO:Accuracy = [0.9743418860379873, 0.9658780406531157, 0.9874708430523159, 0.9591469510163279, 0.9558147284238587, 0.9794735088303899, 0.9910029990003332, 0.9825391536154615, 0.9772742419193602, 0.9594801732755748]
2022-01-27 00:12:41:INFO:Loss = [0.06783613667367314, 0.07829311977808645, 0.03702759217423635, 0.10236367761998837, 0.11575236089870589, 0.051410362541262085, 0.02455841971077904, 0.04806342668306122, 0.05247945386252529, 0.08900229868827175]
2022-01-27 00:12:41:INFO:-------------Training local models-------------
2022-01-27 00:20:52:INFO:-------------Aggregating local models-------------
2022-01-27 00:20:55:INFO:-------------Round number: 15-------------
2022-01-27 00:20:55:INFO:-------------Sending models-------------
2022-01-27 00:20:55:INFO:-------------Evaluating models-------------
2022-01-27 00:20:55:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:20:55:INFO:Accuracy = [0.9741419526824392, 0.9662779073642119, 0.9874708430523159, 0.9598133955348217, 0.9563478840386538, 0.9798067310896368, 0.991136287904032, 0.9826724425191603, 0.9774741752749083, 0.9606131289570143]
2022-01-27 00:20:55:INFO:Loss = [0.06837363484890688, 0.07734812939310406, 0.03671883213013769, 0.10145698769144477, 0.11471098931596177, 0.05097602355716939, 0.024014963758466592, 0.047583807500664495, 0.05150391882984239, 0.08752045265688464]
2022-01-27 00:20:55:INFO:-------------Training local models-------------
2022-01-27 00:28:52:INFO:-------------Aggregating local models-------------
2022-01-27 00:28:55:INFO:-------------Round number: 16-------------
2022-01-27 00:28:55:INFO:-------------Sending models-------------
2022-01-27 00:28:55:INFO:-------------Evaluating models-------------
2022-01-27 00:28:55:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:28:55:INFO:Accuracy = [0.9739420193268911, 0.9668777074308563, 0.9877374208597134, 0.9604131956014662, 0.9580806397867377, 0.9800733088970344, 0.9912029323558814, 0.9825391536154615, 0.977940686437854, 0.9612795734755082]
2022-01-27 00:28:55:INFO:Loss = [0.06893046187250075, 0.07641935731909243, 0.036479411956449215, 0.10072144189949017, 0.11384069212270291, 0.050623437106804545, 0.02397792525521289, 0.0471115562551341, 0.050574691183924034, 0.08705724771080828]
2022-01-27 00:28:55:INFO:-------------Training local models-------------
2022-01-27 00:37:01:INFO:-------------Aggregating local models-------------
2022-01-27 00:37:03:INFO:-------------Round number: 17-------------
2022-01-27 00:37:03:INFO:-------------Sending models-------------
2022-01-27 00:37:03:INFO:-------------Evaluating models-------------
2022-01-27 00:37:04:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:37:04:INFO:Accuracy = [0.9736754415194935, 0.9675441519493502, 0.9878040653115628, 0.9603465511496168, 0.9585471509496835, 0.9803398867044318, 0.9913362212595801, 0.9827390869710096, 0.9780739753415528, 0.9612795734755082]
2022-01-27 00:37:04:INFO:Loss = [0.06949340192196211, 0.07576255297810694, 0.036254840301864454, 0.10023545543645554, 0.1132541984565862, 0.05020524219538167, 0.02384829946024716, 0.046646339350429424, 0.04977197248862776, 0.08689679149520531]
2022-01-27 00:37:04:INFO:-------------Training local models-------------
2022-01-27 00:45:09:INFO:-------------Aggregating local models-------------
2022-01-27 00:45:12:INFO:-------------Round number: 18-------------
2022-01-27 00:45:12:INFO:-------------Sending models-------------
2022-01-27 00:45:12:INFO:-------------Evaluating models-------------
2022-01-27 00:45:13:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:45:13:INFO:Accuracy = [0.9739420193268911, 0.9684105298233922, 0.9876041319560147, 0.9607464178607131, 0.9590803065644785, 0.980206597800733, 0.9914028657114295, 0.9830723092302566, 0.9787404198600467, 0.9617460846384539]
2022-01-27 00:45:13:INFO:Loss = [0.07015079144945958, 0.07475503709222268, 0.036053082981320546, 0.09984211023863067, 0.11266184638023084, 0.049924380657992706, 0.02365335826952684, 0.04620327407691775, 0.04910644151850856, 0.08641850633929259]
2022-01-27 00:45:13:INFO:-------------Training local models-------------
2022-01-27 00:53:17:INFO:-------------Aggregating local models-------------
2022-01-27 00:53:20:INFO:-------------Round number: 19-------------
2022-01-27 00:53:20:INFO:-------------Sending models-------------
2022-01-27 00:53:20:INFO:-------------Evaluating models-------------
2022-01-27 00:53:20:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:53:20:INFO:Accuracy = [0.9741419526824392, 0.9702099300233256, 0.9877374208597134, 0.9606797734088637, 0.9594135288237254, 0.9802732422525825, 0.9914695101632789, 0.9834721759413528, 0.9798067310896368, 0.9624125291569476]
2022-01-27 00:53:20:INFO:Loss = [0.07083494475278211, 0.07348156149036676, 0.035882875191326546, 0.09965540453512334, 0.11234802193645059, 0.04966662223429213, 0.02349487653502504, 0.04577495623297415, 0.04844224225543434, 0.08607968367618728]
2022-01-27 00:53:20:INFO:-------------Training local models-------------
2022-01-27 01:01:26:INFO:-------------Aggregating local models-------------
2022-01-27 01:01:28:INFO:-------------Round number: 20-------------
2022-01-27 01:01:28:INFO:-------------Sending models-------------
2022-01-27 01:01:28:INFO:-------------Evaluating models-------------
2022-01-27 01:01:29:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:01:29:INFO:Accuracy = [0.9746751082972342, 0.9714095301566145, 0.9879373542152616, 0.9612129290236587, 0.9606131289570143, 0.9803398867044318, 0.9915361546151283, 0.9838053982005998, 0.9809396867710763, 0.9629456847717428]
2022-01-27 01:01:29:INFO:Loss = [0.0714999778481406, 0.072290625464142, 0.035726324536438696, 0.09963552094986375, 0.11215885398044849, 0.04952404843403572, 0.023492417418778826, 0.045380270112576185, 0.04789036223062874, 0.08604370288747666]
2022-01-27 01:01:29:INFO:-------------Training local models-------------
2022-01-27 01:09:35:INFO:-------------Aggregating local models-------------
2022-01-27 01:09:37:INFO:-------------Round number: 21-------------
2022-01-27 01:09:37:INFO:-------------Sending models-------------
2022-01-27 01:09:37:INFO:-------------Evaluating models-------------
2022-01-27 01:09:38:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:09:38:INFO:Accuracy = [0.97514161946018, 0.9724758413862046, 0.9878707097634122, 0.9616794401866045, 0.9606131289570143, 0.9806064645118294, 0.991669443518827, 0.984005331556148, 0.9817394201932689, 0.9635454848383872]
2022-01-27 01:09:38:INFO:Loss = [0.07220946719082451, 0.07141462110182563, 0.03559183548208965, 0.09973915843973001, 0.11216576131127365, 0.04943051372628319, 0.023425983779975474, 0.04502369766379912, 0.04739320050535911, 0.0860485852370671]
2022-01-27 01:09:38:INFO:-------------Training local models-------------
2022-01-27 01:17:43:INFO:-------------Aggregating local models-------------
2022-01-27 01:17:46:INFO:-------------Round number: 22-------------
2022-01-27 01:17:46:INFO:-------------Sending models-------------
2022-01-27 01:17:46:INFO:-------------Evaluating models-------------
2022-01-27 01:17:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:17:47:INFO:Accuracy = [0.9754748417194269, 0.9740086637787404, 0.9878707097634122, 0.9622125958013995, 0.960546484505165, 0.9804731756081306, 0.991669443518827, 0.9843385538153949, 0.9825391536154615, 0.9638787070976341]
2022-01-27 01:17:47:INFO:Loss = [0.07286992882657917, 0.07075197127351636, 0.03547862684620737, 0.09992541231327778, 0.11232578707898488, 0.049323619330702874, 0.02353506479820799, 0.04468152657570003, 0.046987880443728126, 0.08623708636640834]
2022-01-27 01:17:47:INFO:-------------Training local models-------------
2022-01-27 01:25:52:INFO:-------------Aggregating local models-------------
2022-01-27 01:25:55:INFO:-------------Round number: 23-------------
2022-01-27 01:25:55:INFO:-------------Sending models-------------
2022-01-27 01:25:55:INFO:-------------Evaluating models-------------
2022-01-27 01:25:56:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:25:56:INFO:Accuracy = [0.9756081306231257, 0.9741419526824392, 0.9879373542152616, 0.9623458847050983, 0.9606797734088637, 0.98053982005998, 0.9916027990669777, 0.9843385538153949, 0.9829390203265578, 0.9652782405864712]
2022-01-27 01:25:56:INFO:Loss = [0.0735988932729419, 0.07030742769452082, 0.03537437630957499, 0.10014405736665186, 0.11252455474130803, 0.049195326265126176, 0.02372064401182805, 0.04435727715779544, 0.04649912460529227, 0.08628134292706853]
2022-01-27 01:25:56:INFO:-------------Training local models-------------
2022-01-27 01:34:01:INFO:-------------Aggregating local models-------------
2022-01-27 01:34:03:INFO:-------------Round number: 24-------------
2022-01-27 01:34:03:INFO:-------------Sending models-------------
2022-01-27 01:34:03:INFO:-------------Evaluating models-------------
2022-01-27 01:34:04:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:34:04:INFO:Accuracy = [0.9760746417860713, 0.9752749083638788, 0.988003998667111, 0.962279240253249, 0.9603465511496168, 0.9806064645118294, 0.9914695101632789, 0.9846051316227924, 0.9825391536154615, 0.9662779073642119]
2022-01-27 01:34:04:INFO:Loss = [0.07426357947309621, 0.07014697551468425, 0.03529161951775931, 0.1004835466606465, 0.11285849368487719, 0.04912959028400087, 0.02403284931216909, 0.04405445593785291, 0.046200010797173896, 0.08657803741150251]
2022-01-27 01:34:04:INFO:-------------Training local models-------------
2022-01-27 01:42:09:INFO:-------------Aggregating local models-------------
2022-01-27 01:42:12:INFO:-------------Round number: 25-------------
2022-01-27 01:42:12:INFO:-------------Sending models-------------
2022-01-27 01:42:12:INFO:-------------Evaluating models-------------
2022-01-27 01:42:12:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:42:12:INFO:Accuracy = [0.9762079306897701, 0.9760079973342219, 0.9880706431189603, 0.9623458847050983, 0.9607464178607131, 0.9808730423192269, 0.9912695768077308, 0.984538487170943, 0.9832055981339554, 0.9674108630456515]
2022-01-27 01:42:12:INFO:Loss = [0.07488205217275473, 0.07009706020134682, 0.03522261471004144, 0.1007759583254796, 0.11318315135031869, 0.04900050426299687, 0.024295652419717505, 0.04377257101061047, 0.04592486463290385, 0.08685180482695003]
2022-01-27 01:42:12:INFO:-------------Training local models-------------
2022-01-27 01:50:14:INFO:-------------Aggregating local models-------------
2022-01-27 01:50:16:INFO:-------------Round number: 26-------------
2022-01-27 01:50:16:INFO:-------------Sending models-------------
2022-01-27 01:50:16:INFO:-------------Evaluating models-------------
2022-01-27 01:50:17:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:50:17:INFO:Accuracy = [0.9761412862379207, 0.9757414195268244, 0.9880706431189603, 0.9630123292235921, 0.9611462845718094, 0.9807397534155281, 0.9912029323558814, 0.9846717760746417, 0.9832722425858047, 0.9677440853048984]
2022-01-27 01:50:17:INFO:Loss = [0.07634849888216771, 0.0703826333197196, 0.035165428828929625, 0.10112690340884928, 0.11354873381621687, 0.04892249283849775, 0.024426093361358425, 0.04349734360749177, 0.045804368110308795, 0.0873221782139051]
2022-01-27 01:50:17:INFO:-------------Training local models-------------
2022-01-27 01:58:25:INFO:-------------Aggregating local models-------------
2022-01-27 01:58:27:INFO:-------------Round number: 27-------------
2022-01-27 01:58:27:INFO:-------------Sending models-------------
2022-01-27 01:58:27:INFO:-------------Evaluating models-------------
2022-01-27 01:58:28:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:58:28:INFO:Accuracy = [0.976541152949017, 0.9761412862379207, 0.9882039320226591, 0.9630123292235921, 0.961412862379207, 0.9808730423192269, 0.9912029323558814, 0.9848050649783405, 0.9832722425858047, 0.9677440853048984]
2022-01-27 01:58:28:INFO:Loss = [0.07699013860718736, 0.07079470355624233, 0.035131896715547506, 0.10150934990584966, 0.11395262138992397, 0.04892511053711951, 0.024848647898475948, 0.04325012518247383, 0.0457540281395563, 0.08899715869220663]
2022-01-27 01:58:28:INFO:-------------Training local models-------------
2022-01-27 02:06:36:INFO:-------------Aggregating local models-------------
2022-01-27 02:06:38:INFO:-------------Round number: 28-------------
2022-01-27 02:06:38:INFO:-------------Sending models-------------
2022-01-27 02:06:38:INFO:-------------Evaluating models-------------
2022-01-27 02:06:39:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:06:39:INFO:Accuracy = [0.9764078640453182, 0.9760746417860713, 0.9883372209263579, 0.9627457514161946, 0.9617460846384539, 0.9808730423192269, 0.9912029323558814, 0.9850716427857381, 0.9834721759413528, 0.9683438853715428]
2022-01-27 02:06:39:INFO:Loss = [0.0777486906275491, 0.07138805237101169, 0.03509188306458246, 0.10186983054589559, 0.11440987284992453, 0.048941747254207656, 0.024988010899759903, 0.04299041339240992, 0.045893840451696956, 0.08963152105430053]
2022-01-27 02:06:39:INFO:-------------Training local models-------------
2022-01-27 02:14:47:INFO:-------------Aggregating local models-------------
2022-01-27 02:14:49:INFO:-------------Round number: 29-------------
2022-01-27 02:14:49:INFO:-------------Sending models-------------
2022-01-27 02:14:50:INFO:-------------Evaluating models-------------
2022-01-27 02:14:50:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:14:50:INFO:Accuracy = [0.976541152949017, 0.9763412195934689, 0.9883372209263579, 0.9626791069643452, 0.9618127290903032, 0.9808730423192269, 0.9910029990003332, 0.9850716427857381, 0.9837387537487504, 0.9684771742752416]
2022-01-27 02:14:50:INFO:Loss = [0.07849612465601256, 0.0720479630109902, 0.03506958919873537, 0.10235479832021527, 0.1150348832472158, 0.04907968140044924, 0.025293288734518048, 0.04273087579200996, 0.04611494845879111, 0.09038289146609683]
2022-01-27 02:14:50:INFO:-------------Training local models-------------
2022-01-27 02:22:58:INFO:-------------Aggregating local models-------------
