2022-01-27 01:44:32:INFO:-------------Round number: 0-------------
2022-01-27 01:44:32:INFO:-------------Sending models-------------
2022-01-27 01:44:33:INFO:-------------Evaluating models-------------
2022-01-27 01:44:33:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:44:33:INFO:Accuracy = [0.9006128430588862, 0.09725552891020517, 0.09885424993338662, 0.1035171862509992, 0.8815614175326405, 0.8822275512922995, 0.09938715694111377, 0.09845456967759127, 0.8987476685318412, 0.8994138022915001]
2022-01-27 01:44:33:INFO:Loss = [0.665433980252563, 0.7255395413985609, 0.7186639183939154, 0.7327777343910598, 0.6907469832258736, 0.6898914382135649, 0.7394655026930222, 0.7035869941961088, 0.6847941407736797, 0.6383327701998304]
2022-01-27 01:44:33:INFO:-------------Training local models-------------
2022-01-27 01:48:44:INFO:-------------Aggregating local models-------------
2022-01-27 01:48:47:INFO:-------------Round number: 1-------------
2022-01-27 01:48:47:INFO:-------------Sending models-------------
2022-01-27 01:48:47:INFO:-------------Evaluating models-------------
2022-01-27 01:48:48:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:48:48:INFO:Accuracy = [0.9176658673061551, 0.9000799360511591, 0.9416466826538769, 0.8991473487876366, 0.9371169730881961, 0.8998134825472955, 0.9404476418864908, 0.9379163335997869, 0.9066080468958166, 0.9131361577404743]
2022-01-27 01:48:48:INFO:Loss = [0.250118446877326, 0.308314844491464, 0.21555571572181625, 0.2999645168139891, 0.2160444126276822, 0.3423441267144774, 0.1975681770884757, 0.24122718036350468, 0.2566700823497858, 0.24571093494509805]
2022-01-27 01:48:48:INFO:-------------Training local models-------------
2022-01-27 01:52:59:INFO:-------------Aggregating local models-------------
2022-01-27 01:53:01:INFO:-------------Round number: 2-------------
2022-01-27 01:53:01:INFO:-------------Sending models-------------
2022-01-27 01:53:01:INFO:-------------Evaluating models-------------
2022-01-27 01:53:02:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:53:02:INFO:Accuracy = [0.9181987743138822, 0.907673860911271, 0.9441779909405809, 0.9177990940580869, 0.9376498800959233, 0.8998134825472955, 0.968558486544098, 0.9380495603517186, 0.9363176125766054, 0.9180655475619505]
2022-01-27 01:53:02:INFO:Loss = [0.19408817362314987, 0.24058212840913745, 0.14721324229962843, 0.23555432869602355, 0.15139999638322485, 0.2625355479588383, 0.11854306536802589, 0.17382477377480565, 0.19303907159783637, 0.18951360499419326]
2022-01-27 01:53:02:INFO:-------------Training local models-------------
2022-01-27 01:57:14:INFO:-------------Aggregating local models-------------
2022-01-27 01:57:16:INFO:-------------Round number: 3-------------
2022-01-27 01:57:16:INFO:-------------Sending models-------------
2022-01-27 01:57:16:INFO:-------------Evaluating models-------------
2022-01-27 01:57:17:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:57:17:INFO:Accuracy = [0.929656274980016, 0.9147348787636558, 0.9543032240873968, 0.9215294431121769, 0.9376498800959233, 0.9006128430588862, 0.968558486544098, 0.9381827871036504, 0.9275246469491074, 0.9187316813216094]
2022-01-27 01:57:17:INFO:Loss = [0.16704733951595832, 0.21324054316982086, 0.11821734459998516, 0.21055475230152054, 0.1293833342054747, 0.23313865695470562, 0.09063111693463582, 0.14952771332848974, 0.1678193497034512, 0.16733626403746957]
2022-01-27 01:57:17:INFO:-------------Training local models-------------
2022-01-27 02:01:27:INFO:-------------Aggregating local models-------------
2022-01-27 02:01:29:INFO:-------------Round number: 4-------------
2022-01-27 02:01:29:INFO:-------------Sending models-------------
2022-01-27 02:01:30:INFO:-------------Evaluating models-------------
2022-01-27 02:01:30:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:01:30:INFO:Accuracy = [0.9343192112976285, 0.9179323208100186, 0.9606981081801226, 0.927124966693312, 0.9404476418864908, 0.9116706634692247, 0.968558486544098, 0.9381827871036504, 0.9221955768718358, 0.927791100452971]
2022-01-27 02:01:30:INFO:Loss = [0.15034575628681526, 0.19646440648771335, 0.09919068369707773, 0.19783345514236803, 0.11735809008944373, 0.2164731227384958, 0.07837292785169281, 0.13803543180705968, 0.15581827619354482, 0.15265118877983871]
2022-01-27 02:01:30:INFO:-------------Training local models-------------
2022-01-27 02:05:37:INFO:-------------Aggregating local models-------------
2022-01-27 02:05:40:INFO:-------------Round number: 5-------------
2022-01-27 02:05:40:INFO:-------------Sending models-------------
2022-01-27 02:05:40:INFO:-------------Evaluating models-------------
2022-01-27 02:05:40:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:05:40:INFO:Accuracy = [0.9373834265920596, 0.9166000532907008, 0.9622968292033041, 0.927124966693312, 0.9500399680255796, 0.9130029309885425, 0.968558486544098, 0.9381827871036504, 0.9219291233679723, 0.9412470023980816]
2022-01-27 02:05:40:INFO:Loss = [0.14403047655904075, 0.18562102014429185, 0.09018919340982454, 0.1919588698641719, 0.1090983321297829, 0.20537384575146753, 0.07325352249863587, 0.13231519922655538, 0.15621981843877306, 0.14046191016835965]
2022-01-27 02:05:40:INFO:-------------Training local models-------------
2022-01-27 02:09:47:INFO:-------------Aggregating local models-------------
2022-01-27 02:09:49:INFO:-------------Round number: 6-------------
2022-01-27 02:09:49:INFO:-------------Sending models-------------
2022-01-27 02:09:49:INFO:-------------Evaluating models-------------
2022-01-27 02:09:50:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:09:50:INFO:Accuracy = [0.9313882227551292, 0.9173994138022915, 0.9625632827071676, 0.9279243272049027, 0.9536370903277378, 0.9197974953370637, 0.968558486544098, 0.939115374367173, 0.924593658406608, 0.9517719158006928]
2022-01-27 02:09:50:INFO:Loss = [0.14144476506493162, 0.1780503999517611, 0.08530716676741426, 0.1877241121984668, 0.10422561076693554, 0.19578469972318008, 0.07079473579093795, 0.12826094251428055, 0.15618766688960678, 0.12915194619463372]
2022-01-27 02:09:50:INFO:-------------Training local models-------------
2022-01-27 02:13:57:INFO:-------------Aggregating local models-------------
2022-01-27 02:13:59:INFO:-------------Round number: 7-------------
2022-01-27 02:13:59:INFO:-------------Sending models-------------
2022-01-27 02:13:59:INFO:-------------Evaluating models-------------
2022-01-27 02:14:00:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:14:00:INFO:Accuracy = [0.9313882227551292, 0.9243272049027444, 0.964828137490008, 0.9281907807087664, 0.9549693578470557, 0.9233946176392219, 0.968558486544098, 0.9421795896616041, 0.926458832933653, 0.9555022648547828]
2022-01-27 02:14:00:INFO:Loss = [0.14013238974359182, 0.17163536649656363, 0.0818409267355278, 0.1833999028382224, 0.1014766281695329, 0.1873719690529438, 0.06915611405281655, 0.12459625311707917, 0.1553188818237649, 0.11953181447116158]
2022-01-27 02:14:00:INFO:-------------Training local models-------------
2022-01-27 02:18:06:INFO:-------------Aggregating local models-------------
2022-01-27 02:18:09:INFO:-------------Round number: 8-------------
2022-01-27 02:18:09:INFO:-------------Sending models-------------
2022-01-27 02:18:09:INFO:-------------Evaluating models-------------
2022-01-27 02:18:09:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:18:09:INFO:Accuracy = [0.9293898214761525, 0.9289901412203571, 0.9688249400479616, 0.9287236877164935, 0.955369038102851, 0.9240607513988809, 0.9697575273114841, 0.946576072475353, 0.9265920596855849, 0.95603517186251]
2022-01-27 02:18:09:INFO:Loss = [0.13960032401954756, 0.16561865017534655, 0.07897072280894234, 0.17879013649564152, 0.09934735035991946, 0.18086040015882063, 0.06777595721674289, 0.12087534000031758, 0.1552880537436117, 0.11274441437865211]
2022-01-27 02:18:09:INFO:-------------Training local models-------------
2022-01-27 02:22:16:INFO:-------------Aggregating local models-------------
2022-01-27 02:22:19:INFO:-------------Round number: 9-------------
2022-01-27 02:22:19:INFO:-------------Sending models-------------
2022-01-27 02:22:19:INFO:-------------Evaluating models-------------
2022-01-27 02:22:20:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:22:20:INFO:Accuracy = [0.930322408739675, 0.9309885424993338, 0.9702904343192112, 0.9316546762589928, 0.9561683986144418, 0.9267252864375166, 0.9709565680788702, 0.9528377298161471, 0.9269917399413802, 0.9567013056221689]
2022-01-27 02:22:20:INFO:Loss = [0.13872484585447933, 0.16022281123438697, 0.07639440421145445, 0.1739446499323196, 0.09735350098110301, 0.17582054425851035, 0.06653796840265425, 0.11705948680071242, 0.15620340565614085, 0.10726387479842923]
2022-01-27 02:22:20:INFO:-------------Training local models-------------
2022-01-27 02:24:44:INFO:-------------Aggregating local models-------------
2022-01-27 02:24:45:INFO:-------------Round number: 10-------------
2022-01-27 02:24:45:INFO:-------------Sending models-------------
2022-01-27 02:24:45:INFO:-------------Evaluating models-------------
2022-01-27 02:24:45:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:24:45:INFO:Accuracy = [0.9315214495070611, 0.934052757793765, 0.971089794830802, 0.9345856648014922, 0.9567013056221689, 0.9275246469491074, 0.9722888355981881, 0.9547029043431922, 0.9268585131894485, 0.9590993871569411]
2022-01-27 02:24:45:INFO:Loss = [0.13751381286023656, 0.15522962424145315, 0.07446365849918322, 0.1691994415500588, 0.09562313479456423, 0.1714854797704264, 0.06541002604013658, 0.1136844532549145, 0.15629361181329404, 0.10226580330099098]
2022-01-27 02:24:45:INFO:-------------Training local models-------------
2022-01-27 02:26:48:INFO:-------------Aggregating local models-------------
2022-01-27 02:26:49:INFO:-------------Round number: 11-------------
2022-01-27 02:26:49:INFO:-------------Sending models-------------
2022-01-27 02:26:49:INFO:-------------Evaluating models-------------
2022-01-27 02:26:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:26:49:INFO:Accuracy = [0.9320543565147882, 0.9356514788169464, 0.9708233413269385, 0.9349853450572875, 0.9573674393818279, 0.9292565947242206, 0.9730881961097788, 0.9569677591260325, 0.9276578737010391, 0.9628297362110312]
2022-01-27 02:26:49:INFO:Loss = [0.13676250973356274, 0.15048861170154773, 0.07308732835000561, 0.16457092593131092, 0.09428793735302655, 0.16779144028112178, 0.06435726427773487, 0.11089122844907727, 0.15545751878134909, 0.09736168616314807]
2022-01-27 02:26:49:INFO:-------------Training local models-------------
2022-01-27 02:28:52:INFO:-------------Aggregating local models-------------
2022-01-27 02:28:53:INFO:-------------Round number: 12-------------
2022-01-27 02:28:53:INFO:-------------Sending models-------------
2022-01-27 02:28:53:INFO:-------------Evaluating models-------------
2022-01-27 02:28:53:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:28:53:INFO:Accuracy = [0.9339195310418332, 0.9380495603517186, 0.9713562483346656, 0.9364508393285371, 0.957900346389555, 0.9316546762589928, 0.9730881961097788, 0.9576338928856915, 0.9297895017319477, 0.9662936317612577]
2022-01-27 02:28:53:INFO:Loss = [0.13594140324306261, 0.14643541059100415, 0.07198523171034733, 0.1599918020128074, 0.09308412375983079, 0.16486424054321902, 0.06335465465547695, 0.10854650523747814, 0.15389785319206437, 0.09339724655975779]
2022-01-27 02:28:53:INFO:-------------Training local models-------------
2022-01-27 02:30:56:INFO:-------------Aggregating local models-------------
2022-01-27 02:30:57:INFO:-------------Round number: 13-------------
2022-01-27 02:30:57:INFO:-------------Sending models-------------
2022-01-27 02:30:57:INFO:-------------Evaluating models-------------
2022-01-27 02:30:57:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:30:57:INFO:Accuracy = [0.9337863042899014, 0.9408473221422862, 0.9721556088462563, 0.9385824673594457, 0.9586997069011457, 0.9315214495070611, 0.9740207833733013, 0.9592326139088729, 0.9316546762589928, 0.9672262190247801]
2022-01-27 02:30:57:INFO:Loss = [0.1363414259322511, 0.1428331268926466, 0.07105504237467607, 0.1555256048791497, 0.09198607978685043, 0.16288720394471423, 0.062373503200824465, 0.10654093101386788, 0.15267313131634488, 0.08966229686070913]
2022-01-27 02:30:57:INFO:-------------Training local models-------------
2022-01-27 02:33:00:INFO:-------------Aggregating local models-------------
2022-01-27 02:33:01:INFO:-------------Round number: 14-------------
2022-01-27 02:33:01:INFO:-------------Sending models-------------
2022-01-27 02:33:01:INFO:-------------Evaluating models-------------
2022-01-27 02:33:01:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:33:01:INFO:Accuracy = [0.9344524380495604, 0.9423128164135358, 0.9728217426059153, 0.9405808686384226, 0.9596322941646682, 0.9323208100186517, 0.9742872368771649, 0.9600319744204636, 0.9324540367705836, 0.968558486544098]
2022-01-27 02:33:01:INFO:Loss = [0.136613508977512, 0.13985928708591328, 0.07026689860746071, 0.1513760040251403, 0.09097098127246286, 0.16178598450101608, 0.06143393810109539, 0.1047615024463174, 0.15154837478461686, 0.08645228392862629]
2022-01-27 02:33:01:INFO:-------------Training local models-------------
2022-01-27 02:35:04:INFO:-------------Aggregating local models-------------
2022-01-27 02:35:05:INFO:-------------Round number: 15-------------
2022-01-27 02:35:05:INFO:-------------Sending models-------------
2022-01-27 02:35:05:INFO:-------------Evaluating models-------------
2022-01-27 02:35:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:35:05:INFO:Accuracy = [0.9345856648014922, 0.9437783106847855, 0.9734878763655742, 0.9435118571809219, 0.9606981081801226, 0.9323208100186517, 0.9753530508926193, 0.9613642419397815, 0.9329869437783107, 0.9686917132960299]
2022-01-27 02:35:05:INFO:Loss = [0.13647096065922143, 0.13761780066972618, 0.06956987939033862, 0.14779872416623263, 0.09001269847511076, 0.1613868957949289, 0.06062158537685556, 0.10324148186482644, 0.1502079471663084, 0.08429945927770237]
2022-01-27 02:35:05:INFO:-------------Training local models-------------
2022-01-27 02:37:08:INFO:-------------Aggregating local models-------------
2022-01-27 02:37:09:INFO:-------------Round number: 16-------------
2022-01-27 02:37:09:INFO:-------------Sending models-------------
2022-01-27 02:37:09:INFO:-------------Evaluating models-------------
2022-01-27 02:37:09:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:37:09:INFO:Accuracy = [0.9349853450572875, 0.9451105782041034, 0.973621103117506, 0.9444444444444444, 0.9608313349320543, 0.9332533972821743, 0.9760191846522782, 0.9616306954436451, 0.9337863042899014, 0.9697575273114841]
2022-01-27 02:37:09:INFO:Loss = [0.13669667722018838, 0.13590964480026102, 0.06898711846642697, 0.14473521149243615, 0.0890907937423291, 0.16142361500415425, 0.05993156320254106, 0.102207370094895, 0.14967883801520968, 0.08237445990043807]
2022-01-27 02:37:09:INFO:-------------Training local models-------------
2022-01-27 02:39:12:INFO:-------------Aggregating local models-------------
2022-01-27 02:39:13:INFO:-------------Round number: 17-------------
2022-01-27 02:39:13:INFO:-------------Sending models-------------
2022-01-27 02:39:13:INFO:-------------Evaluating models-------------
2022-01-27 02:39:13:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:39:13:INFO:Accuracy = [0.9339195310418332, 0.9457767119637623, 0.9741540101252332, 0.9448441247002398, 0.9614974686917133, 0.9336530775379697, 0.9764188649080735, 0.9617639221955768, 0.935251798561151, 0.9705568878230749]
2022-01-27 02:39:13:INFO:Loss = [0.13755027002200398, 0.1345562988498656, 0.06855166252308056, 0.14213464976181642, 0.08822972359144168, 0.16156192196670438, 0.05927471744727052, 0.10122794333581775, 0.14924756353884572, 0.08086619296534867]
2022-01-27 02:39:13:INFO:-------------Training local models-------------
2022-01-27 02:41:16:INFO:-------------Aggregating local models-------------
2022-01-27 02:41:17:INFO:-------------Round number: 18-------------
2022-01-27 02:41:17:INFO:-------------Sending models-------------
2022-01-27 02:41:17:INFO:-------------Evaluating models-------------
2022-01-27 02:41:17:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:41:17:INFO:Accuracy = [0.934052757793765, 0.946576072475353, 0.9742872368771649, 0.9448441247002398, 0.9624300559552358, 0.9348521183053558, 0.9768185451638689, 0.9624300559552358, 0.936584066080469, 0.9713562483346656]
2022-01-27 02:41:17:INFO:Loss = [0.13803119394058003, 0.13346246788279617, 0.06810577311141436, 0.1399500597359082, 0.08745826318332463, 0.16156614714738812, 0.058716252397086624, 0.10024677899374022, 0.1482967699379221, 0.0795361334564758]
2022-01-27 02:41:17:INFO:-------------Training local models-------------
2022-01-27 02:43:20:INFO:-------------Aggregating local models-------------
2022-01-27 02:43:21:INFO:-------------Round number: 19-------------
2022-01-27 02:43:21:INFO:-------------Sending models-------------
2022-01-27 02:43:21:INFO:-------------Evaluating models-------------
2022-01-27 02:43:21:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:43:21:INFO:Accuracy = [0.9345856648014922, 0.9481747934985345, 0.9750865973887557, 0.9457767119637623, 0.9628297362110312, 0.9344524380495604, 0.9768185451638689, 0.9632294164668266, 0.9380495603517186, 0.9712230215827338]
2022-01-27 02:43:21:INFO:Loss = [0.13821539529693547, 0.13252805156245734, 0.06779232860556428, 0.13829196608363542, 0.08678242806647585, 0.16195465177309068, 0.058206431763982124, 0.09966538331769076, 0.14711576675308688, 0.078669551488687]
2022-01-27 02:43:21:INFO:-------------Training local models-------------
2022-01-27 02:45:24:INFO:-------------Aggregating local models-------------
2022-01-27 02:45:25:INFO:-------------Round number: 20-------------
2022-01-27 02:45:25:INFO:-------------Sending models-------------
2022-01-27 02:45:25:INFO:-------------Evaluating models-------------
2022-01-27 02:45:25:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:45:25:INFO:Accuracy = [0.9356514788169464, 0.9487077005062616, 0.975486277644551, 0.9461763922195577, 0.9632294164668266, 0.9332533972821743, 0.9772182254196643, 0.9633626432187583, 0.9388489208633094, 0.9718891553423927]
2022-01-27 02:45:25:INFO:Loss = [0.13871570038142056, 0.1317389883035528, 0.06767731424147994, 0.13683487673966116, 0.08620631373617849, 0.16241723948591338, 0.05778473863933327, 0.09910569510650499, 0.14664815415481783, 0.0779771374741054]
2022-01-27 02:45:25:INFO:-------------Training local models-------------
2022-01-27 02:47:28:INFO:-------------Aggregating local models-------------
2022-01-27 02:47:29:INFO:-------------Round number: 21-------------
2022-01-27 02:47:29:INFO:-------------Sending models-------------
2022-01-27 02:47:29:INFO:-------------Evaluating models-------------
2022-01-27 02:47:29:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:47:29:INFO:Accuracy = [0.9361843858246736, 0.949107380762057, 0.9760191846522782, 0.9469757527311484, 0.9632294164668266, 0.9336530775379697, 0.9772182254196643, 0.9642952304822808, 0.9397815081268319, 0.9716227018385292]
2022-01-27 02:47:29:INFO:Loss = [0.13862844179406356, 0.13130791758973237, 0.06754543749419384, 0.13553531596179264, 0.08560611339425254, 0.16372477385685202, 0.05730998119959507, 0.09885812455234111, 0.14562096429861393, 0.07765035094865724]
2022-01-27 02:47:29:INFO:-------------Training local models-------------
2022-01-27 02:49:32:INFO:-------------Aggregating local models-------------
2022-01-27 02:49:33:INFO:-------------Round number: 22-------------
2022-01-27 02:49:33:INFO:-------------Sending models-------------
2022-01-27 02:49:33:INFO:-------------Evaluating models-------------
2022-01-27 02:49:33:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:49:33:INFO:Accuracy = [0.938449240607514, 0.9500399680255796, 0.9762856381561418, 0.947242206235012, 0.9636290967226219, 0.9339195310418332, 0.977351452171596, 0.9645616839861444, 0.9404476418864908, 0.9720223820943246]
2022-01-27 02:49:33:INFO:Loss = [0.13787301233263746, 0.13118527084146203, 0.06752906908935452, 0.134397712638702, 0.08493600189061287, 0.16455886419767513, 0.05691021736182308, 0.09874498438469344, 0.14508606495999574, 0.0774313378367754]
2022-01-27 02:49:33:INFO:-------------Training local models-------------
2022-01-27 02:51:36:INFO:-------------Aggregating local models-------------
2022-01-27 02:51:37:INFO:-------------Round number: 23-------------
2022-01-27 02:51:37:INFO:-------------Sending models-------------
2022-01-27 02:51:37:INFO:-------------Evaluating models-------------
2022-01-27 02:51:37:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:51:37:INFO:Accuracy = [0.939115374367173, 0.9505728750333067, 0.9758859579003464, 0.9487077005062616, 0.9640287769784173, 0.9331201705302424, 0.9777511324273914, 0.9653610444977352, 0.9419131361577405, 0.9724220623501199]
2022-01-27 02:51:37:INFO:Loss = [0.13715601550441944, 0.13112256837892408, 0.0674811764743139, 0.133391161843745, 0.08442851443179708, 0.16582312220435186, 0.05643272812171518, 0.09855910802001558, 0.14527077808766375, 0.07728356824560756]
2022-01-27 02:51:37:INFO:-------------Training local models-------------
2022-01-27 02:53:40:INFO:-------------Aggregating local models-------------
2022-01-27 02:53:41:INFO:-------------Round number: 24-------------
2022-01-27 02:53:41:INFO:-------------Sending models-------------
2022-01-27 02:53:41:INFO:-------------Evaluating models-------------
2022-01-27 02:53:41:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:53:41:INFO:Accuracy = [0.9396482813749001, 0.9507061017852385, 0.9757527311484147, 0.9484412470023981, 0.9641620037303491, 0.9324540367705836, 0.9778843591793233, 0.9654942712496669, 0.9424460431654677, 0.971755928590461]
2022-01-27 02:53:41:INFO:Loss = [0.13640845243162705, 0.13162086742351278, 0.06745573344605599, 0.13280476710002218, 0.08387906595430317, 0.1675757300425223, 0.05604822638564081, 0.09861007098247666, 0.14550519883449375, 0.07730389810590628]
2022-01-27 02:53:41:INFO:-------------Training local models-------------
2022-01-27 02:55:43:INFO:-------------Aggregating local models-------------
2022-01-27 02:55:44:INFO:-------------Round number: 25-------------
2022-01-27 02:55:44:INFO:-------------Sending models-------------
2022-01-27 02:55:45:INFO:-------------Evaluating models-------------
2022-01-27 02:55:45:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:55:45:INFO:Accuracy = [0.9413802291500133, 0.9509725552891021, 0.975486277644551, 0.949107380762057, 0.964828137490008, 0.9315214495070611, 0.9782840394351185, 0.9650945909938715, 0.9429789501731948, 0.9716227018385292]
2022-01-27 02:55:45:INFO:Loss = [0.13553933950004185, 0.13240471591823022, 0.06748213990074771, 0.1320825016206555, 0.08325681488138094, 0.1700164452390899, 0.05563224745134353, 0.09880343688565577, 0.14555928743537178, 0.07735740084556826]
2022-01-27 02:55:45:INFO:-------------Training local models-------------
2022-01-27 02:57:47:INFO:-------------Aggregating local models-------------
2022-01-27 02:57:48:INFO:-------------Round number: 26-------------
2022-01-27 02:57:48:INFO:-------------Sending models-------------
2022-01-27 02:57:48:INFO:-------------Evaluating models-------------
2022-01-27 02:57:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:57:49:INFO:Accuracy = [0.9417799094058087, 0.9500399680255796, 0.9760191846522782, 0.9501731947775113, 0.9649613642419398, 0.9311217692512657, 0.9792166266986411, 0.9649613642419398, 0.9432454036770583, 0.9714894750865974]
2022-01-27 02:57:49:INFO:Loss = [0.13512774024848406, 0.13348061996558178, 0.0675953140000612, 0.13162773333016112, 0.0827115267523705, 0.17199964453262828, 0.0552552385582843, 0.09918644040829581, 0.14725737637709846, 0.07767718397195708]
2022-01-27 02:57:49:INFO:-------------Training local models-------------
2022-01-27 02:59:51:INFO:-------------Aggregating local models-------------
2022-01-27 02:59:52:INFO:-------------Round number: 27-------------
2022-01-27 02:59:52:INFO:-------------Sending models-------------
2022-01-27 02:59:52:INFO:-------------Evaluating models-------------
2022-01-27 02:59:53:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:59:53:INFO:Accuracy = [0.9420463629096723, 0.949773514521716, 0.9762856381561418, 0.9503064215294431, 0.9654942712496669, 0.9313882227551292, 0.9793498534505729, 0.9649613642419398, 0.9433786304289902, 0.9714894750865974]
2022-01-27 02:59:53:INFO:Loss = [0.13535526428479414, 0.13462365541478047, 0.0677568042959918, 0.13133216245556673, 0.08221878153551766, 0.1745443369859181, 0.05484087550624545, 0.09967923287663459, 0.1499048650696377, 0.07828027789058718]
2022-01-27 02:59:53:INFO:-------------Training local models-------------
2022-01-27 03:01:55:INFO:-------------Aggregating local models-------------
2022-01-27 03:01:56:INFO:-------------Round number: 28-------------
2022-01-27 03:01:56:INFO:-------------Sending models-------------
2022-01-27 03:01:56:INFO:-------------Evaluating models-------------
2022-01-27 03:01:57:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 03:01:57:INFO:Accuracy = [0.9433786304289902, 0.9496402877697842, 0.9762856381561418, 0.9505728750333067, 0.9653610444977352, 0.9309885424993338, 0.9796163069544365, 0.9646949107380762, 0.9433786304289902, 0.9712230215827338]
2022-01-27 03:01:57:INFO:Loss = [0.13566886806584835, 0.1362851224048599, 0.0679960523322238, 0.1311190375976361, 0.08178075233199442, 0.17691134117942792, 0.05447956438897974, 0.10024356439267615, 0.1528233034218016, 0.07906282904963328]
2022-01-27 03:01:57:INFO:-------------Training local models-------------
2022-01-27 03:03:59:INFO:-------------Aggregating local models-------------
2022-01-27 03:04:00:INFO:-------------Round number: 29-------------
2022-01-27 03:04:00:INFO:-------------Sending models-------------
2022-01-27 03:04:00:INFO:-------------Evaluating models-------------
2022-01-27 03:04:00:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 03:04:00:INFO:Accuracy = [0.9441779909405809, 0.9495070610178524, 0.9762856381561418, 0.9508393285371702, 0.966027178257394, 0.9307220889954703, 0.9798827604583, 0.9645616839861444, 0.9437783106847855, 0.9702904343192112]
2022-01-27 03:04:00:INFO:Loss = [0.1355248921700176, 0.13778888803142214, 0.06824684263489611, 0.13086363192337588, 0.08144657182323513, 0.17957296934071124, 0.05413276763389888, 0.10090347073754803, 0.15535985520372383, 0.07955636910126791]
2022-01-27 03:04:00:INFO:-------------Training local models-------------
2022-01-27 03:06:03:INFO:-------------Aggregating local models-------------
