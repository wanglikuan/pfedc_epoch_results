2022-01-25 12:19:40:INFO:-------------Round number: 0-------------
2022-01-25 12:19:40:INFO:-------------Sending models-------------
2022-01-25 12:19:40:INFO:-------------Evaluating models-------------
2022-01-25 12:19:41:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:19:41:INFO:Accuracy = [0.8909090909090909, 0.9545454545454546, 0.9, 0.9090909090909091, 0.8818181818181818, 0.1, 0.09090909090909091, 0.12727272727272726, 0.08181818181818182, 0.8636363636363636]
2022-01-25 12:19:41:INFO:Loss = [0.6607828552072699, 0.6483499537814748, 0.6659317932345651, 0.6574403367259286, 0.6621757144277746, 0.7392762736840681, 0.7426794252612374, 0.7391448904167522, 0.7449987904591994, 0.6712419098073786]
2022-01-25 12:19:41:INFO:-------------Training local models-------------
2022-01-25 12:23:32:INFO:-------------Aggregating local models-------------
2022-01-25 12:23:33:INFO:-------------Round number: 1-------------
2022-01-25 12:23:33:INFO:-------------Sending models-------------
2022-01-25 12:23:33:INFO:-------------Evaluating models-------------
2022-01-25 12:23:33:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:23:33:INFO:Accuracy = [0.8179545454545455, 0.9270454545454545, 0.8554545454545455, 0.8818181818181818, 0.8202272727272727, 0.8959090909090909, 0.8820454545454546, 0.8352272727272727, 0.9022727272727272, 0.7815909090909091]
2022-01-25 12:23:33:INFO:Loss = [0.48338367193513976, 0.33657588208602235, 0.4311172530393709, 0.3759153884242881, 0.47775768172842537, 0.3431142828511921, 0.38105795022777533, 0.5640459929000248, 0.3340487142770805, 0.46594665903936733]
2022-01-25 12:23:33:INFO:-------------Training local models-------------
2022-01-25 12:27:25:INFO:-------------Aggregating local models-------------
2022-01-25 12:27:26:INFO:-------------Round number: 2-------------
2022-01-25 12:27:26:INFO:-------------Sending models-------------
2022-01-25 12:27:26:INFO:-------------Evaluating models-------------
2022-01-25 12:27:26:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:27:26:INFO:Accuracy = [0.8181818181818182, 0.9272727272727272, 0.86, 0.8911363636363636, 0.8272727272727273, 0.9093181818181818, 0.8534090909090909, 0.8454545454545455, 0.9131818181818182, 0.7906818181818182]
2022-01-25 12:27:26:INFO:Loss = [0.4933555256829343, 0.2912166565910659, 0.41677151779559524, 0.3283984732856466, 0.477835612655194, 0.3216169950975613, 0.36599278265017676, 0.5878438975069333, 0.30107355686539616, 0.44809280054813083]
2022-01-25 12:27:26:INFO:-------------Training local models-------------
2022-01-25 12:31:18:INFO:-------------Aggregating local models-------------
2022-01-25 12:31:19:INFO:-------------Round number: 3-------------
2022-01-25 12:31:19:INFO:-------------Sending models-------------
2022-01-25 12:31:19:INFO:-------------Evaluating models-------------
2022-01-25 12:31:19:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:31:19:INFO:Accuracy = [0.8181818181818182, 0.9272727272727272, 0.8638636363636364, 0.9015909090909091, 0.8309090909090909, 0.9111363636363636, 0.8538636363636364, 0.8454545454545455, 0.9095454545454545, 0.7943181818181818]
2022-01-25 12:31:19:INFO:Loss = [0.4883813879907724, 0.2726314995564859, 0.400642501461235, 0.30327309941110964, 0.4664013378237459, 0.3173062358474867, 0.367604712811722, 0.5991318626075306, 0.28782257999674504, 0.44064256038347427]
2022-01-25 12:31:19:INFO:-------------Training local models-------------
2022-01-25 12:35:11:INFO:-------------Aggregating local models-------------
2022-01-25 12:35:12:INFO:-------------Round number: 4-------------
2022-01-25 12:35:12:INFO:-------------Sending models-------------
2022-01-25 12:35:12:INFO:-------------Evaluating models-------------
2022-01-25 12:35:12:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:35:12:INFO:Accuracy = [0.8193181818181818, 0.93, 0.865909090909091, 0.9043181818181818, 0.8327272727272728, 0.9115909090909091, 0.8556818181818182, 0.8454545454545455, 0.9084090909090909, 0.8027272727272727]
2022-01-25 12:35:12:INFO:Loss = [0.48265118435639043, 0.26261002925139937, 0.38570006414824587, 0.2882457237796519, 0.45605212372664194, 0.31708561078306624, 0.3721767253940925, 0.6056363168363036, 0.27987655662529337, 0.4330222510013052]
2022-01-25 12:35:12:INFO:-------------Training local models-------------
2022-01-25 12:39:04:INFO:-------------Aggregating local models-------------
2022-01-25 12:39:05:INFO:-------------Round number: 5-------------
2022-01-25 12:39:05:INFO:-------------Sending models-------------
2022-01-25 12:39:05:INFO:-------------Evaluating models-------------
2022-01-25 12:39:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:39:05:INFO:Accuracy = [0.8227272727272728, 0.9334090909090909, 0.8697727272727273, 0.9065909090909091, 0.8331818181818181, 0.9147727272727273, 0.8575, 0.8454545454545455, 0.9084090909090909, 0.8104545454545454]
2022-01-25 12:39:05:INFO:Loss = [0.47751437953186476, 0.2569823105332696, 0.37393126192460346, 0.27898464798292316, 0.4474496099219488, 0.31831798042932696, 0.37651331701146606, 0.6096794739069248, 0.27371669712857427, 0.4260575629834255]
2022-01-25 12:39:05:INFO:-------------Training local models-------------
2022-01-25 12:42:57:INFO:-------------Aggregating local models-------------
2022-01-25 12:42:58:INFO:-------------Round number: 6-------------
2022-01-25 12:42:58:INFO:-------------Sending models-------------
2022-01-25 12:42:58:INFO:-------------Evaluating models-------------
2022-01-25 12:42:58:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:42:58:INFO:Accuracy = [0.8277272727272728, 0.9345454545454546, 0.8786363636363637, 0.9070454545454546, 0.8345454545454546, 0.9152272727272728, 0.8602272727272727, 0.8454545454545455, 0.9104545454545454, 0.8145454545454546]
2022-01-25 12:42:58:INFO:Loss = [0.4730805735992776, 0.2530324801188809, 0.3651994092432274, 0.2728290208096785, 0.4402144609304907, 0.3198540652763437, 0.37944723250005735, 0.6117489384635436, 0.2686530261369295, 0.4203436048383909]
2022-01-25 12:42:58:INFO:-------------Training local models-------------
2022-01-25 12:46:46:INFO:-------------Aggregating local models-------------
2022-01-25 12:46:47:INFO:-------------Round number: 7-------------
2022-01-25 12:46:47:INFO:-------------Sending models-------------
2022-01-25 12:46:47:INFO:-------------Evaluating models-------------
2022-01-25 12:46:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:46:47:INFO:Accuracy = [0.8338636363636364, 0.9361363636363637, 0.8836363636363637, 0.9043181818181818, 0.8379545454545455, 0.915, 0.8636363636363636, 0.845, 0.9125, 0.8179545454545455]
2022-01-25 12:46:47:INFO:Loss = [0.4691053825462322, 0.24933568789856508, 0.35879655716919595, 0.2683163716002706, 0.4339433182745283, 0.32121986472047864, 0.3810577159927396, 0.6122599727273073, 0.26442165391583167, 0.41648158719339834]
2022-01-25 12:46:47:INFO:-------------Training local models-------------
2022-01-25 12:50:35:INFO:-------------Aggregating local models-------------
2022-01-25 12:50:36:INFO:-------------Round number: 8-------------
2022-01-25 12:50:36:INFO:-------------Sending models-------------
2022-01-25 12:50:36:INFO:-------------Evaluating models-------------
2022-01-25 12:50:36:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:50:36:INFO:Accuracy = [0.8361363636363637, 0.9375, 0.8879545454545454, 0.9038636363636363, 0.84, 0.915, 0.8670454545454546, 0.8456818181818182, 0.9140909090909091, 0.8240909090909091]
2022-01-25 12:50:36:INFO:Loss = [0.46542734739539976, 0.24541936289116908, 0.3539360774384642, 0.2647829922064292, 0.42827232766007495, 0.3223159393856556, 0.381224953497506, 0.6115062205692414, 0.2609281734219456, 0.4142673155472783]
2022-01-25 12:50:36:INFO:-------------Training local models-------------
2022-01-25 12:54:24:INFO:-------------Aggregating local models-------------
2022-01-25 12:54:25:INFO:-------------Round number: 9-------------
2022-01-25 12:54:25:INFO:-------------Sending models-------------
2022-01-25 12:54:25:INFO:-------------Evaluating models-------------
2022-01-25 12:54:25:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:54:25:INFO:Accuracy = [0.8413636363636363, 0.9384090909090909, 0.8909090909090909, 0.9036363636363637, 0.8420454545454545, 0.9154545454545454, 0.8704545454545455, 0.8468181818181818, 0.9168181818181819, 0.8281818181818181]
2022-01-25 12:54:25:INFO:Loss = [0.46207477806707503, 0.2415514899269593, 0.35008703158448706, 0.2620419959331312, 0.4230385856475385, 0.3230457578817467, 0.3802206541379829, 0.6101063768104227, 0.2581520651541227, 0.41316563248824834]
2022-01-25 12:54:25:INFO:-------------Training local models-------------
2022-01-25 12:58:13:INFO:-------------Aggregating local models-------------
2022-01-25 12:58:14:INFO:-------------Round number: 10-------------
2022-01-25 12:58:14:INFO:-------------Sending models-------------
2022-01-25 12:58:14:INFO:-------------Evaluating models-------------
2022-01-25 12:58:14:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:58:14:INFO:Accuracy = [0.845, 0.9388636363636363, 0.894090909090909, 0.9038636363636363, 0.8468181818181818, 0.9147727272727273, 0.8743181818181818, 0.8497727272727272, 0.9211363636363636, 0.8331818181818181]
2022-01-25 12:58:14:INFO:Loss = [0.45916202037637543, 0.23782180377642032, 0.34684783943124453, 0.26008472553856504, 0.4182576852548994, 0.3235204064826989, 0.37820311830569564, 0.608671012151436, 0.25604504614761525, 0.41269384502031076]
2022-01-25 12:58:14:INFO:-------------Training local models-------------
2022-01-25 13:02:02:INFO:-------------Aggregating local models-------------
2022-01-25 13:02:03:INFO:-------------Round number: 11-------------
2022-01-25 13:02:03:INFO:-------------Sending models-------------
2022-01-25 13:02:03:INFO:-------------Evaluating models-------------
2022-01-25 13:02:03:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:02:03:INFO:Accuracy = [0.8477272727272728, 0.9390909090909091, 0.8963636363636364, 0.9040909090909091, 0.8488636363636364, 0.9140909090909091, 0.8765909090909091, 0.8547727272727272, 0.9229545454545455, 0.8359090909090909]
2022-01-25 13:02:03:INFO:Loss = [0.45698198126417333, 0.23445131890158252, 0.34405087017274294, 0.25906130743202416, 0.413918913728875, 0.3237771792591295, 0.37564878382466055, 0.6079549434965222, 0.25467048291254535, 0.41256979369367897]
2022-01-25 13:02:03:INFO:-------------Training local models-------------
2022-01-25 13:05:51:INFO:-------------Aggregating local models-------------
2022-01-25 13:05:52:INFO:-------------Round number: 12-------------
2022-01-25 13:05:52:INFO:-------------Sending models-------------
2022-01-25 13:05:52:INFO:-------------Evaluating models-------------
2022-01-25 13:05:52:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:05:52:INFO:Accuracy = [0.8495454545454545, 0.9395454545454546, 0.9, 0.9043181818181818, 0.8506818181818182, 0.9154545454545454, 0.8784090909090909, 0.8572727272727273, 0.9268181818181818, 0.8381818181818181]
2022-01-25 13:05:52:INFO:Loss = [0.45501492567577356, 0.23125557394497182, 0.3415291081362573, 0.2585579394653905, 0.41020574302687735, 0.32382593271745874, 0.3727554389857687, 0.607476978080707, 0.25358904967222107, 0.41266458762746133]
2022-01-25 13:05:52:INFO:-------------Training local models-------------
2022-01-25 13:09:40:INFO:-------------Aggregating local models-------------
2022-01-25 13:09:41:INFO:-------------Round number: 13-------------
2022-01-25 13:09:41:INFO:-------------Sending models-------------
2022-01-25 13:09:41:INFO:-------------Evaluating models-------------
2022-01-25 13:09:41:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:09:41:INFO:Accuracy = [0.8502272727272727, 0.94, 0.9020454545454546, 0.9027272727272727, 0.8527272727272728, 0.9154545454545454, 0.8815909090909091, 0.8602272727272727, 0.9288636363636363, 0.84]
2022-01-25 13:09:41:INFO:Loss = [0.45340433380571826, 0.22822013055397705, 0.33915531322021375, 0.25846782694941134, 0.40697028244559824, 0.32376266387397085, 0.3699900006245695, 0.6072154766287315, 0.25283230223206127, 0.41281727118290623]
2022-01-25 13:09:41:INFO:-------------Training local models-------------
2022-01-25 13:13:29:INFO:-------------Aggregating local models-------------
2022-01-25 13:13:30:INFO:-------------Round number: 14-------------
2022-01-25 13:13:30:INFO:-------------Sending models-------------
2022-01-25 13:13:30:INFO:-------------Evaluating models-------------
2022-01-25 13:13:31:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:13:31:INFO:Accuracy = [0.8522727272727273, 0.9402272727272727, 0.9031818181818182, 0.9022727272727272, 0.8531818181818182, 0.9161363636363636, 0.8820454545454546, 0.8629545454545454, 0.9297727272727273, 0.8418181818181818]
2022-01-25 13:13:31:INFO:Loss = [0.45209978490311187, 0.22538551714969798, 0.3369174440655942, 0.2587151208056391, 0.4040807488464369, 0.32361982794245703, 0.3676596372139598, 0.6072746100719086, 0.25243286760788497, 0.413102021857313]
2022-01-25 13:13:31:INFO:-------------Training local models-------------
2022-01-25 13:17:18:INFO:-------------Aggregating local models-------------
2022-01-25 13:17:19:INFO:-------------Round number: 15-------------
2022-01-25 13:17:19:INFO:-------------Sending models-------------
2022-01-25 13:17:20:INFO:-------------Evaluating models-------------
2022-01-25 13:17:20:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:17:20:INFO:Accuracy = [0.8529545454545454, 0.9406818181818182, 0.9036363636363637, 0.9045454545454545, 0.8540909090909091, 0.9177272727272727, 0.8843181818181818, 0.865, 0.9293181818181818, 0.8431818181818181]
2022-01-25 13:17:20:INFO:Loss = [0.4510791900223756, 0.22266306365596722, 0.33480909700103273, 0.2591774177160749, 0.4013924628607294, 0.3233842728611886, 0.3658753824626646, 0.6076181787087328, 0.25224338456967166, 0.4134365162335929]
2022-01-25 13:17:20:INFO:-------------Training local models-------------
2022-01-25 13:21:08:INFO:-------------Aggregating local models-------------
2022-01-25 13:21:09:INFO:-------------Round number: 16-------------
2022-01-25 13:21:09:INFO:-------------Sending models-------------
2022-01-25 13:21:09:INFO:-------------Evaluating models-------------
2022-01-25 13:21:09:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:21:09:INFO:Accuracy = [0.8538636363636364, 0.9411363636363637, 0.9043181818181818, 0.905, 0.8556818181818182, 0.9190909090909091, 0.8854545454545455, 0.8654545454545455, 0.9288636363636363, 0.8459090909090909]
2022-01-25 13:21:09:INFO:Loss = [0.4503949824159711, 0.22027917535319416, 0.3327809004435866, 0.259718935600937, 0.39891827574068556, 0.32317546338149855, 0.3646933060520413, 0.6080888272024988, 0.25222689928222364, 0.4137991471279582]
2022-01-25 13:21:09:INFO:-------------Training local models-------------
2022-01-25 13:24:57:INFO:-------------Aggregating local models-------------
2022-01-25 13:24:58:INFO:-------------Round number: 17-------------
2022-01-25 13:24:58:INFO:-------------Sending models-------------
2022-01-25 13:24:58:INFO:-------------Evaluating models-------------
2022-01-25 13:24:58:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:24:58:INFO:Accuracy = [0.8554545454545455, 0.9413636363636364, 0.9045454545454545, 0.9043181818181818, 0.8575, 0.92, 0.8863636363636364, 0.8661363636363636, 0.9279545454545455, 0.8479545454545454]
2022-01-25 13:24:58:INFO:Loss = [0.4500032450855625, 0.2180368558334356, 0.3308439456804825, 0.2602373033693187, 0.3965643993779932, 0.3229942226475528, 0.36406843569182623, 0.608610384546178, 0.2523563649124381, 0.4141311208220114]
2022-01-25 13:24:58:INFO:-------------Training local models-------------
2022-01-25 13:28:46:INFO:-------------Aggregating local models-------------
2022-01-25 13:28:47:INFO:-------------Round number: 18-------------
2022-01-25 13:28:47:INFO:-------------Sending models-------------
2022-01-25 13:28:47:INFO:-------------Evaluating models-------------
2022-01-25 13:28:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:28:47:INFO:Accuracy = [0.8552272727272727, 0.9418181818181818, 0.9047727272727273, 0.9036363636363637, 0.8586363636363636, 0.9195454545454546, 0.8868181818181818, 0.8670454545454546, 0.928409090909091, 0.85]
2022-01-25 13:28:47:INFO:Loss = [0.4497460062221349, 0.2159980278229341, 0.3290045754544818, 0.26068388229415923, 0.3943342327801722, 0.3228258455955339, 0.3638872862502467, 0.6091746438538063, 0.2526297945330787, 0.41452613621315154]
2022-01-25 13:28:47:INFO:-------------Training local models-------------
2022-01-25 13:32:35:INFO:-------------Aggregating local models-------------
2022-01-25 13:32:36:INFO:-------------Round number: 19-------------
2022-01-25 13:32:36:INFO:-------------Sending models-------------
2022-01-25 13:32:36:INFO:-------------Evaluating models-------------
2022-01-25 13:32:36:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:32:36:INFO:Accuracy = [0.8552272727272727, 0.9425, 0.9045454545454545, 0.9038636363636363, 0.8593181818181819, 0.9225, 0.8877272727272727, 0.8675, 0.9290909090909091, 0.8511363636363637]
2022-01-25 13:32:36:INFO:Loss = [0.4498696277314924, 0.2141621844184225, 0.327286399125693, 0.2610479216665474, 0.39227714112308937, 0.3226807105492546, 0.3640424390101213, 0.6097321373098318, 0.252924493827529, 0.41497238569638945]
2022-01-25 13:32:36:INFO:-------------Training local models-------------
2022-01-25 13:36:24:INFO:-------------Aggregating local models-------------
2022-01-25 13:36:25:INFO:-------------Round number: 20-------------
2022-01-25 13:36:25:INFO:-------------Sending models-------------
2022-01-25 13:36:25:INFO:-------------Evaluating models-------------
2022-01-25 13:36:25:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:36:25:INFO:Accuracy = [0.8554545454545455, 0.9425, 0.9052272727272728, 0.9034090909090909, 0.8618181818181818, 0.9238636363636363, 0.8888636363636364, 0.8686363636363637, 0.9293181818181818, 0.8522727272727273]
2022-01-25 13:36:25:INFO:Loss = [0.4502265841890635, 0.2124528348059605, 0.32567989582576873, 0.26141016096014275, 0.3902841733014529, 0.3225312573115595, 0.36438156713265923, 0.6102957743032179, 0.2532377683785109, 0.4154974777669519]
2022-01-25 13:36:25:INFO:-------------Training local models-------------
2022-01-25 13:40:13:INFO:-------------Aggregating local models-------------
2022-01-25 13:40:14:INFO:-------------Round number: 21-------------
2022-01-25 13:40:14:INFO:-------------Sending models-------------
2022-01-25 13:40:14:INFO:-------------Evaluating models-------------
2022-01-25 13:40:15:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:40:15:INFO:Accuracy = [0.855909090909091, 0.9415909090909091, 0.9056818181818181, 0.9043181818181818, 0.8622727272727273, 0.925, 0.8888636363636364, 0.8686363636363637, 0.9302272727272727, 0.8531818181818182]
2022-01-25 13:40:15:INFO:Loss = [0.4508084662986221, 0.21077624689179092, 0.32416630912709726, 0.2617010421691124, 0.38841755700863856, 0.3224503088885368, 0.36498701661184896, 0.6107450527443276, 0.2535217544354964, 0.4161553055746481]
2022-01-25 13:40:15:INFO:-------------Training local models-------------
2022-01-25 13:44:03:INFO:-------------Aggregating local models-------------
2022-01-25 13:44:04:INFO:-------------Round number: 22-------------
2022-01-25 13:44:04:INFO:-------------Sending models-------------
2022-01-25 13:44:04:INFO:-------------Evaluating models-------------
2022-01-25 13:44:04:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:44:04:INFO:Accuracy = [0.855909090909091, 0.9418181818181818, 0.9065909090909091, 0.9043181818181818, 0.8645454545454545, 0.9254545454545454, 0.8895454545454545, 0.8688636363636364, 0.9306818181818182, 0.8545454545454545]
2022-01-25 13:44:04:INFO:Loss = [0.45158744914541865, 0.20920343176588754, 0.3227272391771707, 0.26194927948712243, 0.38660543549657717, 0.32234267267419703, 0.36579407144454307, 0.611149432912035, 0.25384313688978594, 0.4168451809398407]
2022-01-25 13:44:04:INFO:-------------Training local models-------------
2022-01-25 13:47:52:INFO:-------------Aggregating local models-------------
2022-01-25 13:47:53:INFO:-------------Round number: 23-------------
2022-01-25 13:47:53:INFO:-------------Sending models-------------
2022-01-25 13:47:53:INFO:-------------Evaluating models-------------
2022-01-25 13:47:53:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:47:53:INFO:Accuracy = [0.855909090909091, 0.9420454545454545, 0.9075, 0.9043181818181818, 0.8654545454545455, 0.9268181818181818, 0.8895454545454545, 0.8695454545454545, 0.9306818181818182, 0.8556818181818182]
2022-01-25 13:47:53:INFO:Loss = [0.4525161676934328, 0.20782286834807812, 0.32134462816571946, 0.262234970549947, 0.38489276739948597, 0.3222248401847372, 0.3667509352007817, 0.6115084584704494, 0.25414048818400425, 0.4175891688077668]
2022-01-25 13:47:53:INFO:-------------Training local models-------------
2022-01-25 13:51:41:INFO:-------------Aggregating local models-------------
2022-01-25 13:51:42:INFO:-------------Round number: 24-------------
2022-01-25 13:51:42:INFO:-------------Sending models-------------
2022-01-25 13:51:42:INFO:-------------Evaluating models-------------
2022-01-25 13:51:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:51:42:INFO:Accuracy = [0.8563636363636363, 0.9418181818181818, 0.9077272727272727, 0.9036363636363637, 0.8675, 0.9275, 0.8897727272727273, 0.8702272727272727, 0.9313636363636364, 0.855909090909091]
2022-01-25 13:51:42:INFO:Loss = [0.45359551824459976, 0.20660762050617698, 0.3200345538860843, 0.2625325567343018, 0.38324250237651125, 0.32213041094311684, 0.3678135340292515, 0.6117463127447991, 0.25439118351152334, 0.41833047600600615]
2022-01-25 13:51:42:INFO:-------------Training local models-------------
2022-01-25 13:55:30:INFO:-------------Aggregating local models-------------
2022-01-25 13:55:31:INFO:-------------Round number: 25-------------
2022-01-25 13:55:31:INFO:-------------Sending models-------------
2022-01-25 13:55:31:INFO:-------------Evaluating models-------------
2022-01-25 13:55:31:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:55:31:INFO:Accuracy = [0.8568181818181818, 0.9418181818181818, 0.9075, 0.9036363636363637, 0.8688636363636364, 0.9277272727272727, 0.8895454545454545, 0.8706818181818182, 0.9306818181818182, 0.8570454545454546]
2022-01-25 13:55:31:INFO:Loss = [0.4548595210910373, 0.20522997224576434, 0.3187640048812186, 0.26280767459856264, 0.38167562058370097, 0.3218915941595862, 0.36889682218130804, 0.6118663515041011, 0.25454988288904795, 0.4190902607012752]
2022-01-25 13:55:31:INFO:-------------Training local models-------------
2022-01-25 13:59:19:INFO:-------------Aggregating local models-------------
2022-01-25 13:59:20:INFO:-------------Round number: 26-------------
2022-01-25 13:59:20:INFO:-------------Sending models-------------
2022-01-25 13:59:20:INFO:-------------Evaluating models-------------
2022-01-25 13:59:20:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:59:20:INFO:Accuracy = [0.8565909090909091, 0.9422727272727273, 0.9081818181818182, 0.9045454545454545, 0.8706818181818182, 0.9293181818181818, 0.8888636363636364, 0.8711363636363636, 0.9311363636363637, 0.8584090909090909]
2022-01-25 13:59:20:INFO:Loss = [0.4561073061343367, 0.20396672833726784, 0.31755552177994767, 0.26300177457848223, 0.3801930035932773, 0.3217442115303129, 0.3700768893330612, 0.6120103368003832, 0.2547781813180667, 0.4198400685561038]
2022-01-25 13:59:20:INFO:-------------Training local models-------------
2022-01-25 14:03:08:INFO:-------------Aggregating local models-------------
2022-01-25 14:03:09:INFO:-------------Round number: 27-------------
2022-01-25 14:03:09:INFO:-------------Sending models-------------
2022-01-25 14:03:09:INFO:-------------Evaluating models-------------
2022-01-25 14:03:09:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:03:09:INFO:Accuracy = [0.8565909090909091, 0.9427272727272727, 0.9084090909090909, 0.9052272727272728, 0.8725, 0.9295454545454546, 0.8893181818181818, 0.8713636363636363, 0.9311363636363637, 0.8595454545454545]
2022-01-25 14:03:09:INFO:Loss = [0.45744388601742686, 0.202749481133651, 0.3163980519716543, 0.26326552541312676, 0.3787025466627463, 0.3216736814901444, 0.37137367589483883, 0.6120841735426273, 0.25499819058618, 0.42054592467214785]
2022-01-25 14:03:09:INFO:-------------Training local models-------------
2022-01-25 14:06:57:INFO:-------------Aggregating local models-------------
2022-01-25 14:06:58:INFO:-------------Round number: 28-------------
2022-01-25 14:06:58:INFO:-------------Sending models-------------
2022-01-25 14:06:58:INFO:-------------Evaluating models-------------
2022-01-25 14:06:58:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:06:58:INFO:Accuracy = [0.8570454545454546, 0.9445454545454546, 0.9086363636363637, 0.9052272727272728, 0.8734090909090909, 0.9306818181818182, 0.8893181818181818, 0.8718181818181818, 0.9309090909090909, 0.8606818181818182]
2022-01-25 14:06:58:INFO:Loss = [0.4587330185017146, 0.20157440832117574, 0.3153154731654054, 0.2634424860941098, 0.37731962541716213, 0.32144385101802814, 0.3726447363405234, 0.6121793925711906, 0.2552438025505663, 0.42122107626928484]
2022-01-25 14:06:58:INFO:-------------Training local models-------------
2022-01-25 14:10:46:INFO:-------------Aggregating local models-------------
2022-01-25 14:10:47:INFO:-------------Round number: 29-------------
2022-01-25 14:10:47:INFO:-------------Sending models-------------
2022-01-25 14:10:47:INFO:-------------Evaluating models-------------
2022-01-25 14:10:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:10:47:INFO:Accuracy = [0.8565909090909091, 0.9447727272727273, 0.9081818181818182, 0.9052272727272728, 0.8745454545454545, 0.93, 0.889090909090909, 0.8725, 0.9311363636363637, 0.8622727272727273]
2022-01-25 14:10:47:INFO:Loss = [0.46019399328744676, 0.20038373598045753, 0.3143219068086844, 0.26348988961730024, 0.3761912373182978, 0.3213290302770805, 0.37405942978988277, 0.6123389269151217, 0.25541365963713775, 0.42194339817823756]
2022-01-25 14:10:47:INFO:-------------Training local models-------------
2022-01-25 14:14:35:INFO:-------------Aggregating local models-------------
2022-01-25 14:14:36:INFO:-------------Round number: 30-------------
2022-01-25 14:14:36:INFO:-------------Sending models-------------
2022-01-25 14:14:36:INFO:-------------Evaluating models-------------
2022-01-25 14:14:36:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:14:36:INFO:Accuracy = [0.855909090909091, 0.9454545454545454, 0.9090909090909091, 0.905, 0.8770454545454546, 0.93, 0.889090909090909, 0.8727272727272727, 0.9311363636363637, 0.8634090909090909]
2022-01-25 14:14:36:INFO:Loss = [0.4617452194426071, 0.19921138992014512, 0.31339665551587875, 0.26351530655916905, 0.3751068411688638, 0.321190612967687, 0.3754211094555847, 0.6124881207196846, 0.255639785737466, 0.4225755824244433]
2022-01-25 14:14:36:INFO:-------------Training local models-------------
2022-01-25 14:18:24:INFO:-------------Aggregating local models-------------
2022-01-25 14:18:25:INFO:-------------Round number: 31-------------
2022-01-25 14:18:25:INFO:-------------Sending models-------------
2022-01-25 14:18:25:INFO:-------------Evaluating models-------------
2022-01-25 14:18:26:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:18:26:INFO:Accuracy = [0.8556818181818182, 0.9459090909090909, 0.9097727272727273, 0.9047727272727273, 0.8772727272727273, 0.9297727272727273, 0.8893181818181818, 0.8727272727272727, 0.9309090909090909, 0.8645454545454545]
2022-01-25 14:18:26:INFO:Loss = [0.4632742308690054, 0.1980097163754346, 0.3124940836761115, 0.2635255794773746, 0.37413467973132025, 0.3209869587489679, 0.376769778672447, 0.6127481692825147, 0.2557924101094779, 0.42322621232094454]
2022-01-25 14:18:26:INFO:-------------Training local models-------------
2022-01-25 14:22:14:INFO:-------------Aggregating local models-------------
2022-01-25 14:22:15:INFO:-------------Round number: 32-------------
2022-01-25 14:22:15:INFO:-------------Sending models-------------
2022-01-25 14:22:15:INFO:-------------Evaluating models-------------
2022-01-25 14:22:15:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:22:15:INFO:Accuracy = [0.855, 0.946590909090909, 0.9097727272727273, 0.9052272727272728, 0.8784090909090909, 0.9290909090909091, 0.8897727272727273, 0.8729545454545454, 0.9309090909090909, 0.8652272727272727]
2022-01-25 14:22:15:INFO:Loss = [0.4649988512830036, 0.19695604860290503, 0.3116576664274114, 0.2636597873366554, 0.3730755069345998, 0.32070692665795586, 0.3780465060424335, 0.61315767296156, 0.25603994205197195, 0.42386972562394065]
2022-01-25 14:22:15:INFO:-------------Training local models-------------
2022-01-25 14:26:03:INFO:-------------Aggregating local models-------------
2022-01-25 14:26:04:INFO:-------------Round number: 33-------------
2022-01-25 14:26:04:INFO:-------------Sending models-------------
2022-01-25 14:26:04:INFO:-------------Evaluating models-------------
2022-01-25 14:26:04:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:26:04:INFO:Accuracy = [0.855, 0.946590909090909, 0.9095454545454545, 0.9052272727272728, 0.8802272727272727, 0.9290909090909091, 0.8904545454545455, 0.8731818181818182, 0.9306818181818182, 0.8668181818181818]
2022-01-25 14:26:04:INFO:Loss = [0.4666949641172488, 0.19592516944050492, 0.31084879639741053, 0.2636064168063141, 0.3722873354015808, 0.32026936807325745, 0.37924556249874347, 0.6134573082550725, 0.25616488394576165, 0.42447538446497424]
2022-01-25 14:26:04:INFO:-------------Training local models-------------
2022-01-25 14:29:52:INFO:-------------Aggregating local models-------------
2022-01-25 14:29:53:INFO:-------------Round number: 34-------------
2022-01-25 14:29:53:INFO:-------------Sending models-------------
2022-01-25 14:29:53:INFO:-------------Evaluating models-------------
2022-01-25 14:29:53:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:29:53:INFO:Accuracy = [0.8543181818181819, 0.9472727272727273, 0.9102272727272728, 0.9054545454545454, 0.8815909090909091, 0.9293181818181818, 0.8902272727272728, 0.8734090909090909, 0.9311363636363637, 0.8670454545454546]
2022-01-25 14:29:53:INFO:Loss = [0.46830918196250093, 0.19488670023459814, 0.31005373529465446, 0.2634772842809484, 0.3715584481762066, 0.31974213379646904, 0.3804329285329335, 0.6136744810408511, 0.25627760370605923, 0.425014010558053]
2022-01-25 14:29:53:INFO:-------------Training local models-------------
2022-01-25 14:33:41:INFO:-------------Aggregating local models-------------
2022-01-25 14:33:42:INFO:-------------Round number: 35-------------
2022-01-25 14:33:42:INFO:-------------Sending models-------------
2022-01-25 14:33:42:INFO:-------------Evaluating models-------------
2022-01-25 14:33:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:33:42:INFO:Accuracy = [0.8554545454545455, 0.9475, 0.9104545454545454, 0.9047727272727273, 0.8820454545454546, 0.9293181818181818, 0.8897727272727273, 0.8729545454545454, 0.9306818181818182, 0.8675]
2022-01-25 14:33:42:INFO:Loss = [0.4700673983670475, 0.19384497283555738, 0.30931015286001967, 0.2634241605899826, 0.37083239468867596, 0.31928083157637793, 0.38164226636211174, 0.6139436441833492, 0.25640423954438035, 0.4255421108156125]
2022-01-25 14:33:42:INFO:-------------Training local models-------------
2022-01-25 14:37:30:INFO:-------------Aggregating local models-------------
2022-01-25 14:37:31:INFO:-------------Round number: 36-------------
2022-01-25 14:37:31:INFO:-------------Sending models-------------
2022-01-25 14:37:32:INFO:-------------Evaluating models-------------
2022-01-25 14:37:32:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:37:32:INFO:Accuracy = [0.855, 0.9477272727272728, 0.9102272727272728, 0.905, 0.8818181818181818, 0.9286363636363636, 0.8897727272727273, 0.8731818181818182, 0.9306818181818182, 0.8690909090909091]
2022-01-25 14:37:32:INFO:Loss = [0.4719998147752697, 0.19279705605903555, 0.3086435937701026, 0.2633570186662837, 0.37031076090749016, 0.3189145545713307, 0.3828593495029385, 0.6143002936857308, 0.25647285391671837, 0.4259759878916983]
2022-01-25 14:37:32:INFO:-------------Training local models-------------
2022-01-25 14:41:20:INFO:-------------Aggregating local models-------------
2022-01-25 14:41:21:INFO:-------------Round number: 37-------------
2022-01-25 14:41:21:INFO:-------------Sending models-------------
2022-01-25 14:41:21:INFO:-------------Evaluating models-------------
2022-01-25 14:41:21:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:41:21:INFO:Accuracy = [0.8556818181818182, 0.9479545454545455, 0.9111363636363636, 0.9056818181818181, 0.8825, 0.9288636363636363, 0.8895454545454545, 0.8738636363636364, 0.9309090909090909, 0.8697727272727273]
2022-01-25 14:41:21:INFO:Loss = [0.4738019354658635, 0.19180655602500668, 0.30798756231948077, 0.2632739441396552, 0.3697836167769062, 0.31846169527403123, 0.38408464218346955, 0.6146033696224383, 0.25655899931496773, 0.42642656421601055]
2022-01-25 14:41:21:INFO:-------------Training local models-------------
2022-01-25 14:45:09:INFO:-------------Aggregating local models-------------
2022-01-25 14:45:10:INFO:-------------Round number: 38-------------
2022-01-25 14:45:10:INFO:-------------Sending models-------------
2022-01-25 14:45:10:INFO:-------------Evaluating models-------------
2022-01-25 14:45:10:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:45:10:INFO:Accuracy = [0.8554545454545455, 0.9481818181818182, 0.9115909090909091, 0.9065909090909091, 0.8831818181818182, 0.9286363636363636, 0.8895454545454545, 0.8747727272727273, 0.9311363636363637, 0.87]
2022-01-25 14:45:10:INFO:Loss = [0.47578542518035233, 0.19087884689705045, 0.30735807070027066, 0.26324803172941424, 0.36926008493755946, 0.318053053131073, 0.38526598563846415, 0.614958164472641, 0.2566668059280015, 0.42687725478820293]
2022-01-25 14:45:10:INFO:-------------Training local models-------------
2022-01-25 14:48:58:INFO:-------------Aggregating local models-------------
2022-01-25 14:48:59:INFO:-------------Round number: 39-------------
2022-01-25 14:48:59:INFO:-------------Sending models-------------
2022-01-25 14:48:59:INFO:-------------Evaluating models-------------
2022-01-25 14:48:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:48:59:INFO:Accuracy = [0.855, 0.9484090909090909, 0.9115909090909091, 0.9065909090909091, 0.884090909090909, 0.9288636363636363, 0.8897727272727273, 0.8747727272727273, 0.9315909090909091, 0.8697727272727273]
2022-01-25 14:48:59:INFO:Loss = [0.4776539901469898, 0.1899763856976113, 0.30675482493415157, 0.2631457565565308, 0.3688130526075838, 0.3176660558169136, 0.3864590951990315, 0.6152332366751083, 0.2567850577129072, 0.42723390397467564]
2022-01-25 14:48:59:INFO:-------------Training local models-------------
2022-01-25 14:52:47:INFO:-------------Aggregating local models-------------
