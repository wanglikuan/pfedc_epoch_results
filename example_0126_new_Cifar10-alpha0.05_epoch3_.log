2022-01-26 19:41:54:INFO:-------------Round number: 0-------------
2022-01-26 19:41:54:INFO:-------------Sending models-------------
2022-01-26 19:41:54:INFO:-------------Evaluating models-------------
2022-01-26 19:41:54:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 19:41:54:INFO:Accuracy = [0.8991803824881722, 0.1003531685213567, 0.09842073698940494, 0.10081961751182782, 0.8763910175251549, 0.8853201839141733, 0.10028653295128939, 0.09975344839075098, 0.8991137469181049, 0.9005797294595855]
2022-01-26 19:41:54:INFO:Loss = [0.665735710753093, 0.7252041155432307, 0.7190054141443257, 0.7331072797684394, 0.6908852116902903, 0.6900398628600649, 0.7395282456087956, 0.703250268981245, 0.6848465939734868, 0.6383577395964568]
2022-01-26 19:41:54:INFO:-------------Training local models-------------
2022-01-26 19:44:23:INFO:-------------Aggregating local models-------------
2022-01-26 19:44:24:INFO:-------------Round number: 1-------------
2022-01-26 19:44:24:INFO:-------------Sending models-------------
2022-01-26 19:44:25:INFO:-------------Evaluating models-------------
2022-01-26 19:44:25:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 19:44:25:INFO:Accuracy = [0.9908709269007796, 0.9524888385420137, 0.9478243486373026, 0.9474911707869661, 0.983674285333511, 0.9622176317718398, 0.954754447924302, 0.9930032651429332, 0.9774771773172519, 0.9544212700739655]
2022-01-26 19:44:25:INFO:Loss = [0.06815458416540734, 0.14918986406299414, 0.15138829926189828, 0.12518940348823068, 0.09064044470650508, 0.11161435794808502, 0.12511582413567038, 0.057312237187247435, 0.09696723078425641, 0.12774819856641875]
2022-01-26 19:44:25:INFO:-------------Training local models-------------
2022-01-26 19:46:54:INFO:-------------Aggregating local models-------------
2022-01-26 19:46:55:INFO:-------------Round number: 2-------------
2022-01-26 19:46:55:INFO:-------------Sending models-------------
2022-01-26 19:46:56:INFO:-------------Evaluating models-------------
2022-01-26 19:46:56:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 19:46:56:INFO:Accuracy = [0.9908709269007796, 0.9570200573065902, 0.949023788898514, 0.9550876257746385, 0.9841407343239822, 0.9652162324248684, 0.9592856666888785, 0.9973345771973079, 0.9780102618777904, 0.9544212700739655]
2022-01-26 19:46:56:INFO:Loss = [0.04327850290514867, 0.1162342246913029, 0.12562030368964305, 0.09397377657451847, 0.06279699428055041, 0.08217575322848304, 0.09582838694258239, 0.024784849236775847, 0.06832758498741237, 0.09865154611488737]
2022-01-26 19:46:56:INFO:-------------Training local models-------------
2022-01-26 19:51:40:INFO:-------------Aggregating local models-------------
2022-01-26 19:51:43:INFO:-------------Round number: 3-------------
2022-01-26 19:51:43:INFO:-------------Sending models-------------
2022-01-26 19:51:43:INFO:-------------Evaluating models-------------
2022-01-26 19:51:44:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 19:51:44:INFO:Accuracy = [0.9908709269007796, 0.9578196841473979, 0.9506230425801293, 0.9608182848004264, 0.9841407343239822, 0.9646165122942627, 0.9641500633037916, 0.998000932897981, 0.9780102618777904, 0.9544212700739655]
2022-01-26 19:51:44:INFO:Loss = [0.03699891281813553, 0.10640832986628972, 0.11834190904886109, 0.08521180066577082, 0.05514630688393284, 0.07486884288500276, 0.09070632840012928, 0.016959510121474425, 0.06024123021884394, 0.09265171753675412]
2022-01-26 19:51:44:INFO:-------------Training local models-------------
2022-01-26 19:56:45:INFO:-------------Aggregating local models-------------
2022-01-26 19:56:48:INFO:-------------Round number: 4-------------
2022-01-26 19:56:48:INFO:-------------Sending models-------------
2022-01-26 19:56:48:INFO:-------------Evaluating models-------------
2022-01-26 19:56:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 19:56:49:INFO:Accuracy = [0.9908709269007796, 0.9580195908575998, 0.9539548210834944, 0.9620177250616379, 0.9841407343239822, 0.9651495968548011, 0.966015859265676, 0.9982674751782501, 0.9780768974478576, 0.9544212700739655]
2022-01-26 19:56:49:INFO:Loss = [0.03375302620819325, 0.10162449118994511, 0.11496712716828729, 0.08113332445307958, 0.05142948799087828, 0.07090905221129201, 0.08794131672868244, 0.013832055241218263, 0.05568812399333438, 0.0896059988253267]
2022-01-26 19:56:49:INFO:-------------Training local models-------------
2022-01-26 20:01:51:INFO:-------------Aggregating local models-------------
2022-01-26 20:01:53:INFO:-------------Round number: 5-------------
2022-01-26 20:01:53:INFO:-------------Sending models-------------
2022-01-26 20:01:53:INFO:-------------Evaluating models-------------
2022-01-26 20:01:54:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:01:54:INFO:Accuracy = [0.9908709269007796, 0.9580195908575998, 0.9576864130072633, 0.9654827747051375, 0.9841407343239822, 0.966015859265676, 0.9677483840874259, 0.9984673818884521, 0.9780768974478576, 0.9544879056440327]
2022-01-26 20:01:54:INFO:Loss = [0.03147069677527916, 0.09842533998903889, 0.11238279845724196, 0.07822617983994656, 0.04879393847507961, 0.06816046900217637, 0.08523170353644295, 0.012085050725778347, 0.052108450929318297, 0.0866839811134108]
2022-01-26 20:01:54:INFO:-------------Training local models-------------
2022-01-26 20:06:56:INFO:-------------Aggregating local models-------------
2022-01-26 20:06:58:INFO:-------------Round number: 6-------------
2022-01-26 20:06:58:INFO:-------------Sending models-------------
2022-01-26 20:06:59:INFO:-------------Evaluating models-------------
2022-01-26 20:06:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:06:59:INFO:Accuracy = [0.9908709269007796, 0.9580195908575998, 0.9598853868194842, 0.9713467048710601, 0.9841407343239822, 0.9680815619377624, 0.9690144599187046, 0.9985340174585193, 0.9786099820083961, 0.9549543546345038]
2022-01-26 20:06:59:INFO:Loss = [0.02964841084641527, 0.09566770227511087, 0.10966716158275801, 0.07529504825065167, 0.04662136639471715, 0.06575192014757922, 0.08250608010871775, 0.010747191205632185, 0.04837558934725513, 0.08339282161105992]
2022-01-26 20:06:59:INFO:-------------Training local models-------------
2022-01-26 20:12:01:INFO:-------------Aggregating local models-------------
2022-01-26 20:12:04:INFO:-------------Round number: 7-------------
2022-01-26 20:12:04:INFO:-------------Sending models-------------
2022-01-26 20:12:04:INFO:-------------Evaluating models-------------
2022-01-26 20:12:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:12:05:INFO:Accuracy = [0.9908709269007796, 0.9580195908575998, 0.9594189378290131, 0.9733457719730793, 0.9841407343239822, 0.971080162590791, 0.9699473578996468, 0.9985340174585193, 0.9827413873525688, 0.9588858532684748]
2022-01-26 20:12:05:INFO:Loss = [0.028281483783039133, 0.09327302731620801, 0.10670726039668105, 0.0722531495157777, 0.04493726197720083, 0.06359132749390332, 0.08006047283378369, 0.00974837746062662, 0.044654494943282635, 0.07986072707416213]
2022-01-26 20:12:05:INFO:-------------Training local models-------------
2022-01-26 20:17:06:INFO:-------------Aggregating local models-------------
2022-01-26 20:17:09:INFO:-------------Round number: 8-------------
2022-01-26 20:17:09:INFO:-------------Sending models-------------
2022-01-26 20:17:09:INFO:-------------Evaluating models-------------
2022-01-26 20:17:10:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:17:10:INFO:Accuracy = [0.9908709269007796, 0.9580195908575998, 0.9596854801092823, 0.9734790431132139, 0.9841407343239822, 0.9740121276737522, 0.9704138068901179, 0.9985340174585193, 0.9862064369960685, 0.9625508096221763]
2022-01-26 20:17:10:INFO:Loss = [0.02730869837259181, 0.09122900344974333, 0.10371190281751586, 0.0691992549666157, 0.043671413546377054, 0.06161790416970153, 0.07801384229414365, 0.009032479440526153, 0.04133584237801492, 0.07643686465143565]
2022-01-26 20:17:10:INFO:-------------Training local models-------------
2022-01-26 20:22:12:INFO:-------------Aggregating local models-------------
2022-01-26 20:22:14:INFO:-------------Round number: 9-------------
2022-01-26 20:22:14:INFO:-------------Sending models-------------
2022-01-26 20:22:15:INFO:-------------Evaluating models-------------
2022-01-26 20:22:15:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:22:15:INFO:Accuracy = [0.9908709269007796, 0.9580195908575998, 0.9600186579596188, 0.973745585393483, 0.9841407343239822, 0.9767441860465116, 0.9708136203105218, 0.9985340174585193, 0.9869394282668088, 0.9639501565935896]
2022-01-26 20:22:15:INFO:Loss = [0.026587077599333174, 0.08938924830785082, 0.10120559268148713, 0.06650778440949076, 0.04267007394471597, 0.05961558698589035, 0.07625369287527958, 0.00849022270091261, 0.0386195615435472, 0.07339272318765308]
2022-01-26 20:22:15:INFO:-------------Training local models-------------
2022-01-26 20:27:15:INFO:-------------Aggregating local models-------------
2022-01-26 20:27:18:INFO:-------------Round number: 10-------------
2022-01-26 20:27:18:INFO:-------------Sending models-------------
2022-01-26 20:27:18:INFO:-------------Evaluating models-------------
2022-01-26 20:27:19:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:27:19:INFO:Accuracy = [0.9908709269007796, 0.9588192176984074, 0.9606183780902245, 0.9741453988138868, 0.9841407343239822, 0.9789431598587326, 0.9708136203105218, 0.9985340174585193, 0.9874725128273473, 0.9661491304058106]
2022-01-26 20:27:19:INFO:Loss = [0.026015290856912662, 0.08756159507180901, 0.09931654357404772, 0.06454602560001624, 0.04182975238976889, 0.05739658413685855, 0.07459809118948342, 0.00805603010284379, 0.036437825386933485, 0.07075857725913053]
2022-01-26 20:27:19:INFO:-------------Training local models-------------
2022-01-26 20:32:20:INFO:-------------Aggregating local models-------------
2022-01-26 20:32:22:INFO:-------------Round number: 11-------------
2022-01-26 20:32:22:INFO:-------------Sending models-------------
2022-01-26 20:32:22:INFO:-------------Evaluating models-------------
2022-01-26 20:32:23:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:32:23:INFO:Accuracy = [0.9908709269007796, 0.9593523022589459, 0.9608849203704938, 0.9743453055240887, 0.9841407343239822, 0.9805424135403479, 0.971080162590791, 0.9985340174585193, 0.9880055973878856, 0.9665489438262145]
2022-01-26 20:32:23:INFO:Loss = [0.025533810087469938, 0.08566838372209613, 0.09777582402622444, 0.06314771922446648, 0.04104885582844824, 0.054809189895863746, 0.07292242592455976, 0.0077002191407521264, 0.034704440137296184, 0.0684611600017336]
2022-01-26 20:32:23:INFO:-------------Training local models-------------
2022-01-26 20:37:24:INFO:-------------Aggregating local models-------------
2022-01-26 20:37:27:INFO:-------------Round number: 12-------------
2022-01-26 20:37:27:INFO:-------------Sending models-------------
2022-01-26 20:37:27:INFO:-------------Evaluating models-------------
2022-01-26 20:37:28:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:37:28:INFO:Accuracy = [0.9908709269007796, 0.9612847337908976, 0.9610848270806956, 0.974611847804358, 0.9841407343239822, 0.9815419470913573, 0.9713467048710601, 0.9985340174585193, 0.9883387752382221, 0.9687479176384354]
2022-01-26 20:37:28:INFO:Loss = [0.025123781047252724, 0.08360550411959175, 0.09635929784875848, 0.06205707809905374, 0.04030069400078227, 0.051923230852696504, 0.07120583949517208, 0.007407234468095743, 0.03336719763209503, 0.0664487746275049]
2022-01-26 20:37:28:INFO:-------------Training local models-------------
2022-01-26 20:42:29:INFO:-------------Aggregating local models-------------
2022-01-26 20:42:32:INFO:-------------Round number: 13-------------
2022-01-26 20:42:32:INFO:-------------Sending models-------------
2022-01-26 20:42:32:INFO:-------------Evaluating models-------------
2022-01-26 20:42:33:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:42:33:INFO:Accuracy = [0.9908709269007796, 0.9626840807623109, 0.9615512760711667, 0.9750116612247618, 0.9841407343239822, 0.9820750316518958, 0.9718131538615313, 0.9985340174585193, 0.9884720463783567, 0.971080162590791]
2022-01-26 20:42:33:INFO:Loss = [0.024767148204972694, 0.08132431337506148, 0.09497404544446121, 0.061089614788117176, 0.039556671978302996, 0.048955355822141035, 0.06949001235819555, 0.007171445698094423, 0.0322666422580107, 0.06459131914368899]
2022-01-26 20:42:33:INFO:-------------Training local models-------------
2022-01-26 20:47:35:INFO:-------------Aggregating local models-------------
2022-01-26 20:47:37:INFO:-------------Round number: 14-------------
2022-01-26 20:47:37:INFO:-------------Sending models-------------
2022-01-26 20:47:37:INFO:-------------Evaluating models-------------
2022-01-26 20:47:38:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:47:38:INFO:Accuracy = [0.9908709269007796, 0.9641500633037916, 0.9618844539215033, 0.9754781102152329, 0.9841407343239822, 0.9822083027920304, 0.9720796961418005, 0.9985340174585193, 0.9888052242286933, 0.9724795095622043]
2022-01-26 20:47:38:INFO:Loss = [0.02445075849421541, 0.07875172034224587, 0.09364588005849489, 0.06025913939045634, 0.03882274715157694, 0.046421625318569436, 0.06779473707263958, 0.006975116711225346, 0.03127360392102398, 0.06274581605229332]
2022-01-26 20:47:38:INFO:-------------Training local models-------------
2022-01-26 20:52:40:INFO:-------------Aggregating local models-------------
2022-01-26 20:52:42:INFO:-------------Round number: 15-------------
2022-01-26 20:52:42:INFO:-------------Sending models-------------
2022-01-26 20:52:43:INFO:-------------Evaluating models-------------
2022-01-26 20:52:43:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:52:43:INFO:Accuracy = [0.9908709269007796, 0.9660824948357433, 0.9626840807623109, 0.9758779236356367, 0.9841407343239822, 0.9826747517825015, 0.9726794162724062, 0.9985340174585193, 0.9886719530885587, 0.9726794162724062]
2022-01-26 20:52:43:INFO:Loss = [0.02415038945461367, 0.07582288714868066, 0.09230713380956804, 0.059446329660951126, 0.038160917033905714, 0.04444995041023413, 0.06614380543309299, 0.006802074426186535, 0.03035988021566269, 0.06091066083539164]
2022-01-26 20:52:43:INFO:-------------Training local models-------------
2022-01-26 20:57:44:INFO:-------------Aggregating local models-------------
2022-01-26 20:57:47:INFO:-------------Round number: 16-------------
2022-01-26 20:57:47:INFO:-------------Sending models-------------
2022-01-26 20:57:47:INFO:-------------Evaluating models-------------
2022-01-26 20:57:48:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:57:48:INFO:Accuracy = [0.9908709269007796, 0.9693476377690411, 0.9644166055840607, 0.9761444659159059, 0.9841407343239822, 0.9818084893716266, 0.9738122209635504, 0.9985340174585193, 0.9888718597987606, 0.9738788565336176]
2022-01-26 20:57:48:INFO:Loss = [0.02386549381676456, 0.07285364239450658, 0.09106709504394529, 0.05869858434260806, 0.03774080159395338, 0.04433263468851087, 0.0651277989099041, 0.006651590821338147, 0.02958777269342009, 0.059125569043296744]
2022-01-26 20:57:48:INFO:-------------Training local models-------------
2022-01-26 21:02:49:INFO:-------------Aggregating local models-------------
2022-01-26 21:02:51:INFO:-------------Round number: 17-------------
2022-01-26 21:02:51:INFO:-------------Sending models-------------
2022-01-26 21:02:52:INFO:-------------Evaluating models-------------
2022-01-26 21:02:52:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:02:52:INFO:Accuracy = [0.9908709269007796, 0.9714799760111947, 0.965349503565003, 0.9764110081961751, 0.9841407343239822, 0.9811421336709536, 0.974611847804358, 0.9985340174585193, 0.9892050376490971, 0.9745452122342907]
2022-01-26 21:02:52:INFO:Loss = [0.023589386913055867, 0.07007847434330829, 0.0899247230352123, 0.05804960931071504, 0.037229032022598293, 0.04463876281751753, 0.06394753386982324, 0.006529390558042723, 0.02884306757397861, 0.05730757025547861]
2022-01-26 21:02:52:INFO:-------------Training local models-------------
2022-01-26 21:07:54:INFO:-------------Aggregating local models-------------
2022-01-26 21:07:56:INFO:-------------Round number: 18-------------
2022-01-26 21:07:56:INFO:-------------Sending models-------------
2022-01-26 21:07:56:INFO:-------------Evaluating models-------------
2022-01-26 21:07:57:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:07:57:INFO:Accuracy = [0.9908709269007796, 0.9725461451322716, 0.966015859265676, 0.9772106350369827, 0.9841407343239822, 0.9812087692410209, 0.9756113813553675, 0.9985340174585193, 0.9892716732191644, 0.9756780169254348]
2022-01-26 21:07:57:INFO:Loss = [0.023305113448607414, 0.0674955588090592, 0.08890746686911571, 0.057494413237261704, 0.036734000483720226, 0.04428124230885219, 0.06259447889495344, 0.006425596295307902, 0.028184442999491736, 0.05559310941314859]
2022-01-26 21:07:57:INFO:-------------Training local models-------------
2022-01-26 21:14:50:INFO:-------------Aggregating local models-------------
2022-01-26 21:14:54:INFO:-------------Round number: 19-------------
2022-01-26 21:14:54:INFO:-------------Sending models-------------
2022-01-26 21:14:55:INFO:-------------Evaluating models-------------
2022-01-26 21:14:56:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:14:56:INFO:Accuracy = [0.9908709269007796, 0.9731458652628773, 0.9664823082561471, 0.97727727060705, 0.9841407343239822, 0.9806756846804825, 0.975944559205704, 0.9985340174585193, 0.9896048510695009, 0.9760778303458386]
2022-01-26 21:14:56:INFO:Loss = [0.023007935052276805, 0.0654315526264932, 0.08805912673089873, 0.057011344049413416, 0.03633254951470837, 0.044613566542830524, 0.06154611019715987, 0.006337244841191528, 0.02757962640328812, 0.05404222424856554]
2022-01-26 21:14:56:INFO:-------------Training local models-------------
2022-01-26 21:22:17:INFO:-------------Aggregating local models-------------
2022-01-26 21:22:21:INFO:-------------Round number: 20-------------
2022-01-26 21:22:21:INFO:-------------Sending models-------------
2022-01-26 21:22:22:INFO:-------------Evaluating models-------------
2022-01-26 21:22:23:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:22:23:INFO:Accuracy = [0.9908709269007796, 0.9742786699540215, 0.9666155793962817, 0.9770773638968482, 0.9841407343239822, 0.9804757779702805, 0.9766775504764443, 0.9985340174585193, 0.9894715799293663, 0.9764110081961751]
2022-01-26 21:22:23:INFO:Loss = [0.022684189156596497, 0.06382911876411339, 0.0872382104779065, 0.05655840350261418, 0.03596388525613693, 0.04511469343328608, 0.060563114293745814, 0.006262598195468791, 0.027065995320744732, 0.05281815447876231]
2022-01-26 21:22:23:INFO:-------------Training local models-------------
2022-01-26 21:29:44:INFO:-------------Aggregating local models-------------
2022-01-26 21:29:48:INFO:-------------Round number: 21-------------
2022-01-26 21:29:48:INFO:-------------Sending models-------------
2022-01-26 21:29:49:INFO:-------------Evaluating models-------------
2022-01-26 21:29:50:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:29:50:INFO:Accuracy = [0.990937562470847, 0.9746784833744253, 0.9668154861064836, 0.9771439994669154, 0.9841407343239822, 0.9804757779702805, 0.9770773638968482, 0.9985340174585193, 0.9896714866395682, 0.9764776437662425]
2022-01-26 21:29:50:INFO:Loss = [0.022332732031458958, 0.06255358527235451, 0.08658146695631545, 0.056204089857590775, 0.03563472527814135, 0.04531507469950232, 0.059649602699545445, 0.006198838252843663, 0.026651688949207365, 0.05194635453757349]
2022-01-26 21:29:50:INFO:-------------Training local models-------------
2022-01-26 21:37:12:INFO:-------------Aggregating local models-------------
2022-01-26 21:37:16:INFO:-------------Round number: 22-------------
2022-01-26 21:37:16:INFO:-------------Sending models-------------
2022-01-26 21:37:16:INFO:-------------Evaluating models-------------
2022-01-26 21:37:17:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:37:17:INFO:Accuracy = [0.9917371893116546, 0.9754114746451656, 0.966682214966349, 0.9770773638968482, 0.9841407343239822, 0.9808755913906844, 0.9774105417471847, 0.9985340174585193, 0.9901379356300393, 0.9770107283267808]
2022-01-26 21:37:17:INFO:Loss = [0.021955694608843123, 0.061492110800288484, 0.08604863953647578, 0.055943936916127375, 0.03532268119459503, 0.044405188788811195, 0.05864920619571566, 0.006146008982938892, 0.02632805085807571, 0.05146660537685323]
2022-01-26 21:37:17:INFO:-------------Training local models-------------
2022-01-26 21:44:39:INFO:-------------Aggregating local models-------------
2022-01-26 21:44:43:INFO:-------------Round number: 23-------------
2022-01-26 21:44:43:INFO:-------------Sending models-------------
2022-01-26 21:44:43:INFO:-------------Evaluating models-------------
2022-01-26 21:44:44:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:44:44:INFO:Accuracy = [0.9927367228626641, 0.9758112880655694, 0.9670153928166856, 0.9768774571866462, 0.9841407343239822, 0.9826081162124342, 0.978143533017925, 0.9985340174585193, 0.990071300059972, 0.9778103551675884]
2022-01-26 21:44:44:INFO:Loss = [0.02154741165971704, 0.06046573629036738, 0.08555069491410924, 0.05566851352386466, 0.03503463830252441, 0.04333634957276515, 0.05770539944508495, 0.006100602808506011, 0.02611118915207442, 0.05088929302776249]
2022-01-26 21:44:44:INFO:-------------Training local models-------------
2022-01-26 21:52:07:INFO:-------------Aggregating local models-------------
2022-01-26 21:52:11:INFO:-------------Round number: 24-------------
2022-01-26 21:52:11:INFO:-------------Sending models-------------
2022-01-26 21:52:11:INFO:-------------Evaluating models-------------
2022-01-26 21:52:12:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:52:12:INFO:Accuracy = [0.9932031718531352, 0.9762777370560405, 0.9671486639568202, 0.9772106350369827, 0.9841407343239822, 0.9841407343239822, 0.9783434397281269, 0.9985340174585193, 0.9904044779103085, 0.978809888718598]
2022-01-26 21:52:12:INFO:Loss = [0.02112518886599889, 0.059635156980053415, 0.0851740813802385, 0.05539688561836618, 0.03474024324788505, 0.04217827357507636, 0.05689862114489414, 0.0060611830578894054, 0.02598806929229272, 0.05049455822167893]
2022-01-26 21:52:12:INFO:-------------Training local models-------------
2022-01-26 21:59:34:INFO:-------------Aggregating local models-------------
2022-01-26 21:59:38:INFO:-------------Round number: 25-------------
2022-01-26 21:59:38:INFO:-------------Sending models-------------
2022-01-26 21:59:39:INFO:-------------Evaluating models-------------
2022-01-26 21:59:40:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:59:40:INFO:Accuracy = [0.9937362564136736, 0.9768774571866462, 0.9674152062370893, 0.9773439061771173, 0.9841407343239822, 0.9848737255947224, 0.9785433464383287, 0.9985340174585193, 0.9905377490504431, 0.9794762444192711]
2022-01-26 21:59:40:INFO:Loss = [0.020715527093482795, 0.05863569973722727, 0.08475054007278085, 0.055180528317913646, 0.03448037026803855, 0.041932035052358776, 0.05624137249894383, 0.006025778702572693, 0.02585774146813724, 0.04960875447878677]
2022-01-26 21:59:40:INFO:-------------Training local models-------------
2022-01-26 22:07:02:INFO:-------------Aggregating local models-------------
2022-01-26 22:07:06:INFO:-------------Round number: 26-------------
2022-01-26 22:07:06:INFO:-------------Sending models-------------
2022-01-26 22:07:06:INFO:-------------Evaluating models-------------
2022-01-26 22:07:07:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:07:07:INFO:Accuracy = [0.9940027986939428, 0.9770107283267808, 0.9677483840874259, 0.9774105417471847, 0.9842073698940494, 0.9854734457253281, 0.9786766175784634, 0.9985340174585193, 0.9905377490504431, 0.9797427866995402]
2022-01-26 22:07:07:INFO:Loss = [0.020326685936554366, 0.0577340056364546, 0.08431731702397283, 0.05486198083211747, 0.034186031986290916, 0.041052307077608076, 0.055578980336134516, 0.005993657923993402, 0.02585352038179583, 0.048985780773754775]
2022-01-26 22:07:07:INFO:-------------Training local models-------------
2022-01-26 22:14:29:INFO:-------------Aggregating local models-------------
2022-01-26 22:14:33:INFO:-------------Round number: 27-------------
2022-01-26 22:14:33:INFO:-------------Sending models-------------
2022-01-26 22:14:34:INFO:-------------Evaluating models-------------
2022-01-26 22:14:35:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:14:35:INFO:Accuracy = [0.9940027986939428, 0.97727727060705, 0.9674818418071567, 0.9776770840274539, 0.9843406410341841, 0.9854068101552609, 0.9787432531485307, 0.9985340174585193, 0.990737655760645, 0.9797427866995402]
2022-01-26 22:14:35:INFO:Loss = [0.01998181917424012, 0.05705557220314395, 0.08397499384174735, 0.05466381094237247, 0.03387716673389392, 0.04045646017825756, 0.05500076079328227, 0.005964841648973123, 0.025843786238538863, 0.048521483994488385]
2022-01-26 22:14:35:INFO:-------------Training local models-------------
2022-01-26 22:21:57:INFO:-------------Aggregating local models-------------
2022-01-26 22:22:01:INFO:-------------Round number: 28-------------
2022-01-26 22:22:01:INFO:-------------Sending models-------------
2022-01-26 22:22:01:INFO:-------------Evaluating models-------------
2022-01-26 22:22:02:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:22:02:INFO:Accuracy = [0.9941360698340774, 0.9774105417471847, 0.9678150196574932, 0.9780768974478576, 0.9844739121743187, 0.9861398014260012, 0.9788765242886653, 0.9985340174585193, 0.9906710201905777, 0.9800093289798094]
2022-01-26 22:22:02:INFO:Loss = [0.01968264845213963, 0.056517755413444795, 0.08371587433723092, 0.05451455232245142, 0.03353904918726951, 0.039588223219944166, 0.05439877075818019, 0.005938680031067961, 0.025829762897553888, 0.048258468600633486]
2022-01-26 22:22:02:INFO:-------------Training local models-------------
2022-01-26 22:29:24:INFO:-------------Aggregating local models-------------
2022-01-26 22:29:28:INFO:-------------Round number: 29-------------
2022-01-26 22:29:28:INFO:-------------Sending models-------------
2022-01-26 22:29:28:INFO:-------------Evaluating models-------------
2022-01-26 22:29:30:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:29:30:INFO:Accuracy = [0.9942027054041447, 0.9777437195975212, 0.9680815619377624, 0.9782101685879923, 0.9846738188845205, 0.9865396148464051, 0.9791430665689345, 0.9985340174585193, 0.9906043846205105, 0.9805424135403479]
2022-01-26 22:29:30:INFO:Loss = [0.019429882614464777, 0.055643206355462584, 0.08333619147934643, 0.054238048404586334, 0.033184369197875256, 0.038947013816795814, 0.0538651904741252, 0.005915334548600573, 0.025890696787955733, 0.047603920137719614]
2022-01-26 22:29:30:INFO:-------------Training local models-------------
2022-01-26 22:36:52:INFO:-------------Aggregating local models-------------
