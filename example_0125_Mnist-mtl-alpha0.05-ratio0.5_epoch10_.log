2022-01-26 08:05:15:INFO:-------------Round number: 0-------------
2022-01-26 08:05:15:INFO:-------------Sending models-------------
2022-01-26 08:05:15:INFO:-------------Evaluating models-------------
2022-01-26 08:05:15:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 08:05:15:INFO:Accuracy = [0.9263895843765648, 0.9158738107160741, 0.8595393089634452, 0.899849774661993, 0.914121181772659, 0.11016524787180772, 0.09414121181772658, 0.12769153730595895, 0.09614421632448673, 0.9123685528292439]
2022-01-26 08:05:15:INFO:Loss = [0.6677707227307913, 0.65035355840257, 0.664374296373884, 0.654283486385016, 0.6628631437994804, 0.7358170935495173, 0.7406060484629245, 0.7388185477579123, 0.7473186791450547, 0.6691222313080779]
2022-01-26 08:05:15:INFO:-------------Training local models-------------
2022-01-26 08:10:07:INFO:-------------Aggregating local models-------------
2022-01-26 08:10:09:INFO:-------------Round number: 1-------------
2022-01-26 08:10:09:INFO:-------------Sending models-------------
2022-01-26 08:10:10:INFO:-------------Evaluating models-------------
2022-01-26 08:10:10:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 08:10:10:INFO:Accuracy = [0.9031046569854783, 0.8965948923385078, 0.85728592889334, 0.8532799198798198, 0.8565348022033049, 0.8447671507260891, 0.8592889334001002, 0.8457686529794692, 0.8182273410115173, 0.7901852779168753]
2022-01-26 08:10:10:INFO:Loss = [0.3384867315560684, 0.41889289016828396, 0.5002149482578054, 0.39159707385723924, 0.4495082191071759, 0.47153007538693514, 0.43441345115249597, 0.4702097045464752, 0.5171380461663246, 0.491751154663641]
2022-01-26 08:10:10:INFO:-------------Training local models-------------
2022-01-26 08:15:02:INFO:-------------Aggregating local models-------------
2022-01-26 08:15:05:INFO:-------------Round number: 2-------------
2022-01-26 08:15:05:INFO:-------------Sending models-------------
2022-01-26 08:15:05:INFO:-------------Evaluating models-------------
2022-01-26 08:15:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 08:15:05:INFO:Accuracy = [0.9203805708562844, 0.8950926389584376, 0.8678017025538307, 0.8312468703054582, 0.85778668002003, 0.8607911867801703, 0.8640460691036554, 0.8507761642463696, 0.8274912368552829, 0.8204807210816224]
2022-01-26 08:15:05:INFO:Loss = [0.26872734995335007, 0.3839929663745475, 0.46999338672356006, 0.3390801893638118, 0.43754976382432437, 0.4190249919712275, 0.39227564840679674, 0.40570035408883837, 0.4723720138969015, 0.39551834574572714]
2022-01-26 08:15:05:INFO:-------------Training local models-------------
2022-01-26 08:19:59:INFO:-------------Aggregating local models-------------
2022-01-26 08:20:01:INFO:-------------Round number: 3-------------
2022-01-26 08:20:01:INFO:-------------Sending models-------------
2022-01-26 08:20:01:INFO:-------------Evaluating models-------------
2022-01-26 08:20:02:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 08:20:02:INFO:Accuracy = [0.9236354531797697, 0.8950926389584376, 0.8725588382573861, 0.8274912368552829, 0.8660490736104156, 0.8620430645968954, 0.8652979469203805, 0.8647971957936905, 0.827741612418628, 0.8289934902353531]
2022-01-26 08:20:02:INFO:Loss = [0.24516684126031235, 0.36573706205857803, 0.45392514790679267, 0.3245712608965482, 0.42093880681724893, 0.40099640711479756, 0.3688420977177165, 0.3750777139801077, 0.4412683064357504, 0.3585059070783869]
2022-01-26 08:20:02:INFO:-------------Training local models-------------
2022-01-26 08:24:54:INFO:-------------Aggregating local models-------------
2022-01-26 08:24:57:INFO:-------------Round number: 4-------------
2022-01-26 08:24:57:INFO:-------------Sending models-------------
2022-01-26 08:24:57:INFO:-------------Evaluating models-------------
2022-01-26 08:24:57:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 08:24:57:INFO:Accuracy = [0.9243865798698047, 0.8950926389584376, 0.8778167250876314, 0.8249874812218327, 0.8688032048072108, 0.8685528292438658, 0.8650475713570356, 0.8765648472709063, 0.8279919879819729, 0.8312468703054582]
2022-01-26 08:24:57:INFO:Loss = [0.23298112509849597, 0.3511881675348749, 0.44333073525359823, 0.3188167264848028, 0.4045655730832881, 0.39226867937103743, 0.35353218883612464, 0.3595614941003366, 0.42175791510696764, 0.3528778646183263]
2022-01-26 08:24:57:INFO:-------------Training local models-------------
2022-01-26 08:29:49:INFO:-------------Aggregating local models-------------
2022-01-26 08:29:52:INFO:-------------Round number: 5-------------
2022-01-26 08:29:52:INFO:-------------Sending models-------------
2022-01-26 08:29:52:INFO:-------------Evaluating models-------------
2022-01-26 08:29:52:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 08:29:52:INFO:Accuracy = [0.9248873309964948, 0.8953430145217827, 0.8818227341011518, 0.8234852278417626, 0.8700550826239359, 0.872058087130696, 0.8650475713570356, 0.8800701051577366, 0.8312468703054582, 0.8327491236855283]
2022-01-26 08:29:52:INFO:Loss = [0.22455752769529536, 0.33863036562425153, 0.4368023123323048, 0.31539408919125383, 0.3912292886506738, 0.38694057486644484, 0.34243435542002176, 0.35231295245399713, 0.40740945623300573, 0.3596316919714291]
2022-01-26 08:29:52:INFO:-------------Training local models-------------
2022-01-26 08:34:45:INFO:-------------Aggregating local models-------------
2022-01-26 08:34:47:INFO:-------------Round number: 6-------------
2022-01-26 08:34:47:INFO:-------------Sending models-------------
2022-01-26 08:34:48:INFO:-------------Evaluating models-------------
2022-01-26 08:34:48:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 08:34:48:INFO:Accuracy = [0.9251377065598397, 0.8965948923385078, 0.8825738607911868, 0.8249874812218327, 0.870555833750626, 0.8733099649474211, 0.8650475713570356, 0.8815723585378067, 0.8380070105157736, 0.8340010015022534]
2022-01-26 08:34:48:INFO:Loss = [0.21804320475061037, 0.32778786309547286, 0.4330973219754651, 0.31286959152313815, 0.38068072721735785, 0.3836556214143876, 0.3334137307639473, 0.34947935533603725, 0.3956512865950806, 0.36965378952988187]
2022-01-26 08:34:48:INFO:-------------Training local models-------------
2022-01-26 08:39:40:INFO:-------------Aggregating local models-------------
2022-01-26 08:39:42:INFO:-------------Round number: 7-------------
2022-01-26 08:39:42:INFO:-------------Sending models-------------
2022-01-26 08:39:42:INFO:-------------Evaluating models-------------
2022-01-26 08:39:43:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 08:39:43:INFO:Accuracy = [0.9251377065598397, 0.899349023535303, 0.8838257386079119, 0.8289934902353531, 0.8708062093139709, 0.8738107160741112, 0.8650475713570356, 0.8835753630445669, 0.8432648973460191, 0.8362543815723585]
2022-01-26 08:39:43:INFO:Loss = [0.21265267942949656, 0.31820524731399347, 0.43084736361178116, 0.31058564752213935, 0.3720569553083211, 0.3815781478613846, 0.32521067103146006, 0.3485783986014729, 0.3854877533626689, 0.3793010850609306]
2022-01-26 08:39:43:INFO:-------------Training local models-------------
2022-01-26 08:44:34:INFO:-------------Aggregating local models-------------
2022-01-26 08:44:37:INFO:-------------Round number: 8-------------
2022-01-26 08:44:37:INFO:-------------Sending models-------------
2022-01-26 08:44:37:INFO:-------------Evaluating models-------------
2022-01-26 08:44:37:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 08:44:37:INFO:Accuracy = [0.9258888332498748, 0.9026039058587881, 0.8833249874812218, 0.8327491236855283, 0.871557336004006, 0.8738107160741112, 0.8652979469203805, 0.8838257386079119, 0.8480220330495744, 0.8329994992488733]
2022-01-26 08:44:37:INFO:Loss = [0.20798178628797895, 0.3095571516585885, 0.4292169058153058, 0.30824652390768376, 0.3649379078842234, 0.38018440390560676, 0.3171440025204611, 0.348426107214639, 0.37662783923702764, 0.3874397244700592]
2022-01-26 08:44:37:INFO:-------------Training local models-------------
2022-01-26 08:49:28:INFO:-------------Aggregating local models-------------
2022-01-26 08:49:31:INFO:-------------Round number: 9-------------
2022-01-26 08:49:31:INFO:-------------Sending models-------------
2022-01-26 08:49:31:INFO:-------------Evaluating models-------------
2022-01-26 08:49:31:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 08:49:31:INFO:Accuracy = [0.9261392088132199, 0.9043565348022033, 0.8835753630445669, 0.8417626439659489, 0.8728092138207311, 0.8738107160741112, 0.8655483224837256, 0.8845768652979469, 0.8507761642463696, 0.8319979969954933]
2022-01-26 08:49:31:INFO:Loss = [0.20375289315421113, 0.30166726503638375, 0.4278429976399124, 0.3058240621758888, 0.3589362026519633, 0.379174661604127, 0.3090640587684569, 0.34839311053204125, 0.3689026126372404, 0.393756555322976]
2022-01-26 08:49:31:INFO:-------------Training local models-------------
2022-01-26 08:54:19:INFO:-------------Aggregating local models-------------
2022-01-26 08:54:21:INFO:-------------Round number: 10-------------
2022-01-26 08:54:21:INFO:-------------Sending models-------------
2022-01-26 08:54:21:INFO:-------------Evaluating models-------------
2022-01-26 08:54:21:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 08:54:21:INFO:Accuracy = [0.9266399599399099, 0.9068602904356535, 0.885077616424637, 0.8467701552328493, 0.8730595893840761, 0.8738107160741112, 0.8670505758637957, 0.885578367551327, 0.8537806710065098, 0.829744616925388]
2022-01-26 08:54:21:INFO:Loss = [0.19983562921565848, 0.29443078415743956, 0.4264991407356802, 0.30327982684247834, 0.35396594529818515, 0.3783277531178238, 0.30102463138272145, 0.34825002958450224, 0.3622624017466403, 0.39842545730423257]
2022-01-26 08:54:21:INFO:-------------Training local models-------------
2022-01-26 08:59:09:INFO:-------------Aggregating local models-------------
2022-01-26 08:59:11:INFO:-------------Round number: 11-------------
2022-01-26 08:59:11:INFO:-------------Sending models-------------
2022-01-26 08:59:11:INFO:-------------Evaluating models-------------
2022-01-26 08:59:12:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 08:59:12:INFO:Accuracy = [0.927391086629945, 0.9078617926890336, 0.885077616424637, 0.8537806710065098, 0.8733099649474211, 0.8738107160741112, 0.870555833750626, 0.886579869804707, 0.8585378067100651, 0.8294942413620431]
2022-01-26 08:59:12:INFO:Loss = [0.19616977692177495, 0.2877748838753689, 0.42506204569258976, 0.3006998452697925, 0.349844927162325, 0.37754557682429785, 0.29317474654739517, 0.3479188202632161, 0.35661063540450755, 0.4017204517040646]
2022-01-26 08:59:12:INFO:-------------Training local models-------------
2022-01-26 09:04:00:INFO:-------------Aggregating local models-------------
2022-01-26 09:04:02:INFO:-------------Round number: 12-------------
2022-01-26 09:04:02:INFO:-------------Sending models-------------
2022-01-26 09:04:02:INFO:-------------Evaluating models-------------
2022-01-26 09:04:02:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 09:04:02:INFO:Accuracy = [0.927891837756635, 0.9088632949424136, 0.885327991987982, 0.8600400600901352, 0.8755633450175263, 0.8738107160741112, 0.8778167250876314, 0.8883324987481221, 0.8640460691036554, 0.8299949924887331]
2022-01-26 09:04:02:INFO:Loss = [0.19277256962416053, 0.2815806941341695, 0.42351822984630116, 0.2981347564631643, 0.3466115663455256, 0.37680456626511605, 0.28571965616651035, 0.3474436170426583, 0.35186845954221596, 0.4040159255274176]
2022-01-26 09:04:02:INFO:-------------Training local models-------------
2022-01-26 09:08:50:INFO:-------------Aggregating local models-------------
2022-01-26 09:08:52:INFO:-------------Round number: 13-------------
2022-01-26 09:08:52:INFO:-------------Sending models-------------
2022-01-26 09:08:52:INFO:-------------Evaluating models-------------
2022-01-26 09:08:53:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 09:08:53:INFO:Accuracy = [0.928893340010015, 0.9106159238858288, 0.885327991987982, 0.8625438157235854, 0.8768152228342514, 0.8753129694541812, 0.885077616424637, 0.8918377566349525, 0.8670505758637957, 0.8314972458688032]
2022-01-26 09:08:53:INFO:Loss = [0.18958061808955393, 0.27581227948748877, 0.4219015745763678, 0.2956583600087708, 0.3440572015875736, 0.3760870579906688, 0.2788717082490333, 0.34680097431362883, 0.3479118292453788, 0.4055093423953433]
2022-01-26 09:08:53:INFO:-------------Training local models-------------
2022-01-26 09:13:41:INFO:-------------Aggregating local models-------------
2022-01-26 09:13:43:INFO:-------------Round number: 14-------------
2022-01-26 09:13:43:INFO:-------------Sending models-------------
2022-01-26 09:13:43:INFO:-------------Evaluating models-------------
2022-01-26 09:13:44:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 09:13:44:INFO:Accuracy = [0.9296444667000501, 0.9113670505758638, 0.886079118678017, 0.8698047070605909, 0.8773159739609414, 0.8750625938908363, 0.8948422633950927, 0.8938407611417125, 0.8688032048072108, 0.8332498748122183]
2022-01-26 09:13:44:INFO:Loss = [0.18660699451124144, 0.27044029915411805, 0.4202295970935356, 0.2933136722214383, 0.3420984395559897, 0.37532633167290924, 0.2727269830790825, 0.34605541544967916, 0.3445395651922487, 0.40644989499046236]
2022-01-26 09:13:44:INFO:-------------Training local models-------------
2022-01-26 09:18:31:INFO:-------------Aggregating local models-------------
2022-01-26 09:18:33:INFO:-------------Round number: 15-------------
2022-01-26 09:18:33:INFO:-------------Sending models-------------
2022-01-26 09:18:34:INFO:-------------Evaluating models-------------
2022-01-26 09:18:34:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 09:18:34:INFO:Accuracy = [0.9311467200801202, 0.9116174261392088, 0.8875813720580872, 0.8733099649474211, 0.8760640961442163, 0.8753129694541812, 0.9046069103655483, 0.8950926389584376, 0.8693039559339009, 0.8342513770655984]
2022-01-26 09:18:34:INFO:Loss = [0.1838346139528178, 0.26544302755750626, 0.41853587594000796, 0.291182663236633, 0.3405101875084844, 0.37453872805347493, 0.2673198658574881, 0.3451975178865774, 0.34161978991996067, 0.40699585959952816]
2022-01-26 09:18:34:INFO:-------------Training local models-------------
2022-01-26 09:23:21:INFO:-------------Aggregating local models-------------
2022-01-26 09:23:24:INFO:-------------Round number: 16-------------
2022-01-26 09:23:24:INFO:-------------Sending models-------------
2022-01-26 09:23:24:INFO:-------------Evaluating models-------------
2022-01-26 09:23:24:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 09:23:24:INFO:Accuracy = [0.9331497245868803, 0.9138708062093139, 0.8890836254381572, 0.8753129694541812, 0.8750625938908363, 0.8755633450175263, 0.9128693039559339, 0.8965948923385078, 0.872058087130696, 0.8360040060090135]
2022-01-26 09:23:24:INFO:Loss = [0.18127706279612005, 0.2607717221327441, 0.41677829054203847, 0.2892797551244979, 0.3392429355274908, 0.3736976383655702, 0.2625682700114994, 0.34430543748619846, 0.3390641486145045, 0.4073482000443706]
2022-01-26 09:23:24:INFO:-------------Training local models-------------
2022-01-26 09:28:12:INFO:-------------Aggregating local models-------------
2022-01-26 09:28:15:INFO:-------------Round number: 17-------------
2022-01-26 09:28:15:INFO:-------------Sending models-------------
2022-01-26 09:28:15:INFO:-------------Evaluating models-------------
2022-01-26 09:28:15:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 09:28:15:INFO:Accuracy = [0.9351527290936404, 0.9153730595893841, 0.8893340010015023, 0.8773159739609414, 0.8753129694541812, 0.8763144717075614, 0.9206309464196294, 0.8973460190285428, 0.8728092138207311, 0.8367551326990486]
2022-01-26 09:28:15:INFO:Loss = [0.17888702144932597, 0.2564522504442786, 0.4150306164546094, 0.2875802629547948, 0.33812147147076055, 0.3728146081980137, 0.25844516233839776, 0.34335790492275836, 0.3367626440952253, 0.40753285623679375]
2022-01-26 09:28:15:INFO:-------------Training local models-------------
2022-01-26 09:33:02:INFO:-------------Aggregating local models-------------
2022-01-26 09:33:05:INFO:-------------Round number: 18-------------
2022-01-26 09:33:05:INFO:-------------Sending models-------------
2022-01-26 09:33:05:INFO:-------------Evaluating models-------------
2022-01-26 09:33:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 09:33:05:INFO:Accuracy = [0.9359038557836755, 0.9176264396594892, 0.8900851276915374, 0.8793189784677016, 0.8758137205808713, 0.8770655983975963, 0.9248873309964948, 0.899849774661993, 0.8748122183274912, 0.8377566349524287]
2022-01-26 09:33:05:INFO:Loss = [0.17666301196146955, 0.2524109849480311, 0.4133333575864718, 0.2861870217701219, 0.33710937335020774, 0.37192964283868385, 0.25484667400502514, 0.34240906306596786, 0.3346785501981295, 0.4076057151000484]
2022-01-26 09:33:05:INFO:-------------Training local models-------------
2022-01-26 09:37:53:INFO:-------------Aggregating local models-------------
2022-01-26 09:37:55:INFO:-------------Round number: 19-------------
2022-01-26 09:37:55:INFO:-------------Sending models-------------
2022-01-26 09:37:55:INFO:-------------Evaluating models-------------
2022-01-26 09:37:56:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 09:37:56:INFO:Accuracy = [0.9364046069103655, 0.9213820731096645, 0.8903355032548823, 0.8808212318477716, 0.8760640961442163, 0.8773159739609414, 0.9276414621932899, 0.900350525788683, 0.8760640961442163, 0.8382573860791187]
2022-01-26 09:37:56:INFO:Loss = [0.17458947103986738, 0.24867533286909563, 0.4116272376677694, 0.2850115579506837, 0.33615219738440455, 0.37096432133727697, 0.2517057237821376, 0.34145940269997216, 0.3327504160399684, 0.4076313046197177]
2022-01-26 09:37:56:INFO:-------------Training local models-------------
2022-01-26 09:42:44:INFO:-------------Aggregating local models-------------
2022-01-26 09:42:46:INFO:-------------Round number: 20-------------
2022-01-26 09:42:46:INFO:-------------Sending models-------------
2022-01-26 09:42:46:INFO:-------------Evaluating models-------------
2022-01-26 09:42:46:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 09:42:46:INFO:Accuracy = [0.9371557336004006, 0.9243865798698047, 0.8910866299449174, 0.8828242363545318, 0.8758137205808713, 0.8783174762143214, 0.9306459689534301, 0.901352028042063, 0.8768152228342514, 0.8387581372058087]
2022-01-26 09:42:46:INFO:Loss = [0.17265513664169266, 0.24520624200549396, 0.4099494834513528, 0.28402298753062716, 0.3352034889080134, 0.36996455977510656, 0.24895990360058956, 0.34052113911354015, 0.33092640620186975, 0.40764690468513465]
2022-01-26 09:42:46:INFO:-------------Training local models-------------
2022-01-26 09:47:34:INFO:-------------Aggregating local models-------------
2022-01-26 09:47:36:INFO:-------------Round number: 21-------------
2022-01-26 09:47:36:INFO:-------------Sending models-------------
2022-01-26 09:47:36:INFO:-------------Evaluating models-------------
2022-01-26 09:47:37:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 09:47:37:INFO:Accuracy = [0.9396594892338508, 0.9276414621932899, 0.8905858788182274, 0.8848272408612919, 0.8755633450175263, 0.8793189784677016, 0.9326489734601903, 0.9018527791687532, 0.8775663495242865, 0.8387581372058087]
2022-01-26 09:47:37:INFO:Loss = [0.1708319148053393, 0.2419376592211136, 0.40828341704002324, 0.2832149354267388, 0.3342272468481821, 0.36893196639375886, 0.24653586828564392, 0.3395751254799589, 0.32919729872170267, 0.4076362826041987]
2022-01-26 09:47:37:INFO:-------------Training local models-------------
2022-01-26 09:52:24:INFO:-------------Aggregating local models-------------
2022-01-26 09:52:27:INFO:-------------Round number: 22-------------
2022-01-26 09:52:27:INFO:-------------Sending models-------------
2022-01-26 09:52:27:INFO:-------------Evaluating models-------------
2022-01-26 09:52:27:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 09:52:27:INFO:Accuracy = [0.9404106159238859, 0.9306459689534301, 0.8900851276915374, 0.885578367551327, 0.8755633450175263, 0.8800701051577366, 0.9349023535302955, 0.9041061592388583, 0.8778167250876314, 0.8392588883324987]
2022-01-26 09:52:27:INFO:Loss = [0.169125956077721, 0.2388914752055458, 0.40664932126275877, 0.282569961353719, 0.3332306578782544, 0.3678696713500442, 0.24438939079435407, 0.3386464807448488, 0.32755942838040014, 0.40762357998379756]
2022-01-26 09:52:27:INFO:-------------Training local models-------------
2022-01-26 09:57:15:INFO:-------------Aggregating local models-------------
2022-01-26 09:57:17:INFO:-------------Round number: 23-------------
2022-01-26 09:57:17:INFO:-------------Sending models-------------
2022-01-26 09:57:17:INFO:-------------Evaluating models-------------
2022-01-26 09:57:18:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 09:57:18:INFO:Accuracy = [0.9411617426139208, 0.9326489734601903, 0.8905858788182274, 0.886579869804707, 0.8753129694541812, 0.8820731096644967, 0.9374061091637457, 0.9041061592388583, 0.8785678517776665, 0.8397596394591887]
2022-01-26 09:57:18:INFO:Loss = [0.1675260370240419, 0.23603986439740895, 0.4050520145077572, 0.28207823815911776, 0.33220863856293487, 0.36678772299783885, 0.24247310988157433, 0.3377411813088491, 0.3260024089773855, 0.40761463968410006]
2022-01-26 09:57:18:INFO:-------------Training local models-------------
2022-01-26 10:02:05:INFO:-------------Aggregating local models-------------
2022-01-26 10:02:07:INFO:-------------Round number: 24-------------
2022-01-26 10:02:07:INFO:-------------Sending models-------------
2022-01-26 10:02:08:INFO:-------------Evaluating models-------------
2022-01-26 10:02:08:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 10:02:08:INFO:Accuracy = [0.941662493740611, 0.9331497245868803, 0.8905858788182274, 0.8893340010015023, 0.8765648472709063, 0.8828242363545318, 0.9389083625438157, 0.9048572859288934, 0.8788182273410116, 0.8397596394591887]
2022-01-26 10:02:08:INFO:Loss = [0.1660243423359592, 0.23336240554671583, 0.4035058329911351, 0.281692121176571, 0.3311582857766559, 0.3657028501098775, 0.24076114641853727, 0.3368571588106842, 0.32452554749374907, 0.4075992793357711]
2022-01-26 10:02:08:INFO:-------------Training local models-------------
2022-01-26 10:06:56:INFO:-------------Aggregating local models-------------
2022-01-26 10:06:58:INFO:-------------Round number: 25-------------
2022-01-26 10:06:58:INFO:-------------Sending models-------------
2022-01-26 10:06:59:INFO:-------------Evaluating models-------------
2022-01-26 10:06:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 10:06:59:INFO:Accuracy = [0.942663995993991, 0.9336504757135704, 0.8905858788182274, 0.8903355032548823, 0.8768152228342514, 0.8833249874812218, 0.9391587381071608, 0.9053580370555834, 0.8795693540310465, 0.8397596394591887]
2022-01-26 10:06:59:INFO:Loss = [0.16462047081063372, 0.2308397914527409, 0.40200246605554824, 0.2814071363748398, 0.3300877871940302, 0.3646206845663806, 0.23922687456453998, 0.3359933822916393, 0.323104208518808, 0.4076024740675833]
2022-01-26 10:06:59:INFO:-------------Training local models-------------
2022-01-26 10:11:46:INFO:-------------Aggregating local models-------------
2022-01-26 10:11:49:INFO:-------------Round number: 26-------------
2022-01-26 10:11:49:INFO:-------------Sending models-------------
2022-01-26 10:11:49:INFO:-------------Evaluating models-------------
2022-01-26 10:11:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 10:11:49:INFO:Accuracy = [0.943164747120681, 0.9351527290936404, 0.8913370055082624, 0.8913370055082624, 0.8773159739609414, 0.8845768652979469, 0.9409113670505759, 0.9061091637456185, 0.8800701051577366, 0.8397596394591887]
2022-01-26 10:11:49:INFO:Loss = [0.1633077713160986, 0.22846149138227592, 0.40055733665023663, 0.28119458905774175, 0.3289872530326877, 0.36357187092858967, 0.2378430935562601, 0.33513821066790855, 0.321707038612463, 0.407596205668665]
2022-01-26 10:11:49:INFO:-------------Training local models-------------
2022-01-26 10:16:37:INFO:-------------Aggregating local models-------------
2022-01-26 10:16:39:INFO:-------------Round number: 27-------------
2022-01-26 10:16:39:INFO:-------------Sending models-------------
2022-01-26 10:16:39:INFO:-------------Evaluating models-------------
2022-01-26 10:16:40:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 10:16:40:INFO:Accuracy = [0.943415122684026, 0.9359038557836755, 0.8910866299449174, 0.8923385077616425, 0.8768152228342514, 0.885578367551327, 0.9419128693039559, 0.9058587881822734, 0.8810716074111167, 0.8397596394591887]
2022-01-26 10:16:40:INFO:Loss = [0.16208217708882386, 0.22624746003490395, 0.3991451802973402, 0.2810355568960682, 0.32788405524506786, 0.3625520590311392, 0.2365932801012855, 0.33430840551923163, 0.3203878959708308, 0.4076060840223893]
2022-01-26 10:16:40:INFO:-------------Training local models-------------
2022-01-26 10:21:27:INFO:-------------Aggregating local models-------------
2022-01-26 10:21:30:INFO:-------------Round number: 28-------------
2022-01-26 10:21:30:INFO:-------------Sending models-------------
2022-01-26 10:21:30:INFO:-------------Evaluating models-------------
2022-01-26 10:21:30:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 10:21:30:INFO:Accuracy = [0.9439158738107161, 0.9364046069103655, 0.8900851276915374, 0.8920881321982974, 0.8770655983975963, 0.885828743114672, 0.942663995993991, 0.9061091637456185, 0.8820731096644967, 0.8400100150225338]
2022-01-26 10:21:30:INFO:Loss = [0.16094034072591745, 0.22415848303047364, 0.3977980806697351, 0.2809157336480975, 0.32677248072758064, 0.3615641794002484, 0.235442014610002, 0.33350355914916124, 0.31913879112953686, 0.40759628158777744]
2022-01-26 10:21:30:INFO:-------------Training local models-------------
2022-01-26 10:26:18:INFO:-------------Aggregating local models-------------
2022-01-26 10:26:20:INFO:-------------Round number: 29-------------
2022-01-26 10:26:20:INFO:-------------Sending models-------------
2022-01-26 10:26:20:INFO:-------------Evaluating models-------------
2022-01-26 10:26:21:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 10:26:21:INFO:Accuracy = [0.9444166249374061, 0.9369053580370555, 0.8900851276915374, 0.8928392588883325, 0.8778167250876314, 0.8873309964947421, 0.943415122684026, 0.9061091637456185, 0.8823234852278418, 0.8400100150225338]
2022-01-26 10:26:21:INFO:Loss = [0.1598646961236994, 0.22219451350394814, 0.3964917498360783, 0.28086576476962416, 0.32563634387383866, 0.36062365331651824, 0.23438776119245744, 0.3327163505981068, 0.3179502592159274, 0.40759173536673887]
2022-01-26 10:26:21:INFO:-------------Training local models-------------
2022-01-26 10:31:08:INFO:-------------Aggregating local models-------------
2022-01-26 10:31:10:INFO:-------------Round number: 30-------------
2022-01-26 10:31:10:INFO:-------------Sending models-------------
2022-01-26 10:31:11:INFO:-------------Evaluating models-------------
2022-01-26 10:31:11:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 10:31:11:INFO:Accuracy = [0.9449173760640961, 0.9371557336004006, 0.8900851276915374, 0.8938407611417125, 0.8785678517776665, 0.8885828743114672, 0.943665498247371, 0.9071106659989985, 0.8833249874812218, 0.8400100150225338]
2022-01-26 10:31:11:INFO:Loss = [0.15887135126329277, 0.22032985918599104, 0.395219053511422, 0.28086174825057103, 0.3244954238071278, 0.3597289671648982, 0.2334287000138527, 0.3319357112200749, 0.31676870712459515, 0.4075777102842255]
2022-01-26 10:31:11:INFO:-------------Training local models-------------
2022-01-26 10:35:59:INFO:-------------Aggregating local models-------------
2022-01-26 10:36:01:INFO:-------------Round number: 31-------------
2022-01-26 10:36:01:INFO:-------------Sending models-------------
2022-01-26 10:36:01:INFO:-------------Evaluating models-------------
2022-01-26 10:36:02:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 10:36:02:INFO:Accuracy = [0.9446670005007511, 0.9381572358537806, 0.8900851276915374, 0.8940911367050576, 0.8795693540310465, 0.8898347521281923, 0.9444166249374061, 0.9071106659989985, 0.885327991987982, 0.8400100150225338]
2022-01-26 10:36:02:INFO:Loss = [0.15795438151617308, 0.21857112011933064, 0.394000391355302, 0.2808909188979282, 0.3233510829183251, 0.35888172319444206, 0.23255395138256935, 0.33117839103646757, 0.3156164643983514, 0.4075700212810417]
2022-01-26 10:36:02:INFO:-------------Training local models-------------
2022-01-26 10:40:49:INFO:-------------Aggregating local models-------------
2022-01-26 10:40:51:INFO:-------------Round number: 32-------------
2022-01-26 10:40:51:INFO:-------------Sending models-------------
2022-01-26 10:40:52:INFO:-------------Evaluating models-------------
2022-01-26 10:40:52:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 10:40:52:INFO:Accuracy = [0.9449173760640961, 0.9389083625438157, 0.8905858788182274, 0.8953430145217827, 0.8795693540310465, 0.8910866299449174, 0.9451677516274412, 0.9071106659989985, 0.885828743114672, 0.8400100150225338]
2022-01-26 10:40:52:INFO:Loss = [0.15709889376317462, 0.21692443363088462, 0.39283685300895144, 0.28094300234771746, 0.32219356274947897, 0.3580711831954708, 0.23175127662695094, 0.33044090803086984, 0.31446342522184983, 0.407558625769994]
2022-01-26 10:40:52:INFO:-------------Training local models-------------
2022-01-26 10:45:40:INFO:-------------Aggregating local models-------------
2022-01-26 10:45:42:INFO:-------------Round number: 33-------------
2022-01-26 10:45:42:INFO:-------------Sending models-------------
2022-01-26 10:45:42:INFO:-------------Evaluating models-------------
2022-01-26 10:45:43:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 10:45:43:INFO:Accuracy = [0.9451677516274412, 0.9399098647971958, 0.8900851276915374, 0.8960941412118177, 0.8795693540310465, 0.8915873810716074, 0.9454181271907862, 0.9073610415623435, 0.8863294942413621, 0.8400100150225338]
2022-01-26 10:45:43:INFO:Loss = [0.15629534039459084, 0.21536179064691205, 0.39170776268041285, 0.2810199300018455, 0.32103476032341477, 0.35728812118456243, 0.23099762581413683, 0.32971826344879457, 0.31335326809057806, 0.4075197675585558]
2022-01-26 10:45:43:INFO:-------------Training local models-------------
2022-01-26 10:48:17:INFO:-------------Aggregating local models-------------
2022-01-26 10:48:18:INFO:-------------Round number: 34-------------
2022-01-26 10:48:18:INFO:-------------Sending models-------------
2022-01-26 10:48:18:INFO:-------------Evaluating models-------------
2022-01-26 10:48:19:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 10:48:19:INFO:Accuracy = [0.9454181271907862, 0.9414121181772659, 0.8898347521281923, 0.8963445167751627, 0.8800701051577366, 0.8923385077616425, 0.9454181271907862, 0.9073610415623435, 0.8870806209313971, 0.8400100150225338]
2022-01-26 10:48:19:INFO:Loss = [0.15555806556257137, 0.2138840956352988, 0.3906186512971864, 0.28110004304036995, 0.31989610839779153, 0.35652275825486324, 0.23030213323200344, 0.32901329763514525, 0.3122773296857162, 0.4075029514380993]
2022-01-26 10:48:19:INFO:-------------Training local models-------------
2022-01-26 10:50:41:INFO:-------------Aggregating local models-------------
2022-01-26 10:50:42:INFO:-------------Round number: 35-------------
2022-01-26 10:50:42:INFO:-------------Sending models-------------
2022-01-26 10:50:42:INFO:-------------Evaluating models-------------
2022-01-26 10:50:43:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 10:50:43:INFO:Accuracy = [0.9456685027541312, 0.941662493740611, 0.8895843765648472, 0.8963445167751627, 0.8803204807210816, 0.8930896344516775, 0.9459188783174762, 0.9078617926890336, 0.8883324987481221, 0.8402603905858789]
2022-01-26 10:50:43:INFO:Loss = [0.15486754522341234, 0.2125000507949153, 0.38956713966977946, 0.28119120110575946, 0.3187528035883309, 0.35577959616252997, 0.22965736183784757, 0.3283182591014263, 0.31123490584257846, 0.40748609479165926]
2022-01-26 10:50:43:INFO:-------------Training local models-------------
2022-01-26 10:53:05:INFO:-------------Aggregating local models-------------
2022-01-26 10:53:06:INFO:-------------Round number: 36-------------
2022-01-26 10:53:06:INFO:-------------Sending models-------------
2022-01-26 10:53:06:INFO:-------------Evaluating models-------------
2022-01-26 10:53:07:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 10:53:07:INFO:Accuracy = [0.9469203805708563, 0.942914371557336, 0.8898347521281923, 0.8963445167751627, 0.8805708562844267, 0.8938407611417125, 0.9466700050075113, 0.9078617926890336, 0.8883324987481221, 0.8405107661492238]
2022-01-26 10:53:07:INFO:Loss = [0.1542288288407918, 0.21119023990916266, 0.388546998801692, 0.2812932794777822, 0.3176127415545703, 0.355051824198419, 0.22904481306936697, 0.32763261979298447, 0.3102465860665096, 0.4074681599982649]
2022-01-26 10:53:07:INFO:-------------Training local models-------------
2022-01-26 10:55:29:INFO:-------------Aggregating local models-------------
2022-01-26 10:55:30:INFO:-------------Round number: 37-------------
2022-01-26 10:55:30:INFO:-------------Sending models-------------
2022-01-26 10:55:31:INFO:-------------Evaluating models-------------
2022-01-26 10:55:31:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 10:55:31:INFO:Accuracy = [0.9474211316975463, 0.942914371557336, 0.8898347521281923, 0.8965948923385078, 0.8813219829744617, 0.8943415122684026, 0.9466700050075113, 0.9081121682523786, 0.8885828743114672, 0.8407611417125689]
2022-01-26 10:55:31:INFO:Loss = [0.15364999150378494, 0.20995964243674675, 0.3875643575675837, 0.28138898586057504, 0.316471467910954, 0.3543308496509439, 0.22847218515633008, 0.32694408574714484, 0.3092767325227013, 0.40744031037947054]
2022-01-26 10:55:31:INFO:-------------Training local models-------------
2022-01-26 10:57:53:INFO:-------------Aggregating local models-------------
2022-01-26 10:57:54:INFO:-------------Round number: 38-------------
2022-01-26 10:57:54:INFO:-------------Sending models-------------
2022-01-26 10:57:54:INFO:-------------Evaluating models-------------
2022-01-26 10:57:55:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 10:57:55:INFO:Accuracy = [0.9476715072608913, 0.943415122684026, 0.8903355032548823, 0.8970956434651978, 0.8818227341011518, 0.8958437656484727, 0.9471707561342013, 0.9081121682523786, 0.8885828743114672, 0.8407611417125689]
2022-01-26 10:57:55:INFO:Loss = [0.1531205135424866, 0.20880292858901334, 0.3866081111628957, 0.2815017636453552, 0.315345931167576, 0.35361648702805815, 0.2279424701048669, 0.3262679133179253, 0.30835239776536166, 0.40742566972414185]
2022-01-26 10:57:55:INFO:-------------Training local models-------------
2022-01-26 11:00:17:INFO:-------------Aggregating local models-------------
2022-01-26 11:00:18:INFO:-------------Round number: 39-------------
2022-01-26 11:00:18:INFO:-------------Sending models-------------
2022-01-26 11:00:19:INFO:-------------Evaluating models-------------
2022-01-26 11:00:19:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 11:00:19:INFO:Accuracy = [0.9476715072608913, 0.9444166249374061, 0.8903355032548823, 0.8978467701552328, 0.8818227341011518, 0.8965948923385078, 0.9474211316975463, 0.9078617926890336, 0.8893340010015023, 0.8410115172759138]
2022-01-26 11:00:19:INFO:Loss = [0.15262804411298603, 0.20770432295851454, 0.3856969048770664, 0.2816106567796781, 0.31421590545536354, 0.352906501753428, 0.22743348966204543, 0.32560172453852926, 0.3074504453521043, 0.4074143196872682]
2022-01-26 11:00:19:INFO:-------------Training local models-------------
2022-01-26 11:02:42:INFO:-------------Aggregating local models-------------
