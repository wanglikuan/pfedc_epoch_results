2022-01-27 00:27:45:INFO:-------------Round number: 0-------------
2022-01-27 00:27:45:INFO:-------------Sending models-------------
2022-01-27 00:27:45:INFO:-------------Evaluating models-------------
2022-01-27 00:27:46:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:27:46:INFO:Accuracy = [0.8998401704848162, 0.09922749067661162, 0.1001598295151838, 0.09909429941395845, 0.8790623335109217, 0.8826584976025573, 0.10042621204049014, 0.09962706446457112, 0.8991742141715503, 0.8994405966968567]
2022-01-27 00:27:46:INFO:Loss = [0.6655192559204904, 0.7253744506381837, 0.7186372587511879, 0.7332048017370872, 0.6907839094490591, 0.6898970211844655, 0.7393671502267419, 0.7035915054535701, 0.6847794067370618, 0.638321891172998]
2022-01-27 00:27:46:INFO:-------------Training local models-------------
2022-01-27 00:30:18:INFO:-------------Aggregating local models-------------
2022-01-27 00:30:21:INFO:-------------Round number: 1-------------
2022-01-27 00:30:21:INFO:-------------Sending models-------------
2022-01-27 00:30:21:INFO:-------------Evaluating models-------------
2022-01-27 00:30:22:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:30:22:INFO:Accuracy = [0.8998401704848162, 0.9005061267980821, 0.8998401704848162, 0.8929142248268513, 0.898907831646244, 0.9011720831113479, 0.8742674480554076, 0.9003729355354289, 0.8991742141715503, 0.8994405966968567]
2022-01-27 00:30:22:INFO:Loss = [0.46745666056934926, 0.5390461692601426, 0.4801347072042235, 0.54054367413658, 0.4657835314108866, 0.5433972362323715, 0.5801394830398822, 0.5377154463805858, 0.5409712700940347, 0.49154958012625455]
2022-01-27 00:30:22:INFO:-------------Training local models-------------
2022-01-27 00:32:54:INFO:-------------Aggregating local models-------------
2022-01-27 00:32:57:INFO:-------------Round number: 2-------------
2022-01-27 00:32:57:INFO:-------------Sending models-------------
2022-01-27 00:32:57:INFO:-------------Evaluating models-------------
2022-01-27 00:32:58:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:32:58:INFO:Accuracy = [0.8998401704848162, 0.9007725093233884, 0.8998401704848162, 0.9009057005860416, 0.898907831646244, 0.9011720831113479, 0.8995737879595098, 0.9003729355354289, 0.8991742141715503, 0.8994405966968567]
2022-01-27 00:32:58:INFO:Loss = [0.30813521582813863, 0.3269825792272531, 0.3241698554358269, 0.3211972722302394, 0.3004228981905436, 0.3399044579668015, 0.33602378033121405, 0.33559284645411075, 0.3293231076436374, 0.3258428796302164]
2022-01-27 00:32:58:INFO:-------------Training local models-------------
2022-01-27 00:35:30:INFO:-------------Aggregating local models-------------
2022-01-27 00:35:32:INFO:-------------Round number: 3-------------
2022-01-27 00:35:32:INFO:-------------Sending models-------------
2022-01-27 00:35:33:INFO:-------------Evaluating models-------------
2022-01-27 00:35:33:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:35:33:INFO:Accuracy = [0.8998401704848162, 0.9007725093233884, 0.8998401704848162, 0.9009057005860416, 0.898907831646244, 0.9011720831113479, 0.8995737879595098, 0.9003729355354289, 0.8991742141715503, 0.8994405966968567]
2022-01-27 00:35:33:INFO:Loss = [0.29170164917027563, 0.2936727823912859, 0.29788181028632993, 0.28745839247340116, 0.2771519651888539, 0.29799235807994723, 0.29542014788147547, 0.29670602561123016, 0.2938430533686342, 0.30424588141971814]
2022-01-27 00:35:33:INFO:-------------Training local models-------------
2022-01-27 00:38:06:INFO:-------------Aggregating local models-------------
2022-01-27 00:38:08:INFO:-------------Round number: 4-------------
2022-01-27 00:38:08:INFO:-------------Sending models-------------
2022-01-27 00:38:09:INFO:-------------Evaluating models-------------
2022-01-27 00:38:09:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:38:09:INFO:Accuracy = [0.8998401704848162, 0.9007725093233884, 0.8998401704848162, 0.9009057005860416, 0.898907831646244, 0.9011720831113479, 0.8995737879595098, 0.9003729355354289, 0.8991742141715503, 0.8994405966968567]
2022-01-27 00:38:09:INFO:Loss = [0.28952983384937064, 0.2897288611870245, 0.29047740228994134, 0.2818628317534082, 0.2709432013943637, 0.28723813795728226, 0.28895143174194693, 0.287061952061447, 0.28670969085354053, 0.30079882657358825]
2022-01-27 00:38:09:INFO:-------------Training local models-------------
2022-01-27 00:40:54:INFO:-------------Aggregating local models-------------
2022-01-27 00:40:58:INFO:-------------Round number: 5-------------
2022-01-27 00:40:58:INFO:-------------Sending models-------------
2022-01-27 00:40:58:INFO:-------------Evaluating models-------------
2022-01-27 00:40:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:40:59:INFO:Accuracy = [0.8998401704848162, 0.9007725093233884, 0.8998401704848162, 0.9009057005860416, 0.898907831646244, 0.9011720831113479, 0.8995737879595098, 0.9003729355354289, 0.8991742141715503, 0.8994405966968567]
2022-01-27 00:40:59:INFO:Loss = [0.2885002354492389, 0.28890848197325764, 0.28719710740302956, 0.2799467886750947, 0.2676515839064864, 0.28301032180374425, 0.28734822789098935, 0.28280389105670894, 0.28379076264092085, 0.299228650577799]
2022-01-27 00:40:59:INFO:-------------Training local models-------------
2022-01-27 00:43:49:INFO:-------------Aggregating local models-------------
2022-01-27 00:43:51:INFO:-------------Round number: 6-------------
2022-01-27 00:43:51:INFO:-------------Sending models-------------
2022-01-27 00:43:51:INFO:-------------Evaluating models-------------
2022-01-27 00:43:52:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:43:52:INFO:Accuracy = [0.8998401704848162, 0.9007725093233884, 0.8998401704848162, 0.9009057005860416, 0.898907831646244, 0.9011720831113479, 0.8995737879595098, 0.9003729355354289, 0.8991742141715503, 0.8994405966968567]
2022-01-27 00:43:52:INFO:Loss = [0.28745309067676694, 0.2885547353638972, 0.28480225707541756, 0.2787191468962311, 0.2648603070940878, 0.28069106618425727, 0.2865699769042881, 0.28021301529268533, 0.28196939272775284, 0.29766828488493036]
2022-01-27 00:43:52:INFO:-------------Training local models-------------
2022-01-27 00:46:24:INFO:-------------Aggregating local models-------------
2022-01-27 00:46:30:INFO:-------------Round number: 7-------------
2022-01-27 00:46:30:INFO:-------------Sending models-------------
2022-01-27 00:46:30:INFO:-------------Evaluating models-------------
2022-01-27 00:46:31:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:46:31:INFO:Accuracy = [0.8998401704848162, 0.9007725093233884, 0.9005061267980821, 0.9009057005860416, 0.8994405966968567, 0.9011720831113479, 0.8995737879595098, 0.9003729355354289, 0.8991742141715503, 0.8994405966968567]
2022-01-27 00:46:31:INFO:Loss = [0.28617479346323405, 0.2883106689077996, 0.28239615742002055, 0.277730786517713, 0.26198330307458756, 0.27915064539099443, 0.2858319527156488, 0.2783760136611349, 0.2806008665678059, 0.2958594962436513]
2022-01-27 00:46:31:INFO:-------------Training local models-------------
2022-01-27 00:50:22:INFO:-------------Aggregating local models-------------
2022-01-27 00:50:26:INFO:-------------Round number: 8-------------
2022-01-27 00:50:26:INFO:-------------Sending models-------------
2022-01-27 00:50:26:INFO:-------------Evaluating models-------------
2022-01-27 00:50:27:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:50:27:INFO:Accuracy = [0.8998401704848162, 0.9007725093233884, 0.902770378263186, 0.9009057005860416, 0.9005061267980821, 0.9011720831113479, 0.8995737879595098, 0.9003729355354289, 0.8991742141715503, 0.8994405966968567]
2022-01-27 00:50:27:INFO:Loss = [0.2845131850557786, 0.28807836437581, 0.279679438304682, 0.27689044361812004, 0.2588650076003814, 0.27797083954783786, 0.2850490106745054, 0.2769537801421647, 0.2794426145929135, 0.29375898577451515]
2022-01-27 00:50:27:INFO:-------------Training local models-------------
2022-01-27 00:54:16:INFO:-------------Aggregating local models-------------
2022-01-27 00:54:20:INFO:-------------Round number: 9-------------
2022-01-27 00:54:20:INFO:-------------Sending models-------------
2022-01-27 00:54:20:INFO:-------------Evaluating models-------------
2022-01-27 00:54:21:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:54:21:INFO:Accuracy = [0.8998401704848162, 0.9007725093233884, 0.904368673415024, 0.9009057005860416, 0.9023708044752264, 0.9011720831113479, 0.8995737879595098, 0.9003729355354289, 0.8991742141715503, 0.8994405966968567]
2022-01-27 00:54:21:INFO:Loss = [0.28251668816203124, 0.28777633352259985, 0.2765189471000138, 0.27612421538985443, 0.25549341127108716, 0.27695636852229083, 0.2841597542952653, 0.27574690438947924, 0.2784205319674474, 0.2912811350908982]
2022-01-27 00:54:21:INFO:-------------Training local models-------------
2022-01-27 00:58:31:INFO:-------------Aggregating local models-------------
2022-01-27 00:58:36:INFO:-------------Round number: 10-------------
2022-01-27 00:58:36:INFO:-------------Sending models-------------
2022-01-27 00:58:36:INFO:-------------Evaluating models-------------
2022-01-27 00:58:37:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:58:37:INFO:Accuracy = [0.8998401704848162, 0.9007725093233884, 0.9053010122535962, 0.9009057005860416, 0.9042354821523708, 0.9011720831113479, 0.8995737879595098, 0.9003729355354289, 0.8991742141715503, 0.8994405966968567]
2022-01-27 00:58:37:INFO:Loss = [0.2801948987368294, 0.28739022597670305, 0.2729589896272624, 0.27537135471298113, 0.2520007573319455, 0.2760354208501456, 0.28316307337294727, 0.27466111537862964, 0.27746958342431927, 0.28846134634893916]
2022-01-27 00:58:37:INFO:-------------Training local models-------------
2022-01-27 01:02:28:INFO:-------------Aggregating local models-------------
2022-01-27 01:02:32:INFO:-------------Round number: 11-------------
2022-01-27 01:02:32:INFO:-------------Sending models-------------
2022-01-27 01:02:32:INFO:-------------Evaluating models-------------
2022-01-27 01:02:33:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:02:33:INFO:Accuracy = [0.8998401704848162, 0.9007725093233884, 0.905966968566862, 0.9009057005860416, 0.9045018646776771, 0.9011720831113479, 0.8995737879595098, 0.9003729355354289, 0.8991742141715503, 0.8994405966968567]
2022-01-27 01:02:33:INFO:Loss = [0.27760955276633587, 0.2868864004266139, 0.26911640273120313, 0.2746533569546151, 0.24858243387593398, 0.27515995009024774, 0.2820627066516652, 0.27359087736972004, 0.2765661748468511, 0.2854026842507105]
2022-01-27 01:02:33:INFO:-------------Training local models-------------
2022-01-27 01:06:19:INFO:-------------Aggregating local models-------------
2022-01-27 01:06:23:INFO:-------------Round number: 12-------------
2022-01-27 01:06:23:INFO:-------------Sending models-------------
2022-01-27 01:06:23:INFO:-------------Evaluating models-------------
2022-01-27 01:06:24:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:06:24:INFO:Accuracy = [0.9010388918486947, 0.9007725093233884, 0.906766116142781, 0.9009057005860416, 0.9057005860415557, 0.9011720831113479, 0.8995737879595098, 0.9003729355354289, 0.8991742141715503, 0.9002397442727758]
2022-01-27 01:06:24:INFO:Loss = [0.2748650516590255, 0.2862707392140351, 0.2651693770259055, 0.27396099644710126, 0.24539800669166092, 0.2742868448323811, 0.2809065913416338, 0.2725388250955255, 0.27569752305966383, 0.2821742826343361]
2022-01-27 01:06:24:INFO:-------------Training local models-------------
2022-01-27 01:10:09:INFO:-------------Aggregating local models-------------
2022-01-27 01:10:13:INFO:-------------Round number: 13-------------
2022-01-27 01:10:13:INFO:-------------Sending models-------------
2022-01-27 01:10:14:INFO:-------------Evaluating models-------------
2022-01-27 01:10:15:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:10:15:INFO:Accuracy = [0.9022376132125732, 0.9007725093233884, 0.9070324986680873, 0.9009057005860416, 0.9063665423548215, 0.9011720831113479, 0.8995737879595098, 0.9003729355354289, 0.8991742141715503, 0.902770378263186]
2022-01-27 01:10:15:INFO:Loss = [0.27209436130542736, 0.2855383108034343, 0.26129117505163446, 0.2733184814801193, 0.24252135765627889, 0.2734176862581008, 0.27970654703825554, 0.2714514058816024, 0.2748639958413972, 0.27891591315832015]
2022-01-27 01:10:15:INFO:-------------Training local models-------------
2022-01-27 01:14:32:INFO:-------------Aggregating local models-------------
2022-01-27 01:14:37:INFO:-------------Round number: 14-------------
2022-01-27 01:14:37:INFO:-------------Sending models-------------
2022-01-27 01:14:38:INFO:-------------Evaluating models-------------
2022-01-27 01:14:39:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:14:39:INFO:Accuracy = [0.9026371870005327, 0.9007725093233884, 0.9080980287693128, 0.9017048481619606, 0.9061001598295152, 0.9011720831113479, 0.8995737879595098, 0.9005061267980821, 0.8991742141715503, 0.9046350559403303]
2022-01-27 01:14:39:INFO:Loss = [0.2693952827828008, 0.28471886438836597, 0.25754988306441645, 0.27271346545410546, 0.23994995556769522, 0.2725587473598249, 0.27848284992453387, 0.2703160345551251, 0.27403024508090384, 0.2757638320078717]
2022-01-27 01:14:39:INFO:-------------Training local models-------------
2022-01-27 01:19:28:INFO:-------------Aggregating local models-------------
2022-01-27 01:19:33:INFO:-------------Round number: 15-------------
2022-01-27 01:19:33:INFO:-------------Sending models-------------
2022-01-27 01:19:33:INFO:-------------Evaluating models-------------
2022-01-27 01:19:34:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:19:34:INFO:Accuracy = [0.9033031433137986, 0.9007725093233884, 0.9088971763452317, 0.9021044219499201, 0.9082312200319659, 0.9011720831113479, 0.8994405966968567, 0.9006393180607352, 0.8991742141715503, 0.905966968566862]
2022-01-27 01:19:34:INFO:Loss = [0.2668398833423297, 0.2838491468119299, 0.25398647454535, 0.2721270434859198, 0.23762669926050298, 0.2717169929336961, 0.27728878995765854, 0.2691443883810196, 0.27320183271648374, 0.2728605214843787]
2022-01-27 01:19:34:INFO:-------------Training local models-------------
2022-01-27 01:24:06:INFO:-------------Aggregating local models-------------
2022-01-27 01:24:11:INFO:-------------Round number: 16-------------
2022-01-27 01:24:11:INFO:-------------Sending models-------------
2022-01-27 01:24:12:INFO:-------------Evaluating models-------------
2022-01-27 01:24:12:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:24:12:INFO:Accuracy = [0.9039690996270645, 0.9007725093233884, 0.9111614278103356, 0.9021044219499201, 0.9084976025572722, 0.9011720831113479, 0.8993074054342035, 0.9007725093233884, 0.8991742141715503, 0.9064997336174747]
2022-01-27 01:24:12:INFO:Loss = [0.26447996055855194, 0.28294166825777717, 0.2506530156734186, 0.2715699232136136, 0.23554607091173102, 0.27091814085000654, 0.27608828634007787, 0.2679195515357442, 0.2723706476678144, 0.2701745364779272]
2022-01-27 01:24:12:INFO:-------------Training local models-------------
2022-01-27 01:28:45:INFO:-------------Aggregating local models-------------
2022-01-27 01:28:50:INFO:-------------Round number: 17-------------
2022-01-27 01:28:50:INFO:-------------Sending models-------------
2022-01-27 01:28:50:INFO:-------------Evaluating models-------------
2022-01-27 01:28:51:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:28:51:INFO:Accuracy = [0.906766116142781, 0.9007725093233884, 0.911427810335642, 0.9017048481619606, 0.9088971763452317, 0.9011720831113479, 0.899706979222163, 0.9009057005860416, 0.8991742141715503, 0.9066329248801278]
2022-01-27 01:28:51:INFO:Loss = [0.2624140748397889, 0.2820209179165799, 0.2475426255992763, 0.2710305313630844, 0.23366358279136193, 0.2701557700638349, 0.2748817706854739, 0.2666879434668949, 0.271518736663406, 0.2676975400408866]
2022-01-27 01:28:51:INFO:-------------Training local models-------------
2022-01-27 01:33:23:INFO:-------------Aggregating local models-------------
2022-01-27 01:33:28:INFO:-------------Round number: 18-------------
2022-01-27 01:33:28:INFO:-------------Sending models-------------
2022-01-27 01:33:28:INFO:-------------Evaluating models-------------
2022-01-27 01:33:29:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:33:29:INFO:Accuracy = [0.9070324986680873, 0.9007725093233884, 0.9119605753862546, 0.9017048481619606, 0.9090303676078849, 0.9011720831113479, 0.9006393180607352, 0.9013052743740011, 0.8991742141715503, 0.9068993074054342]
2022-01-27 01:33:29:INFO:Loss = [0.26057942354030506, 0.2811174658447473, 0.24462358665850548, 0.27049612784800386, 0.23193467918165192, 0.2694510164537671, 0.27371686838118714, 0.26545360317981176, 0.2706607174784239, 0.2654095209497893]
2022-01-27 01:33:29:INFO:-------------Training local models-------------
2022-01-27 01:38:02:INFO:-------------Aggregating local models-------------
2022-01-27 01:38:07:INFO:-------------Round number: 19-------------
2022-01-27 01:38:07:INFO:-------------Sending models-------------
2022-01-27 01:38:07:INFO:-------------Evaluating models-------------
2022-01-27 01:38:08:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:38:08:INFO:Accuracy = [0.9076984549813533, 0.9007725093233884, 0.9116941928609483, 0.9018380394246137, 0.9088971763452317, 0.9011720831113479, 0.9015716568993074, 0.9022376132125732, 0.898907831646244, 0.906766116142781]
2022-01-27 01:38:08:INFO:Loss = [0.2589641211293419, 0.28023601855809654, 0.24190020292638129, 0.26994995787692866, 0.23038930515349348, 0.26879140725145967, 0.27258296335164656, 0.26422571130188705, 0.26979569028159944, 0.2632355855973353]
2022-01-27 01:38:08:INFO:-------------Training local models-------------
2022-01-27 01:42:40:INFO:-------------Aggregating local models-------------
2022-01-27 01:42:45:INFO:-------------Round number: 20-------------
2022-01-27 01:42:45:INFO:-------------Sending models-------------
2022-01-27 01:42:45:INFO:-------------Evaluating models-------------
2022-01-27 01:42:46:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:42:46:INFO:Accuracy = [0.9074320724560468, 0.9015716568993074, 0.9135588705380927, 0.9019712306872669, 0.9092967501331912, 0.9011720831113479, 0.9026371870005327, 0.9025039957378796, 0.8993074054342035, 0.9068993074054342]
2022-01-27 01:42:46:INFO:Loss = [0.2576007807868462, 0.27938831318817964, 0.23933178876151048, 0.2694292477159386, 0.22906414319892088, 0.2681897887235659, 0.2714712406902092, 0.26302506508521256, 0.26891970561373707, 0.2611393590562431]
2022-01-27 01:42:46:INFO:-------------Training local models-------------
2022-01-27 01:47:19:INFO:-------------Aggregating local models-------------
2022-01-27 01:47:24:INFO:-------------Round number: 21-------------
2022-01-27 01:47:24:INFO:-------------Sending models-------------
2022-01-27 01:47:24:INFO:-------------Evaluating models-------------
2022-01-27 01:47:25:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:47:25:INFO:Accuracy = [0.9075652637187, 0.9015716568993074, 0.9142248268513585, 0.9015716568993074, 0.9092967501331912, 0.9011720831113479, 0.9030367607884923, 0.9033031433137986, 0.8991742141715503, 0.9070324986680873]
2022-01-27 01:47:25:INFO:Loss = [0.25632763320860963, 0.27858604962550704, 0.23696290370529408, 0.2689336627211593, 0.2278946612326609, 0.2676530709216291, 0.27040070073146194, 0.26183262572381405, 0.26803433576317925, 0.25912531150716317]
2022-01-27 01:47:25:INFO:-------------Training local models-------------
2022-01-27 01:51:57:INFO:-------------Aggregating local models-------------
2022-01-27 01:52:02:INFO:-------------Round number: 22-------------
2022-01-27 01:52:02:INFO:-------------Sending models-------------
2022-01-27 01:52:02:INFO:-------------Evaluating models-------------
2022-01-27 01:52:03:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:52:03:INFO:Accuracy = [0.9058337773042089, 0.9015716568993074, 0.9147575919019713, 0.9013052743740011, 0.9091635588705381, 0.9011720831113479, 0.9026371870005327, 0.9039690996270645, 0.899706979222163, 0.9074320724560468]
2022-01-27 01:52:03:INFO:Loss = [0.25519884773864987, 0.27784198742727295, 0.23470481322581108, 0.268442407370634, 0.22687833612174696, 0.2671744547380937, 0.2693504795097668, 0.2606632735886409, 0.26713687401179564, 0.2572081229725399]
2022-01-27 01:52:03:INFO:-------------Training local models-------------
2022-01-27 01:56:36:INFO:-------------Aggregating local models-------------
2022-01-27 01:56:40:INFO:-------------Round number: 23-------------
2022-01-27 01:56:40:INFO:-------------Sending models-------------
2022-01-27 01:56:41:INFO:-------------Evaluating models-------------
2022-01-27 01:56:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:56:42:INFO:Accuracy = [0.9061001598295152, 0.9014384656366542, 0.9156899307405434, 0.9013052743740011, 0.9092967501331912, 0.9011720831113479, 0.9039690996270645, 0.9050346297282899, 0.8998401704848162, 0.9078316462440064]
2022-01-27 01:56:42:INFO:Loss = [0.2541744666750611, 0.27712629786532544, 0.23258563873968863, 0.2679601054646129, 0.22596101526438409, 0.2667120432599756, 0.2683399604121397, 0.25948841818566787, 0.2662480219595281, 0.2552619938126859]
2022-01-27 01:56:42:INFO:-------------Training local models-------------
2022-01-27 02:01:14:INFO:-------------Aggregating local models-------------
2022-01-27 02:01:19:INFO:-------------Round number: 24-------------
2022-01-27 02:01:19:INFO:-------------Sending models-------------
2022-01-27 02:01:19:INFO:-------------Evaluating models-------------
2022-01-27 02:01:20:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:01:20:INFO:Accuracy = [0.9061001598295152, 0.9017048481619606, 0.9158231220031966, 0.9011720831113479, 0.9099627064464572, 0.9011720831113479, 0.9038359083644113, 0.905966968566862, 0.9010388918486947, 0.9079648375066596]
2022-01-27 02:01:20:INFO:Loss = [0.2532548650247767, 0.27644327704611865, 0.23055328227148914, 0.26748395276561177, 0.22514478686763312, 0.26628650648129404, 0.2673446952946361, 0.2583823337719367, 0.26534092094804784, 0.2533700389298325]
2022-01-27 02:01:20:INFO:-------------Training local models-------------
2022-01-27 02:05:53:INFO:-------------Aggregating local models-------------
2022-01-27 02:05:58:INFO:-------------Round number: 25-------------
2022-01-27 02:05:58:INFO:-------------Sending models-------------
2022-01-27 02:05:58:INFO:-------------Evaluating models-------------
2022-01-27 02:05:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:05:59:INFO:Accuracy = [0.9061001598295152, 0.9019712306872669, 0.9163558870538092, 0.9011720831113479, 0.9100958977091103, 0.9011720831113479, 0.9045018646776771, 0.9063665423548215, 0.9011720831113479, 0.9080980287693128]
2022-01-27 02:05:59:INFO:Loss = [0.25247862275648164, 0.2757446050049471, 0.22855848007769455, 0.2669871228711221, 0.22443078788532986, 0.26586856524924934, 0.26635227337842793, 0.25732279523935336, 0.2644378465923322, 0.25146516341047204]
2022-01-27 02:05:59:INFO:-------------Training local models-------------
2022-01-27 02:10:31:INFO:-------------Aggregating local models-------------
2022-01-27 02:10:36:INFO:-------------Round number: 26-------------
2022-01-27 02:10:36:INFO:-------------Sending models-------------
2022-01-27 02:10:36:INFO:-------------Evaluating models-------------
2022-01-27 02:10:37:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:10:37:INFO:Accuracy = [0.9054342035162494, 0.9018380394246137, 0.9172882258923815, 0.9013052743740011, 0.9102290889717635, 0.9011720831113479, 0.9050346297282899, 0.9071656899307405, 0.9013052743740011, 0.9080980287693128]
2022-01-27 02:10:37:INFO:Loss = [0.25166854494363944, 0.27504409400681845, 0.22662833920934525, 0.2665049450346837, 0.2237264635723598, 0.2654842445579718, 0.26537759339890393, 0.2562325993268061, 0.26350814493975394, 0.24964986595468566]
2022-01-27 02:10:37:INFO:-------------Training local models-------------
2022-01-27 02:15:10:INFO:-------------Aggregating local models-------------
2022-01-27 02:15:14:INFO:-------------Round number: 27-------------
2022-01-27 02:15:14:INFO:-------------Sending models-------------
2022-01-27 02:15:15:INFO:-------------Evaluating models-------------
2022-01-27 02:15:16:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:15:16:INFO:Accuracy = [0.905167820990943, 0.9019712306872669, 0.9180873734683005, 0.9014384656366542, 0.9104954714970698, 0.9010388918486947, 0.9062333510921684, 0.9080980287693128, 0.9023708044752264, 0.9080980287693128]
2022-01-27 02:15:16:INFO:Loss = [0.2508966139059754, 0.27431787776057553, 0.2247464263089275, 0.2660471989264199, 0.22307872407874674, 0.26508897314737284, 0.2644101420167355, 0.25516956197510965, 0.2625598087271732, 0.24778477094579263]
2022-01-27 02:15:16:INFO:-------------Training local models-------------
2022-01-27 02:19:48:INFO:-------------Aggregating local models-------------
2022-01-27 02:19:54:INFO:-------------Round number: 28-------------
2022-01-27 02:19:54:INFO:-------------Sending models-------------
2022-01-27 02:19:54:INFO:-------------Evaluating models-------------
2022-01-27 02:19:55:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:19:55:INFO:Accuracy = [0.9053010122535962, 0.9023708044752264, 0.9190197123068726, 0.9015716568993074, 0.9107618540223761, 0.9015716568993074, 0.9063665423548215, 0.9094299413958444, 0.9026371870005327, 0.9087639850825786]
2022-01-27 02:19:55:INFO:Loss = [0.25015726502732705, 0.27357976738727635, 0.22288409089218064, 0.265633341527119, 0.22248802089529807, 0.2646965881257348, 0.2634122821735094, 0.2541661195192892, 0.26159494788200854, 0.2460094676092545]
2022-01-27 02:19:55:INFO:-------------Training local models-------------
2022-01-27 02:24:27:INFO:-------------Aggregating local models-------------
2022-01-27 02:24:32:INFO:-------------Round number: 29-------------
2022-01-27 02:24:32:INFO:-------------Sending models-------------
2022-01-27 02:24:32:INFO:-------------Evaluating models-------------
2022-01-27 02:24:33:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:24:33:INFO:Accuracy = [0.9047682472029834, 0.9030367607884923, 0.9188865210442195, 0.9017048481619606, 0.9110282365476825, 0.9014384656366542, 0.9063665423548215, 0.909829515183804, 0.9033031433137986, 0.9088971763452317]
2022-01-27 02:24:33:INFO:Loss = [0.24948577522004958, 0.2728204658342525, 0.22109483240631725, 0.2651790563834518, 0.22191384248156398, 0.2642715254611969, 0.26239923547088034, 0.2531984077743776, 0.2606477609522478, 0.24428735675610758]
2022-01-27 02:24:33:INFO:-------------Training local models-------------
2022-01-27 02:29:05:INFO:-------------Aggregating local models-------------
