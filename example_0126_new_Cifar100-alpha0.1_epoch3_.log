2022-01-27 00:27:37:INFO:-------------Round number: 0-------------
2022-01-27 00:27:37:INFO:-------------Sending models-------------
2022-01-27 00:27:37:INFO:-------------Evaluating models-------------
2022-01-27 00:27:37:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:27:37:INFO:Accuracy = [0.9006128430588862, 0.09725552891020517, 0.09885424993338662, 0.1035171862509992, 0.8815614175326405, 0.8822275512922995, 0.09938715694111377, 0.09845456967759127, 0.8987476685318412, 0.8994138022915001]
2022-01-27 00:27:37:INFO:Loss = [0.665433980252563, 0.7255395413985609, 0.7186639183939154, 0.7327777343910598, 0.6907469832258736, 0.6898914382135649, 0.7394655026930222, 0.7035869941961088, 0.6847941407736797, 0.6383327701998304]
2022-01-27 00:27:37:INFO:-------------Training local models-------------
2022-01-27 00:30:08:INFO:-------------Aggregating local models-------------
2022-01-27 00:30:10:INFO:-------------Round number: 1-------------
2022-01-27 00:30:10:INFO:-------------Sending models-------------
2022-01-27 00:30:10:INFO:-------------Evaluating models-------------
2022-01-27 00:30:11:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:30:11:INFO:Accuracy = [0.9006128430588862, 0.8779642952304823, 0.9385824673594457, 0.8531841193711698, 0.935251798561151, 0.8964828137490009, 0.8719690913935518, 0.9311217692512657, 0.9008792965627498, 0.9016786570743405]
2022-01-27 00:30:11:INFO:Loss = [0.33439748148889725, 0.4225000393309658, 0.2980188708318124, 0.3984101741281138, 0.31297802756886156, 0.45598730022450495, 0.3187688282997909, 0.3401578315338897, 0.3724010819219333, 0.3352682234576955]
2022-01-27 00:30:11:INFO:-------------Training local models-------------
2022-01-27 00:32:42:INFO:-------------Aggregating local models-------------
2022-01-27 00:32:45:INFO:-------------Round number: 2-------------
2022-01-27 00:32:45:INFO:-------------Sending models-------------
2022-01-27 00:32:45:INFO:-------------Evaluating models-------------
2022-01-27 00:32:45:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:32:45:INFO:Accuracy = [0.9100719424460432, 0.902611244337863, 0.9427124966693312, 0.9124700239808153, 0.9376498800959233, 0.8998134825472955, 0.9525712763122836, 0.9385824673594457, 0.9094058086863842, 0.913269384492406]
2022-01-27 00:32:45:INFO:Loss = [0.23271014533669965, 0.28571526069877, 0.1956702218754051, 0.2794673943034997, 0.19518282473280374, 0.31627247625202054, 0.174144731677077, 0.2206150138841993, 0.2359497243540484, 0.22918331806761105]
2022-01-27 00:32:45:INFO:-------------Training local models-------------
2022-01-27 00:35:17:INFO:-------------Aggregating local models-------------
2022-01-27 00:35:19:INFO:-------------Round number: 3-------------
2022-01-27 00:35:19:INFO:-------------Sending models-------------
2022-01-27 00:35:19:INFO:-------------Evaluating models-------------
2022-01-27 00:35:20:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:35:20:INFO:Accuracy = [0.9167332800426325, 0.907673860911271, 0.9437783106847855, 0.9177990940580869, 0.9376498800959233, 0.8998134825472955, 0.9682920330402345, 0.938449240607514, 0.9307220889954703, 0.9168665067945644]
2022-01-27 00:35:20:INFO:Loss = [0.20164867928304978, 0.2491060987133766, 0.1562094000542113, 0.24353382035843232, 0.15926322276438984, 0.2723074000871741, 0.12906053740443857, 0.1825527978310093, 0.20105102762744692, 0.19689580543487104]
2022-01-27 00:35:20:INFO:-------------Training local models-------------
2022-01-27 00:37:50:INFO:-------------Aggregating local models-------------
2022-01-27 00:37:53:INFO:-------------Round number: 4-------------
2022-01-27 00:37:53:INFO:-------------Sending models-------------
2022-01-27 00:37:53:INFO:-------------Evaluating models-------------
2022-01-27 00:37:54:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:37:54:INFO:Accuracy = [0.9223288036237677, 0.9116706634692247, 0.9460431654676259, 0.9184652278177458, 0.9376498800959233, 0.8998134825472955, 0.968558486544098, 0.9381827871036504, 0.9360511590727418, 0.9185984545696776]
2022-01-27 00:37:54:INFO:Loss = [0.1825008918138535, 0.2281813309097386, 0.13434372029495306, 0.22405851520277817, 0.14076027129079463, 0.24885549676901608, 0.10465948213996848, 0.16205769129144115, 0.1816238159273597, 0.17935783364838587]
2022-01-27 00:37:54:INFO:-------------Training local models-------------
2022-01-27 00:40:25:INFO:-------------Aggregating local models-------------
2022-01-27 00:40:27:INFO:-------------Round number: 5-------------
2022-01-27 00:40:27:INFO:-------------Sending models-------------
2022-01-27 00:40:28:INFO:-------------Evaluating models-------------
2022-01-27 00:40:28:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:40:28:INFO:Accuracy = [0.9293898214761525, 0.9144684252597922, 0.9539035438316014, 0.9213962163602452, 0.9376498800959233, 0.9004796163069544, 0.968558486544098, 0.9381827871036504, 0.9281907807087664, 0.9187316813216094]
2022-01-27 00:40:28:INFO:Loss = [0.16763190229138836, 0.2137793683688398, 0.11885241113695304, 0.21102299269509264, 0.12978470895197808, 0.2337016900666326, 0.0910974757398074, 0.14995641804678933, 0.16831002704356965, 0.16779181299690313]
2022-01-27 00:40:28:INFO:-------------Training local models-------------
2022-01-27 00:42:59:INFO:-------------Aggregating local models-------------
2022-01-27 00:43:02:INFO:-------------Round number: 6-------------
2022-01-27 00:43:02:INFO:-------------Sending models-------------
2022-01-27 00:43:02:INFO:-------------Evaluating models-------------
2022-01-27 00:43:02:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:43:02:INFO:Accuracy = [0.9332533972821743, 0.9177990940580869, 0.9588329336530775, 0.9257926991739941, 0.937783106847855, 0.9047428723687716, 0.968558486544098, 0.9381827871036504, 0.924593658406608, 0.918998134825473]
2022-01-27 00:43:02:INFO:Loss = [0.15613848087194832, 0.20287271409532237, 0.10611126034196353, 0.20215509501733148, 0.12198063138334635, 0.22272516116471364, 0.08253889022097353, 0.14201026287462384, 0.15915793473678452, 0.15860170688930042]
2022-01-27 00:43:02:INFO:-------------Training local models-------------
2022-01-27 00:45:33:INFO:-------------Aggregating local models-------------
2022-01-27 00:45:36:INFO:-------------Round number: 7-------------
2022-01-27 00:45:36:INFO:-------------Sending models-------------
2022-01-27 00:45:36:INFO:-------------Evaluating models-------------
2022-01-27 00:45:36:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:45:36:INFO:Accuracy = [0.9368505195843325, 0.918332001065814, 0.9612310151878497, 0.9269917399413802, 0.9415134559019451, 0.9123367972288836, 0.968558486544098, 0.9381827871036504, 0.9223288036237677, 0.9320543565147882]
2022-01-27 00:45:36:INFO:Loss = [0.1488839292455757, 0.19459876197969947, 0.09740117248079794, 0.19670176471286938, 0.11599107713109705, 0.21465187571559904, 0.07732318730678003, 0.13698882613607274, 0.15535678407314435, 0.15081540304863322]
2022-01-27 00:45:36:INFO:-------------Training local models-------------
2022-01-27 00:48:07:INFO:-------------Aggregating local models-------------
2022-01-27 00:48:10:INFO:-------------Round number: 8-------------
2022-01-27 00:48:10:INFO:-------------Sending models-------------
2022-01-27 00:48:10:INFO:-------------Evaluating models-------------
2022-01-27 00:48:11:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:48:11:INFO:Accuracy = [0.9401811883826272, 0.9173994138022915, 0.9620303756994405, 0.9269917399413802, 0.9475086597388755, 0.9140687450039968, 0.968558486544098, 0.9381827871036504, 0.9217958966160406, 0.9392486011191047]
2022-01-27 00:48:11:INFO:Loss = [0.14497800310755712, 0.18815098033542726, 0.09201418974925932, 0.19323125901519597, 0.11104646108185877, 0.20815249021077475, 0.07425280283488107, 0.13361538427024772, 0.15561296672965014, 0.14369276210943263]
2022-01-27 00:48:11:INFO:-------------Training local models-------------
2022-01-27 00:50:42:INFO:-------------Aggregating local models-------------
2022-01-27 00:50:44:INFO:-------------Round number: 9-------------
2022-01-27 00:50:44:INFO:-------------Sending models-------------
2022-01-27 00:50:44:INFO:-------------Evaluating models-------------
2022-01-27 00:50:45:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:50:45:INFO:Accuracy = [0.9349853450572875, 0.9179323208100186, 0.9626965094590993, 0.927124966693312, 0.9521715960564882, 0.9140687450039968, 0.968558486544098, 0.9383160138555822, 0.9224620303756994, 0.9453770317079669]
2022-01-27 00:50:45:INFO:Loss = [0.14295848048614204, 0.18306992515851364, 0.08841814068086803, 0.1905966517555263, 0.1072356954978387, 0.20234952137166276, 0.07233889879333551, 0.13098680430280887, 0.15656730500891752, 0.1369385124603603]
2022-01-27 00:50:45:INFO:-------------Training local models-------------
2022-01-27 00:53:16:INFO:-------------Aggregating local models-------------
2022-01-27 00:53:18:INFO:-------------Round number: 10-------------
2022-01-27 00:53:18:INFO:-------------Sending models-------------
2022-01-27 00:53:18:INFO:-------------Evaluating models-------------
2022-01-27 00:53:19:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:53:19:INFO:Accuracy = [0.9317879030109246, 0.9176658673061551, 0.9624300559552358, 0.9279243272049027, 0.9532374100719424, 0.918332001065814, 0.968558486544098, 0.9387156941113776, 0.9239275246469492, 0.9509725552891021]
2022-01-27 00:53:19:INFO:Loss = [0.14153741461606328, 0.1788099528561874, 0.08575258155608749, 0.188196951824093, 0.10464708532036945, 0.19685827756150187, 0.07102083176444042, 0.12869833501134872, 0.1563239246125718, 0.13043433345271493]
2022-01-27 00:53:19:INFO:-------------Training local models-------------
2022-01-27 00:55:49:INFO:-------------Aggregating local models-------------
2022-01-27 00:55:52:INFO:-------------Round number: 11-------------
2022-01-27 00:55:52:INFO:-------------Sending models-------------
2022-01-27 00:55:52:INFO:-------------Evaluating models-------------
2022-01-27 00:55:53:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:55:53:INFO:Accuracy = [0.9309885424993338, 0.9193978150812683, 0.9628297362110312, 0.9276578737010391, 0.9533706368238742, 0.9220623501199041, 0.968558486544098, 0.9399147348787636, 0.9260591526778578, 0.9535038635758061]
2022-01-27 00:55:53:INFO:Loss = [0.1404388880341187, 0.17499753405021012, 0.08357087403002218, 0.18581203425704274, 0.10281693927259483, 0.19168380345056582, 0.06999502038925488, 0.1265743585501825, 0.1553711284309743, 0.12444156521887771]
2022-01-27 00:55:53:INFO:-------------Training local models-------------
2022-01-27 00:58:24:INFO:-------------Aggregating local models-------------
2022-01-27 00:58:26:INFO:-------------Round number: 12-------------
2022-01-27 00:58:26:INFO:-------------Sending models-------------
2022-01-27 00:58:26:INFO:-------------Evaluating models-------------
2022-01-27 00:58:27:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:58:27:INFO:Accuracy = [0.9315214495070611, 0.9244604316546763, 0.9649613642419398, 0.9281907807087664, 0.9549693578470557, 0.9231281641353584, 0.968558486544098, 0.9421795896616041, 0.926458832933653, 0.955369038102851]
2022-01-27 00:58:27:INFO:Loss = [0.1398661875097462, 0.17134024873167134, 0.08170772426154144, 0.18325868717398738, 0.10137929667074841, 0.18711638435081904, 0.06911461273639707, 0.12448947164818173, 0.15511188719138358, 0.11925873320442618]
2022-01-27 00:58:27:INFO:-------------Training local models-------------
2022-01-27 01:00:58:INFO:-------------Aggregating local models-------------
2022-01-27 01:01:00:INFO:-------------Round number: 13-------------
2022-01-27 01:01:00:INFO:-------------Sending models-------------
2022-01-27 01:01:01:INFO:-------------Evaluating models-------------
2022-01-27 01:01:01:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:01:01:INFO:Accuracy = [0.9299227284838796, 0.9276578737010391, 0.967359445776712, 0.9285904609645617, 0.9551025845989874, 0.9237942978950173, 0.9689581667998934, 0.9441779909405809, 0.9267252864375166, 0.9559019451105782]
2022-01-27 01:01:01:INFO:Loss = [0.13964245362968383, 0.16782808425200557, 0.08003081253069454, 0.18067516965043925, 0.10015815205142733, 0.1831682320004128, 0.06831823033228714, 0.12238372290052092, 0.15498674788391686, 0.11507868496927873]
2022-01-27 01:01:01:INFO:-------------Training local models-------------
2022-01-27 01:03:31:INFO:-------------Aggregating local models-------------
2022-01-27 01:03:34:INFO:-------------Round number: 14-------------
2022-01-27 01:03:34:INFO:-------------Sending models-------------
2022-01-27 01:03:34:INFO:-------------Evaluating models-------------
2022-01-27 01:03:35:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:03:35:INFO:Accuracy = [0.9295230482280842, 0.9291233679722888, 0.9686917132960299, 0.9287236877164935, 0.9555022648547828, 0.9247268851585398, 0.9700239808153477, 0.9475086597388755, 0.9267252864375166, 0.95603517186251]
2022-01-27 01:03:35:INFO:Loss = [0.1391688492236744, 0.1645236395770245, 0.07847319634671539, 0.17799268785860453, 0.09897863405572305, 0.17991149496675654, 0.0675647643495984, 0.12024705307871783, 0.15534475185554633, 0.11173374785430536]
2022-01-27 01:03:35:INFO:-------------Training local models-------------
2022-01-27 01:06:04:INFO:-------------Aggregating local models-------------
2022-01-27 01:06:07:INFO:-------------Round number: 15-------------
2022-01-27 01:06:07:INFO:-------------Sending models-------------
2022-01-27 01:06:07:INFO:-------------Evaluating models-------------
2022-01-27 01:06:08:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:06:08:INFO:Accuracy = [0.9301891819877431, 0.9307220889954703, 0.9700239808153477, 0.9304556354916067, 0.9559019451105782, 0.9256594724220624, 0.9704236610711431, 0.951638689048761, 0.9267252864375166, 0.9568345323741008]
2022-01-27 01:06:08:INFO:Loss = [0.13866435408426986, 0.1615021986998032, 0.0769804758962576, 0.1752508520949767, 0.09786647409892088, 0.17701063891530933, 0.06685241266984325, 0.11808103339861924, 0.15564035628445516, 0.10864493827312086]
2022-01-27 01:06:08:INFO:-------------Training local models-------------
2022-01-27 01:08:36:INFO:-------------Aggregating local models-------------
2022-01-27 01:08:39:INFO:-------------Round number: 16-------------
2022-01-27 01:08:39:INFO:-------------Sending models-------------
2022-01-27 01:08:39:INFO:-------------Evaluating models-------------
2022-01-27 01:08:40:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:08:40:INFO:Accuracy = [0.9309885424993338, 0.9317879030109246, 0.971089794830802, 0.9328537170263789, 0.9564348521183054, 0.9269917399413802, 0.9712230215827338, 0.9535038635758061, 0.9267252864375166, 0.9576338928856915]
2022-01-27 01:08:40:INFO:Loss = [0.13783461989929296, 0.15857210570940194, 0.07566531899100956, 0.17254412778295677, 0.09677160112038374, 0.17441242825710893, 0.06620244189627596, 0.1159962449967917, 0.15596052597986834, 0.10569883360459648]
2022-01-27 01:08:40:INFO:-------------Training local models-------------
2022-01-27 01:11:08:INFO:-------------Aggregating local models-------------
2022-01-27 01:11:10:INFO:-------------Round number: 17-------------
2022-01-27 01:11:10:INFO:-------------Sending models-------------
2022-01-27 01:11:11:INFO:-------------Evaluating models-------------
2022-01-27 01:11:11:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:11:11:INFO:Accuracy = [0.9317879030109246, 0.934052757793765, 0.971089794830802, 0.9343192112976285, 0.9565680788702371, 0.9273914201971756, 0.9720223820943246, 0.9548361310951239, 0.927124966693312, 0.9590993871569411]
2022-01-27 01:11:11:INFO:Loss = [0.1371418729231785, 0.15581337716105653, 0.07463734059202116, 0.1698896477984547, 0.09579077866475591, 0.17200573902336638, 0.06557177628113396, 0.11413987666672039, 0.15596268613982786, 0.10296306332665717]
2022-01-27 01:11:11:INFO:-------------Training local models-------------
2022-01-27 01:13:40:INFO:-------------Aggregating local models-------------
2022-01-27 01:13:43:INFO:-------------Round number: 18-------------
2022-01-27 01:13:43:INFO:-------------Sending models-------------
2022-01-27 01:13:43:INFO:-------------Evaluating models-------------
2022-01-27 01:13:43:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:13:43:INFO:Accuracy = [0.9319211297628563, 0.9341859845456968, 0.9712230215827338, 0.9345856648014922, 0.9568345323741008, 0.9283240074606981, 0.9724220623501199, 0.9555022648547828, 0.9273914201971756, 0.961097788435918]
2022-01-27 01:13:43:INFO:Loss = [0.13664701937277765, 0.15301189295093096, 0.07381019110063146, 0.1673009966865332, 0.09502976349217125, 0.16974692986977527, 0.06496959211084051, 0.11248152070915944, 0.15548879568113264, 0.10002407161248986]
2022-01-27 01:13:43:INFO:-------------Training local models-------------
2022-01-27 01:16:12:INFO:-------------Aggregating local models-------------
2022-01-27 01:16:15:INFO:-------------Round number: 19-------------
2022-01-27 01:16:15:INFO:-------------Sending models-------------
2022-01-27 01:16:15:INFO:-------------Evaluating models-------------
2022-01-27 01:16:15:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:16:15:INFO:Accuracy = [0.9325872635225153, 0.9360511590727418, 0.9708233413269385, 0.9345856648014922, 0.9573674393818279, 0.929656274980016, 0.9730881961097788, 0.9571009858779643, 0.927791100452971, 0.9629629629629629]
2022-01-27 01:16:15:INFO:Loss = [0.13619000724357183, 0.15044844119903927, 0.07309378653795139, 0.16473295776505115, 0.09428922555798756, 0.16778838456583042, 0.06438945500758587, 0.11099255704760355, 0.15507108071734607, 0.09753458231952203]
2022-01-27 01:16:15:INFO:-------------Training local models-------------
2022-01-27 01:18:44:INFO:-------------Aggregating local models-------------
2022-01-27 01:18:46:INFO:-------------Round number: 20-------------
2022-01-27 01:18:46:INFO:-------------Sending models-------------
2022-01-27 01:18:46:INFO:-------------Evaluating models-------------
2022-01-27 01:18:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:18:47:INFO:Accuracy = [0.9337863042899014, 0.9373834265920596, 0.9709565680788702, 0.9355182520650147, 0.9583000266453504, 0.9305888622435385, 0.9730881961097788, 0.9576338928856915, 0.9287236877164935, 0.9653610444977352]
2022-01-27 01:18:47:INFO:Loss = [0.1357152150618902, 0.14814822052037116, 0.07247409143889558, 0.1621863158068272, 0.09362622357802408, 0.1661539323790381, 0.06383120106556466, 0.10965423878271793, 0.1546107890234938, 0.09519534615563247]
2022-01-27 01:18:47:INFO:-------------Training local models-------------
2022-01-27 01:21:16:INFO:-------------Aggregating local models-------------
2022-01-27 01:21:18:INFO:-------------Round number: 21-------------
2022-01-27 01:21:18:INFO:-------------Sending models-------------
2022-01-27 01:21:19:INFO:-------------Evaluating models-------------
2022-01-27 01:21:19:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:21:19:INFO:Accuracy = [0.934052757793765, 0.938449240607514, 0.9714894750865974, 0.9364508393285371, 0.957900346389555, 0.9316546762589928, 0.9732214228617106, 0.9577671196376233, 0.9300559552358113, 0.9661604050093259]
2022-01-27 01:21:19:INFO:Loss = [0.13533210632291826, 0.14602175477562798, 0.07183716798634791, 0.15970424472675107, 0.09296460694565198, 0.1646267206163512, 0.06327744229321544, 0.10840594766611056, 0.15341613658731254, 0.09319339931845416]
2022-01-27 01:21:19:INFO:-------------Training local models-------------
2022-01-27 01:23:48:INFO:-------------Aggregating local models-------------
2022-01-27 01:23:50:INFO:-------------Round number: 22-------------
2022-01-27 01:23:50:INFO:-------------Sending models-------------
2022-01-27 01:23:51:INFO:-------------Evaluating models-------------
2022-01-27 01:23:51:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:23:51:INFO:Accuracy = [0.9348521183053558, 0.940314415134559, 0.9721556088462563, 0.9376498800959233, 0.9586997069011457, 0.9325872635225153, 0.9738875566213696, 0.958566480149214, 0.9308553157474021, 0.9672262190247801]
2022-01-27 01:23:51:INFO:Loss = [0.13530986492239924, 0.14397537399435228, 0.07130833652330179, 0.1572192889177989, 0.09231283157858494, 0.16342962174528708, 0.06273435574708301, 0.10726941491308074, 0.15269328168179364, 0.09108135074640507]
2022-01-27 01:23:51:INFO:-------------Training local models-------------
2022-01-27 01:26:19:INFO:-------------Aggregating local models-------------
2022-01-27 01:26:22:INFO:-------------Round number: 23-------------
2022-01-27 01:26:22:INFO:-------------Sending models-------------
2022-01-27 01:26:22:INFO:-------------Evaluating models-------------
2022-01-27 01:26:23:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:26:23:INFO:Accuracy = [0.9344524380495604, 0.9413802291500133, 0.9725552891020517, 0.9385824673594457, 0.9583000266453504, 0.9317879030109246, 0.9740207833733013, 0.9592326139088729, 0.9319211297628563, 0.9672262190247801]
2022-01-27 01:26:23:INFO:Loss = [0.1354065920041471, 0.14211447513619627, 0.07080795208198071, 0.1548157848828051, 0.0917589467977121, 0.16250590844801174, 0.06219514929906757, 0.106241600518667, 0.1522241298757999, 0.08915719645937667]
2022-01-27 01:26:23:INFO:-------------Training local models-------------
2022-01-27 01:28:52:INFO:-------------Aggregating local models-------------
2022-01-27 01:28:54:INFO:-------------Round number: 24-------------
2022-01-27 01:28:54:INFO:-------------Sending models-------------
2022-01-27 01:28:54:INFO:-------------Evaluating models-------------
2022-01-27 01:28:55:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:28:55:INFO:Accuracy = [0.935251798561151, 0.9428457234212629, 0.9730881961097788, 0.9393818278710365, 0.9589661604050094, 0.9316546762589928, 0.9741540101252332, 0.9593658406608047, 0.9327204902744471, 0.9682920330402345]
2022-01-27 01:28:55:INFO:Loss = [0.13545146711537817, 0.14044031040723018, 0.07037366567043123, 0.1525623313323232, 0.09119650315838869, 0.16185296173195365, 0.06165021721354869, 0.10527577153751196, 0.15149327026085208, 0.08746968429758144]
2022-01-27 01:28:55:INFO:-------------Training local models-------------
2022-01-27 01:31:24:INFO:-------------Aggregating local models-------------
2022-01-27 01:31:26:INFO:-------------Round number: 25-------------
2022-01-27 01:31:26:INFO:-------------Sending models-------------
2022-01-27 01:31:26:INFO:-------------Evaluating models-------------
2022-01-27 01:31:27:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:31:27:INFO:Accuracy = [0.9351185718092193, 0.9431121769251266, 0.9730881961097788, 0.9412470023980816, 0.9597655209166001, 0.9321875832667199, 0.9742872368771649, 0.960431654676259, 0.9323208100186517, 0.9688249400479616]
2022-01-27 01:31:27:INFO:Loss = [0.13532032461013543, 0.139016396401003, 0.06997129437259873, 0.15045435571434393, 0.09064577618213877, 0.1615134366851823, 0.06117253283491555, 0.10440306412768756, 0.15069660450069722, 0.08601950498057194]
2022-01-27 01:31:27:INFO:-------------Training local models-------------
2022-01-27 01:33:56:INFO:-------------Aggregating local models-------------
2022-01-27 01:33:58:INFO:-------------Round number: 26-------------
2022-01-27 01:33:58:INFO:-------------Sending models-------------
2022-01-27 01:33:58:INFO:-------------Evaluating models-------------
2022-01-27 01:33:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:33:59:INFO:Accuracy = [0.9351185718092193, 0.9433786304289902, 0.9733546496136424, 0.9431121769251266, 0.960431654676259, 0.9324540367705836, 0.9749533706368239, 0.9609645616839861, 0.9329869437783107, 0.9688249400479616]
2022-01-27 01:33:59:INFO:Loss = [0.13513056174832103, 0.13784865957500003, 0.06960144347427465, 0.14848913919752077, 0.09014003037950823, 0.1611588957967023, 0.06072690460557399, 0.1035728069938328, 0.15029985906860066, 0.08473179174818209]
2022-01-27 01:33:59:INFO:-------------Training local models-------------
2022-01-27 01:36:27:INFO:-------------Aggregating local models-------------
2022-01-27 01:36:30:INFO:-------------Round number: 27-------------
2022-01-27 01:36:30:INFO:-------------Sending models-------------
2022-01-27 01:36:30:INFO:-------------Evaluating models-------------
2022-01-27 01:36:30:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:36:30:INFO:Accuracy = [0.9353850253130829, 0.944710897948308, 0.9737543298694378, 0.9441779909405809, 0.9609645616839861, 0.9327204902744471, 0.9757527311484147, 0.9614974686917133, 0.9336530775379697, 0.9693578470556888]
2022-01-27 01:36:30:INFO:Loss = [0.13534973495924973, 0.1368231888778077, 0.06925848327595059, 0.14671932662795767, 0.0896290227367485, 0.1611167071286359, 0.060311277959844874, 0.1028350113375393, 0.14991800237413894, 0.0836656395926227]
2022-01-27 01:36:30:INFO:-------------Training local models-------------
2022-01-27 01:38:59:INFO:-------------Aggregating local models-------------
2022-01-27 01:39:02:INFO:-------------Round number: 28-------------
2022-01-27 01:39:02:INFO:-------------Sending models-------------
2022-01-27 01:39:02:INFO:-------------Evaluating models-------------
2022-01-27 01:39:02:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:39:02:INFO:Accuracy = [0.93591793232081, 0.9451105782041034, 0.9738875566213696, 0.9448441247002398, 0.9608313349320543, 0.9325872635225153, 0.9760191846522782, 0.9617639221955768, 0.9343192112976285, 0.9700239808153477]
2022-01-27 01:39:02:INFO:Loss = [0.13562311433889349, 0.13587345585697172, 0.06894835342675452, 0.14501923032440575, 0.08912724385233843, 0.1610510564263049, 0.05992138178804766, 0.10219629875714564, 0.1494402299605675, 0.08246540993923736]
2022-01-27 01:39:02:INFO:-------------Training local models-------------
2022-01-27 01:41:31:INFO:-------------Aggregating local models-------------
2022-01-27 01:41:34:INFO:-------------Round number: 29-------------
2022-01-27 01:41:34:INFO:-------------Sending models-------------
2022-01-27 01:41:34:INFO:-------------Evaluating models-------------
2022-01-27 01:41:34:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:41:34:INFO:Accuracy = [0.9363176125766054, 0.9457767119637623, 0.9738875566213696, 0.9443112176925127, 0.961097788435918, 0.9335198507860378, 0.9762856381561418, 0.9617639221955768, 0.9351185718092193, 0.9701572075672795]
2022-01-27 01:41:34:INFO:Loss = [0.1359935623901169, 0.13506147162220358, 0.06870142423792298, 0.1435833462280885, 0.08862373392087834, 0.16108992265467215, 0.05957213296912356, 0.10169206903476419, 0.1493968583249166, 0.08164896986225348]
2022-01-27 01:41:34:INFO:-------------Training local models-------------
2022-01-27 01:44:03:INFO:-------------Aggregating local models-------------
