2022-01-26 19:47:34:INFO:-------------Round number: 0-------------
2022-01-26 19:47:34:INFO:-------------Sending models-------------
2022-01-26 19:47:35:INFO:-------------Evaluating models-------------
2022-01-26 19:47:35:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 19:47:35:INFO:Accuracy = [0.8999800093289798, 0.10001999067102019, 0.09988671953088558, 0.09995335510095289, 0.87552475511428, 0.883254481242087, 0.1000866262410875, 0.1000866262410875, 0.8999800093289798, 0.9001132804691144]
2022-01-26 19:47:35:INFO:Loss = [0.6656848083467369, 0.7252451019759911, 0.7189095253160207, 0.7331641170847795, 0.6908848814955716, 0.6900490836751781, 0.739565224231914, 0.7032630279418939, 0.684827916438824, 0.6384259511606757]
2022-01-26 19:47:35:INFO:-------------Training local models-------------
2022-01-26 19:52:35:INFO:-------------Aggregating local models-------------
2022-01-26 19:52:37:INFO:-------------Round number: 1-------------
2022-01-26 19:52:37:INFO:-------------Sending models-------------
2022-01-26 19:52:37:INFO:-------------Evaluating models-------------
2022-01-26 19:52:38:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 19:52:38:INFO:Accuracy = [0.9105084293996135, 0.8999800093289798, 0.9001132804691144, 0.9074431931765177, 0.8999133737589126, 0.9000466448990471, 0.8999133737589126, 0.8999133737589126, 0.8999800093289798, 0.9001132804691144]
2022-01-26 19:52:38:INFO:Loss = [0.27451896291798833, 0.34584630731605687, 0.28294621644530576, 0.30070588179242963, 0.28370081795527347, 0.3145046650210561, 0.32402325109637314, 0.3013997075439667, 0.30732635141139886, 0.3023243969853836]
2022-01-26 19:52:38:INFO:-------------Training local models-------------
2022-01-26 19:57:39:INFO:-------------Aggregating local models-------------
2022-01-26 19:57:41:INFO:-------------Round number: 2-------------
2022-01-26 19:57:41:INFO:-------------Sending models-------------
2022-01-26 19:57:41:INFO:-------------Evaluating models-------------
2022-01-26 19:57:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 19:57:42:INFO:Accuracy = [0.9105084293996135, 0.8999800093289798, 0.9001132804691144, 0.9074431931765177, 0.8999133737589126, 0.9000466448990471, 0.8999133737589126, 0.8999133737589126, 0.8999800093289798, 0.9001132804691144]
2022-01-26 19:57:42:INFO:Loss = [0.2516892640333554, 0.29750606435032523, 0.26860401058061784, 0.26571456507640706, 0.2770433063311211, 0.28005085237030825, 0.28286664237605186, 0.26893173785934943, 0.2700560538357872, 0.24958915780404844]
2022-01-26 19:57:42:INFO:-------------Training local models-------------
2022-01-26 20:02:42:INFO:-------------Aggregating local models-------------
2022-01-26 20:02:45:INFO:-------------Round number: 3-------------
2022-01-26 20:02:45:INFO:-------------Sending models-------------
2022-01-26 20:02:45:INFO:-------------Evaluating models-------------
2022-01-26 20:02:46:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:02:46:INFO:Accuracy = [0.9105084293996135, 0.8999800093289798, 0.9001132804691144, 0.9074431931765177, 0.8999133737589126, 0.9000466448990471, 0.8999133737589126, 0.8999133737589126, 0.8999800093289798, 0.9001132804691144]
2022-01-26 20:02:46:INFO:Loss = [0.24847002307856283, 0.2914102152657694, 0.26858196154839015, 0.26334381874042784, 0.2762237191994614, 0.27720428188475715, 0.27799475166114807, 0.2641100234412808, 0.26580477684286696, 0.24052225716226883]
2022-01-26 20:02:46:INFO:-------------Training local models-------------
2022-01-26 20:07:46:INFO:-------------Aggregating local models-------------
2022-01-26 20:07:48:INFO:-------------Round number: 4-------------
2022-01-26 20:07:48:INFO:-------------Sending models-------------
2022-01-26 20:07:49:INFO:-------------Evaluating models-------------
2022-01-26 20:07:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:07:49:INFO:Accuracy = [0.9136403011927767, 0.8999800093289798, 0.9001132804691144, 0.9074431931765177, 0.8999133737589126, 0.9000466448990471, 0.8999133737589126, 0.9000466448990471, 0.8999800093289798, 0.9028453388418738]
2022-01-26 20:07:49:INFO:Loss = [0.24595972970639426, 0.2889756996289095, 0.2676140279088676, 0.26248600300392266, 0.275094332366595, 0.2760681305126576, 0.27366630761907923, 0.26179317634101174, 0.2610268442324441, 0.23311040030916846]
2022-01-26 20:07:49:INFO:-------------Training local models-------------
2022-01-26 20:12:50:INFO:-------------Aggregating local models-------------
2022-01-26 20:12:52:INFO:-------------Round number: 5-------------
2022-01-26 20:12:52:INFO:-------------Sending models-------------
2022-01-26 20:12:53:INFO:-------------Evaluating models-------------
2022-01-26 20:12:53:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:12:53:INFO:Accuracy = [0.9178383421070168, 0.8999800093289798, 0.9001132804691144, 0.9074431931765177, 0.8999133737589126, 0.9000466448990471, 0.8998467381888452, 0.9011128140201239, 0.9029786099820084, 0.911707869660825]
2022-01-26 20:12:53:INFO:Loss = [0.2429729567105542, 0.2869892523808257, 0.2661483978749984, 0.2616891660252497, 0.2737235017774942, 0.2751615918731399, 0.26842107673462906, 0.2599953563645345, 0.2549637536143252, 0.2244550160975361]
2022-01-26 20:12:53:INFO:-------------Training local models-------------
2022-01-26 20:17:54:INFO:-------------Aggregating local models-------------
2022-01-26 20:17:56:INFO:-------------Round number: 6-------------
2022-01-26 20:17:56:INFO:-------------Sending models-------------
2022-01-26 20:17:56:INFO:-------------Evaluating models-------------
2022-01-26 20:17:57:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:17:57:INFO:Accuracy = [0.9174385286866129, 0.8999800093289798, 0.9001132804691144, 0.9076430998867195, 0.8999133737589126, 0.9000466448990471, 0.9037116012527487, 0.9034450589724795, 0.8999133737589126, 0.91503964816419]
2022-01-26 20:17:57:INFO:Loss = [0.2394419429788879, 0.28431398081863485, 0.26421433987253956, 0.26049725595518364, 0.2720167649268286, 0.27418294436685997, 0.26321903815151787, 0.25804857907650075, 0.24903294336354032, 0.2159126444348835]
2022-01-26 20:17:57:INFO:-------------Training local models-------------
2022-01-26 20:22:58:INFO:-------------Aggregating local models-------------
2022-01-26 20:23:00:INFO:-------------Round number: 7-------------
2022-01-26 20:23:00:INFO:-------------Sending models-------------
2022-01-26 20:23:01:INFO:-------------Evaluating models-------------
2022-01-26 20:23:01:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:23:01:INFO:Accuracy = [0.9177050709668821, 0.9000466448990471, 0.9001132804691144, 0.9121076830812288, 0.8999133737589126, 0.9000466448990471, 0.9042446858132871, 0.9055773972146332, 0.8983141200772973, 0.9185713333777571]
2022-01-26 20:23:01:INFO:Loss = [0.23552754551828595, 0.28007561165983164, 0.2618716871032647, 0.2585501776760063, 0.26992608144921043, 0.27297518367088397, 0.2589820306007165, 0.25584704198376756, 0.24479007390067722, 0.2090208071758501]
2022-01-26 20:23:01:INFO:-------------Training local models-------------
2022-01-26 20:28:00:INFO:-------------Aggregating local models-------------
2022-01-26 20:28:03:INFO:-------------Round number: 8-------------
2022-01-26 20:28:03:INFO:-------------Sending models-------------
2022-01-26 20:28:03:INFO:-------------Evaluating models-------------
2022-01-26 20:28:04:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:28:04:INFO:Accuracy = [0.9184380622376225, 0.9024455254214699, 0.9015792630105951, 0.9159725461451322, 0.8999133737589126, 0.9000466448990471, 0.9045112280935563, 0.9061771173452389, 0.9003798227493837, 0.9208369427600454]
2022-01-26 20:28:04:INFO:Loss = [0.23143192186495876, 0.27364604994371666, 0.2594098375103968, 0.2556055746394169, 0.2675379761029562, 0.27145649819420314, 0.2552558302821246, 0.2534276409062066, 0.24160174748950533, 0.20368389449538574]
2022-01-26 20:28:04:INFO:-------------Training local models-------------
2022-01-26 20:33:03:INFO:-------------Aggregating local models-------------
2022-01-26 20:33:06:INFO:-------------Round number: 9-------------
2022-01-26 20:33:06:INFO:-------------Sending models-------------
2022-01-26 20:33:06:INFO:-------------Evaluating models-------------
2022-01-26 20:33:07:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:33:07:INFO:Accuracy = [0.9193043246484973, 0.9076430998867195, 0.9026454321316719, 0.9169720796961418, 0.8999133737589126, 0.9013127207303259, 0.9043113213833545, 0.9063770240554408, 0.9018458052908642, 0.9225028320117279]
2022-01-26 20:33:07:INFO:Loss = [0.22753654769669884, 0.26539392450079297, 0.2570552108479818, 0.2519193135567832, 0.2650631263890844, 0.26959354793508294, 0.2515774739681165, 0.2508052647019594, 0.23777699756259243, 0.19923990699938587]
2022-01-26 20:33:07:INFO:-------------Training local models-------------
2022-01-26 20:38:07:INFO:-------------Aggregating local models-------------
2022-01-26 20:38:09:INFO:-------------Round number: 10-------------
2022-01-26 20:38:09:INFO:-------------Sending models-------------
2022-01-26 20:38:10:INFO:-------------Evaluating models-------------
2022-01-26 20:38:10:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:38:10:INFO:Accuracy = [0.9191710535083628, 0.9085093622975945, 0.9027120677017392, 0.9185046978076897, 0.9013127207303259, 0.9016458985806624, 0.9051775837942294, 0.9067102019057773, 0.9041114146731525, 0.9232358232824682]
2022-01-26 20:38:10:INFO:Loss = [0.22414469437966236, 0.2568388144279802, 0.2547243831074396, 0.2482007346754906, 0.2626680792552926, 0.2673887567639454, 0.24768943360239562, 0.24803396908013037, 0.2328712303907928, 0.19520083996205712]
2022-01-26 20:38:10:INFO:-------------Training local models-------------
2022-01-26 20:43:10:INFO:-------------Aggregating local models-------------
2022-01-26 20:43:13:INFO:-------------Round number: 11-------------
2022-01-26 20:43:13:INFO:-------------Sending models-------------
2022-01-26 20:43:13:INFO:-------------Evaluating models-------------
2022-01-26 20:43:14:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:43:14:INFO:Accuracy = [0.920103951489305, 0.9100419804091424, 0.9025787965616046, 0.9190377823682282, 0.9025121609915373, 0.9037116012527487, 0.9061771173452389, 0.9070433797561138, 0.9067768374758446, 0.9242353568334777]
2022-01-26 20:43:14:INFO:Loss = [0.22111053276836112, 0.24944276632615114, 0.2524935977964523, 0.2450470962005182, 0.2605315199458318, 0.26492431397904975, 0.2438594105736562, 0.24522928899028892, 0.22734502099053253, 0.19124104980207252]
2022-01-26 20:43:14:INFO:-------------Training local models-------------
2022-01-26 20:48:14:INFO:-------------Aggregating local models-------------
2022-01-26 20:48:17:INFO:-------------Round number: 12-------------
2022-01-26 20:48:17:INFO:-------------Sending models-------------
2022-01-26 20:48:17:INFO:-------------Evaluating models-------------
2022-01-26 20:48:17:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:48:17:INFO:Accuracy = [0.9207036716199107, 0.9109748783900846, 0.9026454321316719, 0.9197041380689012, 0.9037116012527487, 0.9033117878323449, 0.9084427267275271, 0.9077097354567868, 0.9091757179982675, 0.9259678816552276]
2022-01-26 20:48:17:INFO:Loss = [0.21829920903281666, 0.24338423716418328, 0.25031718920176327, 0.24244938193217636, 0.25866954342179194, 0.26213303495610807, 0.2402171003659243, 0.24235664299353368, 0.22179967792425093, 0.1873198857629486]
2022-01-26 20:48:17:INFO:-------------Training local models-------------
2022-01-26 20:53:18:INFO:-------------Aggregating local models-------------
2022-01-26 20:53:20:INFO:-------------Round number: 13-------------
2022-01-26 20:53:20:INFO:-------------Sending models-------------
2022-01-26 20:53:20:INFO:-------------Evaluating models-------------
2022-01-26 20:53:21:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:53:21:INFO:Accuracy = [0.9211701206103818, 0.9125074965016325, 0.9039115079629506, 0.9204371293396415, 0.9038448723928834, 0.9045778636636237, 0.9114413273805557, 0.9081761844472579, 0.9121743186512961, 0.927167321916439]
2022-01-26 20:53:21:INFO:Loss = [0.2156621111432645, 0.2383761498513584, 0.24820407943211398, 0.2404140756564355, 0.25712211238036764, 0.2590674926698935, 0.23694185926982014, 0.23941918982940316, 0.21661492027126197, 0.18341126770010174]
2022-01-26 20:53:21:INFO:-------------Training local models-------------
2022-01-26 20:58:21:INFO:-------------Aggregating local models-------------
2022-01-26 20:58:24:INFO:-------------Round number: 14-------------
2022-01-26 20:58:24:INFO:-------------Sending models-------------
2022-01-26 20:58:24:INFO:-------------Evaluating models-------------
2022-01-26 20:58:25:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:58:25:INFO:Accuracy = [0.9213033917505165, 0.9143066568934497, 0.9050443126540948, 0.9208369427600454, 0.9047111348037582, 0.9057106683547678, 0.9138402079029786, 0.9098420736989405, 0.9147731058839208, 0.9273005930565736]
2022-01-26 20:58:25:INFO:Loss = [0.21316520890745153, 0.23400973234065744, 0.24613890308493808, 0.23877176560698338, 0.255842710184428, 0.2558682086465638, 0.23405523638036135, 0.2364484742647488, 0.2120189331760185, 0.17965090523312938]
2022-01-26 20:58:25:INFO:-------------Training local models-------------
2022-01-26 21:03:25:INFO:-------------Aggregating local models-------------
2022-01-26 21:03:28:INFO:-------------Round number: 15-------------
2022-01-26 21:03:28:INFO:-------------Sending models-------------
2022-01-26 21:03:28:INFO:-------------Evaluating models-------------
2022-01-26 21:03:29:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:03:29:INFO:Accuracy = [0.9231025521423336, 0.9161724528553342, 0.9056440327847005, 0.9211034850403145, 0.9045778636636237, 0.9069101086159792, 0.9157060038648631, 0.9113080562404211, 0.9163057239954688, 0.9286333044579196]
2022-01-26 21:03:29:INFO:Loss = [0.21078244727242673, 0.2300711168622793, 0.24417845972173774, 0.23747951111967205, 0.2548283820815085, 0.25280391219254933, 0.23138778507543184, 0.23351309295164877, 0.20807377509635627, 0.17613337002471968]
2022-01-26 21:03:29:INFO:-------------Training local models-------------
2022-01-26 21:08:29:INFO:-------------Aggregating local models-------------
2022-01-26 21:08:32:INFO:-------------Round number: 16-------------
2022-01-26 21:08:32:INFO:-------------Sending models-------------
2022-01-26 21:08:32:INFO:-------------Evaluating models-------------
2022-01-26 21:08:33:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:08:33:INFO:Accuracy = [0.923635636702872, 0.9164389951356033, 0.9056440327847005, 0.9212367561804491, 0.9049776770840274, 0.9077097354567868, 0.9175717998267475, 0.9121076830812288, 0.9169054441260746, 0.929166389018458]
2022-01-26 21:08:33:INFO:Loss = [0.20857644617059065, 0.2263624729099477, 0.24230724880862178, 0.2363233880385704, 0.25400257333351034, 0.2499604949518763, 0.22912972887300642, 0.23059766353707947, 0.20471815234665472, 0.17299849960242325]
2022-01-26 21:08:33:INFO:-------------Training local models-------------
2022-01-26 21:15:46:INFO:-------------Aggregating local models-------------
2022-01-26 21:15:50:INFO:-------------Round number: 17-------------
2022-01-26 21:15:50:INFO:-------------Sending models-------------
2022-01-26 21:15:50:INFO:-------------Evaluating models-------------
2022-01-26 21:15:51:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:15:51:INFO:Accuracy = [0.924968348104218, 0.9175051642566802, 0.905977210635037, 0.9213033917505165, 0.905110948224162, 0.9087759045778636, 0.9191710535083628, 0.9139734790431132, 0.9176384353968148, 0.9302325581395349]
2022-01-26 21:15:51:INFO:Loss = [0.20653267071781028, 0.22273403181774318, 0.24055952795406915, 0.23529045361567005, 0.253294040527965, 0.2473681007190509, 0.2270199615801734, 0.22774702180357256, 0.20171028280616063, 0.17012902856634388]
2022-01-26 21:15:51:INFO:-------------Training local models-------------
2022-01-26 21:23:17:INFO:-------------Aggregating local models-------------
2022-01-26 21:23:21:INFO:-------------Round number: 18-------------
2022-01-26 21:23:21:INFO:-------------Sending models-------------
2022-01-26 21:23:22:INFO:-------------Evaluating models-------------
2022-01-26 21:23:23:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:23:23:INFO:Accuracy = [0.9250349836742854, 0.9186379689478243, 0.9061771173452389, 0.9211034850403145, 0.9053108549343639, 0.9095755314186713, 0.919904044779103, 0.9155727327247285, 0.9175717998267475, 0.9312320916905444]
2022-01-26 21:23:23:INFO:Loss = [0.20477949757286087, 0.219283772553168, 0.2389837335647463, 0.23439876642866314, 0.2527478267729457, 0.245049415092076, 0.225417993986099, 0.22502689483817895, 0.19900422877510648, 0.1676716616400522]
2022-01-26 21:23:23:INFO:-------------Training local models-------------
2022-01-26 21:30:49:INFO:-------------Aggregating local models-------------
2022-01-26 21:30:53:INFO:-------------Round number: 19-------------
2022-01-26 21:30:53:INFO:-------------Sending models-------------
2022-01-26 21:30:54:INFO:-------------Evaluating models-------------
2022-01-26 21:30:55:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:30:55:INFO:Accuracy = [0.9252348903844873, 0.9192376890784301, 0.9069767441860465, 0.9213700273205837, 0.9053108549343639, 0.910175251549277, 0.92097021390018, 0.9166389018458053, 0.9184380622376225, 0.9318318118211502]
2022-01-26 21:30:55:INFO:Loss = [0.2031914246872841, 0.21573170037913955, 0.2375243848722552, 0.23362425795433014, 0.25218857066649847, 0.2429556803306288, 0.22390388735353614, 0.2224738364108962, 0.19638636807410031, 0.16555485453385366]
2022-01-26 21:30:55:INFO:-------------Training local models-------------
2022-01-26 21:38:17:INFO:-------------Aggregating local models-------------
2022-01-26 21:38:21:INFO:-------------Round number: 20-------------
2022-01-26 21:38:21:INFO:-------------Sending models-------------
2022-01-26 21:38:22:INFO:-------------Evaluating models-------------
2022-01-26 21:38:23:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:38:23:INFO:Accuracy = [0.9252348903844873, 0.9207036716199107, 0.9070433797561138, 0.9214366628906511, 0.9053108549343639, 0.9105750649696808, 0.9219697474511894, 0.9178383421070168, 0.918771240087959, 0.9320983541014194]
2022-01-26 21:38:23:INFO:Loss = [0.20179753978605444, 0.21219520983487583, 0.2361776509469989, 0.23294691458029695, 0.2517591497406017, 0.2410736615012629, 0.22265277594896885, 0.22009673768363966, 0.19398178210313868, 0.163758136324619]
2022-01-26 21:38:23:INFO:-------------Training local models-------------
2022-01-26 21:45:42:INFO:-------------Aggregating local models-------------
2022-01-26 21:45:46:INFO:-------------Round number: 21-------------
2022-01-26 21:45:46:INFO:-------------Sending models-------------
2022-01-26 21:45:46:INFO:-------------Evaluating models-------------
2022-01-26 21:45:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:45:47:INFO:Accuracy = [0.9253681615246219, 0.9211034850403145, 0.9073765576064503, 0.9215699340307857, 0.9053108549343639, 0.911041513960152, 0.9231025521423336, 0.9181048843872859, 0.9197041380689012, 0.9334977010728327]
2022-01-26 21:45:47:INFO:Loss = [0.2005972373573292, 0.20883944276972247, 0.23497676361989428, 0.23231765348073277, 0.25129492418568583, 0.23943061622318534, 0.22165368788727255, 0.21782230033858901, 0.19164369916622412, 0.16233247145056237]
2022-01-26 21:45:47:INFO:-------------Training local models-------------
2022-01-26 21:53:06:INFO:-------------Aggregating local models-------------
2022-01-26 21:53:10:INFO:-------------Round number: 22-------------
2022-01-26 21:53:10:INFO:-------------Sending models-------------
2022-01-26 21:53:10:INFO:-------------Evaluating models-------------
2022-01-26 21:53:11:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:53:11:INFO:Accuracy = [0.9257013393749584, 0.9225028320117279, 0.9081761844472579, 0.9215699340307857, 0.9055107616445659, 0.9122409542213633, 0.9235690011328047, 0.9189045112280936, 0.9207036716199107, 0.9340974212034384]
2022-01-26 21:53:11:INFO:Loss = [0.1994724058023401, 0.2055268819998877, 0.23383760251074548, 0.2317335952122735, 0.25084306628289954, 0.23791663435210136, 0.22061718939496658, 0.21563122362559228, 0.18955233982606584, 0.16060327976732333]
2022-01-26 21:53:11:INFO:-------------Training local models-------------
2022-01-26 22:00:31:INFO:-------------Aggregating local models-------------
2022-01-26 22:00:35:INFO:-------------Round number: 23-------------
2022-01-26 22:00:35:INFO:-------------Sending models-------------
2022-01-26 22:00:35:INFO:-------------Evaluating models-------------
2022-01-26 22:00:36:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:00:36:INFO:Accuracy = [0.9261677883654295, 0.9235023655627373, 0.9087759045778636, 0.9217032051709202, 0.9055107616445659, 0.9121076830812288, 0.924301992403545, 0.9192376890784301, 0.9220363830212568, 0.9346305057639768]
2022-01-26 22:00:36:INFO:Loss = [0.19847493816596318, 0.202175810769525, 0.2327311450605968, 0.23115536170912518, 0.2503059765936769, 0.23647431996182136, 0.21952795509568948, 0.21349909441300194, 0.1874340459330888, 0.15901376467993406]
2022-01-26 22:00:36:INFO:-------------Training local models-------------
2022-01-26 22:07:55:INFO:-------------Aggregating local models-------------
2022-01-26 22:07:59:INFO:-------------Round number: 24-------------
2022-01-26 22:07:59:INFO:-------------Sending models-------------
2022-01-26 22:07:59:INFO:-------------Evaluating models-------------
2022-01-26 22:08:00:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:08:00:INFO:Accuracy = [0.9263010595055641, 0.9242353568334777, 0.909508895848604, 0.9218364763110548, 0.9053774905044313, 0.9118411408009596, 0.9251016192443526, 0.9199706803491704, 0.9231025521423336, 0.935763310455121]
2022-01-26 22:08:00:INFO:Loss = [0.19755218091486054, 0.19882944607283684, 0.23168915857448544, 0.23061744095447928, 0.24982592464300116, 0.2350759315480396, 0.21837333849361107, 0.2113579176715257, 0.1854049653015813, 0.1571914917879145]
2022-01-26 22:08:00:INFO:-------------Training local models-------------
2022-01-26 22:15:20:INFO:-------------Aggregating local models-------------
2022-01-26 22:15:24:INFO:-------------Round number: 25-------------
2022-01-26 22:15:24:INFO:-------------Sending models-------------
2022-01-26 22:15:24:INFO:-------------Evaluating models-------------
2022-01-26 22:15:25:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:15:25:INFO:Accuracy = [0.9271006863463717, 0.9250349836742854, 0.9099087092690078, 0.9218364763110548, 0.905110948224162, 0.9125074965016325, 0.9255680682348237, 0.9207036716199107, 0.9239688145532085, 0.9362963950156593]
2022-01-26 22:15:25:INFO:Loss = [0.19677195599361108, 0.1954871584570264, 0.2307055089056756, 0.2301253369390198, 0.24937272432911278, 0.2338186041843274, 0.21736586523575738, 0.2093200522872845, 0.18345543051313853, 0.1554375650799388]
2022-01-26 22:15:25:INFO:-------------Training local models-------------
2022-01-26 22:22:45:INFO:-------------Aggregating local models-------------
2022-01-26 22:22:49:INFO:-------------Round number: 26-------------
2022-01-26 22:22:49:INFO:-------------Sending models-------------
2022-01-26 22:22:49:INFO:-------------Evaluating models-------------
2022-01-26 22:22:50:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:22:50:INFO:Accuracy = [0.9272339574865063, 0.925834610515093, 0.9105750649696808, 0.9217698407409876, 0.9051775837942294, 0.9127740387819018, 0.9261677883654295, 0.9211701206103818, 0.9243686279736123, 0.9376291064170054]
2022-01-26 22:22:50:INFO:Loss = [0.19586951910698266, 0.19212046459264084, 0.22977502582573775, 0.22957888382857555, 0.24885713667168488, 0.23251788104772805, 0.21655677207980506, 0.2073310667408215, 0.18161660115712766, 0.15396561272433776]
2022-01-26 22:22:50:INFO:-------------Training local models-------------
2022-01-26 22:30:10:INFO:-------------Aggregating local models-------------
2022-01-26 22:30:14:INFO:-------------Round number: 27-------------
2022-01-26 22:30:14:INFO:-------------Sending models-------------
2022-01-26 22:30:14:INFO:-------------Evaluating models-------------
2022-01-26 22:30:15:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:30:15:INFO:Accuracy = [0.9273672286266409, 0.9265009662157659, 0.9112414206703539, 0.9217698407409876, 0.9060438462051043, 0.9135070300526421, 0.9266342373559006, 0.9218364763110548, 0.924968348104218, 0.9382288265476111]
2022-01-26 22:30:15:INFO:Loss = [0.19507461516039515, 0.18884011137749726, 0.22884464449684058, 0.22905462739381355, 0.24832799727263596, 0.23127923215701388, 0.21565703439238987, 0.20536891375973756, 0.1799071265502801, 0.15234633204381204]
2022-01-26 22:30:15:INFO:-------------Training local models-------------
2022-01-26 22:37:33:INFO:-------------Aggregating local models-------------
2022-01-26 22:37:37:INFO:-------------Round number: 28-------------
2022-01-26 22:37:37:INFO:-------------Sending models-------------
2022-01-26 22:37:38:INFO:-------------Evaluating models-------------
2022-01-26 22:37:39:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:37:39:INFO:Accuracy = [0.9275004997667755, 0.927833677617112, 0.9113080562404211, 0.9217698407409876, 0.906843473045912, 0.9138402079029786, 0.926967415206237, 0.9232358232824682, 0.9259678816552276, 0.9382954621176784]
2022-01-26 22:37:39:INFO:Loss = [0.19429261786954435, 0.18572694441822302, 0.22793119114324, 0.22844668678771038, 0.24772259662168733, 0.23003563657973938, 0.21487928302976605, 0.20346971281542006, 0.1782510844944602, 0.15119355567281034]
2022-01-26 22:37:39:INFO:-------------Training local models-------------
2022-01-26 22:44:59:INFO:-------------Aggregating local models-------------
2022-01-26 22:45:03:INFO:-------------Round number: 29-------------
2022-01-26 22:45:03:INFO:-------------Sending models-------------
2022-01-26 22:45:03:INFO:-------------Evaluating models-------------
2022-01-26 22:45:04:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:45:04:INFO:Accuracy = [0.9280335843273139, 0.9294329312987273, 0.9113080562404211, 0.9218364763110548, 0.9074431931765177, 0.91503964816419, 0.9275004997667755, 0.9239688145532085, 0.9256347038048911, 0.9386286399680149]
2022-01-26 22:45:04:INFO:Loss = [0.19347513924338117, 0.18275292581696334, 0.22705494845078114, 0.2278446010719485, 0.2471240452235249, 0.22886313315268209, 0.21415220211466243, 0.20167370664420306, 0.17678293997466063, 0.15027930015514876]
2022-01-26 22:45:04:INFO:-------------Training local models-------------
2022-01-26 22:52:23:INFO:-------------Aggregating local models-------------
