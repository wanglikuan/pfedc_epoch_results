2022-01-25 14:53:07:INFO:-------------Round number: 0-------------
2022-01-25 14:53:07:INFO:-------------Sending models-------------
2022-01-25 14:53:08:INFO:-------------Evaluating models-------------
2022-01-25 14:53:08:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:53:08:INFO:Accuracy = [0.9045226130653267, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.10050251256281408, 0.10050251256281408, 0.10050251256281408, 0.10050251256281408, 0.8994974874371859]
2022-01-25 14:53:08:INFO:Loss = [0.6598240086181679, 0.6540545683410299, 0.66586336448564, 0.6581337074538571, 0.6606102061631093, 0.7393000775845207, 0.741513819550749, 0.742316616539979, 0.7425791070089868, 0.6690071129319656]
2022-01-25 14:53:08:INFO:-------------Training local models-------------
2022-01-25 14:56:58:INFO:-------------Aggregating local models-------------
2022-01-25 14:56:59:INFO:-------------Round number: 1-------------
2022-01-25 14:56:59:INFO:-------------Sending models-------------
2022-01-25 14:56:59:INFO:-------------Evaluating models-------------
2022-01-25 14:56:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:56:59:INFO:Accuracy = [0.9047738693467337, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8693467336683417]
2022-01-25 14:56:59:INFO:Loss = [0.3472792952691191, 0.36950590607508943, 0.3612426137504865, 0.35402810498697673, 0.3619168860528936, 0.3375537308616255, 0.36903663406419995, 0.3553336764400329, 0.32240460416180405, 0.40260803220260083]
2022-01-25 14:56:59:INFO:-------------Training local models-------------
2022-01-25 15:00:50:INFO:-------------Aggregating local models-------------
2022-01-25 15:00:51:INFO:-------------Round number: 2-------------
2022-01-25 15:00:51:INFO:-------------Sending models-------------
2022-01-25 15:00:51:INFO:-------------Evaluating models-------------
2022-01-25 15:00:51:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:00:51:INFO:Accuracy = [0.9059045226130653, 0.8989949748743719, 0.8994974874371859, 0.8994974874371859, 0.8996231155778894, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.900251256281407, 0.8976130653266332]
2022-01-25 15:00:51:INFO:Loss = [0.36109575101328856, 0.3549172240286017, 0.3418017456579448, 0.3541983307606012, 0.3600369281505221, 0.32405284646168425, 0.3605619071416519, 0.33788593944592693, 0.309957573761293, 0.34217729760174775]
2022-01-25 15:00:51:INFO:-------------Training local models-------------
2022-01-25 15:04:42:INFO:-------------Aggregating local models-------------
2022-01-25 15:04:43:INFO:-------------Round number: 3-------------
2022-01-25 15:04:43:INFO:-------------Sending models-------------
2022-01-25 15:04:43:INFO:-------------Evaluating models-------------
2022-01-25 15:04:43:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:04:43:INFO:Accuracy = [0.9042713567839196, 0.8954773869346734, 0.8994974874371859, 0.8994974874371859, 0.8953517587939699, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.9015075376884422, 0.8994974874371859]
2022-01-25 15:04:43:INFO:Loss = [0.36102294089300696, 0.35582686968185195, 0.3387580627772077, 0.35433215846368415, 0.36122420145638623, 0.32468258001696526, 0.36192845025254256, 0.3376522712671577, 0.2997197254219247, 0.34311167933234016]
2022-01-25 15:04:43:INFO:-------------Training local models-------------
2022-01-25 15:08:33:INFO:-------------Aggregating local models-------------
2022-01-25 15:08:34:INFO:-------------Round number: 4-------------
2022-01-25 15:08:34:INFO:-------------Sending models-------------
2022-01-25 15:08:34:INFO:-------------Evaluating models-------------
2022-01-25 15:08:34:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:08:34:INFO:Accuracy = [0.9026381909547738, 0.8937185929648241, 0.9007537688442211, 0.8997487437185929, 0.8957286432160804, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.9041457286432161, 0.9005025125628141]
2022-01-25 15:08:34:INFO:Loss = [0.35560135133377274, 0.35378181155602534, 0.33233350530341643, 0.3510603605203293, 0.3584474060104121, 0.32124902540115857, 0.36095962048175945, 0.33445869049235205, 0.2868417137531779, 0.3441399365813289]
2022-01-25 15:08:34:INFO:-------------Training local models-------------
2022-01-25 15:12:25:INFO:-------------Aggregating local models-------------
2022-01-25 15:12:26:INFO:-------------Round number: 5-------------
2022-01-25 15:12:26:INFO:-------------Sending models-------------
2022-01-25 15:12:26:INFO:-------------Evaluating models-------------
2022-01-25 15:12:26:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:12:26:INFO:Accuracy = [0.9015075376884422, 0.8937185929648241, 0.9027638190954774, 0.9003768844221105, 0.8974874371859296, 0.8994974874371859, 0.8996231155778894, 0.8996231155778894, 0.9076633165829145, 0.8984924623115578]
2022-01-25 15:12:26:INFO:Loss = [0.349228114175175, 0.34980895770854087, 0.3236254745691865, 0.3462555383018513, 0.35413876565257507, 0.3144766914485088, 0.3586013143386074, 0.329040745095392, 0.273757163903222, 0.34189583892798303]
2022-01-25 15:12:26:INFO:-------------Training local models-------------
2022-01-25 15:16:17:INFO:-------------Aggregating local models-------------
2022-01-25 15:16:18:INFO:-------------Round number: 6-------------
2022-01-25 15:16:18:INFO:-------------Sending models-------------
2022-01-25 15:16:18:INFO:-------------Evaluating models-------------
2022-01-25 15:16:18:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:16:18:INFO:Accuracy = [0.8991206030150753, 0.8947236180904523, 0.903391959798995, 0.900251256281407, 0.8996231155778894, 0.9, 0.8996231155778894, 0.9005025125628141, 0.9099246231155779, 0.8989949748743719]
2022-01-25 15:16:18:INFO:Loss = [0.3430801565365763, 0.34487269811294785, 0.3140738606452942, 0.34085612770301016, 0.3490963883735427, 0.30525481071903476, 0.35549604443449473, 0.3222345697819887, 0.2614053131347925, 0.3371978355712028]
2022-01-25 15:16:18:INFO:-------------Training local models-------------
2022-01-25 15:20:09:INFO:-------------Aggregating local models-------------
2022-01-25 15:20:10:INFO:-------------Round number: 7-------------
2022-01-25 15:20:10:INFO:-------------Sending models-------------
2022-01-25 15:20:10:INFO:-------------Evaluating models-------------
2022-01-25 15:20:10:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:20:10:INFO:Accuracy = [0.896859296482412, 0.8945979899497487, 0.9025125628140703, 0.9005025125628141, 0.9007537688442211, 0.9025125628140703, 0.9001256281407035, 0.9018844221105528, 0.9116834170854271, 0.8994974874371859]
2022-01-25 15:20:10:INFO:Loss = [0.3374032731678093, 0.3395230683250044, 0.3044975470358403, 0.33517454751771897, 0.3435714616248356, 0.2944516169665447, 0.35187581316310557, 0.31470457752745357, 0.25031272430515766, 0.33118214454483147]
2022-01-25 15:20:10:INFO:-------------Training local models-------------
2022-01-25 15:24:00:INFO:-------------Aggregating local models-------------
2022-01-25 15:24:01:INFO:-------------Round number: 8-------------
2022-01-25 15:24:01:INFO:-------------Sending models-------------
2022-01-25 15:24:01:INFO:-------------Evaluating models-------------
2022-01-25 15:24:01:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:24:01:INFO:Accuracy = [0.896859296482412, 0.8944723618090452, 0.9026381909547738, 0.9005025125628141, 0.9016331658291458, 0.9061557788944724, 0.8996231155778894, 0.9038944723618091, 0.9133165829145728, 0.9005025125628141]
2022-01-25 15:24:01:INFO:Loss = [0.3322552680997318, 0.33408558428587026, 0.29529617299985644, 0.32947923070821333, 0.3378210807565469, 0.2829713310728121, 0.34790507602931264, 0.3069880898274369, 0.2407516739775787, 0.32483839749091836]
2022-01-25 15:24:01:INFO:-------------Training local models-------------
2022-01-25 15:27:51:INFO:-------------Aggregating local models-------------
2022-01-25 15:27:52:INFO:-------------Round number: 9-------------
2022-01-25 15:27:52:INFO:-------------Sending models-------------
2022-01-25 15:27:52:INFO:-------------Evaluating models-------------
2022-01-25 15:27:52:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:27:52:INFO:Accuracy = [0.8969849246231156, 0.8948492462311558, 0.9045226130653267, 0.9020100502512562, 0.9026381909547738, 0.9099246231155779, 0.8996231155778894, 0.9047738693467337, 0.914321608040201, 0.9013819095477387]
2022-01-25 15:27:52:INFO:Loss = [0.32755786575723306, 0.32879377774257756, 0.2866957156202901, 0.3239582484990508, 0.332121123920134, 0.2715704638754303, 0.3437019498204466, 0.29941663415587727, 0.23275820626385846, 0.31875827938468015]
2022-01-25 15:27:52:INFO:-------------Training local models-------------
2022-01-25 15:31:41:INFO:-------------Aggregating local models-------------
2022-01-25 15:31:42:INFO:-------------Round number: 10-------------
2022-01-25 15:31:42:INFO:-------------Sending models-------------
2022-01-25 15:31:42:INFO:-------------Evaluating models-------------
2022-01-25 15:31:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:31:42:INFO:Accuracy = [0.8963567839195979, 0.8957286432160804, 0.9064070351758794, 0.9028894472361809, 0.9022613065326633, 0.9133165829145728, 0.9006281407035176, 0.9051507537688442, 0.9160804020100503, 0.9016331658291458]
2022-01-25 15:31:42:INFO:Loss = [0.323238308637417, 0.32384106756454734, 0.27880067696523425, 0.3186553869415168, 0.3266212862340649, 0.26075096420906296, 0.3393714681043098, 0.29215972357658887, 0.22617967891034169, 0.31306853635826304]
2022-01-25 15:31:42:INFO:-------------Training local models-------------
2022-01-25 15:35:28:INFO:-------------Aggregating local models-------------
2022-01-25 15:35:29:INFO:-------------Round number: 11-------------
2022-01-25 15:35:29:INFO:-------------Sending models-------------
2022-01-25 15:35:29:INFO:-------------Evaluating models-------------
2022-01-25 15:35:30:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:35:30:INFO:Accuracy = [0.8953517587939699, 0.8951005025125628, 0.9081658291457286, 0.9043969849246232, 0.903643216080402, 0.9168341708542713, 0.9005025125628141, 0.9055276381909547, 0.917713567839196, 0.9021356783919598]
2022-01-25 15:35:30:INFO:Loss = [0.3192373234521242, 0.31929464106583716, 0.2716144888694562, 0.3136578962281721, 0.32138086683187056, 0.2507597513534316, 0.3350043191981675, 0.2852699054245973, 0.22085952901061456, 0.3077871756038474]
2022-01-25 15:35:30:INFO:-------------Training local models-------------
2022-01-25 15:39:16:INFO:-------------Aggregating local models-------------
2022-01-25 15:39:17:INFO:-------------Round number: 12-------------
2022-01-25 15:39:17:INFO:-------------Sending models-------------
2022-01-25 15:39:17:INFO:-------------Evaluating models-------------
2022-01-25 15:39:17:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:39:17:INFO:Accuracy = [0.8959798994974875, 0.8952261306532663, 0.9103015075376885, 0.9055276381909547, 0.9038944723618091, 0.9208542713567839, 0.9006281407035176, 0.9060301507537688, 0.9189698492462312, 0.9025125628140703]
2022-01-25 15:39:17:INFO:Loss = [0.31545850835581446, 0.3151301490002541, 0.2650586737310467, 0.30901304374088595, 0.31646322215621797, 0.24171768975018257, 0.33066315087840786, 0.27877781483995256, 0.21654515627341056, 0.30283299612639536]
2022-01-25 15:39:17:INFO:-------------Training local models-------------
2022-01-25 15:43:04:INFO:-------------Aggregating local models-------------
2022-01-25 15:43:05:INFO:-------------Round number: 13-------------
2022-01-25 15:43:05:INFO:-------------Sending models-------------
2022-01-25 15:43:05:INFO:-------------Evaluating models-------------
2022-01-25 15:43:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:43:05:INFO:Accuracy = [0.8963567839195979, 0.8962311557788945, 0.9118090452261306, 0.9062814070351759, 0.9043969849246232, 0.925251256281407, 0.9005025125628141, 0.907035175879397, 0.9195979899497487, 0.9030150753768844]
2022-01-25 15:43:05:INFO:Loss = [0.31189903968842186, 0.31134128795197263, 0.2590488416315922, 0.30471787605453377, 0.31186490547117873, 0.23364581796691644, 0.32638740913951814, 0.27269990300413355, 0.21304650829365504, 0.29811121710580796]
2022-01-25 15:43:05:INFO:-------------Training local models-------------
2022-01-25 15:46:52:INFO:-------------Aggregating local models-------------
2022-01-25 15:46:53:INFO:-------------Round number: 14-------------
2022-01-25 15:46:53:INFO:-------------Sending models-------------
2022-01-25 15:46:53:INFO:-------------Evaluating models-------------
2022-01-25 15:46:53:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:46:53:INFO:Accuracy = [0.8963567839195979, 0.8963567839195979, 0.9139447236180904, 0.9062814070351759, 0.9052763819095477, 0.928643216080402, 0.900251256281407, 0.9079145728643216, 0.9195979899497487, 0.903643216080402]
2022-01-25 15:46:53:INFO:Loss = [0.3085054465284075, 0.307880436655265, 0.25353053668935094, 0.3007600389084025, 0.3076025165205625, 0.22652537297064335, 0.32222129576769304, 0.26704420591119543, 0.21023832036921727, 0.29360085980377004]
2022-01-25 15:46:53:INFO:-------------Training local models-------------
2022-01-25 15:50:39:INFO:-------------Aggregating local models-------------
2022-01-25 15:50:40:INFO:-------------Round number: 15-------------
2022-01-25 15:50:40:INFO:-------------Sending models-------------
2022-01-25 15:50:40:INFO:-------------Evaluating models-------------
2022-01-25 15:50:40:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:50:40:INFO:Accuracy = [0.8967336683417085, 0.8964824120603015, 0.9158291457286433, 0.9056532663316583, 0.9060301507537688, 0.9311557788944723, 0.9005025125628141, 0.9086683417085427, 0.9193467336683417, 0.9041457286432161]
2022-01-25 15:50:40:INFO:Loss = [0.30530125699731425, 0.30471056849513223, 0.24843025858977333, 0.29709941650455324, 0.303620098823279, 0.22029777590054364, 0.31820515412182065, 0.2618239215720239, 0.2080174704742192, 0.2892906134152532]
2022-01-25 15:50:40:INFO:-------------Training local models-------------
2022-01-25 15:54:27:INFO:-------------Aggregating local models-------------
2022-01-25 15:54:28:INFO:-------------Round number: 16-------------
2022-01-25 15:54:28:INFO:-------------Sending models-------------
2022-01-25 15:54:28:INFO:-------------Evaluating models-------------
2022-01-25 15:54:28:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:54:28:INFO:Accuracy = [0.8967336683417085, 0.8962311557788945, 0.9167085427135678, 0.9057788944723618, 0.9071608040201005, 0.9325376884422111, 0.8994974874371859, 0.9096733668341709, 0.9193467336683417, 0.9050251256281407]
2022-01-25 15:54:28:INFO:Loss = [0.30230509620581064, 0.30177920832106814, 0.24370404052075428, 0.29371588890576483, 0.2998934070668628, 0.21484309734411575, 0.31434447816268885, 0.25699208766671283, 0.20625409139460654, 0.2851674669052488]
2022-01-25 15:54:28:INFO:-------------Training local models-------------
2022-01-25 15:58:14:INFO:-------------Aggregating local models-------------
2022-01-25 15:58:15:INFO:-------------Round number: 17-------------
2022-01-25 15:58:15:INFO:-------------Sending models-------------
2022-01-25 15:58:15:INFO:-------------Evaluating models-------------
2022-01-25 15:58:15:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:58:15:INFO:Accuracy = [0.8981155778894472, 0.8969849246231156, 0.9189698492462312, 0.9050251256281407, 0.907537688442211, 0.9339195979899497, 0.8992462311557788, 0.910678391959799, 0.9197236180904522, 0.9060301507537688]
2022-01-25 15:58:15:INFO:Loss = [0.2994935595612954, 0.2990607348219234, 0.2393588479889098, 0.2905764521366388, 0.29642787920170693, 0.2100505241047797, 0.3106422187694952, 0.25256596251049235, 0.20488158003169687, 0.28122818200432476]
2022-01-25 15:58:15:INFO:-------------Training local models-------------
2022-01-25 16:02:02:INFO:-------------Aggregating local models-------------
2022-01-25 16:02:03:INFO:-------------Round number: 18-------------
2022-01-25 16:02:03:INFO:-------------Sending models-------------
2022-01-25 16:02:03:INFO:-------------Evaluating models-------------
2022-01-25 16:02:03:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 16:02:03:INFO:Accuracy = [0.8976130653266332, 0.8972361809045226, 0.9195979899497487, 0.9059045226130653, 0.9080402010050251, 0.9347989949748744, 0.8983668341708543, 0.9123115577889447, 0.9199748743718593, 0.9060301507537688]
2022-01-25 16:02:03:INFO:Loss = [0.29680810181597184, 0.2965264428201033, 0.23534149762673592, 0.28764897936852135, 0.2931879246654223, 0.20583227478978622, 0.3070887613236605, 0.24851318954223364, 0.2038273952115121, 0.2774632662983995]
2022-01-25 16:02:03:INFO:-------------Training local models-------------
2022-01-25 16:05:50:INFO:-------------Aggregating local models-------------
2022-01-25 16:05:51:INFO:-------------Round number: 19-------------
2022-01-25 16:05:51:INFO:-------------Sending models-------------
2022-01-25 16:05:51:INFO:-------------Evaluating models-------------
2022-01-25 16:05:51:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 16:05:51:INFO:Accuracy = [0.8977386934673367, 0.8983668341708543, 0.921105527638191, 0.907035175879397, 0.9084170854271357, 0.9358040201005026, 0.8983668341708543, 0.9134422110552763, 0.9195979899497487, 0.9066582914572864]
2022-01-25 16:05:51:INFO:Loss = [0.29430888081905454, 0.2941669600093784, 0.23160553427796868, 0.284906013826629, 0.2901251832743985, 0.2020966154546594, 0.3036867496955335, 0.2448119786216985, 0.203017041611312, 0.27389033026431675]
2022-01-25 16:05:51:INFO:-------------Training local models-------------
2022-01-25 16:09:37:INFO:-------------Aggregating local models-------------
2022-01-25 16:09:38:INFO:-------------Round number: 20-------------
2022-01-25 16:09:38:INFO:-------------Sending models-------------
2022-01-25 16:09:38:INFO:-------------Evaluating models-------------
2022-01-25 16:09:39:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 16:09:39:INFO:Accuracy = [0.8981155778894472, 0.8976130653266332, 0.921859296482412, 0.9079145728643216, 0.9094221105527638, 0.9358040201005026, 0.8989949748743719, 0.914321608040201, 0.9193467336683417, 0.9072864321608041]
2022-01-25 16:09:39:INFO:Loss = [0.29200223717141205, 0.2919648086006318, 0.22814057670046936, 0.28231289765643114, 0.28725144551627, 0.1987724831730277, 0.3004499774182861, 0.24144582120916952, 0.20249381077349485, 0.2705078523362701]
2022-01-25 16:09:39:INFO:-------------Training local models-------------
2022-01-25 16:13:25:INFO:-------------Aggregating local models-------------
2022-01-25 16:13:26:INFO:-------------Round number: 21-------------
2022-01-25 16:13:26:INFO:-------------Sending models-------------
2022-01-25 16:13:26:INFO:-------------Evaluating models-------------
2022-01-25 16:13:26:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 16:13:26:INFO:Accuracy = [0.8984924623115578, 0.8971105527638191, 0.9226130653266331, 0.9080402010050251, 0.9097989949748744, 0.9365577889447236, 0.8997487437185929, 0.9157035175879397, 0.9195979899497487, 0.9081658291457286]
2022-01-25 16:13:26:INFO:Loss = [0.28982658432352, 0.28987059521315683, 0.2249002691040087, 0.279884228679403, 0.2845065216323239, 0.19580505398949186, 0.29733332901743786, 0.23838078503932186, 0.2021895476322078, 0.2672561255831215]
2022-01-25 16:13:26:INFO:-------------Training local models-------------
2022-01-25 16:17:13:INFO:-------------Aggregating local models-------------
2022-01-25 16:17:13:INFO:-------------Round number: 22-------------
2022-01-25 16:17:13:INFO:-------------Sending models-------------
2022-01-25 16:17:14:INFO:-------------Evaluating models-------------
2022-01-25 16:17:14:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 16:17:14:INFO:Accuracy = [0.8987437185929649, 0.8969849246231156, 0.9233668341708543, 0.9084170854271357, 0.9100502512562814, 0.9373115577889447, 0.9001256281407035, 0.9169597989949749, 0.9198492462311558, 0.9076633165829145]
2022-01-25 16:17:14:INFO:Loss = [0.2877554969309862, 0.28789876139343684, 0.22188067009401083, 0.2775814608862652, 0.2819073709411238, 0.19311231640565335, 0.29433747452108106, 0.23557079991503577, 0.2020567435415546, 0.26415136336681233]
2022-01-25 16:17:14:INFO:-------------Training local models-------------
2022-01-25 16:21:00:INFO:-------------Aggregating local models-------------
2022-01-25 16:21:01:INFO:-------------Round number: 23-------------
2022-01-25 16:21:01:INFO:-------------Sending models-------------
2022-01-25 16:21:01:INFO:-------------Evaluating models-------------
2022-01-25 16:21:01:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 16:21:01:INFO:Accuracy = [0.8982412060301508, 0.8972361809045226, 0.9243718592964824, 0.9084170854271357, 0.910678391959799, 0.9385678391959799, 0.9006281407035176, 0.9183417085427136, 0.9198492462311558, 0.9082914572864321]
2022-01-25 16:21:01:INFO:Loss = [0.2857841278295309, 0.28601990026145724, 0.21907250830276528, 0.27538348816747044, 0.2794356760966718, 0.19066876764573046, 0.2914891259454603, 0.2330443080346189, 0.2021724881239273, 0.2612079723396493]
2022-01-25 16:21:01:INFO:-------------Training local models-------------
2022-01-25 16:24:48:INFO:-------------Aggregating local models-------------
2022-01-25 16:24:49:INFO:-------------Round number: 24-------------
2022-01-25 16:24:49:INFO:-------------Sending models-------------
2022-01-25 16:24:49:INFO:-------------Evaluating models-------------
2022-01-25 16:24:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 16:24:49:INFO:Accuracy = [0.8986180904522613, 0.8982412060301508, 0.9253768844221105, 0.9094221105527638, 0.9115577889447236, 0.9391959798994974, 0.9012562814070352, 0.9203517587939698, 0.9195979899497487, 0.9096733668341709]
2022-01-25 16:24:49:INFO:Loss = [0.283902786897926, 0.2842608454389189, 0.21643628823996788, 0.27328349297969184, 0.27702050203054995, 0.1884162543931199, 0.28874930634570484, 0.23072187774744465, 0.20241955401909412, 0.2583981936600939]
2022-01-25 16:24:49:INFO:-------------Training local models-------------
2022-01-25 16:28:36:INFO:-------------Aggregating local models-------------
2022-01-25 16:28:37:INFO:-------------Round number: 25-------------
2022-01-25 16:28:37:INFO:-------------Sending models-------------
2022-01-25 16:28:37:INFO:-------------Evaluating models-------------
2022-01-25 16:28:37:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 16:28:37:INFO:Accuracy = [0.8983668341708543, 0.8988693467336684, 0.925251256281407, 0.9099246231155779, 0.9116834170854271, 0.9396984924623115, 0.9018844221105528, 0.9209798994974875, 0.9194723618090452, 0.9105527638190954]
2022-01-25 16:28:37:INFO:Loss = [0.28217372089746084, 0.28260251864716035, 0.21398328162317898, 0.27131736705351117, 0.2747702543160424, 0.18639402402256003, 0.28619692358539334, 0.2286529091734383, 0.20298175027023008, 0.25578493134460256]
2022-01-25 16:28:37:INFO:-------------Training local models-------------
2022-01-25 16:32:24:INFO:-------------Aggregating local models-------------
2022-01-25 16:32:25:INFO:-------------Round number: 26-------------
2022-01-25 16:32:25:INFO:-------------Sending models-------------
2022-01-25 16:32:25:INFO:-------------Evaluating models-------------
2022-01-25 16:32:25:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 16:32:25:INFO:Accuracy = [0.8986180904522613, 0.8996231155778894, 0.9262562814070352, 0.9100502512562814, 0.9118090452261306, 0.9407035175879397, 0.9023869346733668, 0.9217336683417086, 0.9193467336683417, 0.9123115577889447]
2022-01-25 16:32:25:INFO:Loss = [0.28051632962273854, 0.2810183215380913, 0.21169045065815126, 0.2694250563131505, 0.2726123893081243, 0.1845315394913731, 0.2837835072572507, 0.2267606739123263, 0.20377177224686396, 0.2533276175434266]
2022-01-25 16:32:25:INFO:-------------Training local models-------------
2022-01-25 16:36:11:INFO:-------------Aggregating local models-------------
2022-01-25 16:36:12:INFO:-------------Round number: 27-------------
2022-01-25 16:36:12:INFO:-------------Sending models-------------
2022-01-25 16:36:12:INFO:-------------Evaluating models-------------
2022-01-25 16:36:13:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 16:36:13:INFO:Accuracy = [0.8986180904522613, 0.8998743718592965, 0.9273869346733669, 0.910427135678392, 0.9114321608040201, 0.9412060301507538, 0.9032663316582915, 0.9221105527638191, 0.9189698492462312, 0.9130653266331659]
2022-01-25 16:36:13:INFO:Loss = [0.27899603597145883, 0.279499989358624, 0.2095176105073948, 0.2675934932639251, 0.2705053914731471, 0.18280717079064354, 0.28148876467541833, 0.22505302749686504, 0.20467646532322295, 0.25101365545886245]
2022-01-25 16:36:13:INFO:-------------Training local models-------------
2022-01-25 16:39:59:INFO:-------------Aggregating local models-------------
2022-01-25 16:40:00:INFO:-------------Round number: 28-------------
2022-01-25 16:40:00:INFO:-------------Sending models-------------
2022-01-25 16:40:00:INFO:-------------Evaluating models-------------
2022-01-25 16:40:00:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 16:40:00:INFO:Accuracy = [0.8991206030150753, 0.8996231155778894, 0.9281407035175879, 0.910929648241206, 0.9119346733668342, 0.9419597989949748, 0.903391959798995, 0.9232412060301508, 0.9188442211055277, 0.9138190954773869]
2022-01-25 16:40:00:INFO:Loss = [0.27763977143258306, 0.278141087697978, 0.2074636064432374, 0.2658183043775846, 0.2684583048425128, 0.1811769130691212, 0.2792935032191588, 0.22345883062287192, 0.20572640443567056, 0.2488028570335714]
2022-01-25 16:40:00:INFO:-------------Training local models-------------
2022-01-25 16:43:47:INFO:-------------Aggregating local models-------------
2022-01-25 16:43:47:INFO:-------------Round number: 29-------------
2022-01-25 16:43:47:INFO:-------------Sending models-------------
2022-01-25 16:43:48:INFO:-------------Evaluating models-------------
2022-01-25 16:43:48:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 16:43:48:INFO:Accuracy = [0.9001256281407035, 0.8992462311557788, 0.928643216080402, 0.9115577889447236, 0.9131909547738694, 0.9423366834170854, 0.9042713567839196, 0.9233668341708543, 0.9185929648241206, 0.914321608040201]
2022-01-25 16:43:48:INFO:Loss = [0.276342602702321, 0.27686378689267527, 0.20552599385156103, 0.26410811128628314, 0.26651291376981306, 0.1796740574677985, 0.2772286032612, 0.22201968448695225, 0.20688602852461926, 0.24675357626311145]
2022-01-25 16:43:48:INFO:-------------Training local models-------------
2022-01-25 16:47:34:INFO:-------------Aggregating local models-------------
2022-01-25 16:47:35:INFO:-------------Round number: 30-------------
2022-01-25 16:47:35:INFO:-------------Sending models-------------
2022-01-25 16:47:35:INFO:-------------Evaluating models-------------
2022-01-25 16:47:35:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 16:47:35:INFO:Accuracy = [0.9, 0.8993718592964824, 0.928894472361809, 0.9123115577889447, 0.9139447236180904, 0.9425879396984924, 0.9047738693467337, 0.9236180904522613, 0.9183417085427136, 0.9146984924623116]
2022-01-25 16:47:35:INFO:Loss = [0.2751573166504605, 0.27570575251052126, 0.2036647662595289, 0.26247295250545194, 0.26457072742021265, 0.17824259377903676, 0.2752624861708838, 0.22067683946397437, 0.208162790716593, 0.24479590753215041]
2022-01-25 16:47:35:INFO:-------------Training local models-------------
2022-01-25 16:51:22:INFO:-------------Aggregating local models-------------
2022-01-25 16:51:23:INFO:-------------Round number: 31-------------
2022-01-25 16:51:23:INFO:-------------Sending models-------------
2022-01-25 16:51:23:INFO:-------------Evaluating models-------------
2022-01-25 16:51:23:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 16:51:23:INFO:Accuracy = [0.9003768844221105, 0.8998743718592965, 0.9298994974874372, 0.9129396984924623, 0.914321608040201, 0.9430904522613065, 0.9052763819095477, 0.9238693467336684, 0.9183417085427136, 0.9148241206030151]
2022-01-25 16:51:23:INFO:Loss = [0.27409662968355075, 0.27462335005776967, 0.20190319359003, 0.2608962204288598, 0.26275186562657954, 0.1769640325526496, 0.27344631145347903, 0.21948143027385875, 0.20960929929910593, 0.24298840072286787]
2022-01-25 16:51:23:INFO:-------------Training local models-------------
2022-01-25 16:55:10:INFO:-------------Aggregating local models-------------
2022-01-25 16:55:11:INFO:-------------Round number: 32-------------
2022-01-25 16:55:11:INFO:-------------Sending models-------------
2022-01-25 16:55:11:INFO:-------------Evaluating models-------------
2022-01-25 16:55:11:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 16:55:11:INFO:Accuracy = [0.9008793969849246, 0.9006281407035176, 0.9302763819095478, 0.9136934673366834, 0.9146984924623116, 0.9435929648241206, 0.9062814070351759, 0.9234924623115578, 0.917964824120603, 0.9152010050251256]
2022-01-25 16:55:11:INFO:Loss = [0.2730615926536745, 0.2736226600318698, 0.2002028931475165, 0.25937864963133733, 0.26096368869345393, 0.17567638341505923, 0.2717204279636019, 0.21829086238864678, 0.21104696003635923, 0.24122336147418574]
2022-01-25 16:55:11:INFO:-------------Training local models-------------
2022-01-25 16:58:58:INFO:-------------Aggregating local models-------------
2022-01-25 16:58:59:INFO:-------------Round number: 33-------------
2022-01-25 16:58:59:INFO:-------------Sending models-------------
2022-01-25 16:58:59:INFO:-------------Evaluating models-------------
2022-01-25 16:58:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 16:58:59:INFO:Accuracy = [0.9007537688442211, 0.9003768844221105, 0.9307788944723618, 0.9139447236180904, 0.9153266331658292, 0.9437185929648241, 0.9069095477386935, 0.9236180904522613, 0.9180904522613065, 0.9153266331658292]
2022-01-25 16:58:59:INFO:Loss = [0.2721563918193119, 0.2726994752883911, 0.1985770577761396, 0.2579330154250016, 0.2592831174632413, 0.17451627133180148, 0.2701057137256891, 0.2172215927635605, 0.2125328887048079, 0.23957190456701882]
2022-01-25 16:58:59:INFO:-------------Training local models-------------
2022-01-25 17:02:45:INFO:-------------Aggregating local models-------------
2022-01-25 17:02:46:INFO:-------------Round number: 34-------------
2022-01-25 17:02:46:INFO:-------------Sending models-------------
2022-01-25 17:02:46:INFO:-------------Evaluating models-------------
2022-01-25 17:02:46:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 17:02:46:INFO:Accuracy = [0.9007537688442211, 0.9001256281407035, 0.9312814070351759, 0.914321608040201, 0.9153266331658292, 0.9434673366834171, 0.907035175879397, 0.9242462311557789, 0.917713567839196, 0.9153266331658292]
2022-01-25 17:02:46:INFO:Loss = [0.2713472595615032, 0.2718563899023449, 0.19701423095398812, 0.25653429044850506, 0.25765514478611584, 0.17344722376396907, 0.2685909182132788, 0.21623265118005885, 0.2140436638240239, 0.23800999315539798]
2022-01-25 17:02:46:INFO:-------------Training local models-------------
2022-01-25 17:06:33:INFO:-------------Aggregating local models-------------
2022-01-25 17:06:34:INFO:-------------Round number: 35-------------
2022-01-25 17:06:34:INFO:-------------Sending models-------------
2022-01-25 17:06:34:INFO:-------------Evaluating models-------------
2022-01-25 17:06:34:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 17:06:34:INFO:Accuracy = [0.900251256281407, 0.9001256281407035, 0.9316582914572864, 0.9139447236180904, 0.9162060301507537, 0.9435929648241206, 0.9071608040201005, 0.9246231155778895, 0.9175879396984925, 0.9162060301507537]
2022-01-25 17:06:34:INFO:Loss = [0.27049288352782924, 0.27103192797258274, 0.19552016580224635, 0.25518425101011843, 0.25608533051744775, 0.17239895133516897, 0.26716880223259853, 0.2152789659685825, 0.2155726075771466, 0.2365428214546424]
2022-01-25 17:06:34:INFO:-------------Training local models-------------
2022-01-25 17:10:20:INFO:-------------Aggregating local models-------------
2022-01-25 17:10:21:INFO:-------------Round number: 36-------------
2022-01-25 17:10:21:INFO:-------------Sending models-------------
2022-01-25 17:10:21:INFO:-------------Evaluating models-------------
2022-01-25 17:10:22:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 17:10:22:INFO:Accuracy = [0.9001256281407035, 0.9, 0.9321608040201005, 0.9136934673366834, 0.9172110552763819, 0.9442211055276382, 0.9084170854271357, 0.9246231155778895, 0.9173366834170854, 0.9169597989949749]
2022-01-25 17:10:22:INFO:Loss = [0.2696903195973935, 0.2702828177704883, 0.19407189169421268, 0.2538911571454762, 0.2545672472397886, 0.1713994939123566, 0.2658340848570493, 0.2143731775819956, 0.21718741915932852, 0.23515201730644283]
2022-01-25 17:10:22:INFO:-------------Training local models-------------
2022-01-25 17:14:08:INFO:-------------Aggregating local models-------------
2022-01-25 17:14:09:INFO:-------------Round number: 37-------------
2022-01-25 17:14:09:INFO:-------------Sending models-------------
2022-01-25 17:14:09:INFO:-------------Evaluating models-------------
2022-01-25 17:14:09:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 17:14:09:INFO:Accuracy = [0.9010050251256282, 0.8996231155778894, 0.9326633165829146, 0.9144472361809045, 0.9173366834170854, 0.9440954773869347, 0.9085427135678392, 0.9246231155778895, 0.9170854271356784, 0.917713567839196]
2022-01-25 17:14:09:INFO:Loss = [0.2689392005898358, 0.26960050378313016, 0.1926772387782533, 0.2526414254352675, 0.2530618976408513, 0.17042345168003484, 0.2645796364426014, 0.2135121354730285, 0.21878059972171207, 0.23379436479741006]
2022-01-25 17:14:09:INFO:-------------Training local models-------------
2022-01-25 17:17:56:INFO:-------------Aggregating local models-------------
2022-01-25 17:17:57:INFO:-------------Round number: 38-------------
2022-01-25 17:17:57:INFO:-------------Sending models-------------
2022-01-25 17:17:57:INFO:-------------Evaluating models-------------
2022-01-25 17:17:57:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 17:17:57:INFO:Accuracy = [0.9012562814070352, 0.8998743718592965, 0.9331658291457287, 0.9150753768844221, 0.9174623115577889, 0.9442211055276382, 0.9092964824120603, 0.9246231155778895, 0.9163316582914572, 0.9175879396984925]
2022-01-25 17:17:57:INFO:Loss = [0.26826378750093, 0.2690039192462087, 0.19130321625788607, 0.2514436909152036, 0.25167160702111135, 0.16956352468711047, 0.2634272725887634, 0.21275831268510625, 0.22040412780927054, 0.2325833359705144]
2022-01-25 17:17:57:INFO:-------------Training local models-------------
2022-01-25 17:21:44:INFO:-------------Aggregating local models-------------
2022-01-25 17:21:45:INFO:-------------Round number: 39-------------
2022-01-25 17:21:45:INFO:-------------Sending models-------------
2022-01-25 17:21:45:INFO:-------------Evaluating models-------------
2022-01-25 17:21:45:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 17:21:45:INFO:Accuracy = [0.9016331658291458, 0.9001256281407035, 0.9332914572864321, 0.9155778894472362, 0.9175879396984925, 0.9444723618090453, 0.9095477386934674, 0.9246231155778895, 0.9160804020100503, 0.9178391959798995]
2022-01-25 17:21:45:INFO:Loss = [0.2675920332923541, 0.26845476480584646, 0.1899703660951787, 0.25028429236543837, 0.25036194680923196, 0.16869744972967024, 0.2623378593268706, 0.21197078747665463, 0.2220724272967583, 0.2314170249293198]
2022-01-25 17:21:45:INFO:-------------Training local models-------------
2022-01-25 17:25:32:INFO:-------------Aggregating local models-------------
