2022-01-26 00:28:25:INFO:-------------Round number: 0-------------
2022-01-26 00:28:25:INFO:-------------Sending models-------------
2022-01-26 00:28:26:INFO:-------------Evaluating models-------------
2022-01-26 00:28:26:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 00:28:26:INFO:Accuracy = [0.9045226130653267, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.10050251256281408, 0.10050251256281408, 0.10050251256281408, 0.10050251256281408, 0.8994974874371859]
2022-01-26 00:28:26:INFO:Loss = [0.6598240086181679, 0.6540545683410299, 0.66586336448564, 0.6581337074538571, 0.6606102061631093, 0.7393000775845207, 0.741513819550749, 0.742316616539979, 0.7425791070089868, 0.6690071129319656]
2022-01-26 00:28:26:INFO:-------------Training local models-------------
2022-01-26 00:33:06:INFO:-------------Aggregating local models-------------
2022-01-26 00:33:12:INFO:-------------Round number: 1-------------
2022-01-26 00:33:12:INFO:-------------Sending models-------------
2022-01-26 00:33:12:INFO:-------------Evaluating models-------------
2022-01-26 00:33:13:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 00:33:13:INFO:Accuracy = [0.9045226130653267, 0.8994974874371859, 0.8991206030150753, 0.8993718592964824, 0.8994974874371859, 0.8996231155778894, 0.8989949748743719, 0.8899497487437186, 0.8994974874371859, 0.8207286432160804]
2022-01-26 00:33:13:INFO:Loss = [0.4186627078595473, 0.5279536915184865, 0.5254189911200173, 0.4673834101638602, 0.5002235595005841, 0.5270050551424075, 0.523017047937192, 0.5512254405860326, 0.47676063767030613, 0.6356791931780139]
2022-01-26 00:33:13:INFO:-------------Training local models-------------
2022-01-26 00:37:54:INFO:-------------Aggregating local models-------------
2022-01-26 00:37:59:INFO:-------------Round number: 2-------------
2022-01-26 00:37:59:INFO:-------------Sending models-------------
2022-01-26 00:38:00:INFO:-------------Evaluating models-------------
2022-01-26 00:38:01:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 00:38:01:INFO:Accuracy = [0.9045226130653267, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8594221105527639]
2022-01-26 00:38:01:INFO:Loss = [0.35105574363140607, 0.42547107985870325, 0.41878978301532305, 0.3813498253798365, 0.4031235670025025, 0.3984905506797771, 0.41427423666470015, 0.42082853068658455, 0.3647685600585075, 0.5150960045843268]
2022-01-26 00:38:01:INFO:-------------Training local models-------------
2022-01-26 00:42:41:INFO:-------------Aggregating local models-------------
2022-01-26 00:42:46:INFO:-------------Round number: 3-------------
2022-01-26 00:42:46:INFO:-------------Sending models-------------
2022-01-26 00:42:47:INFO:-------------Evaluating models-------------
2022-01-26 00:42:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 00:42:47:INFO:Accuracy = [0.9045226130653267, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8629396984924623]
2022-01-26 00:42:47:INFO:Loss = [0.34561739607372477, 0.3776748394546796, 0.37003896898360705, 0.3567898384290724, 0.36678680478028913, 0.34595496435860296, 0.3749896803093915, 0.3648045420946188, 0.3276837468147278, 0.4237260656740198]
2022-01-26 00:42:47:INFO:-------------Training local models-------------
2022-01-26 00:47:29:INFO:-------------Aggregating local models-------------
2022-01-26 00:47:34:INFO:-------------Round number: 4-------------
2022-01-26 00:47:34:INFO:-------------Sending models-------------
2022-01-26 00:47:35:INFO:-------------Evaluating models-------------
2022-01-26 00:47:35:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 00:47:35:INFO:Accuracy = [0.9052763819095477, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8814070351758794]
2022-01-26 00:47:35:INFO:Loss = [0.35085060866783613, 0.3604938634975472, 0.35126505320395657, 0.3521519339264338, 0.3578037104414935, 0.32884062384840235, 0.3630328913729394, 0.34518161805430847, 0.31708035561906633, 0.3751665058747009]
2022-01-26 00:47:35:INFO:-------------Training local models-------------
2022-01-26 00:52:16:INFO:-------------Aggregating local models-------------
2022-01-26 00:52:21:INFO:-------------Round number: 5-------------
2022-01-26 00:52:21:INFO:-------------Sending models-------------
2022-01-26 00:52:22:INFO:-------------Evaluating models-------------
2022-01-26 00:52:23:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 00:52:23:INFO:Accuracy = [0.9051507537688442, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8993718592964824, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8912060301507537]
2022-01-26 00:52:23:INFO:Loss = [0.3557325474749408, 0.35539417740088614, 0.34471873961501387, 0.3524524268492981, 0.35734010356754514, 0.3242952167688303, 0.36016368566445967, 0.33931459973205874, 0.31366678443386325, 0.3533701604634673]
2022-01-26 00:52:23:INFO:-------------Training local models-------------
2022-01-26 00:57:04:INFO:-------------Aggregating local models-------------
2022-01-26 00:57:09:INFO:-------------Round number: 6-------------
2022-01-26 00:57:09:INFO:-------------Sending models-------------
2022-01-26 00:57:10:INFO:-------------Evaluating models-------------
2022-01-26 00:57:11:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 00:57:11:INFO:Accuracy = [0.9054020100502512, 0.8993718592964824, 0.8994974874371859, 0.8994974874371859, 0.900251256281407, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.8997487437185929, 0.8964824120603015]
2022-01-26 00:57:11:INFO:Loss = [0.35913214196062565, 0.3544344142753275, 0.34255332159037566, 0.35355699451724487, 0.35876467764078074, 0.32371390914198145, 0.36007643225205005, 0.33801782640380473, 0.3116560082639282, 0.3447093387045453]
2022-01-26 00:57:11:INFO:-------------Training local models-------------
2022-01-26 01:01:51:INFO:-------------Aggregating local models-------------
2022-01-26 01:01:56:INFO:-------------Round number: 7-------------
2022-01-26 01:01:56:INFO:-------------Sending models-------------
2022-01-26 01:01:57:INFO:-------------Evaluating models-------------
2022-01-26 01:01:57:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 01:01:57:INFO:Accuracy = [0.9060301507537688, 0.8988693467336684, 0.8994974874371859, 0.8994974874371859, 0.8997487437185929, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.9006281407035176, 0.8976130653266332]
2022-01-26 01:01:57:INFO:Loss = [0.3610983521270393, 0.35468236121100993, 0.3417259541588213, 0.3544483367522158, 0.3601242267905767, 0.3241671537933637, 0.3606734701137447, 0.33800951155585857, 0.3095406813537655, 0.34191182465409514]
2022-01-26 01:01:57:INFO:-------------Training local models-------------
2022-01-26 01:06:39:INFO:-------------Aggregating local models-------------
2022-01-26 01:06:44:INFO:-------------Round number: 8-------------
2022-01-26 01:06:44:INFO:-------------Sending models-------------
2022-01-26 01:06:44:INFO:-------------Evaluating models-------------
2022-01-26 01:06:45:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 01:06:45:INFO:Accuracy = [0.9057788944723618, 0.8982412060301508, 0.8994974874371859, 0.8994974874371859, 0.8979899497487437, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.9011306532663317, 0.8979899497487437]
2022-01-26 01:06:45:INFO:Loss = [0.361855361601291, 0.3551072247663335, 0.3411174188906224, 0.35491667320979897, 0.360958959439292, 0.3246715158673387, 0.3612757867305123, 0.33818573059149126, 0.3070192109400304, 0.34156803973955124]
2022-01-26 01:06:45:INFO:-------------Training local models-------------
2022-01-26 01:11:26:INFO:-------------Aggregating local models-------------
2022-01-26 01:11:31:INFO:-------------Round number: 9-------------
2022-01-26 01:11:31:INFO:-------------Sending models-------------
2022-01-26 01:11:31:INFO:-------------Evaluating models-------------
2022-01-26 01:11:32:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 01:11:32:INFO:Accuracy = [0.9048994974874371, 0.8967336683417085, 0.8994974874371859, 0.8996231155778894, 0.8964824120603015, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.9013819095477387, 0.8986180904522613]
2022-01-26 01:11:32:INFO:Loss = [0.36169746804083863, 0.35536744157273564, 0.34033762599954653, 0.3549828818395509, 0.3612661137053715, 0.324915366855698, 0.3616915646210388, 0.3381986499731265, 0.304109180243171, 0.34212864957862166]
2022-01-26 01:11:32:INFO:-------------Training local models-------------
2022-01-26 01:16:13:INFO:-------------Aggregating local models-------------
2022-01-26 01:16:19:INFO:-------------Round number: 10-------------
2022-01-26 01:16:19:INFO:-------------Sending models-------------
2022-01-26 01:16:19:INFO:-------------Evaluating models-------------
2022-01-26 01:16:20:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 01:16:20:INFO:Accuracy = [0.9048994974874371, 0.8963567839195979, 0.8994974874371859, 0.8994974874371859, 0.8954773869346734, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.9013819095477387, 0.8991206030150753]
2022-01-26 01:16:20:INFO:Loss = [0.3609032018072716, 0.3553688740310956, 0.3392797970592077, 0.3547019868639845, 0.3611463580898304, 0.32481512711874805, 0.36188496626801225, 0.33795202691950393, 0.3008968169665217, 0.3428999530011086]
2022-01-26 01:16:20:INFO:-------------Training local models-------------
2022-01-26 01:20:48:INFO:-------------Aggregating local models-------------
2022-01-26 01:20:52:INFO:-------------Round number: 11-------------
2022-01-26 01:20:52:INFO:-------------Sending models-------------
2022-01-26 01:20:53:INFO:-------------Evaluating models-------------
2022-01-26 01:20:53:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 01:20:53:INFO:Accuracy = [0.9040201005025126, 0.8951005025125628, 0.8994974874371859, 0.8992462311557788, 0.8949748743718593, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.9018844221105528, 0.8994974874371859]
2022-01-26 01:20:53:INFO:Loss = [0.3596856680478732, 0.35509821188509766, 0.33792671336600527, 0.35414351635242824, 0.36070062407297104, 0.32437201720386294, 0.36187277756743697, 0.33745126823085037, 0.29748896453248797, 0.3435818609879844]
2022-01-26 01:20:53:INFO:-------------Training local models-------------
2022-01-26 01:24:23:INFO:-------------Aggregating local models-------------
2022-01-26 01:24:27:INFO:-------------Round number: 12-------------
2022-01-26 01:24:27:INFO:-------------Sending models-------------
2022-01-26 01:24:27:INFO:-------------Evaluating models-------------
2022-01-26 01:24:28:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 01:24:28:INFO:Accuracy = [0.9031407035175879, 0.8942211055276382, 0.8997487437185929, 0.8989949748743719, 0.8956030150753769, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.9025125628140703, 0.9008793969849246]
2022-01-26 01:24:28:INFO:Loss = [0.3582061535758364, 0.3545921483830591, 0.336308904329137, 0.3533715059110268, 0.360012480062456, 0.32361004430444995, 0.3616879654290089, 0.3367184244807641, 0.29395826602700964, 0.3440493538451554]
2022-01-26 01:24:28:INFO:-------------Training local models-------------
2022-01-26 01:27:57:INFO:-------------Aggregating local models-------------
2022-01-26 01:28:01:INFO:-------------Round number: 13-------------
2022-01-26 01:28:01:INFO:-------------Sending models-------------
2022-01-26 01:28:01:INFO:-------------Evaluating models-------------
2022-01-26 01:28:02:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 01:28:02:INFO:Accuracy = [0.9030150753768844, 0.8940954773869346, 0.900251256281407, 0.8993718592964824, 0.8957286432160804, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.903391959798995, 0.9012562814070352]
2022-01-26 01:28:02:INFO:Loss = [0.35657218859610545, 0.35388779340676924, 0.33446132178282617, 0.3524231524323698, 0.3591591062857278, 0.32256067188540893, 0.36136063094714177, 0.33577763315421255, 0.29036945913305234, 0.34425331255299363]
2022-01-26 01:28:02:INFO:-------------Training local models-------------
2022-01-26 01:31:30:INFO:-------------Aggregating local models-------------
2022-01-26 01:31:34:INFO:-------------Round number: 14-------------
2022-01-26 01:31:34:INFO:-------------Sending models-------------
2022-01-26 01:31:34:INFO:-------------Evaluating models-------------
2022-01-26 01:31:35:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 01:31:35:INFO:Accuracy = [0.9026381909547738, 0.8937185929648241, 0.9008793969849246, 0.8998743718592965, 0.8957286432160804, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.9042713567839196, 0.9006281407035176]
2022-01-26 01:31:35:INFO:Loss = [0.35484707773892427, 0.353021820436171, 0.33242150706861484, 0.3513399015119926, 0.35818031550052776, 0.3212544985452489, 0.3609140437452038, 0.33465938996430017, 0.28677431048460345, 0.3441929291540654]
2022-01-26 01:31:35:INFO:-------------Training local models-------------
2022-01-26 01:35:00:INFO:-------------Aggregating local models-------------
2022-01-26 01:35:04:INFO:-------------Round number: 15-------------
2022-01-26 01:35:04:INFO:-------------Sending models-------------
2022-01-26 01:35:05:INFO:-------------Evaluating models-------------
2022-01-26 01:35:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 01:35:05:INFO:Accuracy = [0.9026381909547738, 0.8938442211055276, 0.9010050251256282, 0.9005025125628141, 0.8964824120603015, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.9056532663316583, 0.8992462311557788]
2022-01-26 01:35:05:INFO:Loss = [0.353079189073725, 0.3520278337612823, 0.3302318784759272, 0.3501570344570294, 0.357107597679349, 0.3197149451653562, 0.36037052411529885, 0.33339111005241545, 0.2831984455861039, 0.34388037228105056]
2022-01-26 01:35:05:INFO:-------------Training local models-------------
2022-01-26 01:38:31:INFO:-------------Aggregating local models-------------
2022-01-26 01:38:35:INFO:-------------Round number: 16-------------
2022-01-26 01:38:35:INFO:-------------Sending models-------------
2022-01-26 01:38:35:INFO:-------------Evaluating models-------------
2022-01-26 01:38:36:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 01:38:36:INFO:Accuracy = [0.9028894472361809, 0.8938442211055276, 0.9012562814070352, 0.9001256281407035, 0.8963567839195979, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.9061557788944724, 0.8988693467336684]
2022-01-26 01:38:36:INFO:Loss = [0.35130333015929216, 0.3509224710152976, 0.32792957823480196, 0.3489054436959214, 0.3559502318276832, 0.31796267613693696, 0.3597523664409791, 0.33199414101677327, 0.2796651735976713, 0.34334085499821]
2022-01-26 01:38:36:INFO:-------------Training local models-------------
2022-01-26 01:42:02:INFO:-------------Aggregating local models-------------
2022-01-26 01:42:06:INFO:-------------Round number: 17-------------
2022-01-26 01:42:06:INFO:-------------Sending models-------------
2022-01-26 01:42:06:INFO:-------------Evaluating models-------------
2022-01-26 01:42:07:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 01:42:07:INFO:Accuracy = [0.9023869346733668, 0.8937185929648241, 0.9020100502512562, 0.9003768844221105, 0.8972361809045226, 0.8994974874371859, 0.8994974874371859, 0.8994974874371859, 0.9072864321608041, 0.8988693467336684]
2022-01-26 01:42:07:INFO:Loss = [0.34953948634971477, 0.34973392504543516, 0.32553962202527414, 0.3476041288831126, 0.3547392517478023, 0.31602019041626894, 0.35907313347461833, 0.3304802872727265, 0.27618943506748833, 0.34259646127571414]
2022-01-26 01:42:07:INFO:-------------Training local models-------------
2022-01-26 01:45:33:INFO:-------------Aggregating local models-------------
2022-01-26 01:45:37:INFO:-------------Round number: 18-------------
2022-01-26 01:45:37:INFO:-------------Sending models-------------
2022-01-26 01:45:37:INFO:-------------Evaluating models-------------
2022-01-26 01:45:38:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 01:45:38:INFO:Accuracy = [0.9016331658291458, 0.8938442211055276, 0.9026381909547738, 0.9003768844221105, 0.8976130653266332, 0.8994974874371859, 0.8996231155778894, 0.8996231155778894, 0.907788944723618, 0.8984924623115578]
2022-01-26 01:45:38:INFO:Loss = [0.34780097840793767, 0.3484776824263472, 0.3230957242112663, 0.3462644255340998, 0.3534834310038006, 0.31390735836484324, 0.35834008620012947, 0.32886745282753027, 0.2727800427968778, 0.34166906392154983]
2022-01-26 01:45:38:INFO:-------------Training local models-------------
2022-01-26 01:49:04:INFO:-------------Aggregating local models-------------
2022-01-26 01:49:08:INFO:-------------Round number: 19-------------
2022-01-26 01:49:08:INFO:-------------Sending models-------------
2022-01-26 01:49:08:INFO:-------------Evaluating models-------------
2022-01-26 01:49:09:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 01:49:09:INFO:Accuracy = [0.9013819095477387, 0.8938442211055276, 0.9028894472361809, 0.8998743718592965, 0.8982412060301508, 0.8994974874371859, 0.8996231155778894, 0.8996231155778894, 0.9084170854271357, 0.8986180904522613]
2022-01-26 01:49:09:INFO:Loss = [0.34609987451952307, 0.3471724334074624, 0.32062449467242066, 0.34489607286812674, 0.35218518283498945, 0.31164853237382134, 0.35756768967638064, 0.32717834330683376, 0.26944812638076704, 0.3405796461668446]
2022-01-26 01:49:09:INFO:-------------Training local models-------------
2022-01-26 01:52:35:INFO:-------------Aggregating local models-------------
2022-01-26 01:52:39:INFO:-------------Round number: 20-------------
2022-01-26 01:52:39:INFO:-------------Sending models-------------
2022-01-26 01:52:39:INFO:-------------Evaluating models-------------
2022-01-26 01:52:40:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 01:52:40:INFO:Accuracy = [0.9010050251256282, 0.8945979899497487, 0.9030150753768844, 0.900251256281407, 0.8988693467336684, 0.8996231155778894, 0.8996231155778894, 0.9001256281407035, 0.9089195979899497, 0.8989949748743719]
2022-01-26 01:52:40:INFO:Loss = [0.3444352786772739, 0.34582587372717544, 0.3181421467706786, 0.3435148751016837, 0.3508596665895165, 0.3092566816950563, 0.35675843322097356, 0.3254247161012199, 0.2662099538436487, 0.3393571890478757]
2022-01-26 01:52:40:INFO:-------------Training local models-------------
2022-01-26 01:56:06:INFO:-------------Aggregating local models-------------
2022-01-26 01:56:10:INFO:-------------Round number: 21-------------
2022-01-26 01:56:10:INFO:-------------Sending models-------------
2022-01-26 01:56:10:INFO:-------------Evaluating models-------------
2022-01-26 01:56:11:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 01:56:11:INFO:Accuracy = [0.9006281407035176, 0.8948492462311558, 0.9035175879396985, 0.9003768844221105, 0.8993718592964824, 0.8996231155778894, 0.8996231155778894, 0.9003768844221105, 0.9094221105527638, 0.8993718592964824]
2022-01-26 01:56:11:INFO:Loss = [0.34281351960886586, 0.34444752605117146, 0.31565704537396455, 0.3421209147527589, 0.349508427345573, 0.3067494856951824, 0.3559148993024874, 0.3236170450047632, 0.26307103202570625, 0.33802826485442156]
2022-01-26 01:56:11:INFO:-------------Training local models-------------
2022-01-26 01:59:37:INFO:-------------Aggregating local models-------------
2022-01-26 01:59:41:INFO:-------------Round number: 22-------------
2022-01-26 01:59:41:INFO:-------------Sending models-------------
2022-01-26 01:59:41:INFO:-------------Evaluating models-------------
2022-01-26 01:59:41:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 01:59:41:INFO:Accuracy = [0.9001256281407035, 0.8956030150753769, 0.9032663316582915, 0.900251256281407, 0.8997487437185929, 0.9, 0.8997487437185929, 0.9006281407035176, 0.9099246231155779, 0.8993718592964824]
2022-01-26 01:59:41:INFO:Loss = [0.3412363695415982, 0.34305059775036184, 0.3131851529955265, 0.34071481931748704, 0.3481352414617586, 0.3041468652049501, 0.3550447176149742, 0.321768042879488, 0.26003358621693135, 0.3366079388850897]
2022-01-26 01:59:41:INFO:-------------Training local models-------------
2022-01-26 02:03:07:INFO:-------------Aggregating local models-------------
2022-01-26 02:03:11:INFO:-------------Round number: 23-------------
2022-01-26 02:03:11:INFO:-------------Sending models-------------
2022-01-26 02:03:12:INFO:-------------Evaluating models-------------
2022-01-26 02:03:12:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 02:03:12:INFO:Accuracy = [0.8987437185929649, 0.8953517587939699, 0.9026381909547738, 0.900251256281407, 0.8998743718592965, 0.9006281407035176, 0.8997487437185929, 0.9011306532663317, 0.9103015075376885, 0.8992462311557788]
2022-01-26 02:03:12:INFO:Loss = [0.3397013635407366, 0.34164046866809905, 0.31073610057782886, 0.33929936879843325, 0.3467384861342272, 0.30146602739640815, 0.3541486129988378, 0.3198905259221043, 0.25710332453550405, 0.33512372092985027]
2022-01-26 02:03:12:INFO:-------------Training local models-------------
2022-01-26 02:06:38:INFO:-------------Aggregating local models-------------
2022-01-26 02:06:42:INFO:-------------Round number: 24-------------
2022-01-26 02:06:42:INFO:-------------Sending models-------------
2022-01-26 02:06:42:INFO:-------------Evaluating models-------------
2022-01-26 02:06:43:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 02:06:43:INFO:Accuracy = [0.8987437185929649, 0.8945979899497487, 0.9025125628140703, 0.9003768844221105, 0.900251256281407, 0.9016331658291458, 0.8996231155778894, 0.9015075376884422, 0.9108040201005025, 0.8993718592964824]
2022-01-26 02:06:43:INFO:Loss = [0.3382077461258326, 0.34022424313890276, 0.3083191440632595, 0.3378815724322544, 0.34532732070989947, 0.29872350911399226, 0.3532280021875947, 0.3179939820538813, 0.25428125666613555, 0.33358835814586235]
2022-01-26 02:06:43:INFO:-------------Training local models-------------
2022-01-26 02:10:09:INFO:-------------Aggregating local models-------------
2022-01-26 02:10:13:INFO:-------------Round number: 25-------------
2022-01-26 02:10:13:INFO:-------------Sending models-------------
2022-01-26 02:10:13:INFO:-------------Evaluating models-------------
2022-01-26 02:10:14:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 02:10:14:INFO:Accuracy = [0.8983668341708543, 0.8947236180904523, 0.9023869346733668, 0.9003768844221105, 0.9008793969849246, 0.9023869346733668, 0.9, 0.9018844221105528, 0.9116834170854271, 0.8994974874371859]
2022-01-26 02:10:14:INFO:Loss = [0.33676184413383653, 0.33880405120514145, 0.30593988269417727, 0.33646429693279556, 0.34390187533057515, 0.29594070797589556, 0.3522880381375701, 0.31608913651662857, 0.25157734661845105, 0.33202794688430864]
2022-01-26 02:10:14:INFO:-------------Training local models-------------
2022-01-26 02:13:40:INFO:-------------Aggregating local models-------------
2022-01-26 02:13:44:INFO:-------------Round number: 26-------------
2022-01-26 02:13:44:INFO:-------------Sending models-------------
2022-01-26 02:13:44:INFO:-------------Evaluating models-------------
2022-01-26 02:13:45:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 02:13:45:INFO:Accuracy = [0.8978643216080402, 0.8947236180904523, 0.9023869346733668, 0.9005025125628141, 0.9011306532663317, 0.9030150753768844, 0.9, 0.9027638190954774, 0.9121859296482412, 0.8994974874371859]
2022-01-26 02:13:45:INFO:Loss = [0.33536921654963614, 0.3373904463334299, 0.30359744800994143, 0.3350541317582729, 0.3424707615195806, 0.29313492505394634, 0.35133241513865676, 0.3141852471996192, 0.24899519702897, 0.3304525658712914]
2022-01-26 02:13:45:INFO:-------------Training local models-------------
2022-01-26 02:17:11:INFO:-------------Aggregating local models-------------
2022-01-26 02:17:15:INFO:-------------Round number: 27-------------
2022-01-26 02:17:15:INFO:-------------Sending models-------------
2022-01-26 02:17:15:INFO:-------------Evaluating models-------------
2022-01-26 02:17:16:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 02:17:16:INFO:Accuracy = [0.8974874371859296, 0.8948492462311558, 0.9022613065326633, 0.9003768844221105, 0.9012562814070352, 0.9040201005025126, 0.8997487437185929, 0.9031407035175879, 0.9123115577889447, 0.8997487437185929]
2022-01-26 02:17:16:INFO:Loss = [0.3340179459238659, 0.3359833672717588, 0.3012945069440046, 0.33365729361323254, 0.3410364486763825, 0.29031275729438166, 0.3503663782498345, 0.31228781929567234, 0.24652475463086038, 0.32888370108364817]
2022-01-26 02:17:16:INFO:-------------Training local models-------------
2022-01-26 02:20:42:INFO:-------------Aggregating local models-------------
2022-01-26 02:20:46:INFO:-------------Round number: 28-------------
2022-01-26 02:20:46:INFO:-------------Sending models-------------
2022-01-26 02:20:46:INFO:-------------Evaluating models-------------
2022-01-26 02:20:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 02:20:47:INFO:Accuracy = [0.8971105527638191, 0.8949748743718593, 0.9023869346733668, 0.9003768844221105, 0.9015075376884422, 0.9051507537688442, 0.8994974874371859, 0.903643216080402, 0.9126884422110553, 0.900251256281407]
2022-01-26 02:20:47:INFO:Loss = [0.3327043773466019, 0.33458582839774126, 0.29903826417036394, 0.332277355182111, 0.3396078220863438, 0.28748652533670166, 0.3493859086503935, 0.31040039403953745, 0.24416258616663103, 0.327320012015913]
2022-01-26 02:20:47:INFO:-------------Training local models-------------
2022-01-26 02:24:13:INFO:-------------Aggregating local models-------------
2022-01-26 02:24:17:INFO:-------------Round number: 29-------------
2022-01-26 02:24:17:INFO:-------------Sending models-------------
2022-01-26 02:24:17:INFO:-------------Evaluating models-------------
2022-01-26 02:24:18:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 02:24:18:INFO:Accuracy = [0.8971105527638191, 0.8947236180904523, 0.9021356783919598, 0.9005025125628141, 0.9016331658291458, 0.9057788944723618, 0.8994974874371859, 0.9038944723618091, 0.9131909547738694, 0.9003768844221105]
2022-01-26 02:24:18:INFO:Loss = [0.33142640101419174, 0.33320122837421284, 0.296834805353203, 0.3309141950092124, 0.33819026249137957, 0.2846702856933651, 0.34839752196666585, 0.30852966092938755, 0.241914902949453, 0.3257743317877228]
2022-01-26 02:24:18:INFO:-------------Training local models-------------
2022-01-26 02:27:44:INFO:-------------Aggregating local models-------------
2022-01-26 02:27:48:INFO:-------------Round number: 30-------------
2022-01-26 02:27:48:INFO:-------------Sending models-------------
2022-01-26 02:27:48:INFO:-------------Evaluating models-------------
2022-01-26 02:27:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 02:27:49:INFO:Accuracy = [0.8972361809045226, 0.8944723618090452, 0.9023869346733668, 0.9001256281407035, 0.9018844221105528, 0.907035175879397, 0.8997487437185929, 0.9045226130653267, 0.9133165829145728, 0.9006281407035176]
2022-01-26 02:27:49:INFO:Loss = [0.33018511006065726, 0.33183285623938596, 0.2946812076185217, 0.3295770627469873, 0.3367857366950069, 0.28187391955648833, 0.3474045684888734, 0.30667609680238084, 0.23977718947820328, 0.3242560670004418]
2022-01-26 02:27:49:INFO:-------------Training local models-------------
2022-01-26 02:31:14:INFO:-------------Aggregating local models-------------
2022-01-26 02:31:18:INFO:-------------Round number: 31-------------
2022-01-26 02:31:18:INFO:-------------Sending models-------------
2022-01-26 02:31:19:INFO:-------------Evaluating models-------------
2022-01-26 02:31:19:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 02:31:19:INFO:Accuracy = [0.8976130653266332, 0.8943467336683417, 0.9031407035175879, 0.9, 0.9021356783919598, 0.9074120603015076, 0.8994974874371859, 0.9043969849246232, 0.9138190954773869, 0.9007537688442211]
2022-01-26 02:31:19:INFO:Loss = [0.32897871118928096, 0.33048370166040547, 0.29257928606253775, 0.32825947406902983, 0.3353922653138338, 0.2791104653672357, 0.3464035036875375, 0.3048483381918327, 0.23774913544930407, 0.3227710220681962]
2022-01-26 02:31:19:INFO:-------------Training local models-------------
2022-01-26 02:34:45:INFO:-------------Aggregating local models-------------
2022-01-26 02:34:49:INFO:-------------Round number: 32-------------
2022-01-26 02:34:49:INFO:-------------Sending models-------------
2022-01-26 02:34:50:INFO:-------------Evaluating models-------------
2022-01-26 02:34:50:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 02:34:50:INFO:Accuracy = [0.8976130653266332, 0.8947236180904523, 0.903391959798995, 0.900251256281407, 0.9021356783919598, 0.9081658291457286, 0.8992462311557788, 0.9043969849246232, 0.9139447236180904, 0.9008793969849246]
2022-01-26 02:34:50:INFO:Loss = [0.3278078428404078, 0.32916061827285803, 0.29053047329337156, 0.32695770024055215, 0.33402559655395586, 0.276384848745624, 0.34539872887146533, 0.3030469481968999, 0.23581866800186024, 0.3213151937453591]
2022-01-26 02:34:50:INFO:-------------Training local models-------------
2022-01-26 02:38:16:INFO:-------------Aggregating local models-------------
2022-01-26 02:38:20:INFO:-------------Round number: 33-------------
2022-01-26 02:38:20:INFO:-------------Sending models-------------
2022-01-26 02:38:21:INFO:-------------Evaluating models-------------
2022-01-26 02:38:21:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 02:38:21:INFO:Accuracy = [0.8977386934673367, 0.8956030150753769, 0.9037688442211055, 0.9013819095477387, 0.9023869346733668, 0.9091708542713568, 0.8994974874371859, 0.9046482412060302, 0.9144472361809045, 0.9013819095477387]
2022-01-26 02:38:21:INFO:Loss = [0.3266727912436291, 0.32786366523210725, 0.2885351474560685, 0.32567786915817454, 0.33266382930266797, 0.2737065059455795, 0.34439274683669585, 0.3012763818903784, 0.23398773521933725, 0.31989539568148667]
2022-01-26 02:38:21:INFO:-------------Training local models-------------
2022-01-26 02:41:47:INFO:-------------Aggregating local models-------------
2022-01-26 02:41:51:INFO:-------------Round number: 34-------------
2022-01-26 02:41:51:INFO:-------------Sending models-------------
2022-01-26 02:41:52:INFO:-------------Evaluating models-------------
2022-01-26 02:41:52:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 02:41:52:INFO:Accuracy = [0.8976130653266332, 0.8956030150753769, 0.9048994974874371, 0.9018844221105528, 0.9026381909547738, 0.910427135678392, 0.8998743718592965, 0.9042713567839196, 0.914572864321608, 0.9012562814070352]
2022-01-26 02:41:52:INFO:Loss = [0.3255690635654645, 0.3265930587921909, 0.2865919306050593, 0.3244213264192169, 0.33132929703099046, 0.27107845089543403, 0.3433885099600308, 0.29953556219537053, 0.23225581511181204, 0.31850937458138967]
2022-01-26 02:41:52:INFO:-------------Training local models-------------
2022-01-26 02:45:18:INFO:-------------Aggregating local models-------------
2022-01-26 02:45:22:INFO:-------------Round number: 35-------------
2022-01-26 02:45:22:INFO:-------------Sending models-------------
2022-01-26 02:45:22:INFO:-------------Evaluating models-------------
2022-01-26 02:45:23:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 02:45:23:INFO:Accuracy = [0.8977386934673367, 0.8957286432160804, 0.9054020100502512, 0.9020100502512562, 0.9028894472361809, 0.9114321608040201, 0.900251256281407, 0.9047738693467337, 0.9152010050251256, 0.9013819095477387]
2022-01-26 02:45:23:INFO:Loss = [0.3244928552525764, 0.3253536082092841, 0.2847030652527833, 0.3231835082248228, 0.33001743369366054, 0.2685034741558621, 0.3423856880197573, 0.29782507197940766, 0.23061282213908343, 0.3171541040866219]
2022-01-26 02:45:23:INFO:-------------Training local models-------------
2022-01-26 02:48:49:INFO:-------------Aggregating local models-------------
2022-01-26 02:48:53:INFO:-------------Round number: 36-------------
2022-01-26 02:48:53:INFO:-------------Sending models-------------
2022-01-26 02:48:53:INFO:-------------Evaluating models-------------
2022-01-26 02:48:54:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 02:48:54:INFO:Accuracy = [0.8978643216080402, 0.8956030150753769, 0.9055276381909547, 0.9021356783919598, 0.9027638190954774, 0.9125628140703518, 0.9003768844221105, 0.9048994974874371, 0.9157035175879397, 0.9016331658291458]
2022-01-26 02:48:54:INFO:Loss = [0.3234412964204111, 0.32413952928691653, 0.2828692757903631, 0.321971462899117, 0.32872922067067134, 0.2659849122391274, 0.34138573084644336, 0.29614495197732243, 0.22905476608468062, 0.3158292980050322]
2022-01-26 02:48:54:INFO:-------------Training local models-------------
2022-01-26 02:52:20:INFO:-------------Aggregating local models-------------
2022-01-26 02:52:24:INFO:-------------Round number: 37-------------
2022-01-26 02:52:24:INFO:-------------Sending models-------------
2022-01-26 02:52:24:INFO:-------------Evaluating models-------------
2022-01-26 02:52:25:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 02:52:25:INFO:Accuracy = [0.8977386934673367, 0.8959798994974875, 0.9055276381909547, 0.9030150753768844, 0.9027638190954774, 0.9126884422110553, 0.9007537688442211, 0.9051507537688442, 0.9160804020100503, 0.9016331658291458]
2022-01-26 02:52:25:INFO:Loss = [0.3224146534763651, 0.32295530330595656, 0.28108595888219284, 0.3207812223901701, 0.3274624808948843, 0.2635239492259433, 0.340387629204659, 0.29449376913171316, 0.22757502461797627, 0.31453527592534397]
2022-01-26 02:52:25:INFO:-------------Training local models-------------
2022-01-26 02:55:51:INFO:-------------Aggregating local models-------------
2022-01-26 02:55:55:INFO:-------------Round number: 38-------------
2022-01-26 02:55:55:INFO:-------------Sending models-------------
2022-01-26 02:55:55:INFO:-------------Evaluating models-------------
2022-01-26 02:55:56:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 02:55:56:INFO:Accuracy = [0.8973618090452261, 0.896105527638191, 0.9066582914572864, 0.9031407035175879, 0.9028894472361809, 0.9134422110552763, 0.9005025125628141, 0.9048994974874371, 0.9162060301507537, 0.9018844221105528]
2022-01-26 02:55:56:INFO:Loss = [0.3214166051422681, 0.3218036707322202, 0.2793543171043971, 0.31961404648258457, 0.32621476159023877, 0.26112079388232684, 0.3393943411621017, 0.292872773642516, 0.22617117611307594, 0.31327543111901784]
2022-01-26 02:55:56:INFO:-------------Training local models-------------
2022-01-26 02:59:21:INFO:-------------Aggregating local models-------------
2022-01-26 02:59:25:INFO:-------------Round number: 39-------------
2022-01-26 02:59:25:INFO:-------------Sending models-------------
2022-01-26 02:59:26:INFO:-------------Evaluating models-------------
2022-01-26 02:59:26:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 02:59:26:INFO:Accuracy = [0.8971105527638191, 0.8963567839195979, 0.9059045226130653, 0.9032663316582915, 0.9032663316582915, 0.9144472361809045, 0.9006281407035176, 0.9051507537688442, 0.9164572864321608, 0.9020100502512562]
2022-01-26 02:59:26:INFO:Loss = [0.32044334594047996, 0.3206838150719302, 0.2776728973316787, 0.31846954190551335, 0.32498759106175984, 0.25877805099115897, 0.33840593201431196, 0.29128332525941, 0.22484142119860528, 0.31204702536664414]
2022-01-26 02:59:26:INFO:-------------Training local models-------------
2022-01-26 03:02:52:INFO:-------------Aggregating local models-------------
