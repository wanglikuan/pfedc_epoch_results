2022-01-25 15:03:58:INFO:-------------Round number: 0-------------
2022-01-25 15:03:58:INFO:-------------Sending models-------------
2022-01-25 15:03:58:INFO:-------------Evaluating models-------------
2022-01-25 15:03:58:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:03:58:INFO:Accuracy = [0.899631298648095, 0.88529291274068, 0.8955346169602622, 0.8975829578041786, 0.899631298648095, 0.08111429741909054, 0.0962720196640721, 0.10446538303973782, 0.09340434248258911, 0.8975829578041786]
2022-01-25 15:03:58:INFO:Loss = [0.6694261140568928, 0.6529066985696615, 0.6620884674682523, 0.6550320217119578, 0.6637347804406099, 0.7383340320617436, 0.7404487229905037, 0.7411296843798715, 0.7476874158268627, 0.6698590415953027]
2022-01-25 15:03:58:INFO:-------------Training local models-------------
2022-01-25 15:04:42:INFO:-------------Aggregating local models-------------
2022-01-25 15:04:43:INFO:-------------Round number: 1-------------
2022-01-25 15:04:43:INFO:-------------Sending models-------------
2022-01-25 15:04:43:INFO:-------------Evaluating models-------------
2022-01-25 15:04:43:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:04:43:INFO:Accuracy = [0.899631298648095, 0.8837566571077428, 0.8937935272429333, 0.895637034002458, 0.8947152806226956, 0.9021917247029906, 0.8854977468250717, 0.8697255223269152, 0.899119213437116, 0.6441007783695207]
2022-01-25 15:04:43:INFO:Loss = [0.4913007974905442, 0.535418341497157, 0.5498085946076623, 0.5208788542492816, 0.5446315707699142, 0.5725501114651347, 0.5731652957318211, 0.5893793003217748, 0.5488165761513917, 0.6772478419657078]
2022-01-25 15:04:43:INFO:-------------Training local models-------------
2022-01-25 15:05:27:INFO:-------------Aggregating local models-------------
2022-01-25 15:05:28:INFO:-------------Round number: 2-------------
2022-01-25 15:05:28:INFO:-------------Sending models-------------
2022-01-25 15:05:28:INFO:-------------Evaluating models-------------
2022-01-25 15:05:28:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:05:28:INFO:Accuracy = [0.899631298648095, 0.8853953297828758, 0.8955346169602622, 0.8975829578041786, 0.8993240475215076, 0.9188857025809095, 0.9034207292093405, 0.8955346169602622, 0.9065956575174109, 0.8208725931995084]
2022-01-25 15:05:28:INFO:Loss = [0.4005675830926772, 0.44071831554784874, 0.4554340064751472, 0.4258562370048151, 0.44213784645383647, 0.4391165982728877, 0.451311189054051, 0.46752590042970454, 0.4401040681710696, 0.6048821736522406]
2022-01-25 15:05:28:INFO:-------------Training local models-------------
2022-01-25 15:06:12:INFO:-------------Aggregating local models-------------
2022-01-25 15:06:13:INFO:-------------Round number: 3-------------
2022-01-25 15:06:13:INFO:-------------Sending models-------------
2022-01-25 15:06:13:INFO:-------------Evaluating models-------------
2022-01-25 15:06:13:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:06:13:INFO:Accuracy = [0.899631298648095, 0.8869315854158132, 0.8955346169602622, 0.8975829578041786, 0.899631298648095, 0.9188857025809095, 0.9037279803359279, 0.8955346169602622, 0.9065956575174109, 0.8767922982384269]
2022-01-25 15:06:13:INFO:Loss = [0.3760299296597143, 0.3751391168898952, 0.39612118477388664, 0.3858857961224269, 0.3772017335925909, 0.35474565325572704, 0.3857384647217162, 0.39178540223399816, 0.39150554359581863, 0.5111429516358826]
2022-01-25 15:06:13:INFO:-------------Training local models-------------
2022-01-25 15:06:57:INFO:-------------Aggregating local models-------------
2022-01-25 15:06:58:INFO:-------------Round number: 4-------------
2022-01-25 15:06:58:INFO:-------------Sending models-------------
2022-01-25 15:06:58:INFO:-------------Evaluating models-------------
2022-01-25 15:06:58:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:06:58:INFO:Accuracy = [0.899631298648095, 0.8890823433019255, 0.8955346169602622, 0.8975829578041786, 0.899631298648095, 0.9188857025809095, 0.9037279803359279, 0.8955346169602622, 0.9065956575174109, 0.8947152806226956]
2022-01-25 15:06:58:INFO:Loss = [0.37658706766777184, 0.3393191214542514, 0.3684203322978354, 0.3751697861473124, 0.3487473823456723, 0.3136694346886893, 0.35921480684605644, 0.35737129183625743, 0.37873181061104205, 0.43925276638566835]
2022-01-25 15:06:58:INFO:-------------Training local models-------------
2022-01-25 15:07:42:INFO:-------------Aggregating local models-------------
2022-01-25 15:07:43:INFO:-------------Round number: 5-------------
2022-01-25 15:07:43:INFO:-------------Sending models-------------
2022-01-25 15:07:43:INFO:-------------Evaluating models-------------
2022-01-25 15:07:44:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:07:44:INFO:Accuracy = [0.899631298648095, 0.891028267103646, 0.8955346169602622, 0.8975829578041786, 0.899631298648095, 0.9188857025809095, 0.9037279803359279, 0.8955346169602622, 0.9065956575174109, 0.8977877918885703]
2022-01-25 15:07:44:INFO:Loss = [0.38271620163037023, 0.3217244669886604, 0.35852240484142245, 0.37484850096853967, 0.3398289403121572, 0.29631263573243083, 0.3511200979083398, 0.34499669975125363, 0.3800897089640859, 0.39702323371516246]
2022-01-25 15:07:44:INFO:-------------Training local models-------------
2022-01-25 15:08:27:INFO:-------------Aggregating local models-------------
2022-01-25 15:08:28:INFO:-------------Round number: 6-------------
2022-01-25 15:08:28:INFO:-------------Sending models-------------
2022-01-25 15:08:28:INFO:-------------Evaluating models-------------
2022-01-25 15:08:29:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:08:29:INFO:Accuracy = [0.899631298648095, 0.8911306841458418, 0.8955346169602622, 0.8975829578041786, 0.899631298648095, 0.9188857025809095, 0.9037279803359279, 0.8955346169602622, 0.9065956575174109, 0.8976853748463745]
2022-01-25 15:08:29:INFO:Loss = [0.3882564475232585, 0.31291757607950826, 0.3565714761755204, 0.3768385824537922, 0.33872892275080235, 0.28963004045103724, 0.350183455548976, 0.34198132397233827, 0.38537003589997776, 0.37575764458707395]
2022-01-25 15:08:29:INFO:-------------Training local models-------------
2022-01-25 15:09:13:INFO:-------------Aggregating local models-------------
2022-01-25 15:09:14:INFO:-------------Round number: 7-------------
2022-01-25 15:09:14:INFO:-------------Sending models-------------
2022-01-25 15:09:14:INFO:-------------Evaluating models-------------
2022-01-25 15:09:14:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:09:14:INFO:Accuracy = [0.899631298648095, 0.8915403523146251, 0.8955346169602622, 0.8975829578041786, 0.9001433838590741, 0.9188857025809095, 0.9037279803359279, 0.8955346169602622, 0.9065956575174109, 0.8975829578041786]
2022-01-25 15:09:14:INFO:Loss = [0.3918990253156836, 0.3078048168263783, 0.35762735671107765, 0.37853942928085654, 0.34012548139548504, 0.2873763449221852, 0.35151266990346236, 0.3423518581511983, 0.3908794601144561, 0.36648386861520044]
2022-01-25 15:09:14:INFO:-------------Training local models-------------
2022-01-25 15:09:58:INFO:-------------Aggregating local models-------------
2022-01-25 15:09:59:INFO:-------------Round number: 8-------------
2022-01-25 15:09:59:INFO:-------------Sending models-------------
2022-01-25 15:09:59:INFO:-------------Evaluating models-------------
2022-01-25 15:09:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:09:59:INFO:Accuracy = [0.899631298648095, 0.8913355182302335, 0.8955346169602622, 0.8975829578041786, 0.9006554690700532, 0.9188857025809095, 0.9038303973781238, 0.8955346169602622, 0.9065956575174109, 0.8975829578041786]
2022-01-25 15:09:59:INFO:Loss = [0.3937474769837345, 0.30404277032165683, 0.35955251690453555, 0.3793576804128205, 0.3419510200436562, 0.28686168741604406, 0.35318533787164275, 0.343627441675997, 0.39553065482749833, 0.36342383349457025]
2022-01-25 15:09:59:INFO:-------------Training local models-------------
2022-01-25 15:10:43:INFO:-------------Aggregating local models-------------
2022-01-25 15:10:44:INFO:-------------Round number: 9-------------
2022-01-25 15:10:44:INFO:-------------Sending models-------------
2022-01-25 15:10:44:INFO:-------------Evaluating models-------------
2022-01-25 15:10:44:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:10:44:INFO:Accuracy = [0.899631298648095, 0.8919500204834084, 0.8955346169602622, 0.8975829578041786, 0.9010651372388365, 0.9188857025809095, 0.9041376485047112, 0.8955346169602622, 0.9065956575174109, 0.8975829578041786]
2022-01-25 15:10:44:INFO:Loss = [0.3941754745147796, 0.3006371808166218, 0.36147980120632794, 0.3793413751117278, 0.3434851164000535, 0.286969043018721, 0.35451734486611736, 0.3448545400149409, 0.39916367094528077, 0.3633614899022127]
2022-01-25 15:10:44:INFO:-------------Training local models-------------
2022-01-25 15:11:28:INFO:-------------Aggregating local models-------------
2022-01-25 15:11:29:INFO:-------------Round number: 10-------------
2022-01-25 15:11:29:INFO:-------------Sending models-------------
2022-01-25 15:11:29:INFO:-------------Evaluating models-------------
2022-01-25 15:11:29:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:11:29:INFO:Accuracy = [0.899631298648095, 0.8925645227365834, 0.8955346169602622, 0.8975829578041786, 0.9010651372388365, 0.9188857025809095, 0.9049569848422777, 0.8955346169602622, 0.9068004916018025, 0.8975829578041786]
2022-01-25 15:11:29:INFO:Loss = [0.39355685414776165, 0.29721179669085757, 0.36309947884446625, 0.3786673727203031, 0.34451290817045377, 0.2872392595032633, 0.3553242405471329, 0.3457082365439203, 0.4018879878061523, 0.3646145481242356]
2022-01-25 15:11:29:INFO:-------------Training local models-------------
2022-01-25 15:12:13:INFO:-------------Aggregating local models-------------
2022-01-25 15:12:14:INFO:-------------Round number: 11-------------
2022-01-25 15:12:14:INFO:-------------Sending models-------------
2022-01-25 15:12:14:INFO:-------------Evaluating models-------------
2022-01-25 15:12:14:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:12:14:INFO:Accuracy = [0.9002458009012699, 0.8934862761163458, 0.8955346169602622, 0.8975829578041786, 0.9009627201966407, 0.9188857025809095, 0.9063908234330192, 0.8955346169602622, 0.9069029086439984, 0.8976853748463745]
2022-01-25 15:12:14:INFO:Loss = [0.3921738415193431, 0.29365869281857, 0.36432587116993337, 0.3775173197822803, 0.34501920307771633, 0.28748579686566245, 0.3556111413208689, 0.34611098541558055, 0.40387375961355054, 0.36633087112577856]
2022-01-25 15:12:14:INFO:-------------Training local models-------------
2022-01-25 15:12:58:INFO:-------------Aggregating local models-------------
2022-01-25 15:12:59:INFO:-------------Round number: 12-------------
2022-01-25 15:12:59:INFO:-------------Sending models-------------
2022-01-25 15:12:59:INFO:-------------Evaluating models-------------
2022-01-25 15:12:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:12:59:INFO:Accuracy = [0.9016796394920115, 0.8955346169602622, 0.8955346169602622, 0.8975829578041786, 0.9008603031544449, 0.9188857025809095, 0.9073125768127817, 0.8955346169602622, 0.90710774272839, 0.8977877918885703]
2022-01-25 15:12:59:INFO:Loss = [0.39024864403788107, 0.2899548220007525, 0.36517181911340557, 0.37602772970868154, 0.34505049630676027, 0.28765050827041294, 0.3554440395130529, 0.3460789177809422, 0.4052806231029185, 0.3680950948317634]
2022-01-25 15:12:59:INFO:-------------Training local models-------------
2022-01-25 15:13:43:INFO:-------------Aggregating local models-------------
2022-01-25 15:13:44:INFO:-------------Round number: 13-------------
2022-01-25 15:13:44:INFO:-------------Sending models-------------
2022-01-25 15:13:44:INFO:-------------Evaluating models-------------
2022-01-25 15:13:45:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:13:45:INFO:Accuracy = [0.902498975829578, 0.8972757066775912, 0.8955346169602622, 0.8975829578041786, 0.9006554690700532, 0.9188857025809095, 0.9082343301925441, 0.8955346169602622, 0.9070053256861942, 0.8977877918885703]
2022-01-25 15:13:45:INFO:Loss = [0.3879084249440274, 0.28612140575572637, 0.3656696863762427, 0.3743054021587874, 0.3446651763545593, 0.28770191000157563, 0.35491283099971704, 0.3456539816754561, 0.4062334945126269, 0.3697021362485821]
2022-01-25 15:13:45:INFO:-------------Training local models-------------
2022-01-25 15:14:28:INFO:-------------Aggregating local models-------------
2022-01-25 15:14:29:INFO:-------------Round number: 14-------------
2022-01-25 15:14:29:INFO:-------------Sending models-------------
2022-01-25 15:14:29:INFO:-------------Evaluating models-------------
2022-01-25 15:14:30:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:14:30:INFO:Accuracy = [0.9035231462515363, 0.8981974600573536, 0.8955346169602622, 0.8975829578041786, 0.900757886112249, 0.9188857025809095, 0.9092585006145023, 0.895637034002458, 0.9068004916018025, 0.8979926259729619]
2022-01-25 15:14:30:INFO:Loss = [0.385285231369116, 0.2822112485793881, 0.365864903268903, 0.37241713387990083, 0.3439401143468193, 0.2876524987561346, 0.35407456287420563, 0.34489526814219895, 0.4068285184286669, 0.3710764355374525]
2022-01-25 15:14:30:INFO:-------------Training local models-------------
2022-01-25 15:15:14:INFO:-------------Aggregating local models-------------
2022-01-25 15:15:15:INFO:-------------Round number: 15-------------
2022-01-25 15:15:15:INFO:-------------Sending models-------------
2022-01-25 15:15:15:INFO:-------------Evaluating models-------------
2022-01-25 15:15:15:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:15:15:INFO:Accuracy = [0.9046497337156902, 0.8992216304793118, 0.895637034002458, 0.8975829578041786, 0.9010651372388365, 0.9188857025809095, 0.9094633346988938, 0.8957394510446538, 0.9066980745596067, 0.8978902089307661]
2022-01-25 15:15:15:INFO:Loss = [0.3824532088922434, 0.27825999457582934, 0.36579828276857884, 0.37040718471488715, 0.34293139782085225, 0.287507206623076, 0.35299080748848133, 0.3438459647966672, 0.40715027735312953, 0.3721976840333683]
2022-01-25 15:15:15:INFO:-------------Training local models-------------
2022-01-25 15:15:59:INFO:-------------Aggregating local models-------------
2022-01-25 15:16:00:INFO:-------------Round number: 16-------------
2022-01-25 15:16:00:INFO:-------------Sending models-------------
2022-01-25 15:16:00:INFO:-------------Evaluating models-------------
2022-01-25 15:16:00:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:16:00:INFO:Accuracy = [0.9062884063908234, 0.9003482179434658, 0.895637034002458, 0.8976853748463745, 0.901372388365424, 0.9188857025809095, 0.9100778369520688, 0.8960467021712413, 0.9068004916018025, 0.8974805407619828]
2022-01-25 15:16:00:INFO:Loss = [0.3794701565354635, 0.27428988637902463, 0.3655120871964169, 0.36831382153550407, 0.34168947462430505, 0.28727544586346165, 0.351701786278433, 0.3425618400740018, 0.4072789079283617, 0.3730648353250239]
2022-01-25 15:16:00:INFO:-------------Training local models-------------
2022-01-25 15:16:44:INFO:-------------Aggregating local models-------------
2022-01-25 15:16:45:INFO:-------------Round number: 17-------------
2022-01-25 15:16:45:INFO:-------------Sending models-------------
2022-01-25 15:16:45:INFO:-------------Evaluating models-------------
2022-01-25 15:16:45:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:16:45:INFO:Accuracy = [0.9072101597705858, 0.9003482179434658, 0.8958418680868496, 0.8977877918885703, 0.9021917247029906, 0.9188857025809095, 0.9105899221630479, 0.8962515362556329, 0.9066980745596067, 0.8979926259729619]
2022-01-25 15:16:45:INFO:Loss = [0.37638718920841124, 0.2703427140132075, 0.3650278103419964, 0.3661617722021952, 0.34026520290869466, 0.2869681721192276, 0.35024996402809633, 0.3410795421409392, 0.40725434436499064, 0.3736956232745889]
2022-01-25 15:16:45:INFO:-------------Training local models-------------
2022-01-25 15:17:29:INFO:-------------Aggregating local models-------------
2022-01-25 15:17:30:INFO:-------------Round number: 18-------------
2022-01-25 15:17:30:INFO:-------------Sending models-------------
2022-01-25 15:17:30:INFO:-------------Evaluating models-------------
2022-01-25 15:17:30:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:17:30:INFO:Accuracy = [0.9080294961081524, 0.9008603031544449, 0.8960467021712413, 0.8978902089307661, 0.9032158951249488, 0.9188857025809095, 0.9103850880786563, 0.8970708725931995, 0.9062884063908234, 0.8976853748463745]
2022-01-25 15:17:30:INFO:Loss = [0.3732268062818129, 0.26644032162685516, 0.3643707849271519, 0.36396401688694613, 0.33869426798217367, 0.2865948688180389, 0.34866129412227653, 0.3394248348426887, 0.4071022648108106, 0.37410796517929745]
2022-01-25 15:17:30:INFO:-------------Training local models-------------
2022-01-25 15:18:14:INFO:-------------Aggregating local models-------------
2022-01-25 15:18:15:INFO:-------------Round number: 19-------------
2022-01-25 15:18:15:INFO:-------------Sending models-------------
2022-01-25 15:18:15:INFO:-------------Evaluating models-------------
2022-01-25 15:18:16:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:18:16:INFO:Accuracy = [0.9084391642769357, 0.9011675542810323, 0.8965587873822204, 0.8979926259729619, 0.9039328144203196, 0.9188857025809095, 0.9103850880786563, 0.8978902089307661, 0.9060835723064318, 0.897378123719787]
2022-01-25 15:18:16:INFO:Loss = [0.37002755712224833, 0.2625994280389663, 0.36356408842173527, 0.3617360985325478, 0.3370114157723384, 0.28616510941337475, 0.34696811233410235, 0.33762973218863246, 0.4068408373377787, 0.3743252311693943]
2022-01-25 15:18:16:INFO:-------------Training local models-------------
2022-01-25 15:18:59:INFO:-------------Aggregating local models-------------
2022-01-25 15:19:00:INFO:-------------Round number: 20-------------
2022-01-25 15:19:00:INFO:-------------Sending models-------------
2022-01-25 15:19:00:INFO:-------------Evaluating models-------------
2022-01-25 15:19:01:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:19:01:INFO:Accuracy = [0.9084391642769357, 0.9015772224498156, 0.8966612044244162, 0.8986071282261369, 0.9038303973781238, 0.9188857025809095, 0.909975419909873, 0.8988119623105285, 0.9061859893486276, 0.897378123719787]
2022-01-25 15:19:01:INFO:Loss = [0.36680393750118895, 0.258836003264587, 0.3626200527789064, 0.3594897567114836, 0.33524197663551764, 0.2856846933722586, 0.34519038284987225, 0.3357164653408044, 0.4064994344321056, 0.37436523839727576]
2022-01-25 15:19:01:INFO:-------------Training local models-------------
2022-01-25 15:19:45:INFO:-------------Aggregating local models-------------
2022-01-25 15:19:46:INFO:-------------Round number: 21-------------
2022-01-25 15:19:46:INFO:-------------Sending models-------------
2022-01-25 15:19:46:INFO:-------------Evaluating models-------------
2022-01-25 15:19:46:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:19:46:INFO:Accuracy = [0.9086439983613274, 0.9023965587873822, 0.8971732896353953, 0.899119213437116, 0.9044448996312986, 0.9188857025809095, 0.909360917656698, 0.899631298648095, 0.905981155264236, 0.8977877918885703]
2022-01-25 15:19:46:INFO:Loss = [0.3635745921547249, 0.25515963997125674, 0.3615597514607339, 0.3572307308980892, 0.33340527876045606, 0.2851631799103278, 0.3433436152907924, 0.3337061970369926, 0.40610426742499955, 0.37424568425053606]
2022-01-25 15:19:46:INFO:-------------Training local models-------------
2022-01-25 15:20:30:INFO:-------------Aggregating local models-------------
2022-01-25 15:20:31:INFO:-------------Round number: 22-------------
2022-01-25 15:20:31:INFO:-------------Sending models-------------
2022-01-25 15:20:31:INFO:-------------Evaluating models-------------
2022-01-25 15:20:31:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:20:31:INFO:Accuracy = [0.908848832445719, 0.9032158951249488, 0.897378123719787, 0.8999385497746825, 0.9047521507578861, 0.9188857025809095, 0.9091560835723065, 0.9002458009012699, 0.9058787382220401, 0.8974805407619828]
2022-01-25 15:20:31:INFO:Loss = [0.3603412808788599, 0.25158459872514044, 0.3603903889253168, 0.35496876396724114, 0.33152276905698397, 0.28459979083157455, 0.3414516279177068, 0.3316182360550582, 0.40565663080218767, 0.3739902369925254]
2022-01-25 15:20:31:INFO:-------------Training local models-------------
2022-01-25 15:21:15:INFO:-------------Aggregating local models-------------
2022-01-25 15:21:16:INFO:-------------Round number: 23-------------
2022-01-25 15:21:16:INFO:-------------Sending models-------------
2022-01-25 15:21:16:INFO:-------------Evaluating models-------------
2022-01-25 15:21:16:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:21:16:INFO:Accuracy = [0.9096681687832855, 0.9036255632937321, 0.8976853748463745, 0.9008603031544449, 0.9046497337156902, 0.9188857025809095, 0.908848832445719, 0.9008603031544449, 0.905981155264236, 0.897378123719787]
2022-01-25 15:21:16:INFO:Loss = [0.35711581481713, 0.24811707220785395, 0.35912855909294106, 0.35270918795242995, 0.32960198565078336, 0.2839999872611927, 0.33952115506959324, 0.3294557292321113, 0.4051746820376836, 0.3736105763804761]
2022-01-25 15:21:16:INFO:-------------Training local models-------------
2022-01-25 15:22:00:INFO:-------------Aggregating local models-------------
2022-01-25 15:22:01:INFO:-------------Round number: 24-------------
2022-01-25 15:22:01:INFO:-------------Sending models-------------
2022-01-25 15:22:01:INFO:-------------Evaluating models-------------
2022-01-25 15:22:01:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:22:01:INFO:Accuracy = [0.9098730028676771, 0.9040352314625154, 0.8979926259729619, 0.9014748054076198, 0.9046497337156902, 0.9188857025809095, 0.9076198279393691, 0.9008603031544449, 0.9058787382220401, 0.8968660385088079]
2022-01-25 15:22:01:INFO:Loss = [0.3539152187507009, 0.2447546212165168, 0.35777977580225206, 0.35045380189874437, 0.3276661840015286, 0.28336408138602787, 0.33757089353740727, 0.3272428498914353, 0.40466075464117846, 0.37312091807027864]
2022-01-25 15:22:01:INFO:-------------Training local models-------------
2022-01-25 15:22:45:INFO:-------------Aggregating local models-------------
2022-01-25 15:22:46:INFO:-------------Round number: 25-------------
2022-01-25 15:22:46:INFO:-------------Sending models-------------
2022-01-25 15:22:46:INFO:-------------Evaluating models-------------
2022-01-25 15:22:46:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:22:46:INFO:Accuracy = [0.9105899221630479, 0.9049569848422777, 0.8987095452683327, 0.9016796394920115, 0.9049569848422777, 0.9188857025809095, 0.9073125768127817, 0.9008603031544449, 0.9057763211798443, 0.8966612044244162]
2022-01-25 15:22:46:INFO:Loss = [0.35075665421445124, 0.24148966239468453, 0.356359963431582, 0.3482069603759995, 0.3257229165378187, 0.2827033479039381, 0.3356094348432465, 0.3249942832052195, 0.4041293005150732, 0.3725416664063125]
2022-01-25 15:22:46:INFO:-------------Training local models-------------
2022-01-25 15:23:30:INFO:-------------Aggregating local models-------------
2022-01-25 15:23:31:INFO:-------------Round number: 26-------------
2022-01-25 15:23:31:INFO:-------------Sending models-------------
2022-01-25 15:23:31:INFO:-------------Evaluating models-------------
2022-01-25 15:23:32:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:23:32:INFO:Accuracy = [0.9109995903318312, 0.9054690700532568, 0.8990167963949202, 0.902498975829578, 0.9055714870954527, 0.9188857025809095, 0.9068004916018025, 0.9006554690700532, 0.9052642359688652, 0.8966612044244162]
2022-01-25 15:23:32:INFO:Loss = [0.34764593959904655, 0.23831147419739726, 0.354886433418683, 0.34597929274844175, 0.32376885563684554, 0.2820171772008683, 0.3336474232052082, 0.3227152642013718, 0.4035774585644042, 0.37188315370479896]
2022-01-25 15:23:32:INFO:-------------Training local models-------------
2022-01-25 15:24:16:INFO:-------------Aggregating local models-------------
2022-01-25 15:24:17:INFO:-------------Round number: 27-------------
2022-01-25 15:24:17:INFO:-------------Sending models-------------
2022-01-25 15:24:17:INFO:-------------Evaluating models-------------
2022-01-25 15:24:17:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:24:17:INFO:Accuracy = [0.9115116755428103, 0.9064932404752151, 0.8995288816058992, 0.9028062269561655, 0.9056739041376485, 0.9188857025809095, 0.9063908234330192, 0.9005530520278574, 0.9055714870954527, 0.8964563703400246]
2022-01-25 15:24:17:INFO:Loss = [0.34457736730190974, 0.23522134288528912, 0.35336858114713726, 0.3437689043709681, 0.3218127782855279, 0.28131222394202754, 0.33168857224020054, 0.32041784163468295, 0.40301134333020977, 0.3711532647891252]
2022-01-25 15:24:17:INFO:-------------Training local models-------------
2022-01-25 15:25:01:INFO:-------------Aggregating local models-------------
2022-01-25 15:25:02:INFO:-------------Round number: 28-------------
2022-01-25 15:25:02:INFO:-------------Sending models-------------
2022-01-25 15:25:02:INFO:-------------Evaluating models-------------
2022-01-25 15:25:02:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:25:02:INFO:Accuracy = [0.9120237607537894, 0.9078246620237608, 0.8999385497746825, 0.9032158951249488, 0.9061859893486276, 0.9188857025809095, 0.9058787382220401, 0.9003482179434658, 0.9056739041376485, 0.8964563703400246]
2022-01-25 15:25:02:INFO:Loss = [0.3415577022670869, 0.23221696059142088, 0.3518108719214339, 0.34157834911855556, 0.31986441365406926, 0.2805886056559562, 0.3297433699299961, 0.3181124924911382, 0.40243046374767194, 0.37036171659296135]
2022-01-25 15:25:02:INFO:-------------Training local models-------------
2022-01-25 15:25:46:INFO:-------------Aggregating local models-------------
2022-01-25 15:25:47:INFO:-------------Round number: 29-------------
2022-01-25 15:25:47:INFO:-------------Sending models-------------
2022-01-25 15:25:47:INFO:-------------Evaluating models-------------
2022-01-25 15:25:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:25:47:INFO:Accuracy = [0.9127406800491602, 0.9090536665301107, 0.9005530520278574, 0.9035231462515363, 0.9058787382220401, 0.9188857025809095, 0.9055714870954527, 0.9008603031544449, 0.9056739041376485, 0.8963539532978287]
2022-01-25 15:25:47:INFO:Loss = [0.33858858791684726, 0.2292974419015834, 0.3502213157078542, 0.339407854391104, 0.31792811140882, 0.2798499841704052, 0.32781498521621333, 0.31580853719525237, 0.4018417788980989, 0.3695189411836245]
2022-01-25 15:25:47:INFO:-------------Training local models-------------
2022-01-25 15:26:31:INFO:-------------Aggregating local models-------------
2022-01-25 15:26:32:INFO:-------------Round number: 30-------------
2022-01-25 15:26:32:INFO:-------------Sending models-------------
2022-01-25 15:26:32:INFO:-------------Evaluating models-------------
2022-01-25 15:26:32:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:26:32:INFO:Accuracy = [0.913457599344531, 0.9095657517410897, 0.9009627201966407, 0.9040352314625154, 0.9056739041376485, 0.9188857025809095, 0.9056739041376485, 0.9010651372388365, 0.9057763211798443, 0.8963539532978287]
2022-01-25 15:26:32:INFO:Loss = [0.33567350639418736, 0.2264573215730168, 0.34860418604161103, 0.3372596406691854, 0.3160081578343069, 0.27909837723955494, 0.32590857245079907, 0.3135123464192269, 0.4012442588125497, 0.3686319499878256]
2022-01-25 15:26:32:INFO:-------------Training local models-------------
2022-01-25 15:27:16:INFO:-------------Aggregating local models-------------
2022-01-25 15:27:17:INFO:-------------Round number: 31-------------
2022-01-25 15:27:17:INFO:-------------Sending models-------------
2022-01-25 15:27:17:INFO:-------------Evaluating models-------------
2022-01-25 15:27:17:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:27:17:INFO:Accuracy = [0.9144817697664891, 0.9100778369520688, 0.901372388365424, 0.9046497337156902, 0.9057763211798443, 0.9188857025809095, 0.9055714870954527, 0.9014748054076198, 0.9057763211798443, 0.8963539532978287]
2022-01-25 15:27:17:INFO:Loss = [0.3328209751770541, 0.22370573767338411, 0.34697142408207665, 0.3351380119160495, 0.31411153731111474, 0.27834149460308466, 0.3240230990965217, 0.3112330211083062, 0.40063875829635, 0.367708340613801]
2022-01-25 15:27:17:INFO:-------------Training local models-------------
2022-01-25 15:28:01:INFO:-------------Aggregating local models-------------
2022-01-25 15:28:02:INFO:-------------Round number: 32-------------
2022-01-25 15:28:02:INFO:-------------Sending models-------------
2022-01-25 15:28:02:INFO:-------------Evaluating models-------------
2022-01-25 15:28:03:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:28:03:INFO:Accuracy = [0.9147890208930766, 0.9109995903318312, 0.9017820565342073, 0.9054690700532568, 0.9058787382220401, 0.9191929537074969, 0.905366653011061, 0.9023965587873822, 0.9052642359688652, 0.8960467021712413]
2022-01-25 15:28:03:INFO:Loss = [0.33002301875848306, 0.22103210871551598, 0.34532877381636146, 0.3330407632237841, 0.31223609330974267, 0.27757680037371674, 0.32216603608190747, 0.308973380902821, 0.40002376483270685, 0.36675486537226887]
2022-01-25 15:28:03:INFO:-------------Training local models-------------
2022-01-25 15:28:47:INFO:-------------Aggregating local models-------------
2022-01-25 15:28:48:INFO:-------------Round number: 33-------------
2022-01-25 15:28:48:INFO:-------------Sending models-------------
2022-01-25 15:28:48:INFO:-------------Evaluating models-------------
2022-01-25 15:28:48:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:28:48:INFO:Accuracy = [0.9156083572306432, 0.911716509627202, 0.9018844735764031, 0.905981155264236, 0.9062884063908234, 0.9191929537074969, 0.9052642359688652, 0.9028062269561655, 0.9055714870954527, 0.8962515362556329]
2022-01-25 15:28:48:INFO:Loss = [0.3272828136726036, 0.21844416290036311, 0.34368288135007236, 0.3309693537341161, 0.31038739133758997, 0.27680773103268996, 0.3203338577897761, 0.30674017219514643, 0.39939316292450755, 0.3657784774710242]
2022-01-25 15:28:48:INFO:-------------Training local models-------------
2022-01-25 15:29:32:INFO:-------------Aggregating local models-------------
2022-01-25 15:29:33:INFO:-------------Round number: 34-------------
2022-01-25 15:29:33:INFO:-------------Sending models-------------
2022-01-25 15:29:33:INFO:-------------Evaluating models-------------
2022-01-25 15:29:33:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:29:33:INFO:Accuracy = [0.9158131913150348, 0.9130479311757477, 0.9027038099139697, 0.9065956575174109, 0.9063908234330192, 0.9195002048340843, 0.9052642359688652, 0.9033183121671446, 0.9054690700532568, 0.8959442851290454]
2022-01-25 15:29:33:INFO:Loss = [0.32460347132353645, 0.21594311680762263, 0.3420394867832594, 0.3289253581582352, 0.308564397364867, 0.27603781471945893, 0.3185254921117971, 0.30453301264627064, 0.3987504994542583, 0.36478575589482487]
2022-01-25 15:29:33:INFO:-------------Training local models-------------
2022-01-25 15:30:17:INFO:-------------Aggregating local models-------------
2022-01-25 15:30:18:INFO:-------------Round number: 35-------------
2022-01-25 15:30:18:INFO:-------------Sending models-------------
2022-01-25 15:30:18:INFO:-------------Evaluating models-------------
2022-01-25 15:30:18:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:30:18:INFO:Accuracy = [0.9162228594838181, 0.9140721015977059, 0.9033183121671446, 0.9075174108971733, 0.9064932404752151, 0.919705038918476, 0.9055714870954527, 0.9037279803359279, 0.9054690700532568, 0.8954321999180663]
2022-01-25 15:30:18:INFO:Loss = [0.3219850988839614, 0.2135207502362927, 0.3404060117396748, 0.3269066342588748, 0.3067692928031447, 0.275266353987446, 0.31674299469398504, 0.3023612684845338, 0.39809882345031156, 0.3637771517593858]
2022-01-25 15:30:18:INFO:-------------Training local models-------------
2022-01-25 15:31:02:INFO:-------------Aggregating local models-------------
2022-01-25 15:31:03:INFO:-------------Round number: 36-------------
2022-01-25 15:31:03:INFO:-------------Sending models-------------
2022-01-25 15:31:03:INFO:-------------Evaluating models-------------
2022-01-25 15:31:03:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:31:03:INFO:Accuracy = [0.916837361736993, 0.9147890208930766, 0.9036255632937321, 0.9079270790659566, 0.9066980745596067, 0.919705038918476, 0.9056739041376485, 0.9038303973781238, 0.9055714870954527, 0.8954321999180663]
2022-01-25 15:31:03:INFO:Loss = [0.31942956143244644, 0.211170272220999, 0.33878474632054506, 0.3249152688975707, 0.3050029485828683, 0.27449742777472336, 0.31498420216823786, 0.3002237776574396, 0.39743920614981443, 0.36276089748926993]
2022-01-25 15:31:03:INFO:-------------Training local models-------------
2022-01-25 15:31:47:INFO:-------------Aggregating local models-------------
2022-01-25 15:31:48:INFO:-------------Round number: 37-------------
2022-01-25 15:31:48:INFO:-------------Sending models-------------
2022-01-25 15:31:48:INFO:-------------Evaluating models-------------
2022-01-25 15:31:48:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:31:48:INFO:Accuracy = [0.9178615321589513, 0.9156083572306432, 0.9041376485047112, 0.9085415813191315, 0.9069029086439984, 0.9199098730028676, 0.905981155264236, 0.9044448996312986, 0.9057763211798443, 0.8957394510446538]
2022-01-25 15:31:48:INFO:Loss = [0.31693704351202867, 0.20888770337490115, 0.3371817319013334, 0.3229512955088417, 0.3032675423994752, 0.27373070682766604, 0.31325123971728747, 0.2981245002431954, 0.3967769635484135, 0.3617418056101352]
2022-01-25 15:31:48:INFO:-------------Training local models-------------
2022-01-25 15:32:32:INFO:-------------Aggregating local models-------------
2022-01-25 15:32:33:INFO:-------------Round number: 38-------------
2022-01-25 15:32:33:INFO:-------------Sending models-------------
2022-01-25 15:32:33:INFO:-------------Evaluating models-------------
2022-01-25 15:32:34:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:32:34:INFO:Accuracy = [0.9183736173699304, 0.9160180253994264, 0.9045473166734944, 0.9091560835723065, 0.9073125768127817, 0.9200122900450635, 0.9065956575174109, 0.9049569848422777, 0.9057763211798443, 0.8957394510446538]
2022-01-25 15:32:34:INFO:Loss = [0.3145042214083261, 0.20667868251700544, 0.3355981489961653, 0.321010459721125, 0.30156453651868625, 0.2729683960707651, 0.3115403290955515, 0.29606663648974624, 0.39610624522987914, 0.36072089466610097]
2022-01-25 15:32:34:INFO:-------------Training local models-------------
2022-01-25 15:33:17:INFO:-------------Aggregating local models-------------
2022-01-25 15:33:18:INFO:-------------Round number: 39-------------
2022-01-25 15:33:18:INFO:-------------Sending models-------------
2022-01-25 15:33:19:INFO:-------------Evaluating models-------------
2022-01-25 15:33:19:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:33:19:INFO:Accuracy = [0.9188857025809095, 0.917451863990168, 0.9047521507578861, 0.9098730028676771, 0.9072101597705858, 0.9205243752560426, 0.9066980745596067, 0.9050594018844735, 0.9057763211798443, 0.8953297828758705]
2022-01-25 15:33:19:INFO:Loss = [0.31213887146415037, 0.2045373751902827, 0.33403529119950637, 0.31909548145112615, 0.29989360981925695, 0.2722125466680691, 0.3098537447034018, 0.2940486681367935, 0.39542774601536357, 0.3597026938761003]
2022-01-25 15:33:19:INFO:-------------Training local models-------------
2022-01-25 15:34:03:INFO:-------------Aggregating local models-------------
