2022-01-26 22:37:32:INFO:-------------Round number: 0-------------
2022-01-26 22:37:32:INFO:-------------Sending models-------------
2022-01-26 22:37:32:INFO:-------------Evaluating models-------------
2022-01-26 22:37:33:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:37:33:INFO:Accuracy = [0.8991803824881722, 0.1003531685213567, 0.09842073698940494, 0.10081961751182782, 0.8763910175251549, 0.8853201839141733, 0.10028653295128939, 0.09975344839075098, 0.8991137469181049, 0.9005797294595855]
2022-01-26 22:37:33:INFO:Loss = [0.665735710753093, 0.7252041155432307, 0.7190054141443257, 0.7331072797684394, 0.6908852116902903, 0.6900398628600649, 0.7395282456087956, 0.703250268981245, 0.6848465939734868, 0.6383577395964568]
2022-01-26 22:37:33:INFO:-------------Training local models-------------
2022-01-26 22:50:02:INFO:-------------Aggregating local models-------------
2022-01-26 22:50:06:INFO:-------------Round number: 1-------------
2022-01-26 22:50:06:INFO:-------------Sending models-------------
2022-01-26 22:50:07:INFO:-------------Evaluating models-------------
2022-01-26 22:50:08:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:50:08:INFO:Accuracy = [0.9908709269007796, 0.9562204304657826, 0.9485573399080429, 0.9532884653828213, 0.9841407343239822, 0.9650829612847338, 0.9568201505963884, 0.9965349503565003, 0.9780102618777904, 0.9544212700739655]
2022-01-26 22:50:08:INFO:Loss = [0.04750924833387508, 0.1226547115020266, 0.13050235694864118, 0.09993254376189094, 0.0678281020831103, 0.08711384998904353, 0.10058650101254267, 0.030487294622798776, 0.07331329413438706, 0.10370839683124833]
2022-01-26 22:50:08:INFO:-------------Training local models-------------
2022-01-26 23:02:38:INFO:-------------Aggregating local models-------------
2022-01-26 23:02:43:INFO:-------------Round number: 2-------------
2022-01-26 23:02:43:INFO:-------------Sending models-------------
2022-01-26 23:02:43:INFO:-------------Evaluating models-------------
2022-01-26 23:02:44:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 23:02:44:INFO:Accuracy = [0.9908709269007796, 0.9578863197174652, 0.9522889318318118, 0.9615512760711667, 0.9841407343239822, 0.96468314786433, 0.9648164190044646, 0.9982008396081828, 0.9780102618777904, 0.9544212700739655]
2022-01-26 23:02:44:INFO:Loss = [0.03567382111608177, 0.10440654340277622, 0.11694219243310455, 0.0834914502971549, 0.053612295212178356, 0.07324465854512285, 0.08969148924868603, 0.015567721133306846, 0.05839070001464688, 0.09149783583202518]
2022-01-26 23:02:44:INFO:-------------Training local models-------------
2022-01-26 23:15:14:INFO:-------------Aggregating local models-------------
2022-01-26 23:15:18:INFO:-------------Round number: 3-------------
2022-01-26 23:15:18:INFO:-------------Sending models-------------
2022-01-26 23:15:19:INFO:-------------Evaluating models-------------
2022-01-26 23:15:20:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 23:15:20:INFO:Accuracy = [0.9908709269007796, 0.9580195908575998, 0.958086226427667, 0.966015859265676, 0.9841407343239822, 0.966015859265676, 0.968014926367695, 0.9984673818884521, 0.9780768974478576, 0.9544879056440327]
2022-01-26 23:15:20:INFO:Loss = [0.03138092881434201, 0.09829562507948693, 0.11227266291017429, 0.07810157534317028, 0.048687261006142596, 0.06804888579372638, 0.08511150421683951, 0.012019031769578043, 0.05195013085607054, 0.08654845091817565]
2022-01-26 23:15:20:INFO:-------------Training local models-------------
2022-01-26 23:27:48:INFO:-------------Aggregating local models-------------
2022-01-26 23:27:52:INFO:-------------Round number: 4-------------
2022-01-26 23:27:52:INFO:-------------Sending models-------------
2022-01-26 23:27:53:INFO:-------------Evaluating models-------------
2022-01-26 23:27:54:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 23:27:54:INFO:Accuracy = [0.9908709269007796, 0.9580195908575998, 0.9593523022589459, 0.9730125941227428, 0.9841407343239822, 0.970213900179916, 0.9698807223295796, 0.9985340174585193, 0.9818751249416938, 0.958086226427667]
2022-01-26 23:27:54:INFO:Loss = [0.02858161206658075, 0.0938323054991024, 0.10747161358547942, 0.07302234693626868, 0.04531241534843505, 0.0641058980602783, 0.08063182277702091, 0.009968395315762631, 0.04555678127445213, 0.08073870268374701]
2022-01-26 23:27:54:INFO:-------------Training local models-------------
2022-01-26 23:40:18:INFO:-------------Aggregating local models-------------
2022-01-26 23:40:22:INFO:-------------Round number: 5-------------
2022-01-26 23:40:22:INFO:-------------Sending models-------------
2022-01-26 23:40:22:INFO:-------------Evaluating models-------------
2022-01-26 23:40:23:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 23:40:23:INFO:Accuracy = [0.9908709269007796, 0.9580195908575998, 0.9596854801092823, 0.9735456786832811, 0.9841407343239822, 0.9752115679349637, 0.9706137136003199, 0.9985340174585193, 0.9865396148464051, 0.9630838941827148]
2022-01-26 23:40:23:INFO:Loss = [0.026945694356417294, 0.09035125575118036, 0.10246363638661987, 0.0678622297469464, 0.04317297521756786, 0.060695647224227225, 0.07717032146848696, 0.008761937662784805, 0.03998507227488166, 0.07494802679311026]
2022-01-26 23:40:23:INFO:-------------Training local models-------------
2022-01-26 23:52:47:INFO:-------------Aggregating local models-------------
2022-01-26 23:52:51:INFO:-------------Round number: 6-------------
2022-01-26 23:52:51:INFO:-------------Sending models-------------
2022-01-26 23:52:51:INFO:-------------Evaluating models-------------
2022-01-26 23:52:52:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 23:52:52:INFO:Accuracy = [0.9908709269007796, 0.9588858532684748, 0.9605517425201573, 0.9741453988138868, 0.9841407343239822, 0.9789431598587326, 0.9708136203105218, 0.9985340174585193, 0.9874725128273473, 0.9661491304058106]
2022-01-26 23:52:52:INFO:Loss = [0.025912834733066634, 0.08719928841143779, 0.0990017459399769, 0.0642470496176801, 0.04166820220920643, 0.05690018793470966, 0.07424999700090473, 0.007979406758237138, 0.03604231715325356, 0.07026214323356639]
2022-01-26 23:52:52:INFO:-------------Training local models-------------
2022-01-27 00:05:16:INFO:-------------Aggregating local models-------------
2022-01-27 00:05:20:INFO:-------------Round number: 7-------------
2022-01-27 00:05:20:INFO:-------------Sending models-------------
2022-01-27 00:05:20:INFO:-------------Evaluating models-------------
2022-01-27 00:05:21:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:05:21:INFO:Accuracy = [0.9908709269007796, 0.9610848270806956, 0.960951555940561, 0.974611847804358, 0.9841407343239822, 0.9814086759512227, 0.9713467048710601, 0.9985340174585193, 0.9883387752382221, 0.9686812820683681]
2022-01-27 00:05:21:INFO:Loss = [0.025146643124498196, 0.0837283390825817, 0.09645142458247646, 0.062141826035319085, 0.04034217704287784, 0.05208890056623625, 0.07129258496081588, 0.0074246758434172, 0.033434168119758585, 0.06655693105244762]
2022-01-27 00:05:21:INFO:-------------Training local models-------------
2022-01-27 00:17:46:INFO:-------------Aggregating local models-------------
2022-01-27 00:17:50:INFO:-------------Round number: 8-------------
2022-01-27 00:17:50:INFO:-------------Sending models-------------
2022-01-27 00:17:50:INFO:-------------Evaluating models-------------
2022-01-27 00:17:51:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:17:51:INFO:Accuracy = [0.9908709269007796, 0.9636169787432531, 0.9617511827813687, 0.9752115679349637, 0.9841407343239822, 0.9822083027920304, 0.9721463317118678, 0.9985340174585193, 0.9888718597987606, 0.9718797894315986]
2022-01-27 00:17:51:INFO:Loss = [0.02454477173095444, 0.07954498413483085, 0.09403400408114788, 0.06052136764640352, 0.0390343499273807, 0.047121448590880556, 0.06829144849174648, 0.007032177185771048, 0.031571576895825196, 0.06331325422721311]
2022-01-27 00:17:51:INFO:-------------Training local models-------------
2022-01-27 00:30:15:INFO:-------------Aggregating local models-------------
2022-01-27 00:30:19:INFO:-------------Round number: 9-------------
2022-01-27 00:30:19:INFO:-------------Sending models-------------
2022-01-27 00:30:19:INFO:-------------Evaluating models-------------
2022-01-27 00:30:20:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:30:20:INFO:Accuracy = [0.9908709269007796, 0.9678816552275604, 0.9634837076031185, 0.9760111947757713, 0.9841407343239822, 0.9827413873525688, 0.9731458652628773, 0.9985340174585193, 0.988738588658626, 0.9734124075431465]
2022-01-27 00:30:20:INFO:Loss = [0.024017767574076036, 0.0743403361632313, 0.09179059591927943, 0.059153422929042146, 0.037944484468718336, 0.043920107621562204, 0.06554241816989716, 0.006728455146600597, 0.029993319635014382, 0.06008661087837215]
2022-01-27 00:30:20:INFO:-------------Training local models-------------
2022-01-27 00:42:44:INFO:-------------Aggregating local models-------------
2022-01-27 00:42:48:INFO:-------------Round number: 10-------------
2022-01-27 00:42:48:INFO:-------------Sending models-------------
2022-01-27 00:42:49:INFO:-------------Evaluating models-------------
2022-01-27 00:42:50:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:42:50:INFO:Accuracy = [0.9908709269007796, 0.9720130605717332, 0.9654827747051375, 0.9765442793363097, 0.9841407343239822, 0.9808755913906844, 0.9748117545145599, 0.9985340174585193, 0.9890717665089624, 0.9750116612247618]
2022-01-27 00:42:50:INFO:Loss = [0.02351962821172575, 0.06943685724035725, 0.08971129729581412, 0.057946818323679775, 0.03710917721444425, 0.0449147037245814, 0.06371855818020257, 0.006502734762748642, 0.02872399873794371, 0.05692312772813159]
2022-01-27 00:42:50:INFO:-------------Training local models-------------
2022-01-27 00:55:14:INFO:-------------Aggregating local models-------------
2022-01-27 00:55:18:INFO:-------------Round number: 11-------------
2022-01-27 00:55:18:INFO:-------------Sending models-------------
2022-01-27 00:55:18:INFO:-------------Evaluating models-------------
2022-01-27 00:55:19:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:55:19:INFO:Accuracy = [0.9908709269007796, 0.97307922969281, 0.9666155793962817, 0.9771439994669154, 0.9841407343239822, 0.9814753115212901, 0.9758112880655694, 0.9985340174585193, 0.989404944359299, 0.9757446524955021]
2022-01-27 00:55:19:INFO:Loss = [0.022990809437621856, 0.06523686712639197, 0.08801397818835743, 0.05698732259716806, 0.036281102921597155, 0.043889048733429505, 0.061363933712558036, 0.006334869253604275, 0.0276012449748033, 0.05409274526929916]
2022-01-27 00:55:19:INFO:-------------Training local models-------------
2022-01-27 01:07:43:INFO:-------------Aggregating local models-------------
2022-01-27 01:07:47:INFO:-------------Round number: 12-------------
2022-01-27 01:07:47:INFO:-------------Sending models-------------
2022-01-27 01:07:47:INFO:-------------Evaluating models-------------
2022-01-27 01:07:48:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:07:48:INFO:Accuracy = [0.990937562470847, 0.974611847804358, 0.9669487572466182, 0.976810821616579, 0.9841407343239822, 0.9804091424002133, 0.9768774571866462, 0.9985340174585193, 0.9896714866395682, 0.9765442793363097]
2022-01-27 01:07:48:INFO:Loss = [0.022381165640027834, 0.06287330924747557, 0.08675680463985776, 0.05630976683380226, 0.035684523291716314, 0.04553564760835204, 0.059903183773516354, 0.006209277261746706, 0.02672331469573905, 0.05225510100240625]
2022-01-27 01:07:48:INFO:-------------Training local models-------------
2022-01-27 01:20:12:INFO:-------------Aggregating local models-------------
2022-01-27 01:20:16:INFO:-------------Round number: 13-------------
2022-01-27 01:20:16:INFO:-------------Sending models-------------
2022-01-27 01:20:16:INFO:-------------Evaluating models-------------
2022-01-27 01:20:17:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:20:17:INFO:Accuracy = [0.9924701805823949, 0.9754781102152329, 0.9667488505364163, 0.9770107283267808, 0.9841407343239822, 0.9814753115212901, 0.9780102618777904, 0.9985340174585193, 0.9900046644899048, 0.9772106350369827]
2022-01-27 01:20:17:INFO:Loss = [0.021673551255703576, 0.06122726080375637, 0.08582429199639338, 0.055840173764430734, 0.03514241629474215, 0.04450849486519088, 0.05828134534633554, 0.006114651400127353, 0.0262446673926923, 0.05160058049511932]
2022-01-27 01:20:17:INFO:-------------Training local models-------------
2022-01-27 01:32:41:INFO:-------------Aggregating local models-------------
2022-01-27 01:32:45:INFO:-------------Round number: 14-------------
2022-01-27 01:32:45:INFO:-------------Sending models-------------
2022-01-27 01:32:46:INFO:-------------Evaluating models-------------
2022-01-27 01:32:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:32:47:INFO:Accuracy = [0.9935363497034717, 0.9764776437662425, 0.9670153928166856, 0.9773439061771173, 0.9841407343239822, 0.9843406410341841, 0.9782768041580596, 0.9985340174585193, 0.9904711134803759, 0.9790764309988672]
2022-01-27 01:32:47:INFO:Loss = [0.020905945375334654, 0.059501925632732204, 0.08502451543465789, 0.05530471807481912, 0.03462387617852178, 0.042551264576104225, 0.05681035653122373, 0.0060426356350153105, 0.025968463741080413, 0.05053589778970204]
2022-01-27 01:32:47:INFO:-------------Training local models-------------
2022-01-27 01:45:11:INFO:-------------Aggregating local models-------------
2022-01-27 01:45:15:INFO:-------------Round number: 15-------------
2022-01-27 01:45:15:INFO:-------------Sending models-------------
2022-01-27 01:45:15:INFO:-------------Evaluating models-------------
2022-01-27 01:45:16:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:45:16:INFO:Accuracy = [0.9940027986939428, 0.9771439994669154, 0.9675484773772239, 0.9774771773172519, 0.9842073698940494, 0.9856067168654628, 0.9785433464383287, 0.9985340174585193, 0.9904044779103085, 0.9795428799893383]
2022-01-27 01:45:16:INFO:Loss = [0.020187588677134598, 0.057817598088070896, 0.08433890505768324, 0.05485688264067038, 0.034073233351811866, 0.040864270043463234, 0.055555190341975556, 0.005983023014688824, 0.02591516094503051, 0.04934790373894482]
2022-01-27 01:45:16:INFO:-------------Training local models-------------
2022-01-27 01:57:40:INFO:-------------Aggregating local models-------------
2022-01-27 01:57:44:INFO:-------------Round number: 16-------------
2022-01-27 01:57:44:INFO:-------------Sending models-------------
2022-01-27 01:57:45:INFO:-------------Evaluating models-------------
2022-01-27 01:57:46:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:57:46:INFO:Accuracy = [0.9941360698340774, 0.97727727060705, 0.9678150196574932, 0.9778769907376558, 0.9845405477443859, 0.9860065302858666, 0.978809888718598, 0.9985340174585193, 0.9905377490504431, 0.9796761511294729]
2022-01-27 01:57:46:INFO:Loss = [0.01961218449295286, 0.056609866388896014, 0.08375562202757207, 0.05449512847490289, 0.0334720216424908, 0.03979216951694469, 0.05453997553748834, 0.005934075525501325, 0.025953990391062016, 0.048604776045701036]
2022-01-27 01:57:46:INFO:-------------Training local models-------------
2022-01-27 02:10:09:INFO:-------------Aggregating local models-------------
2022-01-27 02:10:13:INFO:-------------Round number: 17-------------
2022-01-27 02:10:13:INFO:-------------Sending models-------------
2022-01-27 02:10:14:INFO:-------------Evaluating models-------------
2022-01-27 02:10:15:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:10:15:INFO:Accuracy = [0.994269340974212, 0.9778103551675884, 0.9682814686479643, 0.9786099820083961, 0.9848070900246552, 0.9862064369960685, 0.9792097021390018, 0.9985340174585193, 0.9905377490504431, 0.9804757779702805]
2022-01-27 02:10:15:INFO:Loss = [0.019191000420451954, 0.055129905857004405, 0.08338421947951263, 0.05432501989303147, 0.032785305341127044, 0.039222728373461115, 0.053767392663722983, 0.005889963956724193, 0.0260711264787203, 0.04748807023546713]
2022-01-27 02:10:15:INFO:-------------Training local models-------------
2022-01-27 02:22:15:INFO:-------------Aggregating local models-------------
2022-01-27 02:22:18:INFO:-------------Round number: 18-------------
2022-01-27 02:22:18:INFO:-------------Sending models-------------
2022-01-27 02:22:19:INFO:-------------Evaluating models-------------
2022-01-27 02:22:20:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:22:20:INFO:Accuracy = [0.9943359765442793, 0.9786766175784634, 0.9690810954887719, 0.9786766175784634, 0.9853401745851936, 0.9864063437062704, 0.9792097021390018, 0.9985340174585193, 0.990737655760645, 0.9812754048110882]
2022-01-27 02:22:20:INFO:Loss = [0.018878552077652985, 0.053912862220346525, 0.08306349650823942, 0.054236810529412344, 0.03196515764838631, 0.03813472039187121, 0.0527942153647039, 0.005850438859241373, 0.02616477376710479, 0.04660092314403629]
2022-01-27 02:22:20:INFO:-------------Training local models-------------
2022-01-27 02:34:10:INFO:-------------Aggregating local models-------------
2022-01-27 02:34:14:INFO:-------------Round number: 19-------------
2022-01-27 02:34:14:INFO:-------------Sending models-------------
2022-01-27 02:34:14:INFO:-------------Evaluating models-------------
2022-01-27 02:34:15:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:34:15:INFO:Accuracy = [0.9944026121143467, 0.9793429732791364, 0.9689478243486374, 0.9792763377090691, 0.9866728859865396, 0.9866062504164723, 0.9795428799893383, 0.9985340174585193, 0.9906043846205105, 0.9814086759512227]
2022-01-27 02:34:15:INFO:Loss = [0.018654941781800636, 0.05262650779630767, 0.08334934488872067, 0.05464358820863711, 0.03097894483288668, 0.03738496690046392, 0.05207031502007778, 0.005808746221806618, 0.02627718818513048, 0.04583778753418049]
2022-01-27 02:34:15:INFO:-------------Training local models-------------
2022-01-27 02:46:05:INFO:-------------Aggregating local models-------------
2022-01-27 02:46:09:INFO:-------------Round number: 20-------------
2022-01-27 02:46:09:INFO:-------------Sending models-------------
2022-01-27 02:46:09:INFO:-------------Evaluating models-------------
2022-01-27 02:46:10:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:46:10:INFO:Accuracy = [0.9944026121143467, 0.9805424135403479, 0.9691477310588392, 0.9794762444192711, 0.9882721396681549, 0.9865396148464051, 0.9799426934097422, 0.9985340174585193, 0.990737655760645, 0.9817418538015593]
2022-01-27 02:46:10:INFO:Loss = [0.01847645258501986, 0.05168639177795779, 0.08387589419949598, 0.05524164369566825, 0.029843050685476498, 0.03742817154469458, 0.0516571092987315, 0.0057693013423101795, 0.026333332365593716, 0.04551669242927484]
2022-01-27 02:46:10:INFO:-------------Training local models-------------
2022-01-27 02:58:00:INFO:-------------Aggregating local models-------------
2022-01-27 02:58:04:INFO:-------------Round number: 21-------------
2022-01-27 02:58:04:INFO:-------------Sending models-------------
2022-01-27 02:58:04:INFO:-------------Evaluating models-------------
2022-01-27 02:58:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:58:05:INFO:Accuracy = [0.9944026121143467, 0.9824748450722995, 0.9691477310588392, 0.9793429732791364, 0.9896714866395682, 0.9870726994069434, 0.9802092356900113, 0.9985340174585193, 0.9905377490504431, 0.982341573932165]
2022-01-27 02:58:05:INFO:Loss = [0.01833426036787229, 0.050802705236946015, 0.08512442719591637, 0.05628345683914677, 0.028584230721478945, 0.03707632884776736, 0.05131532104419348, 0.005738289134624852, 0.02661745934690453, 0.0457195651932062]
2022-01-27 02:58:05:INFO:-------------Training local models-------------
2022-01-27 03:09:55:INFO:-------------Aggregating local models-------------
2022-01-27 03:09:59:INFO:-------------Round number: 22-------------
2022-01-27 03:09:59:INFO:-------------Sending models-------------
2022-01-27 03:09:59:INFO:-------------Evaluating models-------------
2022-01-27 03:10:00:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 03:10:00:INFO:Accuracy = [0.9944026121143467, 0.983674285333511, 0.9694142733391085, 0.9792763377090691, 0.9903378423402412, 0.9869394282668088, 0.9807423202505497, 0.9985340174585193, 0.9905377490504431, 0.9825414806423669]
2022-01-27 03:10:00:INFO:Loss = [0.018217646456758337, 0.049994331248156255, 0.08680965809925088, 0.057763261909300444, 0.027435333452864908, 0.03708336591923114, 0.05110910725008246, 0.0057159579973540655, 0.026970170153028782, 0.04619389155254686]
2022-01-27 03:10:00:INFO:-------------Training local models-------------
2022-01-27 03:21:50:INFO:-------------Aggregating local models-------------
2022-01-27 03:21:54:INFO:-------------Round number: 23-------------
2022-01-27 03:21:54:INFO:-------------Sending models-------------
2022-01-27 03:21:54:INFO:-------------Evaluating models-------------
2022-01-27 03:21:55:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 03:21:55:INFO:Accuracy = [0.9943359765442793, 0.9840740987539148, 0.9691477310588392, 0.9794096088492037, 0.9904044779103085, 0.9868727926967416, 0.9807423202505497, 0.9985340174585193, 0.9905377490504431, 0.9822749383620977]
2022-01-27 03:21:55:INFO:Loss = [0.01811920121396304, 0.049506720960766325, 0.08900048798354901, 0.05952681978453236, 0.026510440152515847, 0.03711253676358763, 0.051204562714898594, 0.005702742794045851, 0.027308408364970616, 0.0469762107130039]
2022-01-27 03:21:55:INFO:-------------Training local models-------------
2022-01-27 03:33:46:INFO:-------------Aggregating local models-------------
2022-01-27 03:33:49:INFO:-------------Round number: 24-------------
2022-01-27 03:33:49:INFO:-------------Sending models-------------
2022-01-27 03:33:49:INFO:-------------Evaluating models-------------
2022-01-27 03:33:50:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 03:33:50:INFO:Accuracy = [0.994269340974212, 0.9842073698940494, 0.9692143666289065, 0.9792763377090691, 0.9906043846205105, 0.9867395215566069, 0.9808755913906844, 0.9985340174585193, 0.9904044779103085, 0.9822749383620977]
2022-01-27 03:33:50:INFO:Loss = [0.01802475764637976, 0.04938108571936897, 0.09146028404735065, 0.0614427583533712, 0.025818590208272298, 0.037202116538850145, 0.051487827277631446, 0.005693827460006057, 0.02772631249926792, 0.04800162228795743]
2022-01-27 03:33:50:INFO:-------------Training local models-------------
2022-01-27 03:45:42:INFO:-------------Aggregating local models-------------
2022-01-27 03:45:46:INFO:-------------Round number: 25-------------
2022-01-27 03:45:46:INFO:-------------Sending models-------------
2022-01-27 03:45:46:INFO:-------------Evaluating models-------------
2022-01-27 03:45:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 03:45:47:INFO:Accuracy = [0.9942027054041447, 0.9842073698940494, 0.9689478243486374, 0.9795428799893383, 0.9908042913307124, 0.9869394282668088, 0.9811421336709536, 0.9985340174585193, 0.9903378423402412, 0.9820750316518958]
2022-01-27 03:45:47:INFO:Loss = [0.017940614734649876, 0.04965330553607, 0.09405524733771768, 0.06336211942295034, 0.02532071293043857, 0.037392402500609795, 0.051901127194591876, 0.005688144294279228, 0.028060192259248124, 0.049107758484721625]
2022-01-27 03:45:47:INFO:-------------Training local models-------------
2022-01-27 03:57:38:INFO:-------------Aggregating local models-------------
2022-01-27 03:57:41:INFO:-------------Round number: 26-------------
2022-01-27 03:57:41:INFO:-------------Sending models-------------
2022-01-27 03:57:42:INFO:-------------Evaluating models-------------
2022-01-27 03:57:43:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 03:57:43:INFO:Accuracy = [0.9942027054041447, 0.9842073698940494, 0.9690144599187046, 0.9793429732791364, 0.990937562470847, 0.9868061571266742, 0.9812754048110882, 0.9985340174585193, 0.9904044779103085, 0.9820083960818284]
2022-01-27 03:57:43:INFO:Loss = [0.017859435026664063, 0.05008581966460724, 0.0967417096513658, 0.06533831132544105, 0.02491258434940447, 0.037578638440270186, 0.052333862579377506, 0.005684002266242638, 0.028522205631752905, 0.050399378329490374]
2022-01-27 03:57:43:INFO:-------------Training local models-------------
2022-01-27 04:09:33:INFO:-------------Aggregating local models-------------
2022-01-27 04:09:37:INFO:-------------Round number: 27-------------
2022-01-27 04:09:37:INFO:-------------Sending models-------------
2022-01-27 04:09:38:INFO:-------------Evaluating models-------------
2022-01-27 04:09:39:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 04:09:39:INFO:Accuracy = [0.9942027054041447, 0.9840074631838476, 0.9694142733391085, 0.9790764309988672, 0.9911374691810488, 0.9868061571266742, 0.9818084893716266, 0.9985340174585193, 0.9904044779103085, 0.9817418538015593]
2022-01-27 04:09:39:INFO:Loss = [0.017782627559417966, 0.05061289870084176, 0.09949133007791819, 0.06745843619191702, 0.024586671481864667, 0.03767316868249794, 0.05272198902443931, 0.0056803668950930345, 0.028973673329095433, 0.05169831613676641]
2022-01-27 04:09:39:INFO:-------------Training local models-------------
2022-01-27 04:21:29:INFO:-------------Aggregating local models-------------
2022-01-27 04:21:33:INFO:-------------Round number: 28-------------
2022-01-27 04:21:33:INFO:-------------Sending models-------------
2022-01-27 04:21:33:INFO:-------------Evaluating models-------------
2022-01-27 04:21:34:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 04:21:34:INFO:Accuracy = [0.9942027054041447, 0.9840074631838476, 0.9694809089091757, 0.9791430665689345, 0.9912707403211835, 0.9864729792763377, 0.9819417605117612, 0.9985340174585193, 0.9903378423402412, 0.9817418538015593]
2022-01-27 04:21:34:INFO:Loss = [0.017706392364841318, 0.05119216093267004, 0.10216588996345949, 0.06950618200256328, 0.024336459275709314, 0.03797317253793329, 0.05317932298190965, 0.005678426047173687, 0.02934073292355688, 0.052952140163998074]
2022-01-27 04:21:34:INFO:-------------Training local models-------------
2022-01-27 04:33:25:INFO:-------------Aggregating local models-------------
2022-01-27 04:33:29:INFO:-------------Round number: 29-------------
2022-01-27 04:33:29:INFO:-------------Sending models-------------
2022-01-27 04:33:29:INFO:-------------Evaluating models-------------
2022-01-27 04:33:30:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 04:33:30:INFO:Accuracy = [0.9941360698340774, 0.9843406410341841, 0.9698807223295796, 0.9793429732791364, 0.9915372826014527, 0.9866728859865396, 0.9822749383620977, 0.9985340174585193, 0.9904044779103085, 0.981675218231492]
2022-01-27 04:33:30:INFO:Loss = [0.01763043084391568, 0.05185410622393344, 0.10498933570478432, 0.07171472176784366, 0.024156025393042152, 0.03822452501146555, 0.05361969373974738, 0.005676426444043071, 0.029749277670944624, 0.054290245555705816]
2022-01-27 04:33:30:INFO:-------------Training local models-------------
2022-01-27 04:45:21:INFO:-------------Aggregating local models-------------
