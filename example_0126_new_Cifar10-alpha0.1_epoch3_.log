2022-01-26 19:44:33:INFO:-------------Round number: 0-------------
2022-01-26 19:44:33:INFO:-------------Sending models-------------
2022-01-26 19:44:33:INFO:-------------Evaluating models-------------
2022-01-26 19:44:34:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 19:44:34:INFO:Accuracy = [0.9000333222259247, 0.09963345551482838, 0.09983338887037654, 0.09996667777407531, 0.8760413195601466, 0.8805731422859047, 0.10003332222592469, 0.09983338887037654, 0.8994335221592802, 0.8993668777074308]
2022-01-26 19:44:34:INFO:Loss = [0.6656853142558475, 0.7252704504886018, 0.7189109772334532, 0.7331650955682594, 0.6908818278460453, 0.6900989621490369, 0.7395622698516299, 0.703261496920619, 0.6848333545940314, 0.6385443350069923]
2022-01-26 19:44:34:INFO:-------------Training local models-------------
2022-01-26 19:49:37:INFO:-------------Aggregating local models-------------
2022-01-26 19:49:39:INFO:-------------Round number: 1-------------
2022-01-26 19:49:39:INFO:-------------Sending models-------------
2022-01-26 19:49:40:INFO:-------------Evaluating models-------------
2022-01-26 19:49:40:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 19:49:40:INFO:Accuracy = [0.9311562812395868, 0.9532822392535821, 0.9848050649783405, 0.9285571476174609, 0.9147617460846384, 0.9574141952682439, 0.9843385538153949, 0.9824725091636122, 0.9428857047650783, 0.9265578140619793]
2022-01-26 19:49:40:INFO:Loss = [0.19556647155710713, 0.18701833803572881, 0.10129685905137928, 0.1976838770378052, 0.21837878456123244, 0.17646100012394975, 0.1524579508701803, 0.13485817078777806, 0.17518525228037143, 0.20366871739566694]
2022-01-26 19:49:40:INFO:-------------Training local models-------------
2022-01-26 19:54:44:INFO:-------------Aggregating local models-------------
2022-01-26 19:54:46:INFO:-------------Round number: 2-------------
2022-01-26 19:54:46:INFO:-------------Sending models-------------
2022-01-26 19:54:46:INFO:-------------Evaluating models-------------
2022-01-26 19:54:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 19:54:47:INFO:Accuracy = [0.9337554148617128, 0.9532822392535821, 0.9848050649783405, 0.9289570143285572, 0.9170943018993669, 0.9574141952682439, 0.9844051982672443, 0.9824725091636122, 0.9592802399200266, 0.93188937020993]
2022-01-26 19:54:47:INFO:Loss = [0.1333229752024403, 0.12066038535491702, 0.04943271925262002, 0.1492602541087824, 0.1793342616920189, 0.10116501179111327, 0.061614102934838155, 0.06967945769030423, 0.10480975072847364, 0.1442425953430831]
2022-01-26 19:54:47:INFO:-------------Training local models-------------
2022-01-26 19:59:51:INFO:-------------Aggregating local models-------------
2022-01-26 19:59:53:INFO:-------------Round number: 3-------------
2022-01-26 19:59:53:INFO:-------------Sending models-------------
2022-01-26 19:59:53:INFO:-------------Evaluating models-------------
2022-01-26 19:59:54:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 19:59:54:INFO:Accuracy = [0.9516161279573475, 0.9532822392535821, 0.9848050649783405, 0.9300899700099967, 0.932755748083972, 0.9709430189936687, 0.9844051982672443, 0.9824725091636122, 0.9694768410529824, 0.9369543485504832]
2022-01-26 19:59:54:INFO:Loss = [0.11198091388472735, 0.11018406071245357, 0.04325060051425507, 0.13990428483435466, 0.16676094886188614, 0.0777330460354111, 0.04687111044885396, 0.05991960447790552, 0.0812225754442679, 0.13225036990348255]
2022-01-26 19:59:54:INFO:-------------Training local models-------------
2022-01-26 20:04:57:INFO:-------------Aggregating local models-------------
2022-01-26 20:04:59:INFO:-------------Round number: 4-------------
2022-01-26 20:04:59:INFO:-------------Sending models-------------
2022-01-26 20:04:59:INFO:-------------Evaluating models-------------
2022-01-26 20:05:00:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:05:00:INFO:Accuracy = [0.9639453515494835, 0.9532822392535821, 0.9848050649783405, 0.9412862379206931, 0.935021659446851, 0.975674775074975, 0.9844051982672443, 0.9824725091636122, 0.9721426191269577, 0.9426857714095301]
2022-01-26 20:05:00:INFO:Loss = [0.09684280372219006, 0.10771948916315276, 0.04178618402036434, 0.13295619205053602, 0.15775882157733584, 0.06489910620090299, 0.04267213821089313, 0.05707778964011369, 0.06951893321984044, 0.12678678010407896]
2022-01-26 20:05:00:INFO:-------------Training local models-------------
2022-01-26 20:10:04:INFO:-------------Aggregating local models-------------
2022-01-26 20:10:06:INFO:-------------Round number: 5-------------
2022-01-26 20:10:06:INFO:-------------Sending models-------------
2022-01-26 20:10:06:INFO:-------------Evaluating models-------------
2022-01-26 20:10:07:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:10:07:INFO:Accuracy = [0.9682772409196935, 0.9532822392535821, 0.9848050649783405, 0.9454181939353549, 0.9434855048317228, 0.9769410196601133, 0.9844051982672443, 0.9824725091636122, 0.9726091302899034, 0.9456847717427525]
2022-01-26 20:10:07:INFO:Loss = [0.08696974949280166, 0.10640702404087485, 0.041071881660569354, 0.12623205004536608, 0.15038638938895976, 0.060324599084870124, 0.04034277132976247, 0.05557154868241019, 0.06623484107622425, 0.12161526229670978]
2022-01-26 20:10:07:INFO:-------------Training local models-------------
2022-01-26 20:15:11:INFO:-------------Aggregating local models-------------
2022-01-26 20:15:13:INFO:-------------Round number: 6-------------
2022-01-26 20:15:13:INFO:-------------Sending models-------------
2022-01-26 20:15:13:INFO:-------------Evaluating models-------------
2022-01-26 20:15:14:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:15:14:INFO:Accuracy = [0.9703432189270244, 0.9532822392535821, 0.9848050649783405, 0.9469510163278907, 0.9464178607130956, 0.9772075974675108, 0.9844051982672443, 0.9824725091636122, 0.973408863712096, 0.9460846384538487]
2022-01-26 20:15:14:INFO:Loss = [0.08027812389669936, 0.10516566389344442, 0.04059312824312004, 0.12131882455804804, 0.14327853957951203, 0.05797467287078606, 0.038546890644742204, 0.05457917065609086, 0.06391433903923266, 0.11678122285536563]
2022-01-26 20:15:14:INFO:-------------Training local models-------------
2022-01-26 20:20:17:INFO:-------------Aggregating local models-------------
2022-01-26 20:20:19:INFO:-------------Round number: 7-------------
2022-01-26 20:20:19:INFO:-------------Sending models-------------
2022-01-26 20:20:19:INFO:-------------Evaluating models-------------
2022-01-26 20:20:20:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:20:20:INFO:Accuracy = [0.9713428857047651, 0.9532822392535821, 0.9848050649783405, 0.9479506831056315, 0.9476174608463845, 0.9778073975341552, 0.9844051982672443, 0.9824725091636122, 0.9736087970676441, 0.9466844385204932]
2022-01-26 20:20:20:INFO:Loss = [0.07627178941966928, 0.1038543960107326, 0.040270742748274975, 0.11806473459663076, 0.13870847090346827, 0.056781328445886535, 0.036961827440314884, 0.053836139751968624, 0.062383840180687065, 0.11335300989791171]
2022-01-26 20:20:20:INFO:-------------Training local models-------------
2022-01-26 20:25:23:INFO:-------------Aggregating local models-------------
2022-01-26 20:25:25:INFO:-------------Round number: 8-------------
2022-01-26 20:25:25:INFO:-------------Sending models-------------
2022-01-26 20:25:25:INFO:-------------Evaluating models-------------
2022-01-26 20:25:26:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:25:26:INFO:Accuracy = [0.9720759746751083, 0.9532822392535821, 0.9848050649783405, 0.9484171942685772, 0.9477507497500833, 0.9776074641786071, 0.9851382872375875, 0.9824725091636122, 0.9738753748750416, 0.9474175274908364]
2022-01-26 20:25:26:INFO:Loss = [0.07390466059008176, 0.10244171655554075, 0.04003161308597693, 0.11598201351564115, 0.13596189781102194, 0.056064121226411745, 0.0356090942521034, 0.05322364651413696, 0.061287810306560705, 0.11114011250579993]
2022-01-26 20:25:26:INFO:-------------Training local models-------------
2022-01-26 20:30:29:INFO:-------------Aggregating local models-------------
2022-01-26 20:30:31:INFO:-------------Round number: 9-------------
2022-01-26 20:30:31:INFO:-------------Sending models-------------
2022-01-26 20:30:32:INFO:-------------Evaluating models-------------
2022-01-26 20:30:32:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:30:32:INFO:Accuracy = [0.972875708097301, 0.9532822392535821, 0.9848050649783405, 0.9486837720759747, 0.9478173942019327, 0.9778740419860047, 0.9864711762745751, 0.9824725091636122, 0.9743418860379873, 0.9476841052982339]
2022-01-26 20:30:32:INFO:Loss = [0.07229219998410844, 0.10096987711091661, 0.03984351750694139, 0.11462861737975759, 0.13387576808657353, 0.05565440274826777, 0.034522106764656245, 0.05270243340474414, 0.060434934051235054, 0.10948275404620571]
2022-01-26 20:30:32:INFO:-------------Training local models-------------
2022-01-26 20:35:34:INFO:-------------Aggregating local models-------------
2022-01-26 20:35:37:INFO:-------------Round number: 10-------------
2022-01-26 20:35:37:INFO:-------------Sending models-------------
2022-01-26 20:35:37:INFO:-------------Evaluating models-------------
2022-01-26 20:35:37:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:35:37:INFO:Accuracy = [0.9733422192602466, 0.9532822392535821, 0.9848050649783405, 0.9496834388537154, 0.9481506164611796, 0.977940686437854, 0.9869376874375209, 0.9824725091636122, 0.9746751082972342, 0.9486171276241253]
2022-01-26 20:35:37:INFO:Loss = [0.07104013364123006, 0.09942130019825594, 0.039687713950079355, 0.11366465811789367, 0.13210319303262535, 0.05521800800866544, 0.033582740046017356, 0.05224559458334344, 0.05974296890358814, 0.10785090787907561]
2022-01-26 20:35:37:INFO:-------------Training local models-------------
2022-01-26 20:40:35:INFO:-------------Aggregating local models-------------
2022-01-26 20:40:37:INFO:-------------Round number: 11-------------
2022-01-26 20:40:37:INFO:-------------Sending models-------------
2022-01-26 20:40:37:INFO:-------------Evaluating models-------------
2022-01-26 20:40:38:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:40:38:INFO:Accuracy = [0.9736087970676441, 0.9536821059646784, 0.9848050649783405, 0.949950016661113, 0.9483505498167277, 0.9777407530823059, 0.9872709096967678, 0.9824725091636122, 0.9746751082972342, 0.9496167944018661]
2022-01-26 20:40:38:INFO:Loss = [0.0700224421956331, 0.09768986992414966, 0.039559836281671895, 0.11282677403457023, 0.13051744132734147, 0.054713384090063606, 0.03281426755638507, 0.0518358911072339, 0.05915758432047311, 0.10600852942352292]
2022-01-26 20:40:38:INFO:-------------Training local models-------------
2022-01-26 20:45:35:INFO:-------------Aggregating local models-------------
2022-01-26 20:45:38:INFO:-------------Round number: 12-------------
2022-01-26 20:45:38:INFO:-------------Sending models-------------
2022-01-26 20:45:38:INFO:-------------Evaluating models-------------
2022-01-26 20:45:39:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:45:39:INFO:Accuracy = [0.9742085971342885, 0.9561479506831057, 0.9848050649783405, 0.9505498167277574, 0.9486837720759747, 0.9777407530823059, 0.9878707097634122, 0.9824725091636122, 0.9746084638453849, 0.9503498833722093]
2022-01-26 20:45:39:INFO:Loss = [0.06919949388304357, 0.09564165141412452, 0.039422081994753666, 0.1120597180943149, 0.12894937152079683, 0.05438602911708549, 0.03190034453012142, 0.05146451620572417, 0.058597282544821154, 0.10380784067465063]
2022-01-26 20:45:39:INFO:-------------Training local models-------------
2022-01-26 20:50:36:INFO:-------------Aggregating local models-------------
2022-01-26 20:50:39:INFO:-------------Round number: 13-------------
2022-01-26 20:50:39:INFO:-------------Sending models-------------
2022-01-26 20:50:39:INFO:-------------Evaluating models-------------
2022-01-26 20:50:40:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:50:40:INFO:Accuracy = [0.9745418193935355, 0.9583472175941353, 0.9848050649783405, 0.9514828390536488, 0.9494168610463178, 0.9778740419860047, 0.9881372875708098, 0.9824725091636122, 0.974808397200933, 0.9521492835721426]
2022-01-26 20:50:40:INFO:Loss = [0.06850753841644594, 0.09308198734287992, 0.03927661376162209, 0.11128514999079123, 0.12744610324871952, 0.05409355426016094, 0.03087430845090745, 0.05111906729861515, 0.05813964766566448, 0.10121545125900633]
2022-01-26 20:50:40:INFO:-------------Training local models-------------
2022-01-26 20:55:36:INFO:-------------Aggregating local models-------------
2022-01-26 20:55:39:INFO:-------------Round number: 14-------------
2022-01-26 20:55:39:INFO:-------------Sending models-------------
2022-01-26 20:55:39:INFO:-------------Evaluating models-------------
2022-01-26 20:55:40:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:55:40:INFO:Accuracy = [0.9747417527490836, 0.9608130623125625, 0.9848050649783405, 0.9524158613795402, 0.9498167277574142, 0.9781406197934022, 0.9887370876374542, 0.9824725091636122, 0.9746751082972342, 0.9538820393202266]
2022-01-26 20:55:40:INFO:Loss = [0.06792164363401641, 0.08995729452711874, 0.039135300384760936, 0.11051436576975437, 0.12594873248973038, 0.05381435703636757, 0.029871265939619175, 0.05079692036078683, 0.05770248221991292, 0.09846023749566712]
2022-01-26 20:55:40:INFO:-------------Training local models-------------
2022-01-26 21:00:38:INFO:-------------Aggregating local models-------------
2022-01-26 21:00:40:INFO:-------------Round number: 15-------------
2022-01-26 21:00:40:INFO:-------------Sending models-------------
2022-01-26 21:00:40:INFO:-------------Evaluating models-------------
2022-01-26 21:00:41:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:00:41:INFO:Accuracy = [0.9744751749416861, 0.9620793068977007, 0.9850049983338887, 0.953615461512829, 0.9510829723425525, 0.978273908697101, 0.9892702432522492, 0.9824725091636122, 0.974808397200933, 0.9549483505498167]
2022-01-26 21:00:41:INFO:Loss = [0.06751400101492133, 0.08672918097538074, 0.039020651425047605, 0.1096635390914056, 0.12450221547222404, 0.05354194456426638, 0.029107648290542704, 0.05049195791068972, 0.057272632742978793, 0.09652338890819734]
2022-01-26 21:00:41:INFO:-------------Training local models-------------
2022-01-26 21:05:38:INFO:-------------Aggregating local models-------------
2022-01-26 21:05:41:INFO:-------------Round number: 16-------------
2022-01-26 21:05:41:INFO:-------------Sending models-------------
2022-01-26 21:05:41:INFO:-------------Evaluating models-------------
2022-01-26 21:05:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:05:42:INFO:Accuracy = [0.9745418193935355, 0.9632122625791403, 0.985404865044985, 0.9547484171942686, 0.9520826391202932, 0.9784071976007997, 0.9896701099633456, 0.9824725091636122, 0.9748750416527824, 0.9556814395201599]
2022-01-26 21:05:42:INFO:Loss = [0.06724019017624601, 0.08424797087216476, 0.03891447481578411, 0.10878248082191312, 0.12314065621696181, 0.053361035813835445, 0.02849263751286047, 0.05020558189929509, 0.056848602762514626, 0.09604482153956681]
2022-01-26 21:05:42:INFO:-------------Training local models-------------
2022-01-26 21:10:39:INFO:-------------Aggregating local models-------------
2022-01-26 21:10:41:INFO:-------------Round number: 17-------------
2022-01-26 21:10:41:INFO:-------------Sending models-------------
2022-01-26 21:10:41:INFO:-------------Evaluating models-------------
2022-01-26 21:10:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:10:42:INFO:Accuracy = [0.9743418860379873, 0.963678773742086, 0.9855381539486838, 0.9558147284238587, 0.9522825724758414, 0.9783405531489503, 0.9901366211262912, 0.9824725091636122, 0.9750749750083305, 0.9554815061646118]
2022-01-26 21:10:42:INFO:Loss = [0.06705221556225914, 0.08300413565447719, 0.038757528490550607, 0.10790110925911421, 0.12186190738851928, 0.053184307858075416, 0.027952472947896573, 0.04993537886254272, 0.05642392003439523, 0.09627484527363925]
2022-01-26 21:10:42:INFO:-------------Training local models-------------
2022-01-26 21:15:40:INFO:-------------Aggregating local models-------------
2022-01-26 21:15:42:INFO:-------------Round number: 18-------------
2022-01-26 21:15:42:INFO:-------------Sending models-------------
2022-01-26 21:15:42:INFO:-------------Evaluating models-------------
2022-01-26 21:15:43:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:15:43:INFO:Accuracy = [0.9745418193935355, 0.9637454181939353, 0.9860713095634789, 0.9564811729423526, 0.9532155948017328, 0.978273908697101, 0.99026991002999, 0.9824725091636122, 0.9752082639120293, 0.9556147950683106]
2022-01-26 21:15:43:INFO:Loss = [0.06691022076236026, 0.08237184977767903, 0.038560723157029554, 0.10704988010273417, 0.12069792289709726, 0.05283634354511032, 0.027660830363986817, 0.049675575760127225, 0.055957554998838914, 0.0964445192647752]
2022-01-26 21:15:43:INFO:-------------Training local models-------------
2022-01-26 21:20:40:INFO:-------------Aggregating local models-------------
2022-01-26 21:20:43:INFO:-------------Round number: 19-------------
2022-01-26 21:20:43:INFO:-------------Sending models-------------
2022-01-26 21:20:43:INFO:-------------Evaluating models-------------
2022-01-26 21:20:44:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:20:44:INFO:Accuracy = [0.974808397200933, 0.964211929356881, 0.9865378207264245, 0.9572142619126958, 0.9535488170609797, 0.9783405531489503, 0.9906697767410862, 0.9824725091636122, 0.9752082639120293, 0.9564811729423526]
2022-01-26 21:20:44:INFO:Loss = [0.06691172312879491, 0.08182320177839199, 0.0383268440527713, 0.10623902671664201, 0.11973588647789107, 0.052521598545398944, 0.027165982528329836, 0.04942295876007441, 0.05545874203431578, 0.09580078178606327]
2022-01-26 21:20:44:INFO:-------------Training local models-------------
2022-01-26 21:25:41:INFO:-------------Aggregating local models-------------
2022-01-26 21:25:44:INFO:-------------Round number: 20-------------
2022-01-26 21:25:44:INFO:-------------Sending models-------------
2022-01-26 21:25:44:INFO:-------------Evaluating models-------------
2022-01-26 21:25:45:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:25:45:INFO:Accuracy = [0.9750083305564812, 0.9644785071642785, 0.9870709763412195, 0.9577474175274908, 0.953615461512829, 0.978807064311896, 0.990803065644785, 0.9824725091636122, 0.9753415528157281, 0.9571476174608464]
2022-01-26 21:25:45:INFO:Loss = [0.06691948243227579, 0.08095962912216, 0.038070325360982794, 0.105439446480342, 0.11878840529113412, 0.052354710726592285, 0.026617817688061148, 0.04917535013294136, 0.054939138981682734, 0.09432845524093102]
2022-01-26 21:25:45:INFO:-------------Training local models-------------
2022-01-26 21:30:42:INFO:-------------Aggregating local models-------------
2022-01-26 21:30:44:INFO:-------------Round number: 21-------------
2022-01-26 21:30:44:INFO:-------------Sending models-------------
2022-01-26 21:30:44:INFO:-------------Evaluating models-------------
2022-01-26 21:30:45:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:30:45:INFO:Accuracy = [0.97514161946018, 0.9649450183272242, 0.987137620793069, 0.957947350883039, 0.9538820393202266, 0.9789403532155948, 0.9908697100966345, 0.9824725091636122, 0.9755414861712762, 0.9580806397867377]
2022-01-26 21:30:45:INFO:Loss = [0.0669571706210651, 0.08025619048314389, 0.037808597664159595, 0.10464893321106479, 0.11792035707923347, 0.05216589902558141, 0.026076054426025095, 0.04892847758853472, 0.054442572678373255, 0.09294992065371298]
2022-01-26 21:30:45:INFO:-------------Training local models-------------
2022-01-26 21:35:42:INFO:-------------Aggregating local models-------------
2022-01-26 21:35:45:INFO:-------------Round number: 22-------------
2022-01-26 21:35:45:INFO:-------------Sending models-------------
2022-01-26 21:35:45:INFO:-------------Evaluating models-------------
2022-01-26 21:35:46:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:35:46:INFO:Accuracy = [0.974808397200933, 0.9651449516827724, 0.9872709096967678, 0.9583472175941353, 0.9547484171942686, 0.9791402865711429, 0.9910029990003332, 0.9824725091636122, 0.9764745084971677, 0.9585471509496835]
2022-01-26 21:35:46:INFO:Loss = [0.06711809708750531, 0.07940803199548505, 0.03755644617132805, 0.10390653664552699, 0.11716806233435642, 0.05206615001044907, 0.025509855928984807, 0.048681972693942935, 0.054000224735816435, 0.09129132941793003]
2022-01-26 21:35:46:INFO:-------------Training local models-------------
2022-01-26 21:40:43:INFO:-------------Aggregating local models-------------
2022-01-26 21:40:46:INFO:-------------Round number: 23-------------
2022-01-26 21:40:46:INFO:-------------Sending models-------------
2022-01-26 21:40:46:INFO:-------------Evaluating models-------------
2022-01-26 21:40:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:40:47:INFO:Accuracy = [0.9746751082972342, 0.9654781739420193, 0.9875374875041653, 0.9587470843052316, 0.9550816394535155, 0.9792735754748417, 0.9909363545484838, 0.9824725091636122, 0.9768743752082639, 0.9593468843718761]
2022-01-26 21:40:47:INFO:Loss = [0.0672711861427595, 0.07871853742064186, 0.03733566217377096, 0.10320575179867761, 0.11646113665130514, 0.051785525414674606, 0.025151093466133992, 0.04843295600681078, 0.053490889604942665, 0.09013141712654126]
2022-01-26 21:40:47:INFO:-------------Training local models-------------
2022-01-26 21:45:43:INFO:-------------Aggregating local models-------------
2022-01-26 21:45:46:INFO:-------------Round number: 24-------------
2022-01-26 21:45:46:INFO:-------------Sending models-------------
2022-01-26 21:45:46:INFO:-------------Evaluating models-------------
2022-01-26 21:45:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:45:47:INFO:Accuracy = [0.9746751082972342, 0.9657447517494169, 0.9873375541486171, 0.9590136621126292, 0.9551482839053649, 0.9794068643785405, 0.9908697100966345, 0.9824725091636122, 0.9772075974675108, 0.9594135288237254]
2022-01-26 21:45:47:INFO:Loss = [0.06751144306348668, 0.07818488894122466, 0.03713258708495641, 0.10262646023479657, 0.115833243888946, 0.05166887963911511, 0.024819212416338023, 0.04818074505020728, 0.05302827773061746, 0.08921845135912883]
2022-01-26 21:45:47:INFO:-------------Training local models-------------
2022-01-26 21:50:44:INFO:-------------Aggregating local models-------------
2022-01-26 21:50:47:INFO:-------------Round number: 25-------------
2022-01-26 21:50:47:INFO:-------------Sending models-------------
2022-01-26 21:50:47:INFO:-------------Evaluating models-------------
2022-01-26 21:50:48:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:50:48:INFO:Accuracy = [0.9744085304898367, 0.9663445518160613, 0.9874041986004665, 0.9588803732089304, 0.9558147284238587, 0.979673442185938, 0.9910029990003332, 0.9825391536154615, 0.9772075974675108, 0.9602799066977674]
2022-01-26 21:50:48:INFO:Loss = [0.06778010018229329, 0.07751559797630175, 0.0369435150614134, 0.10210861675434185, 0.11531773587986902, 0.05143719801663407, 0.024526657814266318, 0.04792719112094464, 0.05245793862633169, 0.08820129857431039]
2022-01-26 21:50:48:INFO:-------------Training local models-------------
2022-01-26 21:55:45:INFO:-------------Aggregating local models-------------
2022-01-26 21:55:48:INFO:-------------Round number: 26-------------
2022-01-26 21:55:48:INFO:-------------Sending models-------------
2022-01-26 21:55:48:INFO:-------------Evaluating models-------------
2022-01-26 21:55:48:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:55:48:INFO:Accuracy = [0.9742085971342885, 0.9666111296234589, 0.9874708430523159, 0.9594135288237254, 0.9565478173942019, 0.9798067310896368, 0.9910696434521826, 0.9826057980673109, 0.9773408863712096, 0.9607464178607131]
2022-01-26 21:55:48:INFO:Loss = [0.06815557527820948, 0.0770251148469018, 0.036774338603089, 0.10162108236088735, 0.11486129337187383, 0.05133181341535619, 0.024162818375050358, 0.04767390873527209, 0.051999156421415234, 0.08725771278344008]
2022-01-26 21:55:48:INFO:-------------Training local models-------------
2022-01-26 22:00:45:INFO:-------------Aggregating local models-------------
2022-01-26 22:00:48:INFO:-------------Round number: 27-------------
2022-01-26 22:00:48:INFO:-------------Sending models-------------
2022-01-26 22:00:48:INFO:-------------Evaluating models-------------
2022-01-26 22:00:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:00:49:INFO:Accuracy = [0.9738753748750416, 0.9664778407197601, 0.9875374875041653, 0.9603465511496168, 0.9573475508163946, 0.9799400199933356, 0.9910696434521826, 0.9826724425191603, 0.9774741752749083, 0.9609463512162613]
2022-01-26 22:00:49:INFO:Loss = [0.0684695612664617, 0.07644785232318758, 0.036642801245850294, 0.10119589768457171, 0.11434851904613806, 0.05117463724123192, 0.02420040579784823, 0.047419289416637894, 0.0514907184816537, 0.08692084529911029]
2022-01-26 22:00:49:INFO:-------------Training local models-------------
2022-01-26 22:05:46:INFO:-------------Aggregating local models-------------
2022-01-26 22:05:49:INFO:-------------Round number: 28-------------
2022-01-26 22:05:49:INFO:-------------Sending models-------------
2022-01-26 22:05:49:INFO:-------------Evaluating models-------------
2022-01-26 22:05:50:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:05:50:INFO:Accuracy = [0.9737420859713429, 0.967344218593802, 0.9877374208597134, 0.9602799066977674, 0.9580139953348884, 0.9801399533488837, 0.991136287904032, 0.9826057980673109, 0.9774741752749083, 0.9615461512829057]
2022-01-26 22:05:50:INFO:Loss = [0.06885754709911913, 0.07591838560363237, 0.036526453802804705, 0.10086919089997522, 0.11396070369273739, 0.050970499740090304, 0.024235017412662825, 0.04716752901486164, 0.0510322893184978, 0.08664173994734457]
2022-01-26 22:05:50:INFO:-------------Training local models-------------
2022-01-26 22:10:47:INFO:-------------Aggregating local models-------------
2022-01-26 22:10:49:INFO:-------------Round number: 29-------------
2022-01-26 22:10:49:INFO:-------------Sending models-------------
2022-01-26 22:10:50:INFO:-------------Evaluating models-------------
2022-01-26 22:10:50:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:10:50:INFO:Accuracy = [0.9739420193268911, 0.9676107964011996, 0.9878040653115628, 0.9604798400533155, 0.9582805731422859, 0.9802732422525825, 0.9912695768077308, 0.9825391536154615, 0.9778740419860047, 0.9616794401866045]
2022-01-26 22:10:50:INFO:Loss = [0.06920268182602492, 0.07557027255899229, 0.03640180660740053, 0.10054842630943937, 0.11358590513543511, 0.050631283829175845, 0.024047109916622462, 0.04691431818160119, 0.050545945079629506, 0.08632607225361599]
2022-01-26 22:10:50:INFO:-------------Training local models-------------
2022-01-26 22:15:47:INFO:-------------Aggregating local models-------------
