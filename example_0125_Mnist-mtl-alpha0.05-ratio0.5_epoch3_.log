2022-01-25 14:03:34:INFO:-------------Round number: 0-------------
2022-01-25 14:03:34:INFO:-------------Sending models-------------
2022-01-25 14:03:34:INFO:-------------Evaluating models-------------
2022-01-25 14:03:34:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:03:34:INFO:Accuracy = [0.9263895843765648, 0.9158738107160741, 0.8595393089634452, 0.899849774661993, 0.914121181772659, 0.11016524787180772, 0.09414121181772658, 0.12769153730595895, 0.09614421632448673, 0.9123685528292439]
2022-01-25 14:03:34:INFO:Loss = [0.6677707227307913, 0.65035355840257, 0.664374296373884, 0.654283486385016, 0.6628631437994804, 0.7358170935495173, 0.7406060484629245, 0.7388185477579123, 0.7473186791450547, 0.6691222313080779]
2022-01-25 14:03:34:INFO:-------------Training local models-------------
2022-01-25 14:04:17:INFO:-------------Aggregating local models-------------
2022-01-25 14:04:18:INFO:-------------Round number: 1-------------
2022-01-25 14:04:18:INFO:-------------Sending models-------------
2022-01-25 14:04:18:INFO:-------------Evaluating models-------------
2022-01-25 14:04:18:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:04:18:INFO:Accuracy = [0.8778167250876314, 0.8963445167751627, 0.8360040060090135, 0.8535302954431647, 0.85628442663996, 0.7233350025037556, 0.743865798698047, 0.7243365047571357, 0.7220831246870305, 0.6755132699048573]
2022-01-25 14:04:18:INFO:Loss = [0.502006153638102, 0.5314362746181641, 0.5787067723441375, 0.5281040287116318, 0.5345603353905869, 0.6020609671226668, 0.5725953400873756, 0.598423719928452, 0.5915771511028454, 0.6603907014079612]
2022-01-25 14:04:18:INFO:-------------Training local models-------------
2022-01-25 14:05:02:INFO:-------------Aggregating local models-------------
2022-01-25 14:05:03:INFO:-------------Round number: 2-------------
2022-01-25 14:05:03:INFO:-------------Sending models-------------
2022-01-25 14:05:03:INFO:-------------Evaluating models-------------
2022-01-25 14:05:03:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:05:03:INFO:Accuracy = [0.8990986479719579, 0.9018527791687532, 0.8487731597396094, 0.8585378067100651, 0.85728592889334, 0.8047070605908864, 0.8322483725588382, 0.8239859789684527, 0.7976965448172258, 0.7478718077115674]
2022-01-25 14:05:03:INFO:Loss = [0.40712549347051785, 0.4611403127580986, 0.5291635078724528, 0.44578436222048656, 0.4726901736910724, 0.5234164436593555, 0.48130211103978043, 0.520504544506341, 0.5396697684631878, 0.5772757777719422]
2022-01-25 14:05:03:INFO:-------------Training local models-------------
2022-01-25 14:05:47:INFO:-------------Aggregating local models-------------
2022-01-25 14:05:48:INFO:-------------Round number: 3-------------
2022-01-25 14:05:48:INFO:-------------Sending models-------------
2022-01-25 14:05:48:INFO:-------------Evaluating models-------------
2022-01-25 14:05:48:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:05:48:INFO:Accuracy = [0.9028542814221332, 0.8980971457185779, 0.85628442663996, 0.8535302954431647, 0.8565348022033049, 0.8362543815723585, 0.8580370555833751, 0.842513770655984, 0.8157235853780671, 0.78592889334001]
2022-01-25 14:05:48:INFO:Loss = [0.35205236603969936, 0.426315467544441, 0.5055965382193528, 0.4021178218211958, 0.45232441932901285, 0.4815979827536782, 0.44235418152910994, 0.480410572583519, 0.5215633158153693, 0.5092518195980003]
2022-01-25 14:05:48:INFO:-------------Training local models-------------
2022-01-25 14:06:32:INFO:-------------Aggregating local models-------------
2022-01-25 14:06:33:INFO:-------------Round number: 4-------------
2022-01-25 14:06:33:INFO:-------------Sending models-------------
2022-01-25 14:06:33:INFO:-------------Evaluating models-------------
2022-01-25 14:06:33:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:06:33:INFO:Accuracy = [0.9058587881822734, 0.8955933900851277, 0.8600400600901352, 0.8527791687531296, 0.8552829243865798, 0.8530295443164747, 0.8617926890335503, 0.8477716574862293, 0.8227341011517276, 0.8009514271407111]
2022-01-25 14:06:33:INFO:Loss = [0.31764819190973154, 0.4085587070700813, 0.49212008476272245, 0.37584116867368944, 0.4464935169466172, 0.45628735369363305, 0.4230692307327202, 0.45390415968560893, 0.5089263870111729, 0.4651301122444477]
2022-01-25 14:06:33:INFO:-------------Training local models-------------
2022-01-25 14:07:17:INFO:-------------Aggregating local models-------------
2022-01-25 14:07:18:INFO:-------------Round number: 5-------------
2022-01-25 14:07:18:INFO:-------------Sending models-------------
2022-01-25 14:07:18:INFO:-------------Evaluating models-------------
2022-01-25 14:07:18:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:07:18:INFO:Accuracy = [0.9138708062093139, 0.8950926389584376, 0.8655483224837256, 0.8440160240360541, 0.8555332999499249, 0.8582874311467201, 0.8632949424136205, 0.8492739108662994, 0.8259889834752128, 0.8087130696044066]
2022-01-25 14:07:18:INFO:Loss = [0.29431282087454447, 0.3975462113459523, 0.4825448744627659, 0.35817639006168384, 0.4436297761819675, 0.4388825391747084, 0.4099979701085398, 0.43326926671069266, 0.49547534048651487, 0.43436503708437196]
2022-01-25 14:07:18:INFO:-------------Training local models-------------
2022-01-25 14:08:02:INFO:-------------Aggregating local models-------------
2022-01-25 14:08:03:INFO:-------------Round number: 6-------------
2022-01-25 14:08:03:INFO:-------------Sending models-------------
2022-01-25 14:08:03:INFO:-------------Evaluating models-------------
2022-01-25 14:08:03:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:08:03:INFO:Accuracy = [0.9196294441662494, 0.8950926389584376, 0.8678017025538307, 0.8350025037556335, 0.857536304456685, 0.8595393089634452, 0.8635453179769654, 0.8492739108662994, 0.8272408612919379, 0.8184777165748623]
2022-01-25 14:08:03:INFO:Loss = [0.27802062771795155, 0.3894078266551801, 0.4749978252126461, 0.34606360552788645, 0.4405698381661884, 0.4264305558029523, 0.3995604890594086, 0.41672616475996266, 0.482232230089131, 0.41061342969204734]
2022-01-25 14:08:03:INFO:-------------Training local models-------------
2022-01-25 14:08:47:INFO:-------------Aggregating local models-------------
2022-01-25 14:08:48:INFO:-------------Round number: 7-------------
2022-01-25 14:08:48:INFO:-------------Sending models-------------
2022-01-25 14:08:48:INFO:-------------Evaluating models-------------
2022-01-25 14:08:48:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:08:48:INFO:Accuracy = [0.9216324486730095, 0.8950926389584376, 0.8685528292438658, 0.8294942413620431, 0.8582874311467201, 0.8607911867801703, 0.8637956935403105, 0.8512769153730596, 0.827741612418628, 0.8222333500250375]
2022-01-25 14:08:48:INFO:Loss = [0.2664065407291773, 0.38277037657982016, 0.4688212734086996, 0.33788570781034577, 0.4367436979399247, 0.41740643143053197, 0.3907429351945653, 0.40354546102726413, 0.47028858222405, 0.3918942903841458]
2022-01-25 14:08:48:INFO:-------------Training local models-------------
2022-01-25 14:09:31:INFO:-------------Aggregating local models-------------
2022-01-25 14:09:32:INFO:-------------Round number: 8-------------
2022-01-25 14:09:32:INFO:-------------Sending models-------------
2022-01-25 14:09:33:INFO:-------------Evaluating models-------------
2022-01-25 14:09:33:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:09:33:INFO:Accuracy = [0.9223835753630446, 0.8950926389584376, 0.8703054581872809, 0.8272408612919379, 0.8617926890335503, 0.8615423134702053, 0.8647971957936905, 0.8535302954431647, 0.827741612418628, 0.8254882323485228]
2022-01-25 14:09:33:INFO:Loss = [0.25792465842612045, 0.37705290799402724, 0.4636137718040987, 0.3323342200155516, 0.4323016160917895, 0.4108113936387827, 0.3831543732417256, 0.39299743147179833, 0.460011645309295, 0.3775683887532325]
2022-01-25 14:09:33:INFO:-------------Training local models-------------
2022-01-25 14:10:16:INFO:-------------Aggregating local models-------------
2022-01-25 14:10:17:INFO:-------------Round number: 9-------------
2022-01-25 14:10:17:INFO:-------------Sending models-------------
2022-01-25 14:10:17:INFO:-------------Evaluating models-------------
2022-01-25 14:10:18:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:10:18:INFO:Accuracy = [0.9228843264897346, 0.8950926389584376, 0.870555833750626, 0.8254882323485228, 0.8632949424136205, 0.8617926890335503, 0.8652979469203805, 0.8580370555833751, 0.827741612418628, 0.8274912368552829]
2022-01-25 14:10:18:INFO:Loss = [0.25147650353076534, 0.3719483095007395, 0.45910416760015066, 0.3284833125919794, 0.4275250121568454, 0.40587570625518227, 0.3765702989699975, 0.3844776632744375, 0.45127709716141995, 0.3671447582853959]
2022-01-25 14:10:18:INFO:-------------Training local models-------------
2022-01-25 14:11:01:INFO:-------------Aggregating local models-------------
2022-01-25 14:11:02:INFO:-------------Round number: 10-------------
2022-01-25 14:11:02:INFO:-------------Sending models-------------
2022-01-25 14:11:02:INFO:-------------Evaluating models-------------
2022-01-25 14:11:02:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:11:02:INFO:Accuracy = [0.9233850776164246, 0.8950926389584376, 0.872058087130696, 0.8269904857285929, 0.8652979469203805, 0.8620430645968954, 0.8652979469203805, 0.8630445668502754, 0.827741612418628, 0.8289934902353531]
2022-01-25 14:11:02:INFO:Loss = [0.24635592641173193, 0.3672622039708466, 0.4551330718436149, 0.3256914023772576, 0.42262816966444156, 0.40205169276277913, 0.3708110306598293, 0.377499126954658, 0.4438182438823311, 0.36001503713798333]
2022-01-25 14:11:02:INFO:-------------Training local models-------------
2022-01-25 14:11:46:INFO:-------------Aggregating local models-------------
2022-01-25 14:11:47:INFO:-------------Round number: 11-------------
2022-01-25 14:11:47:INFO:-------------Sending models-------------
2022-01-25 14:11:47:INFO:-------------Evaluating models-------------
2022-01-25 14:11:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:11:47:INFO:Accuracy = [0.9241362043064597, 0.8950926389584376, 0.8730595893840761, 0.8274912368552829, 0.8678017025538307, 0.8630445668502754, 0.8652979469203805, 0.8678017025538307, 0.827741612418628, 0.8294942413620431]
2022-01-25 14:11:47:INFO:Loss = [0.24212442519566213, 0.3629019217093232, 0.45160982034714314, 0.32354398330362977, 0.41779964323212476, 0.39894607519562103, 0.3657598011307586, 0.37173800848277067, 0.43734610375878763, 0.3555402214653812]
2022-01-25 14:11:47:INFO:-------------Training local models-------------
2022-01-25 14:12:31:INFO:-------------Aggregating local models-------------
2022-01-25 14:12:32:INFO:-------------Round number: 12-------------
2022-01-25 14:12:32:INFO:-------------Sending models-------------
2022-01-25 14:12:32:INFO:-------------Evaluating models-------------
2022-01-25 14:12:32:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:12:32:INFO:Accuracy = [0.9243865798698047, 0.8950926389584376, 0.8755633450175263, 0.827741612418628, 0.8683024536805208, 0.8650475713570356, 0.8652979469203805, 0.872058087130696, 0.827741612418628, 0.8302453680520782]
2022-01-25 14:12:32:INFO:Loss = [0.2385083425709158, 0.35876747741493126, 0.4484625903093925, 0.321834527970183, 0.41313647439994355, 0.39634188301264345, 0.3612796127774954, 0.36696415650588354, 0.4316549055080914, 0.3531332133092083]
2022-01-25 14:12:32:INFO:-------------Training local models-------------
2022-01-25 14:13:16:INFO:-------------Aggregating local models-------------
2022-01-25 14:13:17:INFO:-------------Round number: 13-------------
2022-01-25 14:13:17:INFO:-------------Sending models-------------
2022-01-25 14:13:17:INFO:-------------Evaluating models-------------
2022-01-25 14:13:17:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:13:17:INFO:Accuracy = [0.9243865798698047, 0.8950926389584376, 0.8770655983975963, 0.8262393590385578, 0.8685528292438658, 0.8675513269904858, 0.8652979469203805, 0.8750625938908363, 0.8279919879819729, 0.8307461191787682]
2022-01-25 14:13:17:INFO:Loss = [0.235342995125535, 0.35484740188514136, 0.44567333966256695, 0.3204279617975621, 0.4086870370357184, 0.39410386351345256, 0.35727910930570633, 0.3630446826495346, 0.42656393011560423, 0.35227807156781726]
2022-01-25 14:13:17:INFO:-------------Training local models-------------
2022-01-25 14:14:01:INFO:-------------Aggregating local models-------------
2022-01-25 14:14:02:INFO:-------------Round number: 14-------------
2022-01-25 14:14:02:INFO:-------------Sending models-------------
2022-01-25 14:14:02:INFO:-------------Evaluating models-------------
2022-01-25 14:14:02:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:14:02:INFO:Accuracy = [0.9243865798698047, 0.8950926389584376, 0.8778167250876314, 0.8254882323485228, 0.8693039559339009, 0.8688032048072108, 0.8650475713570356, 0.8763144717075614, 0.8279919879819729, 0.8312468703054582]
2022-01-25 14:14:02:INFO:Loss = [0.23252509307701785, 0.3511153035731888, 0.4432393637680275, 0.3192305221466248, 0.404493082063711, 0.3921571388872388, 0.3536848841891095, 0.35985813617965595, 0.42195433982285124, 0.35257664711518205]
2022-01-25 14:14:02:INFO:-------------Training local models-------------
2022-01-25 14:14:45:INFO:-------------Aggregating local models-------------
2022-01-25 14:14:46:INFO:-------------Round number: 15-------------
2022-01-25 14:14:46:INFO:-------------Sending models-------------
2022-01-25 14:14:46:INFO:-------------Evaluating models-------------
2022-01-25 14:14:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:14:47:INFO:Accuracy = [0.9243865798698047, 0.8950926389584376, 0.8788182273410116, 0.8254882323485228, 0.8700550826239359, 0.8700550826239359, 0.8650475713570356, 0.8773159739609414, 0.8279919879819729, 0.8312468703054582]
2022-01-25 14:14:47:INFO:Loss = [0.22998116552257516, 0.3475419256123693, 0.44112159333923534, 0.31819754719741655, 0.40057279527386486, 0.3904684793761837, 0.35040756937666223, 0.35728099597409285, 0.417734148706525, 0.3537161220615925]
2022-01-25 14:14:47:INFO:-------------Training local models-------------
2022-01-25 14:15:30:INFO:-------------Aggregating local models-------------
2022-01-25 14:15:31:INFO:-------------Round number: 16-------------
2022-01-25 14:15:31:INFO:-------------Sending models-------------
2022-01-25 14:15:31:INFO:-------------Evaluating models-------------
2022-01-25 14:15:31:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:15:31:INFO:Accuracy = [0.9246369554331497, 0.8950926389584376, 0.8800701051577366, 0.8232348522784176, 0.8698047070605909, 0.8708062093139709, 0.8650475713570356, 0.8778167250876314, 0.8279919879819729, 0.8319979969954933]
2022-01-25 14:15:31:INFO:Loss = [0.22765845625851822, 0.34411253264436426, 0.4392983506200019, 0.31728682532506863, 0.3969106068913944, 0.3890005312967275, 0.3473848735410081, 0.35522698483372256, 0.4138323337571396, 0.3554527032103727]
2022-01-25 14:15:31:INFO:-------------Training local models-------------
2022-01-25 14:16:15:INFO:-------------Aggregating local models-------------
2022-01-25 14:16:16:INFO:-------------Round number: 17-------------
2022-01-25 14:16:16:INFO:-------------Sending models-------------
2022-01-25 14:16:16:INFO:-------------Evaluating models-------------
2022-01-25 14:16:16:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:16:16:INFO:Accuracy = [0.9248873309964948, 0.8953430145217827, 0.8813219829744617, 0.8232348522784176, 0.8700550826239359, 0.872058087130696, 0.8650475713570356, 0.8785678517776665, 0.8294942413620431, 0.8324987481221833]
2022-01-25 14:16:16:INFO:Loss = [0.22552012375233677, 0.3408831334973088, 0.43775182282953196, 0.31649342625862215, 0.3935097949777561, 0.38772505428198994, 0.3446141706043798, 0.3536109799206953, 0.4102024021245419, 0.3575925627545186]
2022-01-25 14:16:16:INFO:-------------Training local models-------------
2022-01-25 14:16:59:INFO:-------------Aggregating local models-------------
2022-01-25 14:17:00:INFO:-------------Round number: 18-------------
2022-01-25 14:17:00:INFO:-------------Sending models-------------
2022-01-25 14:17:01:INFO:-------------Evaluating models-------------
2022-01-25 14:17:01:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:17:01:INFO:Accuracy = [0.9248873309964948, 0.8953430145217827, 0.8818227341011518, 0.8234852278417626, 0.8703054581872809, 0.872058087130696, 0.8650475713570356, 0.8795693540310465, 0.8319979969954933, 0.8332498748122183]
2022-01-25 14:17:01:INFO:Loss = [0.2235423346963801, 0.33777794472363243, 0.43642511561421543, 0.31577152389280766, 0.39034048343105515, 0.38660840925368356, 0.3419976975551597, 0.35234906558569057, 0.4068032771370639, 0.3599917289029581]
2022-01-25 14:17:01:INFO:-------------Training local models-------------
2022-01-25 14:17:44:INFO:-------------Aggregating local models-------------
2022-01-25 14:17:45:INFO:-------------Round number: 19-------------
2022-01-25 14:17:45:INFO:-------------Sending models-------------
2022-01-25 14:17:45:INFO:-------------Evaluating models-------------
2022-01-25 14:17:45:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:17:45:INFO:Accuracy = [0.9248873309964948, 0.8953430145217827, 0.8823234852278418, 0.8239859789684527, 0.8703054581872809, 0.8725588382573861, 0.8650475713570356, 0.8803204807210816, 0.8342513770655984, 0.8340010015022534]
2022-01-25 14:17:45:INFO:Loss = [0.22170314440208394, 0.33483431365109634, 0.4353074731221763, 0.3150981975393813, 0.38738572541094407, 0.38563516860828734, 0.33955588382395974, 0.35137308740473744, 0.4035860475067154, 0.36254825991737893]
2022-01-25 14:17:45:INFO:-------------Training local models-------------
2022-01-25 14:18:29:INFO:-------------Aggregating local models-------------
2022-01-25 14:18:30:INFO:-------------Round number: 20-------------
2022-01-25 14:18:30:INFO:-------------Sending models-------------
2022-01-25 14:18:30:INFO:-------------Evaluating models-------------
2022-01-25 14:18:30:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:18:30:INFO:Accuracy = [0.9251377065598397, 0.8960941412118177, 0.8823234852278418, 0.8242363545317977, 0.8703054581872809, 0.8730595893840761, 0.8650475713570356, 0.8805708562844267, 0.8355032548823235, 0.8340010015022534]
2022-01-25 14:18:30:INFO:Loss = [0.21998813684686852, 0.332003545248881, 0.4343441714139531, 0.3144718128271423, 0.38462818601583987, 0.384781235156037, 0.33721997986550445, 0.3506335768625154, 0.4005295359413256, 0.3651813763953022]
2022-01-25 14:18:30:INFO:-------------Training local models-------------
2022-01-25 14:19:14:INFO:-------------Aggregating local models-------------
2022-01-25 14:19:15:INFO:-------------Round number: 21-------------
2022-01-25 14:19:15:INFO:-------------Sending models-------------
2022-01-25 14:19:15:INFO:-------------Evaluating models-------------
2022-01-25 14:19:15:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:19:15:INFO:Accuracy = [0.9251377065598397, 0.8965948923385078, 0.8825738607911868, 0.8247371056584877, 0.870555833750626, 0.8733099649474211, 0.8650475713570356, 0.8815723585378067, 0.8372558838257386, 0.8340010015022534]
2022-01-25 14:19:15:INFO:Loss = [0.21837390915407442, 0.3292744991830776, 0.4335130228738883, 0.31387924923900556, 0.3820346064035642, 0.384038846598426, 0.3349712876140494, 0.35007716406033684, 0.39761837234400665, 0.36781844557423854]
2022-01-25 14:19:15:INFO:-------------Training local models-------------
2022-01-25 14:19:58:INFO:-------------Aggregating local models-------------
2022-01-25 14:19:59:INFO:-------------Round number: 22-------------
2022-01-25 14:19:59:INFO:-------------Sending models-------------
2022-01-25 14:20:00:INFO:-------------Evaluating models-------------
2022-01-25 14:20:00:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:20:00:INFO:Accuracy = [0.9251377065598397, 0.8970956434651978, 0.8830746119178768, 0.8252378567851778, 0.8708062093139709, 0.8735603405107661, 0.8650475713570356, 0.8818227341011518, 0.8387581372058087, 0.8342513770655984]
2022-01-25 14:20:00:INFO:Loss = [0.2168501318357423, 0.32667433612506125, 0.43280282019580163, 0.3133133492691598, 0.3795976608519549, 0.3833786492232694, 0.33282032402347245, 0.3496671947744175, 0.39482829760582616, 0.37042571438087496]
2022-01-25 14:20:00:INFO:-------------Training local models-------------
2022-01-25 14:20:43:INFO:-------------Aggregating local models-------------
2022-01-25 14:20:44:INFO:-------------Round number: 23-------------
2022-01-25 14:20:44:INFO:-------------Sending models-------------
2022-01-25 14:20:44:INFO:-------------Evaluating models-------------
2022-01-25 14:20:45:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:20:45:INFO:Accuracy = [0.9251377065598397, 0.8975963945918878, 0.8830746119178768, 0.8262393590385578, 0.8708062093139709, 0.8735603405107661, 0.8650475713570356, 0.8820731096644967, 0.8397596394591887, 0.8347521281922884]
2022-01-25 14:20:45:INFO:Loss = [0.21540607686672672, 0.32414980243809166, 0.4321672316767932, 0.31276755182037075, 0.37729683541686965, 0.3828045024196573, 0.3307068116362937, 0.349367140522812, 0.3921607987039455, 0.37296180076790814]
2022-01-25 14:20:45:INFO:-------------Training local models-------------
2022-01-25 14:21:28:INFO:-------------Aggregating local models-------------
2022-01-25 14:21:29:INFO:-------------Round number: 24-------------
2022-01-25 14:21:29:INFO:-------------Sending models-------------
2022-01-25 14:21:29:INFO:-------------Evaluating models-------------
2022-01-25 14:21:29:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:21:29:INFO:Accuracy = [0.9251377065598397, 0.8980971457185779, 0.8833249874812218, 0.8274912368552829, 0.8708062093139709, 0.8738107160741112, 0.8650475713570356, 0.8828242363545318, 0.8412618928392589, 0.8355032548823235]
2022-01-25 14:21:29:INFO:Loss = [0.21403500509897105, 0.321731262266357, 0.431607384180569, 0.3122292995654815, 0.375126270835005, 0.38229224133469875, 0.32864832629965113, 0.34915541800870625, 0.38959964445948836, 0.3754147149778205]
2022-01-25 14:21:29:INFO:-------------Training local models-------------
2022-01-25 14:22:13:INFO:-------------Aggregating local models-------------
2022-01-25 14:22:14:INFO:-------------Round number: 25-------------
2022-01-25 14:22:14:INFO:-------------Sending models-------------
2022-01-25 14:22:14:INFO:-------------Evaluating models-------------
2022-01-25 14:22:14:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:22:14:INFO:Accuracy = [0.9251377065598397, 0.8990986479719579, 0.8838257386079119, 0.828492739108663, 0.871056584877316, 0.8738107160741112, 0.8650475713570356, 0.8833249874812218, 0.8422633950926389, 0.8357536304456685]
2022-01-25 14:22:14:INFO:Loss = [0.2127243752379001, 0.3194047019325041, 0.43110575802128953, 0.3116941031258722, 0.3730700896462296, 0.38183396265869535, 0.3266325189041393, 0.3490056086479792, 0.3871431107711864, 0.37775806181783833]
2022-01-25 14:22:14:INFO:-------------Training local models-------------
2022-01-25 14:22:58:INFO:-------------Aggregating local models-------------
2022-01-25 14:22:59:INFO:-------------Round number: 26-------------
2022-01-25 14:22:59:INFO:-------------Sending models-------------
2022-01-25 14:22:59:INFO:-------------Evaluating models-------------
2022-01-25 14:22:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:22:59:INFO:Accuracy = [0.9253880821231848, 0.899849774661993, 0.8838257386079119, 0.829243865798698, 0.871306960440661, 0.8738107160741112, 0.8650475713570356, 0.8835753630445669, 0.8437656484727091, 0.8365047571357036]
2022-01-25 14:22:59:INFO:Loss = [0.2114686773599146, 0.31714517066744774, 0.4306417094309463, 0.3111571553932726, 0.3711192802900953, 0.38142430048709214, 0.32463385213973744, 0.34890119503719735, 0.3847868342366924, 0.379987936258469]
2022-01-25 14:22:59:INFO:-------------Training local models-------------
2022-01-25 14:23:43:INFO:-------------Aggregating local models-------------
2022-01-25 14:23:44:INFO:-------------Round number: 27-------------
2022-01-25 14:23:44:INFO:-------------Sending models-------------
2022-01-25 14:23:44:INFO:-------------Evaluating models-------------
2022-01-25 14:23:44:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:23:44:INFO:Accuracy = [0.9256384576865297, 0.9016024036054081, 0.8838257386079119, 0.8299949924887331, 0.871306960440661, 0.8738107160741112, 0.8650475713570356, 0.8835753630445669, 0.8447671507260891, 0.8360040060090135]
2022-01-25 14:23:44:INFO:Loss = [0.2102634212771129, 0.31494764187468244, 0.4302142110618711, 0.3106183007268098, 0.3692710387941266, 0.3810576654643727, 0.32264301010938456, 0.3488397249326685, 0.3825282355962318, 0.3821016903182013]
2022-01-25 14:23:44:INFO:-------------Training local models-------------
2022-01-25 14:24:27:INFO:-------------Aggregating local models-------------
2022-01-25 14:24:28:INFO:-------------Round number: 28-------------
2022-01-25 14:24:28:INFO:-------------Sending models-------------
2022-01-25 14:24:29:INFO:-------------Evaluating models-------------
2022-01-25 14:24:29:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:24:29:INFO:Accuracy = [0.9258888332498748, 0.9021031547320981, 0.8838257386079119, 0.8314972458688032, 0.871557336004006, 0.8738107160741112, 0.8650475713570356, 0.8838257386079119, 0.8460190285428142, 0.8342513770655984]
2022-01-25 14:24:29:INFO:Loss = [0.2091055041664426, 0.3128331859690104, 0.4298219253191548, 0.31007835489848623, 0.3675245564701092, 0.38072271018233533, 0.3206816012874916, 0.3488077666795217, 0.3803584744707419, 0.3840987287797771]
2022-01-25 14:24:29:INFO:-------------Training local models-------------
2022-01-25 14:25:12:INFO:-------------Aggregating local models-------------
2022-01-25 14:25:13:INFO:-------------Round number: 29-------------
2022-01-25 14:25:13:INFO:-------------Sending models-------------
2022-01-25 14:25:13:INFO:-------------Evaluating models-------------
2022-01-25 14:25:13:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:25:13:INFO:Accuracy = [0.9258888332498748, 0.9021031547320981, 0.8838257386079119, 0.8322483725588382, 0.872058087130696, 0.8738107160741112, 0.8652979469203805, 0.8835753630445669, 0.8467701552328493, 0.8337506259389084]
2022-01-25 14:25:13:INFO:Loss = [0.20798263770644612, 0.31078324608192776, 0.4294546093142549, 0.3095384165781056, 0.3658426343002247, 0.3804217580914344, 0.31873382581301707, 0.3487826946610515, 0.3782736563803367, 0.3859587579573965]
2022-01-25 14:25:13:INFO:-------------Training local models-------------
2022-01-25 14:25:57:INFO:-------------Aggregating local models-------------
2022-01-25 14:25:58:INFO:-------------Round number: 30-------------
2022-01-25 14:25:58:INFO:-------------Sending models-------------
2022-01-25 14:25:58:INFO:-------------Evaluating models-------------
2022-01-25 14:25:58:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:25:58:INFO:Accuracy = [0.9258888332498748, 0.9026039058587881, 0.8838257386079119, 0.8329994992488733, 0.872058087130696, 0.8738107160741112, 0.8652979469203805, 0.8835753630445669, 0.8480220330495744, 0.8332498748122183]
2022-01-25 14:25:58:INFO:Loss = [0.2069001634971089, 0.3087981758956575, 0.4291025642592424, 0.30899877505144685, 0.3642488775423492, 0.3801484373887804, 0.3168021596196755, 0.3487753521822825, 0.3762719959083457, 0.38770234105197043]
2022-01-25 14:25:58:INFO:-------------Training local models-------------
2022-01-25 14:26:42:INFO:-------------Aggregating local models-------------
2022-01-25 14:26:43:INFO:-------------Round number: 31-------------
2022-01-25 14:26:43:INFO:-------------Sending models-------------
2022-01-25 14:26:43:INFO:-------------Evaluating models-------------
2022-01-25 14:26:43:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:26:43:INFO:Accuracy = [0.9258888332498748, 0.9028542814221332, 0.8835753630445669, 0.8342513770655984, 0.872308462694041, 0.8738107160741112, 0.8652979469203805, 0.8835753630445669, 0.8482724086129194, 0.8335002503755633]
2022-01-25 14:26:43:INFO:Loss = [0.20584318590999623, 0.3068803153959435, 0.4287763706925635, 0.30845927090915015, 0.3627083555405375, 0.37989441230571347, 0.3148914401743698, 0.34875980573571086, 0.3743508199917311, 0.38930838984073757]
2022-01-25 14:26:43:INFO:-------------Training local models-------------
2022-01-25 14:27:27:INFO:-------------Aggregating local models-------------
2022-01-25 14:27:28:INFO:-------------Round number: 32-------------
2022-01-25 14:27:28:INFO:-------------Sending models-------------
2022-01-25 14:27:28:INFO:-------------Evaluating models-------------
2022-01-25 14:27:28:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:27:28:INFO:Accuracy = [0.9261392088132199, 0.9036054081121683, 0.8835753630445669, 0.8372558838257386, 0.8728092138207311, 0.8738107160741112, 0.8655483224837256, 0.8838257386079119, 0.8487731597396094, 0.8319979969954933]
2022-01-25 14:27:28:INFO:Loss = [0.20483255589050445, 0.30499843749871525, 0.4284528781388013, 0.30791755981817254, 0.36130259164282447, 0.37966201339093303, 0.3129772059782653, 0.3487695657239381, 0.3724996111388717, 0.3908406922071505]
2022-01-25 14:27:28:INFO:-------------Training local models-------------
2022-01-25 14:28:12:INFO:-------------Aggregating local models-------------
2022-01-25 14:28:13:INFO:-------------Round number: 33-------------
2022-01-25 14:28:13:INFO:-------------Sending models-------------
2022-01-25 14:28:13:INFO:-------------Evaluating models-------------
2022-01-25 14:28:13:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:28:13:INFO:Accuracy = [0.9263895843765648, 0.9041061592388583, 0.8835753630445669, 0.8385077616424637, 0.8728092138207311, 0.8738107160741112, 0.8655483224837256, 0.8840761141712569, 0.8495242864296445, 0.8322483725588382]
2022-01-25 14:28:13:INFO:Loss = [0.20383311476998925, 0.30316994586827384, 0.42813439957930904, 0.30737653108205015, 0.3599079470063313, 0.3794429394077, 0.31107423632005443, 0.3487503059461627, 0.37072752322476965, 0.392227641062561]
2022-01-25 14:28:13:INFO:-------------Training local models-------------
2022-01-25 14:28:56:INFO:-------------Aggregating local models-------------
2022-01-25 14:28:57:INFO:-------------Round number: 34-------------
2022-01-25 14:28:57:INFO:-------------Sending models-------------
2022-01-25 14:28:57:INFO:-------------Evaluating models-------------
2022-01-25 14:28:58:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:28:58:INFO:Accuracy = [0.9266399599399099, 0.9046069103655483, 0.8838257386079119, 0.8410115172759138, 0.8728092138207311, 0.8738107160741112, 0.8657986980470707, 0.8838257386079119, 0.8510265398097145, 0.8319979969954933]
2022-01-25 14:28:58:INFO:Loss = [0.20287983523920244, 0.3013886553781286, 0.4278229038419018, 0.3068264493851423, 0.358643289906524, 0.3792330705640958, 0.3091836474806084, 0.3487565763677171, 0.36903147174184886, 0.3935559996339979]
2022-01-25 14:28:58:INFO:-------------Training local models-------------
2022-01-25 14:29:41:INFO:-------------Aggregating local models-------------
2022-01-25 14:29:42:INFO:-------------Round number: 35-------------
2022-01-25 14:29:42:INFO:-------------Sending models-------------
2022-01-25 14:29:42:INFO:-------------Evaluating models-------------
2022-01-25 14:29:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:29:42:INFO:Accuracy = [0.9266399599399099, 0.9051076614922383, 0.8840761141712569, 0.8417626439659489, 0.8728092138207311, 0.8738107160741112, 0.8662994491737607, 0.8840761141712569, 0.8517776664997496, 0.8317476214321482]
2022-01-25 14:29:42:INFO:Loss = [0.20193743420737464, 0.29966052181131037, 0.4275140354843996, 0.30627737210727257, 0.3574071716436238, 0.3790372553235783, 0.30731805766486475, 0.34873831827059654, 0.36740709209845446, 0.3947572202331834]
2022-01-25 14:29:42:INFO:-------------Training local models-------------
2022-01-25 14:30:26:INFO:-------------Aggregating local models-------------
2022-01-25 14:30:27:INFO:-------------Round number: 36-------------
2022-01-25 14:30:27:INFO:-------------Sending models-------------
2022-01-25 14:30:27:INFO:-------------Evaluating models-------------
2022-01-25 14:30:27:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:30:27:INFO:Accuracy = [0.9266399599399099, 0.9058587881822734, 0.8840761141712569, 0.842764146219329, 0.8728092138207311, 0.8738107160741112, 0.8662994491737607, 0.8843264897346019, 0.8527791687531296, 0.8307461191787682]
2022-01-25 14:30:27:INFO:Loss = [0.20101975092333418, 0.2979679500113608, 0.42719944293177503, 0.3057275343408624, 0.3562293258687361, 0.3788454567495422, 0.3054543718115371, 0.34871067517715926, 0.3658491927743833, 0.3958632632480602]
2022-01-25 14:30:27:INFO:-------------Training local models-------------
2022-01-25 14:31:11:INFO:-------------Aggregating local models-------------
2022-01-25 14:31:12:INFO:-------------Round number: 37-------------
2022-01-25 14:31:12:INFO:-------------Sending models-------------
2022-01-25 14:31:12:INFO:-------------Evaluating models-------------
2022-01-25 14:31:12:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:31:12:INFO:Accuracy = [0.9268903355032548, 0.9063595393089634, 0.8845768652979469, 0.8440160240360541, 0.8728092138207311, 0.8738107160741112, 0.8662994491737607, 0.8848272408612919, 0.8532799198798198, 0.8299949924887331]
2022-01-25 14:31:12:INFO:Loss = [0.2001231107320408, 0.29632641321657793, 0.42688890604458984, 0.3051751137547998, 0.35511812893140376, 0.37865993037491547, 0.3036195901277616, 0.34867710034957816, 0.3643580787236808, 0.3968801095288454]
2022-01-25 14:31:12:INFO:-------------Training local models-------------
2022-01-25 14:31:56:INFO:-------------Aggregating local models-------------
2022-01-25 14:31:57:INFO:-------------Round number: 38-------------
2022-01-25 14:31:57:INFO:-------------Sending models-------------
2022-01-25 14:31:57:INFO:-------------Evaluating models-------------
2022-01-25 14:31:57:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:31:57:INFO:Accuracy = [0.9271407110665999, 0.9068602904356535, 0.8845768652979469, 0.8462694041061593, 0.8728092138207311, 0.8738107160741112, 0.8670505758637957, 0.8848272408612919, 0.8537806710065098, 0.829744616925388]
2022-01-25 14:31:57:INFO:Loss = [0.19925434529319877, 0.2947406323189308, 0.4265828503612438, 0.3046173798581996, 0.35406335330955685, 0.37847893236953023, 0.30180909256052674, 0.3486351211184895, 0.36293298182031714, 0.39782271877032155]
2022-01-25 14:31:57:INFO:-------------Training local models-------------
2022-01-25 14:32:40:INFO:-------------Aggregating local models-------------
2022-01-25 14:32:41:INFO:-------------Round number: 39-------------
2022-01-25 14:32:41:INFO:-------------Sending models-------------
2022-01-25 14:32:41:INFO:-------------Evaluating models-------------
2022-01-25 14:32:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:32:42:INFO:Accuracy = [0.9271407110665999, 0.9071106659989985, 0.8848272408612919, 0.8467701552328493, 0.8730595893840761, 0.8738107160741112, 0.8670505758637957, 0.885327991987982, 0.8545317976965449, 0.8299949924887331]
2022-01-25 14:32:42:INFO:Loss = [0.19840398500466525, 0.293180368739873, 0.42627005948548463, 0.3040638289175453, 0.3530646962175384, 0.3783023774995327, 0.30001716869526474, 0.34858964839018064, 0.3615654005277781, 0.3986941982857215]
2022-01-25 14:32:42:INFO:-------------Training local models-------------
2022-01-25 14:33:25:INFO:-------------Aggregating local models-------------
