2022-01-26 22:53:03:INFO:-------------Round number: 0-------------
2022-01-26 22:53:03:INFO:-------------Sending models-------------
2022-01-26 22:53:04:INFO:-------------Evaluating models-------------
2022-01-26 22:53:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:53:05:INFO:Accuracy = [0.8999800093289798, 0.10001999067102019, 0.09988671953088558, 0.09995335510095289, 0.87552475511428, 0.883254481242087, 0.1000866262410875, 0.1000866262410875, 0.8999800093289798, 0.9001132804691144]
2022-01-26 22:53:05:INFO:Loss = [0.6656848083467369, 0.7252451019759911, 0.7189095253160207, 0.7331641170847795, 0.6908848814955716, 0.6900490836751781, 0.739565224231914, 0.7032630279418939, 0.684827916438824, 0.6384259511606757]
2022-01-26 22:53:05:INFO:-------------Training local models-------------
2022-01-26 23:05:30:INFO:-------------Aggregating local models-------------
2022-01-26 23:05:34:INFO:-------------Round number: 1-------------
2022-01-26 23:05:34:INFO:-------------Sending models-------------
2022-01-26 23:05:35:INFO:-------------Evaluating models-------------
2022-01-26 23:05:36:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 23:05:36:INFO:Accuracy = [0.9105084293996135, 0.8999800093289798, 0.9001132804691144, 0.9074431931765177, 0.8999133737589126, 0.9000466448990471, 0.8999133737589126, 0.8999133737589126, 0.8999800093289798, 0.9001132804691144]
2022-01-26 23:05:36:INFO:Loss = [0.2540388868706743, 0.302942983912751, 0.26859436259160213, 0.26839745046594854, 0.27713114667383226, 0.28301761617363114, 0.2862874814206472, 0.2725109583787268, 0.2729691493188343, 0.2558091413135374]
2022-01-26 23:05:36:INFO:-------------Training local models-------------
2022-01-26 23:18:05:INFO:-------------Aggregating local models-------------
2022-01-26 23:18:09:INFO:-------------Round number: 2-------------
2022-01-26 23:18:09:INFO:-------------Sending models-------------
2022-01-26 23:18:09:INFO:-------------Evaluating models-------------
2022-01-26 23:18:10:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 23:18:10:INFO:Accuracy = [0.9105084293996135, 0.8999800093289798, 0.9001132804691144, 0.9074431931765177, 0.8999133737589126, 0.9000466448990471, 0.8999133737589126, 0.8999133737589126, 0.8999800093289798, 0.9003798227493837]
2022-01-26 23:18:10:INFO:Loss = [0.24762529673225725, 0.2903984762290573, 0.26832067021522815, 0.26300022695736097, 0.2758500371448546, 0.2767464870924221, 0.27655705933959857, 0.263179937276912, 0.264303453052175, 0.23804124505215346]
2022-01-26 23:18:10:INFO:-------------Training local models-------------
2022-01-26 23:30:37:INFO:-------------Aggregating local models-------------
2022-01-26 23:30:41:INFO:-------------Round number: 3-------------
2022-01-26 23:30:41:INFO:-------------Sending models-------------
2022-01-26 23:30:41:INFO:-------------Evaluating models-------------
2022-01-26 23:30:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 23:30:42:INFO:Accuracy = [0.9180382488172186, 0.8999800093289798, 0.9001132804691144, 0.9074431931765177, 0.8999133737589126, 0.9000466448990471, 0.9001132804691144, 0.9011128140201239, 0.9032451522622776, 0.9118411408009596]
2022-01-26 23:30:42:INFO:Loss = [0.2428265889495772, 0.2868887998373212, 0.26608139149146603, 0.26165452169653713, 0.2736575000811977, 0.2751232610845769, 0.26816439556190386, 0.2599215978621134, 0.25467068266320636, 0.2240657635802851]
2022-01-26 23:30:42:INFO:-------------Training local models-------------
2022-01-26 23:43:08:INFO:-------------Aggregating local models-------------
2022-01-26 23:43:12:INFO:-------------Round number: 4-------------
2022-01-26 23:43:12:INFO:-------------Sending models-------------
2022-01-26 23:43:12:INFO:-------------Evaluating models-------------
2022-01-26 23:43:13:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 23:43:13:INFO:Accuracy = [0.9176384353968148, 0.8999800093289798, 0.9001132804691144, 0.9106417005397481, 0.8999133737589126, 0.9000466448990471, 0.9041780502432198, 0.9051775837942294, 0.8987139334977011, 0.9174385286866129]
2022-01-26 23:43:13:INFO:Loss = [0.2365276705494265, 0.2813120148881119, 0.2624928504113162, 0.259111172258417, 0.27047534042363275, 0.27329691704564946, 0.2599466273076686, 0.25642013529697505, 0.24563833059643875, 0.21057615041323943]
2022-01-26 23:43:13:INFO:-------------Training local models-------------
2022-01-26 23:55:31:INFO:-------------Aggregating local models-------------
2022-01-26 23:55:35:INFO:-------------Round number: 5-------------
2022-01-26 23:55:35:INFO:-------------Sending models-------------
2022-01-26 23:55:35:INFO:-------------Evaluating models-------------
2022-01-26 23:55:36:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 23:55:36:INFO:Accuracy = [0.9190377823682282, 0.9053108549343639, 0.9023122542813353, 0.9171053508362764, 0.8999133737589126, 0.9001132804691144, 0.9047111348037582, 0.905977210635037, 0.9009795428799894, 0.9215699340307857]
2022-01-26 23:55:36:INFO:Loss = [0.22955378398032114, 0.26990726597554016, 0.25830039656990084, 0.25391999965675977, 0.2663745280540648, 0.27061954999314386, 0.2535147394379511, 0.25221917823562984, 0.23989218149359698, 0.2015247108496563]
2022-01-26 23:55:36:INFO:-------------Training local models-------------
2022-01-27 00:07:53:INFO:-------------Aggregating local models-------------
2022-01-27 00:07:57:INFO:-------------Round number: 6-------------
2022-01-27 00:07:57:INFO:-------------Sending models-------------
2022-01-27 00:07:57:INFO:-------------Evaluating models-------------
2022-01-27 00:07:58:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:07:58:INFO:Accuracy = [0.9194375957886319, 0.9089091757179982, 0.9027120677017392, 0.9187046045178916, 0.9014459918704605, 0.9021789831412008, 0.9055773972146332, 0.90664356633571, 0.9041780502432198, 0.9234357299926701]
2022-01-27 00:07:58:INFO:Loss = [0.2234976161595283, 0.25521659984389816, 0.25427094215039764, 0.24750211547771975, 0.26220543531101104, 0.2669029744050167, 0.24686828561481172, 0.24747282570343906, 0.231726047504978, 0.19442431071668353]
2022-01-27 00:07:58:INFO:-------------Training local models-------------
2022-01-27 00:20:15:INFO:-------------Aggregating local models-------------
2022-01-27 00:20:19:INFO:-------------Round number: 7-------------
2022-01-27 00:20:19:INFO:-------------Sending models-------------
2022-01-27 00:20:19:INFO:-------------Evaluating models-------------
2022-01-27 00:20:20:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:20:20:INFO:Accuracy = [0.9206370360498434, 0.9106417005397481, 0.9027787032718065, 0.9195708669287666, 0.9037116012527487, 0.9033784234024123, 0.9082428200173253, 0.9077763710268542, 0.9090424468581328, 0.9260345172252948]
2022-01-27 00:20:20:INFO:Loss = [0.21844125324773953, 0.2437514981020724, 0.2504367945216705, 0.2426199598719824, 0.25876582480724764, 0.2622973095716742, 0.24036805694083144, 0.24251969188771433, 0.22201004343218367, 0.1875498338515197]
2022-01-27 00:20:20:INFO:-------------Training local models-------------
2022-01-27 00:32:38:INFO:-------------Aggregating local models-------------
2022-01-27 00:32:41:INFO:-------------Round number: 8-------------
2022-01-27 00:32:41:INFO:-------------Sending models-------------
2022-01-27 00:32:42:INFO:-------------Evaluating models-------------
2022-01-27 00:32:43:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:32:43:INFO:Accuracy = [0.9213033917505165, 0.913906843473046, 0.9048444059438928, 0.9207036716199107, 0.9043779569534217, 0.9053774905044313, 0.912840674351969, 0.9093756247084693, 0.9141067501832478, 0.9270340507763044]
2022-01-27 00:32:43:INFO:Loss = [0.21388200100566174, 0.23533544758426728, 0.24674336917568307, 0.23925608561036707, 0.25618982199918816, 0.2568249634168623, 0.23490778958988298, 0.2373260215065749, 0.21325747331183692, 0.18074087172888867]
2022-01-27 00:32:43:INFO:-------------Training local models-------------
2022-01-27 00:45:00:INFO:-------------Aggregating local models-------------
2022-01-27 00:45:04:INFO:-------------Round number: 9-------------
2022-01-27 00:45:04:INFO:-------------Sending models-------------
2022-01-27 00:45:04:INFO:-------------Evaluating models-------------
2022-01-27 00:45:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:45:05:INFO:Accuracy = [0.9233024588525355, 0.9160391817151996, 0.9055107616445659, 0.9212367561804491, 0.9045112280935563, 0.9071766508962484, 0.9164389951356033, 0.9115079629506231, 0.9165056307056707, 0.9288998467381888]
2022-01-27 00:45:05:INFO:Loss = [0.20969630772399458, 0.22839353237560023, 0.24329605618256067, 0.23697120277183142, 0.2544147329665723, 0.25148759483983263, 0.23020135076779719, 0.23215065375338603, 0.2063655308437073, 0.17470468895373092]
2022-01-27 00:45:05:INFO:-------------Training local models-------------
2022-01-27 00:57:22:INFO:-------------Aggregating local models-------------
2022-01-27 00:57:26:INFO:-------------Round number: 10-------------
2022-01-27 00:57:26:INFO:-------------Sending models-------------
2022-01-27 00:57:26:INFO:-------------Evaluating models-------------
2022-01-27 00:57:27:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:57:27:INFO:Accuracy = [0.9249017125341508, 0.9178383421070168, 0.9060438462051043, 0.9212367561804491, 0.9049776770840274, 0.908842540147931, 0.9191710535083628, 0.9144399280335843, 0.9174385286866129, 0.9301659225694676]
2022-01-27 00:57:27:INFO:Loss = [0.206051781513415, 0.22194276332193424, 0.24016914142097998, 0.23512276191694587, 0.2531687095792329, 0.2468414029975699, 0.2267554909761139, 0.22706024833666483, 0.2009816542383695, 0.16961153218303412]
2022-01-27 00:57:27:INFO:-------------Training local models-------------
2022-01-27 01:09:44:INFO:-------------Aggregating local models-------------
2022-01-27 01:09:48:INFO:-------------Round number: 11-------------
2022-01-27 01:09:48:INFO:-------------Sending models-------------
2022-01-27 01:09:48:INFO:-------------Evaluating models-------------
2022-01-27 01:09:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:09:49:INFO:Accuracy = [0.9253681615246219, 0.9194375957886319, 0.9069101086159792, 0.9214366628906511, 0.9054441260744985, 0.9102418871193443, 0.9210368494702472, 0.916572266275738, 0.9185046978076897, 0.9314319984007463]
2022-01-27 01:09:49:INFO:Loss = [0.20309457136513573, 0.2156372928318323, 0.23748841898222528, 0.23368235330197354, 0.2521925001428948, 0.24292001002936406, 0.22386039092706345, 0.22239191058922822, 0.19625755534103018, 0.16570270155110792]
2022-01-27 01:09:49:INFO:-------------Training local models-------------
2022-01-27 01:22:06:INFO:-------------Aggregating local models-------------
2022-01-27 01:22:10:INFO:-------------Round number: 12-------------
2022-01-27 01:22:10:INFO:-------------Sending models-------------
2022-01-27 01:22:10:INFO:-------------Evaluating models-------------
2022-01-27 01:22:11:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:22:11:INFO:Accuracy = [0.9256347038048911, 0.9210368494702472, 0.9077763710268542, 0.9215032984607183, 0.9052442193642967, 0.9106417005397481, 0.9228360098620644, 0.9181048843872859, 0.9198374092090358, 0.9336976077830346]
2022-01-27 01:22:11:INFO:Loss = [0.2007271091385404, 0.20944136340748745, 0.23519730765181124, 0.2324951469355578, 0.25138046763819466, 0.23975486243546443, 0.22197702839774977, 0.21819145841304285, 0.19197512735842728, 0.16292900999929033]
2022-01-27 01:22:11:INFO:-------------Training local models-------------
2022-01-27 01:34:28:INFO:-------------Aggregating local models-------------
2022-01-27 01:34:32:INFO:-------------Round number: 13-------------
2022-01-27 01:34:32:INFO:-------------Sending models-------------
2022-01-27 01:34:32:INFO:-------------Evaluating models-------------
2022-01-27 01:34:33:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:34:33:INFO:Accuracy = [0.9264343306456987, 0.9233690944226027, 0.9087092690077964, 0.9217032051709202, 0.9053774905044313, 0.9122409542213633, 0.9237022722729393, 0.9191710535083628, 0.9217032051709202, 0.934230692343573]
2022-01-27 01:34:33:INFO:Loss = [0.19876495801583116, 0.20334708494002496, 0.2331563025900882, 0.23146100984561718, 0.2505057079025805, 0.2370252634493652, 0.2200712356173997, 0.21425140214026592, 0.1880849237969952, 0.16009092209777911]
2022-01-27 01:34:33:INFO:-------------Training local models-------------
2022-01-27 01:46:51:INFO:-------------Aggregating local models-------------
2022-01-27 01:46:55:INFO:-------------Round number: 14-------------
2022-01-27 01:46:55:INFO:-------------Sending models-------------
2022-01-27 01:46:55:INFO:-------------Evaluating models-------------
2022-01-27 01:46:56:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:46:56:INFO:Accuracy = [0.9266342373559006, 0.924301992403545, 0.9096421669887386, 0.9219031118811222, 0.9051775837942294, 0.9119077763710268, 0.9250349836742854, 0.9203704937695742, 0.9233690944226027, 0.9358299460251882]
2022-01-27 01:46:56:INFO:Loss = [0.19713102262153126, 0.19723269546347014, 0.23128561371805953, 0.2305093571295953, 0.2496469123912684, 0.23452870886018976, 0.21812513006868825, 0.21034903040658076, 0.18439288117319766, 0.15684736069613406]
2022-01-27 01:46:56:INFO:-------------Training local models-------------
2022-01-27 01:59:13:INFO:-------------Aggregating local models-------------
2022-01-27 01:59:17:INFO:-------------Round number: 15-------------
2022-01-27 01:59:17:INFO:-------------Sending models-------------
2022-01-27 01:59:17:INFO:-------------Evaluating models-------------
2022-01-27 01:59:18:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:59:18:INFO:Accuracy = [0.9273005930565736, 0.9257679749450256, 0.9109748783900846, 0.9217698407409876, 0.9054441260744985, 0.9129739454921036, 0.9262344239354968, 0.9216365696008529, 0.9243686279736123, 0.9373625641367362]
2022-01-27 01:59:18:INFO:Loss = [0.1955546000611826, 0.1910354736260263, 0.22957967887458472, 0.22957785591580426, 0.2487307890047942, 0.2321699920123499, 0.21651335090595888, 0.20667461929924902, 0.18097584551059273, 0.15397544457216636]
2022-01-27 01:59:18:INFO:-------------Training local models-------------
2022-01-27 02:11:35:INFO:-------------Aggregating local models-------------
2022-01-27 02:11:39:INFO:-------------Round number: 16-------------
2022-01-27 02:11:39:INFO:-------------Sending models-------------
2022-01-27 02:11:39:INFO:-------------Evaluating models-------------
2022-01-27 02:11:40:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:11:40:INFO:Accuracy = [0.927833677617112, 0.9283001266075831, 0.9112414206703539, 0.9219031118811222, 0.9069101086159792, 0.9139734790431132, 0.926967415206237, 0.9234357299926701, 0.9256347038048911, 0.937962284267342]
2022-01-27 02:11:40:INFO:Loss = [0.1940954234070012, 0.1850635055949059, 0.2278751960835848, 0.2284927672964152, 0.24765016676209797, 0.2297993399639224, 0.21513895609565567, 0.20310677277720193, 0.17788479743513239, 0.1516260291234644]
2022-01-27 02:11:40:INFO:-------------Training local models-------------
2022-01-27 02:23:30:INFO:-------------Aggregating local models-------------
2022-01-27 02:23:34:INFO:-------------Round number: 17-------------
2022-01-27 02:23:34:INFO:-------------Sending models-------------
2022-01-27 02:23:34:INFO:-------------Evaluating models-------------
2022-01-27 02:23:35:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:23:35:INFO:Accuracy = [0.9284333977477177, 0.9314319984007463, 0.9116412340907577, 0.9215699340307857, 0.9081095488771906, 0.9153061904444593, 0.9273672286266409, 0.9249017125341508, 0.9273672286266409, 0.9388285466782168]
2022-01-27 02:23:35:INFO:Loss = [0.19269563522153366, 0.17963038282144345, 0.2262752151473321, 0.2273772784456697, 0.24661385500285396, 0.2276708213291591, 0.21376353832813327, 0.19982160088868178, 0.17526048397026167, 0.14978280968140512]
2022-01-27 02:23:35:INFO:-------------Training local models-------------
2022-01-27 02:35:19:INFO:-------------Aggregating local models-------------
2022-01-27 02:35:23:INFO:-------------Round number: 18-------------
2022-01-27 02:35:23:INFO:-------------Sending models-------------
2022-01-27 02:35:23:INFO:-------------Evaluating models-------------
2022-01-27 02:35:24:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:35:24:INFO:Accuracy = [0.929832744719131, 0.9327647098020924, 0.9120410475111614, 0.9215699340307857, 0.9077763710268542, 0.9161724528553342, 0.9283001266075831, 0.9260345172252948, 0.9276337709069101, 0.9398280802292264]
2022-01-27 02:35:24:INFO:Loss = [0.19132618378643537, 0.17496119099939425, 0.22475660187679117, 0.2262274027223224, 0.24552914779540194, 0.2257145212727026, 0.21259119813305957, 0.19681546608234532, 0.1730938042675508, 0.14803779971109754]
2022-01-27 02:35:24:INFO:-------------Training local models-------------
2022-01-27 02:47:08:INFO:-------------Aggregating local models-------------
2022-01-27 02:47:12:INFO:-------------Round number: 19-------------
2022-01-27 02:47:12:INFO:-------------Sending models-------------
2022-01-27 02:47:12:INFO:-------------Evaluating models-------------
2022-01-27 02:47:13:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:47:13:INFO:Accuracy = [0.9305657359898714, 0.9345638701939095, 0.9123742253614979, 0.9218364763110548, 0.9076430998867195, 0.9169720796961418, 0.9286333044579196, 0.9265676017858333, 0.928699940027987, 0.9403611647897647]
2022-01-27 02:47:13:INFO:Loss = [0.19023360021498262, 0.1708213759075716, 0.2233172164362453, 0.2251637708588103, 0.24449051167780425, 0.2240660730442796, 0.21171336837260357, 0.19401749999516463, 0.17094322580570342, 0.14578755287862238]
2022-01-27 02:47:13:INFO:-------------Training local models-------------
2022-01-27 02:58:58:INFO:-------------Aggregating local models-------------
2022-01-27 02:59:02:INFO:-------------Round number: 20-------------
2022-01-27 02:59:02:INFO:-------------Sending models-------------
2022-01-27 02:59:02:INFO:-------------Evaluating models-------------
2022-01-27 02:59:03:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:59:03:INFO:Accuracy = [0.931365362830679, 0.9355634037449191, 0.9127740387819018, 0.922103018591324, 0.9076430998867195, 0.9177050709668821, 0.9295662024388619, 0.9268341440661025, 0.929166389018458, 0.9410275204904378]
2022-01-27 02:59:03:INFO:Loss = [0.189152576230869, 0.16732632720666338, 0.22203120663565987, 0.22412087916290252, 0.24331859823748517, 0.22262229310240522, 0.210684177440727, 0.19144599687641037, 0.1689149310303453, 0.14416421842811683]
2022-01-27 02:59:03:INFO:-------------Training local models-------------
2022-01-27 03:10:47:INFO:-------------Aggregating local models-------------
2022-01-27 03:10:51:INFO:-------------Round number: 21-------------
2022-01-27 03:10:51:INFO:-------------Sending models-------------
2022-01-27 03:10:51:INFO:-------------Evaluating models-------------
2022-01-27 03:10:52:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 03:10:52:INFO:Accuracy = [0.9318984473912174, 0.9365629372959285, 0.9127074032118345, 0.9223029253015259, 0.9083094555873925, 0.9186379689478243, 0.9297661091490638, 0.9284333977477177, 0.929832744719131, 0.9422935963217165]
2022-01-27 03:10:52:INFO:Loss = [0.18803992797529057, 0.16434652421444987, 0.22078783698965831, 0.2231038382316983, 0.24217486846441133, 0.22149235207247148, 0.20987040004959517, 0.18915876254774225, 0.16724055751783926, 0.14236347294067614]
2022-01-27 03:10:52:INFO:-------------Training local models-------------
2022-01-27 03:22:37:INFO:-------------Aggregating local models-------------
2022-01-27 03:22:41:INFO:-------------Round number: 22-------------
2022-01-27 03:22:41:INFO:-------------Sending models-------------
2022-01-27 03:22:41:INFO:-------------Evaluating models-------------
2022-01-27 03:22:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 03:22:42:INFO:Accuracy = [0.9329646165122942, 0.937096021856467, 0.9131072166322383, 0.9220363830212568, 0.9087092690077964, 0.9193709602185647, 0.9302325581395349, 0.9292330245885253, 0.9303658292796695, 0.9430932231625242]
2022-01-27 03:22:42:INFO:Loss = [0.18696533108754784, 0.16182941147410798, 0.21969507302622962, 0.22215321754198045, 0.24098426368994338, 0.2205330671695021, 0.2091022364801662, 0.18707389774222521, 0.1659116356343531, 0.14095640770563736]
2022-01-27 03:22:42:INFO:-------------Training local models-------------
2022-01-27 03:34:27:INFO:-------------Aggregating local models-------------
2022-01-27 03:34:31:INFO:-------------Round number: 23-------------
2022-01-27 03:34:31:INFO:-------------Sending models-------------
2022-01-27 03:34:31:INFO:-------------Evaluating models-------------
2022-01-27 03:34:32:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 03:34:32:INFO:Accuracy = [0.9336976077830346, 0.937962284267342, 0.9139734790431132, 0.9223029253015259, 0.9089091757179982, 0.919904044779103, 0.9304324648497367, 0.930898913840208, 0.9312987272606117, 0.943959485573399]
2022-01-27 03:34:32:INFO:Loss = [0.185998861456083, 0.15968809188657915, 0.21880210469458694, 0.22137496660556538, 0.23987134304544278, 0.21974000107156147, 0.208526901226557, 0.1851575734842231, 0.16486929773242054, 0.13979871080767722]
2022-01-27 03:34:32:INFO:-------------Training local models-------------
2022-01-27 03:46:18:INFO:-------------Aggregating local models-------------
2022-01-27 03:46:22:INFO:-------------Round number: 24-------------
2022-01-27 03:46:22:INFO:-------------Sending models-------------
2022-01-27 03:46:22:INFO:-------------Evaluating models-------------
2022-01-27 03:46:23:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 03:46:23:INFO:Accuracy = [0.9344972346238422, 0.9384287332578131, 0.9139734790431132, 0.9225694675817951, 0.9098420736989405, 0.9203704937695742, 0.930898913840208, 0.9318984473912174, 0.9328313453721596, 0.944159392283601]
2022-01-27 03:46:23:INFO:Loss = [0.18492697351606255, 0.15772474534199424, 0.21803947292395373, 0.22052769723887677, 0.23868259954709786, 0.2189886106334926, 0.2078888559634648, 0.1835585564310929, 0.1641557171980661, 0.1386529252099277]
2022-01-27 03:46:23:INFO:-------------Training local models-------------
2022-01-27 03:58:08:INFO:-------------Aggregating local models-------------
2022-01-27 03:58:12:INFO:-------------Round number: 25-------------
2022-01-27 03:58:12:INFO:-------------Sending models-------------
2022-01-27 03:58:12:INFO:-------------Evaluating models-------------
2022-01-27 03:58:13:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 03:58:13:INFO:Accuracy = [0.9344972346238422, 0.939761444659159, 0.9146398347437862, 0.922969281002199, 0.9097754381288732, 0.9195042313586993, 0.9310988205504098, 0.9327647098020924, 0.9332977943626307, 0.9453588325448125]
2022-01-27 03:58:13:INFO:Loss = [0.1839685710526205, 0.1562001302879533, 0.2173868938790242, 0.21983685995036745, 0.23757619313506467, 0.21827552211503484, 0.2075376049070873, 0.18214329515183672, 0.16387285344760255, 0.13843900099675283]
2022-01-27 03:58:13:INFO:-------------Training local models-------------
2022-01-27 04:09:58:INFO:-------------Aggregating local models-------------
2022-01-27 04:10:02:INFO:-------------Round number: 26-------------
2022-01-27 04:10:02:INFO:-------------Sending models-------------
2022-01-27 04:10:02:INFO:-------------Evaluating models-------------
2022-01-27 04:10:03:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 04:10:03:INFO:Accuracy = [0.9345638701939095, 0.9403611647897647, 0.9151729193043247, 0.9232358232824682, 0.91084160724995, 0.9197707736389685, 0.9316985406810155, 0.9332977943626307, 0.9334977010728327, 0.9457586459652162]
2022-01-27 04:10:03:INFO:Loss = [0.18304680207992602, 0.1549608094949493, 0.216823071669215, 0.21911667366884785, 0.23648744693880253, 0.21769470201377397, 0.20719801068694213, 0.18091814918326618, 0.16383657101293056, 0.13865638587937365]
2022-01-27 04:10:03:INFO:-------------Training local models-------------
2022-01-27 04:21:48:INFO:-------------Aggregating local models-------------
2022-01-27 04:21:52:INFO:-------------Round number: 27-------------
2022-01-27 04:21:52:INFO:-------------Sending models-------------
2022-01-27 04:21:52:INFO:-------------Evaluating models-------------
2022-01-27 04:21:53:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 04:21:53:INFO:Accuracy = [0.9345638701939095, 0.940627707070034, 0.9149063770240554, 0.9234357299926701, 0.9114413273805557, 0.9202372226294396, 0.9317651762510828, 0.9336309722129673, 0.9338975144932364, 0.9459585526754182]
2022-01-27 04:21:53:INFO:Loss = [0.182243828699658, 0.15384927866585116, 0.2164123190582164, 0.21850065732496549, 0.23547405051145046, 0.21713999573578482, 0.20724633585247343, 0.17993717716992513, 0.16409952240349437, 0.13926780134073327]
2022-01-27 04:21:53:INFO:-------------Training local models-------------
2022-01-27 04:33:38:INFO:-------------Aggregating local models-------------
2022-01-27 04:33:41:INFO:-------------Round number: 28-------------
2022-01-27 04:33:41:INFO:-------------Sending models-------------
2022-01-27 04:33:42:INFO:-------------Evaluating models-------------
2022-01-27 04:33:43:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 04:33:43:INFO:Accuracy = [0.9347637769041114, 0.9407609782101686, 0.9155727327247285, 0.9242353568334777, 0.9120410475111614, 0.9205037649097088, 0.9321649896714866, 0.9341640567735057, 0.9339641500633038, 0.9464250016658893]
2022-01-27 04:33:43:INFO:Loss = [0.18165505507059443, 0.15310034420863294, 0.21613769586418155, 0.21783026776169725, 0.23449573105475055, 0.21668457468194505, 0.20723331847627832, 0.17921521715078648, 0.16446063282433557, 0.14045891965806306]
2022-01-27 04:33:43:INFO:-------------Training local models-------------
2022-01-27 04:45:27:INFO:-------------Aggregating local models-------------
2022-01-27 04:45:30:INFO:-------------Round number: 29-------------
2022-01-27 04:45:30:INFO:-------------Sending models-------------
2022-01-27 04:45:30:INFO:-------------Evaluating models-------------
2022-01-27 04:45:31:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 04:45:31:INFO:Accuracy = [0.9359632171653228, 0.9402945292196975, 0.915905910575065, 0.9241687212634104, 0.9121076830812288, 0.9205704004797761, 0.9319650829612848, 0.9343639634837076, 0.9345638701939095, 0.94615845938562]
2022-01-27 04:45:31:INFO:Loss = [0.1814327905623675, 0.15273940492255814, 0.21597001523917878, 0.21731671347927187, 0.23369282209082615, 0.21657451734958613, 0.20780980601974297, 0.17871983293108681, 0.16494656627852972, 0.14180522938491358]
2022-01-27 04:45:31:INFO:-------------Training local models-------------
2022-01-27 04:53:09:INFO:-------------Aggregating local models-------------
