2022-01-26 23:05:29:INFO:-------------Round number: 0-------------
2022-01-26 23:05:29:INFO:-------------Sending models-------------
2022-01-26 23:05:29:INFO:-------------Evaluating models-------------
2022-01-26 23:05:30:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 23:05:30:INFO:Accuracy = [0.9002131628030908, 0.09992006394884093, 0.09992006394884093, 0.09978683719690914, 0.8776978417266187, 0.8828936850519584, 0.10071942446043165, 0.09978683719690914, 0.8999467092992273, 0.8998134825472955]
2022-01-26 23:05:30:INFO:Loss = [0.6654636965667029, 0.7252982787424617, 0.7186282753166185, 0.7331456693051626, 0.6907666532589282, 0.6899063229132042, 0.7393160736738699, 0.7035459735426558, 0.6847668739912702, 0.6382551279078793]
2022-01-26 23:05:30:INFO:-------------Training local models-------------
2022-01-26 23:11:47:INFO:-------------Aggregating local models-------------
2022-01-26 23:11:51:INFO:-------------Round number: 1-------------
2022-01-26 23:11:51:INFO:-------------Sending models-------------
2022-01-26 23:11:52:INFO:-------------Evaluating models-------------
2022-01-26 23:11:53:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 23:11:53:INFO:Accuracy = [0.9407140953903543, 0.8879563016253664, 0.9640287769784173, 0.9527045030642153, 0.9621636024513722, 0.9269917399413802, 0.8550492938982147, 0.9507061017852385, 0.9750865973887557, 0.9122035704769518]
2022-01-26 23:11:53:INFO:Loss = [0.20056571047767985, 0.24889271881316197, 0.12120186145799053, 0.14869845211509614, 0.14086097535861383, 0.18906810226609005, 0.24629749734696152, 0.16547379402021656, 0.140381082065196, 0.23502146135698015]
2022-01-26 23:11:53:INFO:-------------Training local models-------------
2022-01-26 23:18:10:INFO:-------------Aggregating local models-------------
2022-01-26 23:18:14:INFO:-------------Round number: 2-------------
2022-01-26 23:18:14:INFO:-------------Sending models-------------
2022-01-26 23:18:14:INFO:-------------Evaluating models-------------
2022-01-26 23:18:15:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 23:18:15:INFO:Accuracy = [0.9508393285371702, 0.9323208100186517, 0.966027178257394, 0.964828137490008, 0.9706901145750066, 0.9321875832667199, 0.9146016520117239, 0.9577671196376233, 0.9757527311484147, 0.9247268851585398]
2022-01-26 23:18:15:INFO:Loss = [0.1623798530011123, 0.2000340044161202, 0.09618063731500387, 0.1076917861214331, 0.10261744391417867, 0.16655070573499597, 0.19742520719177498, 0.12012706356125695, 0.09729884478691064, 0.18826779003321822]
2022-01-26 23:18:15:INFO:-------------Training local models-------------
2022-01-26 23:24:33:INFO:-------------Aggregating local models-------------
2022-01-26 23:24:37:INFO:-------------Round number: 3-------------
2022-01-26 23:24:37:INFO:-------------Sending models-------------
2022-01-26 23:24:38:INFO:-------------Evaluating models-------------
2022-01-26 23:24:39:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 23:24:39:INFO:Accuracy = [0.9547029043431922, 0.9396482813749001, 0.9662936317612577, 0.9700239808153477, 0.9785504929389821, 0.9327204902744471, 0.9356514788169464, 0.9596322941646682, 0.9758859579003464, 0.9341859845456968]
2022-01-26 23:24:39:INFO:Loss = [0.14484159298728885, 0.1637955359505542, 0.08571195142153058, 0.09102768101027642, 0.0787334719361924, 0.1566178768917355, 0.1630684221317868, 0.09946772022653111, 0.08095139442045525, 0.15878800126087617]
2022-01-26 23:24:39:INFO:-------------Training local models-------------
2022-01-26 23:30:56:INFO:-------------Aggregating local models-------------
2022-01-26 23:31:00:INFO:-------------Round number: 4-------------
2022-01-26 23:31:00:INFO:-------------Sending models-------------
2022-01-26 23:31:01:INFO:-------------Evaluating models-------------
2022-01-26 23:31:01:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 23:31:01:INFO:Accuracy = [0.9544364508393285, 0.9477751132427391, 0.967359445776712, 0.9728217426059153, 0.9822808419930722, 0.9339195310418332, 0.9469757527311484, 0.9782840394351185, 0.9758859579003464, 0.9548361310951239]
2022-01-26 23:31:01:INFO:Loss = [0.13295342627541892, 0.14258899898831592, 0.08014920353747164, 0.08291925365132134, 0.06488729135750052, 0.1502200644096653, 0.14269341877553077, 0.08199742748334127, 0.07233400664472125, 0.13550965952025448]
2022-01-26 23:31:01:INFO:-------------Training local models-------------
2022-01-26 23:37:20:INFO:-------------Aggregating local models-------------
2022-01-26 23:37:24:INFO:-------------Round number: 5-------------
2022-01-26 23:37:24:INFO:-------------Sending models-------------
2022-01-26 23:37:25:INFO:-------------Evaluating models-------------
2022-01-26 23:37:25:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 23:37:25:INFO:Accuracy = [0.9547029043431922, 0.9507061017852385, 0.9676258992805755, 0.9732214228617106, 0.9830802025046629, 0.9347188915534239, 0.9521715960564882, 0.9825472954969358, 0.9758859579003464, 0.9600319744204636]
2022-01-26 23:37:25:INFO:Loss = [0.12324112902466523, 0.13111452917188277, 0.0755960516565695, 0.07802775556453721, 0.057661994389204226, 0.1455878678440735, 0.13088759887554574, 0.06757011302873732, 0.06636017473557802, 0.11751268618784375]
2022-01-26 23:37:25:INFO:-------------Training local models-------------
2022-01-26 23:43:43:INFO:-------------Aggregating local models-------------
2022-01-26 23:43:47:INFO:-------------Round number: 6-------------
2022-01-26 23:43:47:INFO:-------------Sending models-------------
2022-01-26 23:43:47:INFO:-------------Evaluating models-------------
2022-01-26 23:43:48:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 23:43:48:INFO:Accuracy = [0.9555022648547828, 0.9528377298161471, 0.969890754063416, 0.973621103117506, 0.9838795630162537, 0.9353850253130829, 0.955369038102851, 0.9830802025046629, 0.9784172661870504, 0.9625632827071676]
2022-01-26 23:43:48:INFO:Loss = [0.1156920119183344, 0.12437894397383953, 0.0712853390364729, 0.0747092515774412, 0.05283902063553319, 0.14177595491689124, 0.12427698466558304, 0.05840685789798297, 0.06147153644102255, 0.10554979103413108]
2022-01-26 23:43:48:INFO:-------------Training local models-------------
2022-01-26 23:50:07:INFO:-------------Aggregating local models-------------
2022-01-26 23:50:11:INFO:-------------Round number: 7-------------
2022-01-26 23:50:11:INFO:-------------Sending models-------------
2022-01-26 23:50:11:INFO:-------------Evaluating models-------------
2022-01-26 23:50:12:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 23:50:12:INFO:Accuracy = [0.9590993871569411, 0.9540367705835332, 0.9721556088462563, 0.973621103117506, 0.9848121502797762, 0.93591793232081, 0.95603517186251, 0.9858779642952304, 0.9816147082334132, 0.966027178257394]
2022-01-26 23:50:12:INFO:Loss = [0.11052478252099203, 0.11942061167073545, 0.06757152271077574, 0.07218354920181334, 0.04932038571805892, 0.1385922992429702, 0.1193365594608365, 0.05184929176097953, 0.05721537778798751, 0.09644788884103243]
2022-01-26 23:50:12:INFO:-------------Training local models-------------
2022-01-26 23:56:29:INFO:-------------Aggregating local models-------------
2022-01-26 23:56:33:INFO:-------------Round number: 8-------------
2022-01-26 23:56:33:INFO:-------------Sending models-------------
2022-01-26 23:56:34:INFO:-------------Evaluating models-------------
2022-01-26 23:56:34:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 23:56:34:INFO:Accuracy = [0.9594990674127365, 0.9548361310951239, 0.9737543298694378, 0.973621103117506, 0.9849453770317079, 0.9361843858246736, 0.9564348521183054, 0.9860111910471623, 0.981215027977618, 0.9669597655209166]
2022-01-26 23:56:34:INFO:Loss = [0.10716919078740993, 0.11573049431662265, 0.0646458560962608, 0.07001443621656972, 0.04680616340751235, 0.13572613530294328, 0.11547948039801136, 0.04775880651814557, 0.05401293882508335, 0.09021059994170945]
2022-01-26 23:56:34:INFO:-------------Training local models-------------
2022-01-27 00:02:52:INFO:-------------Aggregating local models-------------
2022-01-27 00:02:56:INFO:-------------Round number: 9-------------
2022-01-27 00:02:56:INFO:-------------Sending models-------------
2022-01-27 00:02:56:INFO:-------------Evaluating models-------------
2022-01-27 00:02:57:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:02:57:INFO:Accuracy = [0.9600319744204636, 0.9555022648547828, 0.9742872368771649, 0.973621103117506, 0.9852118305355716, 0.9371169730881961, 0.9573674393818279, 0.9865440980548894, 0.9817479349853451, 0.9676258992805755]
2022-01-27 00:02:57:INFO:Loss = [0.10465425857272956, 0.11268144367705862, 0.062258193846417655, 0.06800127275049109, 0.04494050461061113, 0.13306775121050163, 0.11217168229284664, 0.045232396384894166, 0.05176061551316798, 0.08580196936314591]
2022-01-27 00:02:57:INFO:-------------Training local models-------------
2022-01-27 00:09:10:INFO:-------------Aggregating local models-------------
2022-01-27 00:09:14:INFO:-------------Round number: 10-------------
2022-01-27 00:09:14:INFO:-------------Sending models-------------
2022-01-27 00:09:14:INFO:-------------Evaluating models-------------
2022-01-27 00:09:15:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:09:15:INFO:Accuracy = [0.9601652011723955, 0.955369038102851, 0.9744204636290967, 0.973621103117506, 0.9856115107913669, 0.9376498800959233, 0.9584332533972821, 0.9872102318145484, 0.9826805222488676, 0.9682920330402345]
2022-01-27 00:09:15:INFO:Loss = [0.10250235482563934, 0.10996183706480828, 0.060261747984514114, 0.0660019429974664, 0.04352997476124138, 0.13047024893433495, 0.10909019810070934, 0.04345550078501017, 0.05009055342591974, 0.08208154085251655]
2022-01-27 00:09:15:INFO:-------------Training local models-------------
2022-01-27 00:15:29:INFO:-------------Aggregating local models-------------
2022-01-27 00:15:33:INFO:-------------Round number: 11-------------
2022-01-27 00:15:33:INFO:-------------Sending models-------------
2022-01-27 00:15:33:INFO:-------------Evaluating models-------------
2022-01-27 00:15:34:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:15:34:INFO:Accuracy = [0.9609645616839861, 0.9571009858779643, 0.9746869171329603, 0.973621103117506, 0.9853450572875033, 0.9388489208633094, 0.9592326139088729, 0.9873434585664802, 0.9825472954969358, 0.9694910738076206]
2022-01-27 00:15:34:INFO:Loss = [0.10074625050672792, 0.10767199173863742, 0.05866257541015117, 0.06390011502048493, 0.042504312097224814, 0.1278189389775082, 0.10662519435905198, 0.04222884784752876, 0.04892846440606346, 0.0787131584523527]
2022-01-27 00:15:34:INFO:-------------Training local models-------------
2022-01-27 00:21:46:INFO:-------------Aggregating local models-------------
2022-01-27 00:21:50:INFO:-------------Round number: 12-------------
2022-01-27 00:21:50:INFO:-------------Sending models-------------
2022-01-27 00:21:51:INFO:-------------Evaluating models-------------
2022-01-27 00:21:51:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:21:51:INFO:Accuracy = [0.9612310151878497, 0.957900346389555, 0.9760191846522782, 0.9760191846522782, 0.9854782840394352, 0.9397815081268319, 0.9592326139088729, 0.9872102318145484, 0.9828137490007993, 0.9726885158539835]
2022-01-27 00:21:51:INFO:Loss = [0.0992201758338299, 0.10605459521047718, 0.05734594908696383, 0.06154028354073016, 0.041795112841332895, 0.12502694041699453, 0.10505992843652207, 0.04127623379979607, 0.04809627696500216, 0.0753374460103267]
2022-01-27 00:21:51:INFO:-------------Training local models-------------
2022-01-27 00:28:05:INFO:-------------Aggregating local models-------------
2022-01-27 00:28:09:INFO:-------------Round number: 13-------------
2022-01-27 00:28:09:INFO:-------------Sending models-------------
2022-01-27 00:28:09:INFO:-------------Evaluating models-------------
2022-01-27 00:28:10:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:28:10:INFO:Accuracy = [0.9614974686917133, 0.9581667998934186, 0.9769517719158007, 0.9794830802025046, 0.9853450572875033, 0.9427124966693312, 0.960431654676259, 0.9873434585664802, 0.9828137490007993, 0.9750865973887557]
2022-01-27 00:28:10:INFO:Loss = [0.09782893574282193, 0.10447795961193844, 0.056218525613326145, 0.05902393579103372, 0.04128632252270921, 0.12206511888040875, 0.10364478273175491, 0.04050804142845759, 0.047374758919670475, 0.07216617625587571]
2022-01-27 00:28:10:INFO:-------------Training local models-------------
2022-01-27 00:34:23:INFO:-------------Aggregating local models-------------
2022-01-27 00:34:27:INFO:-------------Round number: 14-------------
2022-01-27 00:34:27:INFO:-------------Sending models-------------
2022-01-27 00:34:27:INFO:-------------Evaluating models-------------
2022-01-27 00:34:28:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:34:28:INFO:Accuracy = [0.9620303756994405, 0.9581667998934186, 0.9776179056754596, 0.9813482547295497, 0.9853450572875033, 0.9456434852118305, 0.9605648814281907, 0.9874766853184119, 0.9826805222488676, 0.9760191846522782]
2022-01-27 00:34:28:INFO:Loss = [0.09659563835762384, 0.10333766857327652, 0.05519981258464307, 0.05672895408313248, 0.04089865448308273, 0.11897439959229712, 0.1029353632540545, 0.039863177399555395, 0.04679674467700551, 0.06957796060763283]
2022-01-27 00:34:28:INFO:-------------Training local models-------------
2022-01-27 00:40:41:INFO:-------------Aggregating local models-------------
2022-01-27 00:40:45:INFO:-------------Round number: 15-------------
2022-01-27 00:40:45:INFO:-------------Sending models-------------
2022-01-27 00:40:46:INFO:-------------Evaluating models-------------
2022-01-27 00:40:46:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:40:46:INFO:Accuracy = [0.9630961897148947, 0.9593658406608047, 0.978683719690914, 0.9818811617372768, 0.9850786037836398, 0.9477751132427391, 0.9605648814281907, 0.988009592326139, 0.982414068745004, 0.9762856381561418]
2022-01-27 00:40:46:INFO:Loss = [0.09562773634050854, 0.10216129922230929, 0.054300613780394205, 0.05510371937340768, 0.04065333592076342, 0.11589439969958247, 0.10232664315675055, 0.03923691450471331, 0.04643318993674898, 0.06792964751361291]
2022-01-27 00:40:46:INFO:-------------Training local models-------------
2022-01-27 00:46:59:INFO:-------------Aggregating local models-------------
2022-01-27 00:47:03:INFO:-------------Round number: 16-------------
2022-01-27 00:47:03:INFO:-------------Sending models-------------
2022-01-27 00:47:03:INFO:-------------Evaluating models-------------
2022-01-27 00:47:04:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:47:04:INFO:Accuracy = [0.9638955502264854, 0.9613642419397815, 0.9792166266986411, 0.9813482547295497, 0.9849453770317079, 0.9496402877697842, 0.9602984279243272, 0.9881428190780709, 0.9822808419930722, 0.9757527311484147]
2022-01-27 00:47:04:INFO:Loss = [0.09484202159309688, 0.1010448542679215, 0.05352111873416497, 0.05394213731749744, 0.04046049309377111, 0.11295750480469337, 0.10183698249046243, 0.03884198588974855, 0.04616002650827555, 0.06687365412023034]
2022-01-27 00:47:04:INFO:-------------Training local models-------------
2022-01-27 00:53:18:INFO:-------------Aggregating local models-------------
2022-01-27 00:53:22:INFO:-------------Round number: 17-------------
2022-01-27 00:53:22:INFO:-------------Sending models-------------
2022-01-27 00:53:22:INFO:-------------Evaluating models-------------
2022-01-27 00:53:23:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:53:23:INFO:Accuracy = [0.9641620037303491, 0.9626965094590993, 0.9800159872102319, 0.9814814814814815, 0.9849453770317079, 0.9507061017852385, 0.960431654676259, 0.9882760458300026, 0.9822808419930722, 0.9756195043964828]
2022-01-27 00:53:23:INFO:Loss = [0.09407452182576849, 0.10073294927762938, 0.05287828887745055, 0.05297363020919788, 0.04038363728791838, 0.1103133245360247, 0.10231213831537046, 0.03857997709188019, 0.04580622005542822, 0.06598355233582512]
2022-01-27 00:53:23:INFO:-------------Training local models-------------
2022-01-27 00:59:35:INFO:-------------Aggregating local models-------------
2022-01-27 00:59:39:INFO:-------------Round number: 18-------------
2022-01-27 00:59:39:INFO:-------------Sending models-------------
2022-01-27 00:59:40:INFO:-------------Evaluating models-------------
2022-01-27 00:59:40:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:59:40:INFO:Accuracy = [0.9645616839861444, 0.9632294164668266, 0.9800159872102319, 0.9813482547295497, 0.9849453770317079, 0.951638689048761, 0.9606981081801226, 0.9884092725819345, 0.982414068745004, 0.9760191846522782]
2022-01-27 00:59:40:INFO:Loss = [0.09350068294855281, 0.10072231829397536, 0.05233624839712176, 0.05209084597791753, 0.040259302440297864, 0.1080796403069568, 0.10300116376703834, 0.03832840202706175, 0.045543662010437906, 0.06513627472834742]
2022-01-27 00:59:40:INFO:-------------Training local models-------------
2022-01-27 01:05:54:INFO:-------------Aggregating local models-------------
2022-01-27 01:05:58:INFO:-------------Round number: 19-------------
2022-01-27 01:05:58:INFO:-------------Sending models-------------
2022-01-27 01:05:58:INFO:-------------Evaluating models-------------
2022-01-27 01:05:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:05:59:INFO:Accuracy = [0.964828137490008, 0.9634958699706901, 0.9804156674660272, 0.9816147082334132, 0.9849453770317079, 0.951638689048761, 0.9606981081801226, 0.9884092725819345, 0.9825472954969358, 0.9764188649080735]
2022-01-27 01:05:59:INFO:Loss = [0.09299820906015037, 0.10120809265480664, 0.05183746460957967, 0.051229947122578626, 0.04022892566489064, 0.10621596487348688, 0.10411223026270584, 0.03806775183703374, 0.045393854567648155, 0.06435372009108921]
2022-01-27 01:05:59:INFO:-------------Training local models-------------
2022-01-27 01:12:12:INFO:-------------Aggregating local models-------------
2022-01-27 01:12:16:INFO:-------------Round number: 20-------------
2022-01-27 01:12:16:INFO:-------------Sending models-------------
2022-01-27 01:12:16:INFO:-------------Evaluating models-------------
2022-01-27 01:12:17:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:12:17:INFO:Accuracy = [0.9653610444977352, 0.9634958699706901, 0.9808153477218226, 0.9816147082334132, 0.9852118305355716, 0.9521715960564882, 0.960431654676259, 0.988675726085798, 0.9825472954969358, 0.9766853184119371]
2022-01-27 01:12:17:INFO:Loss = [0.09260987955562329, 0.10199836479104471, 0.05136835569321865, 0.05041228629474268, 0.04023575654527869, 0.10460155914462205, 0.1052373363638683, 0.03788841213051094, 0.045349269617773906, 0.0637252821313188]
2022-01-27 01:12:17:INFO:-------------Training local models-------------
2022-01-27 01:18:30:INFO:-------------Aggregating local models-------------
2022-01-27 01:18:34:INFO:-------------Round number: 21-------------
2022-01-27 01:18:34:INFO:-------------Sending models-------------
2022-01-27 01:18:35:INFO:-------------Evaluating models-------------
2022-01-27 01:18:36:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:18:36:INFO:Accuracy = [0.9649613642419398, 0.9636290967226219, 0.9810818012256861, 0.9816147082334132, 0.9853450572875033, 0.9532374100719424, 0.961097788435918, 0.9884092725819345, 0.9825472954969358, 0.9765520916600053]
2022-01-27 01:18:36:INFO:Loss = [0.0922000441549071, 0.10313971505723778, 0.05089740122409217, 0.04965698499345991, 0.04025320365934942, 0.1031889381804412, 0.10664130291072105, 0.0377505269050985, 0.04527528095954293, 0.06319602793952743]
2022-01-27 01:18:36:INFO:-------------Training local models-------------
2022-01-27 01:24:48:INFO:-------------Aggregating local models-------------
2022-01-27 01:24:52:INFO:-------------Round number: 22-------------
2022-01-27 01:24:52:INFO:-------------Sending models-------------
2022-01-27 01:24:52:INFO:-------------Evaluating models-------------
2022-01-27 01:24:53:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:24:53:INFO:Accuracy = [0.9646949107380762, 0.9629629629629629, 0.9810818012256861, 0.9817479349853451, 0.9853450572875033, 0.9543032240873968, 0.9613642419397815, 0.988675726085798, 0.9826805222488676, 0.9772182254196643]
2022-01-27 01:24:53:INFO:Loss = [0.09192004827919152, 0.10475474433916852, 0.050471445041924315, 0.048913512699361075, 0.0402767275707257, 0.10191959404468386, 0.10838226685096207, 0.03768132384770975, 0.04528053221399229, 0.0626117381015565]
2022-01-27 01:24:53:INFO:-------------Training local models-------------
2022-01-27 01:31:07:INFO:-------------Aggregating local models-------------
2022-01-27 01:31:11:INFO:-------------Round number: 23-------------
2022-01-27 01:31:11:INFO:-------------Sending models-------------
2022-01-27 01:31:11:INFO:-------------Evaluating models-------------
2022-01-27 01:31:12:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:31:12:INFO:Accuracy = [0.9644284572342127, 0.9629629629629629, 0.9810818012256861, 0.9821476152411405, 0.9853450572875033, 0.9544364508393285, 0.9613642419397815, 0.988675726085798, 0.9829469757527312, 0.977351452171596]
2022-01-27 01:31:12:INFO:Loss = [0.09151203463105027, 0.1065715350790095, 0.05005721117685487, 0.04811731391128453, 0.04047534098137072, 0.10075699915878729, 0.11023494480130688, 0.037721397264959926, 0.0451972389374168, 0.062088013573965324]
2022-01-27 01:31:12:INFO:-------------Training local models-------------
2022-01-27 01:37:24:INFO:-------------Aggregating local models-------------
2022-01-27 01:37:28:INFO:-------------Round number: 24-------------
2022-01-27 01:37:28:INFO:-------------Sending models-------------
2022-01-27 01:37:28:INFO:-------------Evaluating models-------------
2022-01-27 01:37:29:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:37:29:INFO:Accuracy = [0.9646949107380762, 0.9629629629629629, 0.9810818012256861, 0.9822808419930722, 0.9854782840394352, 0.9548361310951239, 0.961097788435918, 0.9888089528377298, 0.9829469757527312, 0.978017585931255]
2022-01-27 01:37:29:INFO:Loss = [0.09112863286861414, 0.10843745054357057, 0.04965689995129959, 0.04744383372484294, 0.04060543490543974, 0.09968391028327171, 0.11191939087760339, 0.03780198723410847, 0.045114408554695944, 0.061839560190066166]
2022-01-27 01:37:29:INFO:-------------Training local models-------------
2022-01-27 01:43:43:INFO:-------------Aggregating local models-------------
2022-01-27 01:43:47:INFO:-------------Round number: 25-------------
2022-01-27 01:43:47:INFO:-------------Sending models-------------
2022-01-27 01:43:47:INFO:-------------Evaluating models-------------
2022-01-27 01:43:48:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:43:48:INFO:Accuracy = [0.9658939515054623, 0.9626965094590993, 0.9814814814814815, 0.982414068745004, 0.9854782840394352, 0.9559019451105782, 0.9608313349320543, 0.9889421795896616, 0.9829469757527312, 0.9782840394351185]
2022-01-27 01:43:48:INFO:Loss = [0.09073780385801844, 0.11046298484367449, 0.04928087819348093, 0.046865274225595964, 0.04071482633226803, 0.09865944012504622, 0.11359067019879796, 0.03793242441494418, 0.04495403291106742, 0.06164660262352836]
2022-01-27 01:43:48:INFO:-------------Training local models-------------
2022-01-27 01:50:00:INFO:-------------Aggregating local models-------------
2022-01-27 01:50:04:INFO:-------------Round number: 26-------------
2022-01-27 01:50:04:INFO:-------------Sending models-------------
2022-01-27 01:50:05:INFO:-------------Evaluating models-------------
2022-01-27 01:50:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:50:05:INFO:Accuracy = [0.9665600852651213, 0.9626965094590993, 0.9817479349853451, 0.9825472954969358, 0.9850786037836398, 0.9568345323741008, 0.9608313349320543, 0.9890754063415934, 0.9832134292565947, 0.9785504929389821]
2022-01-27 01:50:05:INFO:Loss = [0.0907260762803261, 0.11276949481477937, 0.04892469570821807, 0.04638727739782205, 0.040867528533764796, 0.09774921804538445, 0.11534815544542307, 0.038144684723878344, 0.04525029031740737, 0.06163487452910151]
2022-01-27 01:50:05:INFO:-------------Training local models-------------
2022-01-27 01:56:19:INFO:-------------Aggregating local models-------------
2022-01-27 01:56:23:INFO:-------------Round number: 27-------------
2022-01-27 01:56:23:INFO:-------------Sending models-------------
2022-01-27 01:56:23:INFO:-------------Evaluating models-------------
2022-01-27 01:56:24:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:56:24:INFO:Accuracy = [0.9665600852651213, 0.9632294164668266, 0.9817479349853451, 0.9829469757527312, 0.9849453770317079, 0.9565680788702371, 0.9609645616839861, 0.9888089528377298, 0.9836131095123901, 0.9782840394351185]
2022-01-27 01:56:24:INFO:Loss = [0.09076770305232357, 0.11509131579678607, 0.048551724503668306, 0.04596962223057709, 0.04107080442056865, 0.09697717102249537, 0.11635847448051093, 0.03835986999578477, 0.045548020343323156, 0.06169846022562176]
2022-01-27 01:56:24:INFO:-------------Training local models-------------
2022-01-27 02:02:37:INFO:-------------Aggregating local models-------------
2022-01-27 02:02:41:INFO:-------------Round number: 28-------------
2022-01-27 02:02:41:INFO:-------------Sending models-------------
2022-01-27 02:02:41:INFO:-------------Evaluating models-------------
2022-01-27 02:02:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:02:42:INFO:Accuracy = [0.9662936317612577, 0.9636290967226219, 0.9818811617372768, 0.9828137490007993, 0.9849453770317079, 0.9565680788702371, 0.9614974686917133, 0.988675726085798, 0.9833466560085266, 0.9782840394351185]
2022-01-27 02:02:42:INFO:Loss = [0.0909129919583942, 0.11782915916757497, 0.048230251153308965, 0.0456677429479487, 0.04116449483896118, 0.0963720960200702, 0.11775205827606083, 0.03861846099597274, 0.045938670864665174, 0.061872891689682054]
2022-01-27 02:02:42:INFO:-------------Training local models-------------
2022-01-27 02:08:56:INFO:-------------Aggregating local models-------------
2022-01-27 02:09:00:INFO:-------------Round number: 29-------------
2022-01-27 02:09:00:INFO:-------------Sending models-------------
2022-01-27 02:09:00:INFO:-------------Evaluating models-------------
2022-01-27 02:09:01:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:09:01:INFO:Accuracy = [0.9662936317612577, 0.9642952304822808, 0.9821476152411405, 0.9826805222488676, 0.9848121502797762, 0.9567013056221689, 0.9613642419397815, 0.9889421795896616, 0.9832134292565947, 0.9782840394351185]
2022-01-27 02:09:01:INFO:Loss = [0.09132654341262428, 0.12078972623028912, 0.04795125139924163, 0.04545016945985638, 0.04132535316657988, 0.09588730527662186, 0.11956798946441613, 0.038919578247884286, 0.046528164256948425, 0.06220984549202697]
2022-01-27 02:09:01:INFO:-------------Training local models-------------
2022-01-27 02:15:13:INFO:-------------Aggregating local models-------------
