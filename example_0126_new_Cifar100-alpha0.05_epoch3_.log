2022-01-26 21:09:33:INFO:-------------Round number: 0-------------
2022-01-26 21:09:33:INFO:-------------Sending models-------------
2022-01-26 21:09:33:INFO:-------------Evaluating models-------------
2022-01-26 21:09:34:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:09:34:INFO:Accuracy = [0.9002131628030908, 0.09992006394884093, 0.09992006394884093, 0.09978683719690914, 0.8776978417266187, 0.8828936850519584, 0.10071942446043165, 0.09978683719690914, 0.8999467092992273, 0.8998134825472955]
2022-01-26 21:09:34:INFO:Loss = [0.6654636965667029, 0.7252982787424617, 0.7186282753166185, 0.7331456693051626, 0.6907666532589282, 0.6899063229132042, 0.7393160736738699, 0.7035459735426558, 0.6847668739912702, 0.6382551279078793]
2022-01-26 21:09:34:INFO:-------------Training local models-------------
2022-01-26 21:13:22:INFO:-------------Aggregating local models-------------
2022-01-26 21:13:26:INFO:-------------Round number: 1-------------
2022-01-26 21:13:26:INFO:-------------Sending models-------------
2022-01-26 21:13:26:INFO:-------------Evaluating models-------------
2022-01-26 21:13:27:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:13:27:INFO:Accuracy = [0.9407140953903543, 0.8703703703703703, 0.9624300559552358, 0.9212629896083133, 0.9588329336530775, 0.9188649080735412, 0.8421262989608314, 0.9431121769251266, 0.973621103117506, 0.9205968558486544]
2022-01-26 21:13:27:INFO:Loss = [0.2687470069152119, 0.34570843934945317, 0.1971813693474864, 0.24865990897872361, 0.21556783203172575, 0.26116613201378125, 0.3500034271486554, 0.26279634774146143, 0.2390434077010055, 0.3150274448371955]
2022-01-26 21:13:27:INFO:-------------Training local models-------------
2022-01-26 21:17:14:INFO:-------------Aggregating local models-------------
2022-01-26 21:17:18:INFO:-------------Round number: 2-------------
2022-01-26 21:17:18:INFO:-------------Sending models-------------
2022-01-26 21:17:19:INFO:-------------Evaluating models-------------
2022-01-26 21:17:19:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:17:19:INFO:Accuracy = [0.9407140953903543, 0.8959499067412736, 0.9646949107380762, 0.9567013056221689, 0.9628297362110312, 0.929656274980016, 0.8646416200373035, 0.9535038635758061, 0.975486277644551, 0.9144684252597922]
2022-01-26 21:17:19:INFO:Loss = [0.18796770100000637, 0.2338282171434078, 0.11176180203358153, 0.13529964610127135, 0.12855237088859273, 0.17936894520640753, 0.23124197137842584, 0.1504927088732092, 0.1255052756828194, 0.22052452167597333]
2022-01-26 21:17:19:INFO:-------------Training local models-------------
2022-01-26 21:21:08:INFO:-------------Aggregating local models-------------
2022-01-26 21:21:12:INFO:-------------Round number: 3-------------
2022-01-26 21:21:12:INFO:-------------Sending models-------------
2022-01-26 21:21:12:INFO:-------------Evaluating models-------------
2022-01-26 21:21:13:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:21:13:INFO:Accuracy = [0.9471089794830801, 0.9304556354916067, 0.966027178257394, 0.9638955502264854, 0.9662936317612577, 0.9323208100186517, 0.9074074074074074, 0.957234212629896, 0.9757527311484147, 0.9228617106314948]
2022-01-26 21:21:13:INFO:Loss = [0.1674224786015459, 0.20798264001173536, 0.0991977983341837, 0.11317478238311893, 0.1080616604633676, 0.16885143142829326, 0.205502221403237, 0.12599172015417448, 0.10261084522081446, 0.19517727971651813]
2022-01-26 21:21:13:INFO:-------------Training local models-------------
2022-01-26 21:25:00:INFO:-------------Aggregating local models-------------
2022-01-26 21:25:04:INFO:-------------Round number: 4-------------
2022-01-26 21:25:04:INFO:-------------Sending models-------------
2022-01-26 21:25:04:INFO:-------------Evaluating models-------------
2022-01-26 21:25:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:25:05:INFO:Accuracy = [0.9537703170796696, 0.9368505195843325, 0.9661604050093259, 0.9669597655209166, 0.9738875566213696, 0.9324540367705836, 0.9259259259259259, 0.9580335731414868, 0.9757527311484147, 0.9293898214761525]
2022-01-26 21:25:05:INFO:Loss = [0.15457268666186044, 0.18498884330442472, 0.09130721415448641, 0.0996576622025968, 0.09289720678749332, 0.1624447977822032, 0.18240429097388258, 0.11110440108741408, 0.08950916546667834, 0.1762356290504811]
2022-01-26 21:25:05:INFO:-------------Training local models-------------
2022-01-26 21:28:54:INFO:-------------Aggregating local models-------------
2022-01-26 21:28:58:INFO:-------------Round number: 5-------------
2022-01-26 21:28:58:INFO:-------------Sending models-------------
2022-01-26 21:28:58:INFO:-------------Evaluating models-------------
2022-01-26 21:28:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:28:59:INFO:Accuracy = [0.9545696775912603, 0.9396482813749001, 0.9662936317612577, 0.9700239808153477, 0.9782840394351185, 0.9327204902744471, 0.9355182520650147, 0.9596322941646682, 0.9758859579003464, 0.934052757793765]
2022-01-26 21:28:59:INFO:Loss = [0.1452097343193437, 0.1645265386879775, 0.08589749342248627, 0.09131203202593773, 0.07924989950191441, 0.1568348841442066, 0.16371935574350743, 0.09992035667859529, 0.08124085510149412, 0.15946393632798703]
2022-01-26 21:28:59:INFO:-------------Training local models-------------
2022-01-26 21:32:46:INFO:-------------Aggregating local models-------------
2022-01-26 21:32:50:INFO:-------------Round number: 6-------------
2022-01-26 21:32:50:INFO:-------------Sending models-------------
2022-01-26 21:32:50:INFO:-------------Evaluating models-------------
2022-01-26 21:32:51:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:32:51:INFO:Accuracy = [0.9547029043431922, 0.9444444444444444, 0.9669597655209166, 0.9726885158539835, 0.9813482547295497, 0.9335198507860378, 0.9419131361577405, 0.9718891553423927, 0.9758859579003464, 0.9397815081268319]
2022-01-26 21:32:51:INFO:Loss = [0.13780041100259283, 0.1504719465320953, 0.08233064215526006, 0.08592652532339601, 0.06970535235814265, 0.15268180701879197, 0.1505494723876004, 0.0897601262893098, 0.07564438031021346, 0.1452850609150369]
2022-01-26 21:32:51:INFO:-------------Training local models-------------
2022-01-26 21:36:40:INFO:-------------Aggregating local models-------------
2022-01-26 21:36:44:INFO:-------------Round number: 7-------------
2022-01-26 21:36:44:INFO:-------------Sending models-------------
2022-01-26 21:36:44:INFO:-------------Evaluating models-------------
2022-01-26 21:36:45:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:36:45:INFO:Accuracy = [0.9543032240873968, 0.9481747934985345, 0.967359445776712, 0.9732214228617106, 0.9822808419930722, 0.934052757793765, 0.9477751132427391, 0.9798827604583, 0.9758859579003464, 0.9556354916067147]
2022-01-26 21:36:45:INFO:Loss = [0.1314283688957324, 0.1403304500873961, 0.07946658320672231, 0.08204472639026562, 0.06359550279809184, 0.1494681628440429, 0.14040498846251362, 0.0794775945517797, 0.07134311760678748, 0.13242056611247438]
2022-01-26 21:36:45:INFO:-------------Training local models-------------
2022-01-26 21:40:32:INFO:-------------Aggregating local models-------------
2022-01-26 21:40:36:INFO:-------------Round number: 8-------------
2022-01-26 21:40:36:INFO:-------------Sending models-------------
2022-01-26 21:40:36:INFO:-------------Evaluating models-------------
2022-01-26 21:40:37:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:40:37:INFO:Accuracy = [0.9545696775912603, 0.9501731947775113, 0.9674926725286438, 0.9732214228617106, 0.982414068745004, 0.9345856648014922, 0.9508393285371702, 0.9818811617372768, 0.9758859579003464, 0.9596322941646682]
2022-01-26 21:40:37:INFO:Loss = [0.12569453944788045, 0.13355759052424365, 0.0768187086223811, 0.07914677661537795, 0.05931421447157441, 0.14674688001501754, 0.13345259805113155, 0.07076754231751796, 0.06781804990133028, 0.12159942322336553]
2022-01-26 21:40:37:INFO:-------------Training local models-------------
2022-01-26 21:44:25:INFO:-------------Aggregating local models-------------
2022-01-26 21:44:29:INFO:-------------Round number: 9-------------
2022-01-26 21:44:29:INFO:-------------Sending models-------------
2022-01-26 21:44:29:INFO:-------------Evaluating models-------------
2022-01-26 21:44:30:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:44:30:INFO:Accuracy = [0.9547029043431922, 0.9513722355448974, 0.9676258992805755, 0.9733546496136424, 0.9832134292565947, 0.9347188915534239, 0.9533706368238742, 0.982414068745004, 0.9758859579003464, 0.9605648814281907]
2022-01-26 21:44:30:INFO:Loss = [0.12065368917964678, 0.1287797786704527, 0.07425053977512625, 0.07688928288439341, 0.0560162973995555, 0.1443419896714321, 0.12859017044994925, 0.0644439631976916, 0.06478659320197362, 0.11349649631258446]
2022-01-26 21:44:30:INFO:-------------Training local models-------------
2022-01-26 21:48:17:INFO:-------------Aggregating local models-------------
2022-01-26 21:48:21:INFO:-------------Round number: 10-------------
2022-01-26 21:48:21:INFO:-------------Sending models-------------
2022-01-26 21:48:21:INFO:-------------Evaluating models-------------
2022-01-26 21:48:22:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:48:22:INFO:Accuracy = [0.9556354916067147, 0.9525712763122836, 0.9693578470556888, 0.973621103117506, 0.9837463362643218, 0.9351185718092193, 0.9549693578470557, 0.9833466560085266, 0.977351452171596, 0.9625632827071676]
2022-01-26 21:48:22:INFO:Loss = [0.11643743352611707, 0.12499496182598346, 0.07177293228117627, 0.07503998493209779, 0.05332465867705861, 0.1421806768890185, 0.12490877513551331, 0.059344563663501576, 0.06200444679560102, 0.10680664673711056]
2022-01-26 21:48:22:INFO:-------------Training local models-------------
2022-01-26 21:52:09:INFO:-------------Aggregating local models-------------
2022-01-26 21:52:13:INFO:-------------Round number: 11-------------
2022-01-26 21:52:13:INFO:-------------Sending models-------------
2022-01-26 21:52:13:INFO:-------------Evaluating models-------------
2022-01-26 21:52:14:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:52:14:INFO:Accuracy = [0.9569677591260325, 0.9528377298161471, 0.971089794830802, 0.973621103117506, 0.9845456967759126, 0.9357847055688783, 0.9559019451105782, 0.9840127897681854, 0.9800159872102319, 0.9641620037303491]
2022-01-26 21:52:14:INFO:Loss = [0.11299886312895317, 0.12177112979991282, 0.06948397544669103, 0.07347210129186117, 0.051088998051049404, 0.14024709390014298, 0.1217606469468847, 0.055057595676537986, 0.05939735637250023, 0.10101999386720016]
2022-01-26 21:52:14:INFO:-------------Training local models-------------
2022-01-26 21:55:59:INFO:-------------Aggregating local models-------------
2022-01-26 21:56:03:INFO:-------------Round number: 12-------------
2022-01-26 21:56:03:INFO:-------------Sending models-------------
2022-01-26 21:56:03:INFO:-------------Evaluating models-------------
2022-01-26 21:56:04:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:56:04:INFO:Accuracy = [0.9590993871569411, 0.9541699973354649, 0.9721556088462563, 0.973621103117506, 0.9848121502797762, 0.9360511590727418, 0.9563016253663735, 0.9860111910471623, 0.9816147082334132, 0.966027178257394]
2022-01-26 21:56:04:INFO:Loss = [0.11037785840692273, 0.11917781671831126, 0.0674848614712606, 0.07210660866358393, 0.049231073477939286, 0.13848646045016952, 0.11914490682232129, 0.051694347009543506, 0.057078398754777264, 0.09621189505766602]
2022-01-26 21:56:04:INFO:-------------Training local models-------------
2022-01-26 21:59:48:INFO:-------------Aggregating local models-------------
2022-01-26 21:59:53:INFO:-------------Round number: 13-------------
2022-01-26 21:59:53:INFO:-------------Sending models-------------
2022-01-26 21:59:53:INFO:-------------Evaluating models-------------
2022-01-26 21:59:54:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:59:54:INFO:Accuracy = [0.9596322941646682, 0.9549693578470557, 0.973621103117506, 0.973621103117506, 0.9849453770317079, 0.9363176125766054, 0.9563016253663735, 0.9862776445510258, 0.9816147082334132, 0.9662936317612577]
2022-01-26 21:59:54:INFO:Loss = [0.1083438296680219, 0.1169680530371043, 0.06574999371684835, 0.07084241076831765, 0.047721586603441585, 0.1368222974944359, 0.11688932334193863, 0.04910653921528498, 0.055143366065541995, 0.09234634439549788]
2022-01-26 21:59:54:INFO:-------------Training local models-------------
2022-01-26 22:03:38:INFO:-------------Aggregating local models-------------
2022-01-26 22:03:42:INFO:-------------Round number: 14-------------
2022-01-26 22:03:42:INFO:-------------Sending models-------------
2022-01-26 22:03:43:INFO:-------------Evaluating models-------------
2022-01-26 22:03:43:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:03:43:INFO:Accuracy = [0.9592326139088729, 0.9549693578470557, 0.9738875566213696, 0.973621103117506, 0.9852118305355716, 0.9363176125766054, 0.9568345323741008, 0.986144417799094, 0.9810818012256861, 0.9670929922728484]
2022-01-26 22:03:43:INFO:Loss = [0.10665745840647314, 0.11498349944842781, 0.06422076281667669, 0.06966342150295399, 0.04645481072147009, 0.13525287423497298, 0.11472770432943973, 0.04728568723679426, 0.0535394209635014, 0.08939352263265866]
2022-01-26 22:03:43:INFO:-------------Training local models-------------
2022-01-26 22:07:28:INFO:-------------Aggregating local models-------------
2022-01-26 22:07:32:INFO:-------------Round number: 15-------------
2022-01-26 22:07:32:INFO:-------------Sending models-------------
2022-01-26 22:07:32:INFO:-------------Evaluating models-------------
2022-01-26 22:07:33:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:07:33:INFO:Accuracy = [0.9602984279243272, 0.9556354916067147, 0.9742872368771649, 0.973621103117506, 0.9852118305355716, 0.9369837463362644, 0.957234212629896, 0.9862776445510258, 0.9817479349853451, 0.9676258992805755]
2022-01-26 22:07:33:INFO:Loss = [0.10521790250615665, 0.11337669702069851, 0.06286782241284875, 0.06852687122746014, 0.04538372786765227, 0.13374491433446337, 0.11300379069423816, 0.045869916368740174, 0.05223958659245549, 0.08692989359282949]
2022-01-26 22:07:33:INFO:-------------Training local models-------------
2022-01-26 22:11:17:INFO:-------------Aggregating local models-------------
2022-01-26 22:11:21:INFO:-------------Round number: 16-------------
2022-01-26 22:11:21:INFO:-------------Sending models-------------
2022-01-26 22:11:22:INFO:-------------Evaluating models-------------
2022-01-26 22:11:23:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:11:23:INFO:Accuracy = [0.9600319744204636, 0.9555022648547828, 0.9741540101252332, 0.973621103117506, 0.9854782840394352, 0.9369837463362644, 0.9577671196376233, 0.986810551558753, 0.9817479349853451, 0.9678923527844391]
2022-01-26 22:11:23:INFO:Loss = [0.10387012426519447, 0.11169201414931336, 0.061634034260362375, 0.06739230644742378, 0.0444718412374768, 0.132275540007407, 0.11113721595828868, 0.04468595252040945, 0.05113151274030213, 0.08467130475880215]
2022-01-26 22:11:23:INFO:-------------Training local models-------------
2022-01-26 22:15:07:INFO:-------------Aggregating local models-------------
2022-01-26 22:15:11:INFO:-------------Round number: 17-------------
2022-01-26 22:15:11:INFO:-------------Sending models-------------
2022-01-26 22:15:11:INFO:-------------Evaluating models-------------
2022-01-26 22:15:12:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:15:12:INFO:Accuracy = [0.9601652011723955, 0.9555022648547828, 0.9742872368771649, 0.973621103117506, 0.9856115107913669, 0.9375166533439915, 0.9583000266453504, 0.9870770050626165, 0.982414068745004, 0.9680255795363709]
2022-01-26 22:15:12:INFO:Loss = [0.10269885836260631, 0.11022899996952963, 0.060533111643802484, 0.06627133651520413, 0.04367988624535499, 0.13082258697422083, 0.10945479419061806, 0.04367306062318596, 0.0502358270097988, 0.08255765916091133]
2022-01-26 22:15:12:INFO:-------------Training local models-------------
2022-01-26 22:18:57:INFO:-------------Aggregating local models-------------
2022-01-26 22:19:01:INFO:-------------Round number: 18-------------
2022-01-26 22:19:01:INFO:-------------Sending models-------------
2022-01-26 22:19:01:INFO:-------------Evaluating models-------------
2022-01-26 22:19:02:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:19:02:INFO:Accuracy = [0.9602984279243272, 0.9564348521183054, 0.9744204636290967, 0.973621103117506, 0.9857447375432987, 0.9379163335997869, 0.9586997069011457, 0.9870770050626165, 0.9825472954969358, 0.9686917132960299]
2022-01-26 22:19:02:INFO:Loss = [0.10163336629206499, 0.10880380790146836, 0.05957576374552554, 0.0651519333911674, 0.04306268238460391, 0.12937087781745368, 0.10784267270909954, 0.04291665299440459, 0.04947684455683152, 0.08066904498288427]
2022-01-26 22:19:02:INFO:-------------Training local models-------------
2022-01-26 22:22:46:INFO:-------------Aggregating local models-------------
2022-01-26 22:22:50:INFO:-------------Round number: 19-------------
2022-01-26 22:22:50:INFO:-------------Sending models-------------
2022-01-26 22:22:50:INFO:-------------Evaluating models-------------
2022-01-26 22:22:51:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:22:51:INFO:Accuracy = [0.9608313349320543, 0.9576338928856915, 0.9746869171329603, 0.973621103117506, 0.9854782840394352, 0.9388489208633094, 0.9590993871569411, 0.9872102318145484, 0.982414068745004, 0.969224620303757]
2022-01-26 22:22:51:INFO:Loss = [0.10066749355967919, 0.10766216499902853, 0.05871369523193871, 0.06395434528662484, 0.04252704901651935, 0.12788030543288115, 0.10666716506684928, 0.04225158088405592, 0.048866111609028554, 0.07876974779013236]
2022-01-26 22:22:51:INFO:-------------Training local models-------------
2022-01-26 22:26:36:INFO:-------------Aggregating local models-------------
2022-01-26 22:26:40:INFO:-------------Round number: 20-------------
2022-01-26 22:26:40:INFO:-------------Sending models-------------
2022-01-26 22:26:40:INFO:-------------Evaluating models-------------
2022-01-26 22:26:41:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:26:41:INFO:Accuracy = [0.9612310151878497, 0.9577671196376233, 0.9753530508926193, 0.9741540101252332, 0.9854782840394352, 0.9399147348787636, 0.9590993871569411, 0.9873434585664802, 0.9826805222488676, 0.971089794830802]
2022-01-26 22:26:41:INFO:Loss = [0.09982116909638886, 0.10672602792194918, 0.05795590427667692, 0.06270138373124103, 0.04211557014555429, 0.12635524092481507, 0.10572461122746654, 0.04173065686352965, 0.04840815106649091, 0.07694769997425491]
2022-01-26 22:26:41:INFO:-------------Training local models-------------
2022-01-26 22:30:25:INFO:-------------Aggregating local models-------------
2022-01-26 22:30:29:INFO:-------------Round number: 21-------------
2022-01-26 22:30:29:INFO:-------------Sending models-------------
2022-01-26 22:30:29:INFO:-------------Evaluating models-------------
2022-01-26 22:30:30:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:30:30:INFO:Accuracy = [0.9613642419397815, 0.9580335731414868, 0.9760191846522782, 0.9762856381561418, 0.9853450572875033, 0.9397815081268319, 0.9594990674127365, 0.9873434585664802, 0.9828137490007993, 0.9728217426059153]
2022-01-26 22:30:30:INFO:Loss = [0.09899166187379904, 0.10589012242580517, 0.05726581595658329, 0.06134952163145237, 0.04177731058407681, 0.12479170238916013, 0.10491034151956649, 0.041289022693936694, 0.04795236138585383, 0.07511314662307542]
2022-01-26 22:30:30:INFO:-------------Training local models-------------
2022-01-26 22:34:15:INFO:-------------Aggregating local models-------------
2022-01-26 22:34:19:INFO:-------------Round number: 22-------------
2022-01-26 22:34:19:INFO:-------------Sending models-------------
2022-01-26 22:34:20:INFO:-------------Evaluating models-------------
2022-01-26 22:34:20:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:34:20:INFO:Accuracy = [0.9613642419397815, 0.9584332533972821, 0.9760191846522782, 0.9782840394351185, 0.9853450572875033, 0.9408473221422862, 0.9598987476685319, 0.9872102318145484, 0.9826805222488676, 0.9738875566213696]
2022-01-26 22:34:20:INFO:Loss = [0.09822299236318435, 0.10493168361410124, 0.056630223817886155, 0.059958069861600835, 0.04149258884985252, 0.12318246657438722, 0.10404649651254036, 0.04081822197359305, 0.04754979585135229, 0.07329184874267344]
2022-01-26 22:34:20:INFO:-------------Training local models-------------
2022-01-26 22:38:03:INFO:-------------Aggregating local models-------------
2022-01-26 22:38:08:INFO:-------------Round number: 23-------------
2022-01-26 22:38:08:INFO:-------------Sending models-------------
2022-01-26 22:38:08:INFO:-------------Evaluating models-------------
2022-01-26 22:38:09:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:38:09:INFO:Accuracy = [0.9616306954436451, 0.9580335731414868, 0.9772182254196643, 0.9802824407140954, 0.9852118305355716, 0.9425792699173994, 0.9605648814281907, 0.9873434585664802, 0.9828137490007993, 0.9756195043964828]
2022-01-26 22:38:09:INFO:Loss = [0.09748310615695811, 0.10423705002267307, 0.05604324904798224, 0.058570323972317054, 0.04122329159638411, 0.12153967656223082, 0.10351677504484759, 0.04041344228950831, 0.0471894549495879, 0.0715918671015657]
2022-01-26 22:38:09:INFO:-------------Training local models-------------
2022-01-26 22:41:54:INFO:-------------Aggregating local models-------------
2022-01-26 22:41:58:INFO:-------------Round number: 24-------------
2022-01-26 22:41:58:INFO:-------------Sending models-------------
2022-01-26 22:41:58:INFO:-------------Evaluating models-------------
2022-01-26 22:41:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:41:59:INFO:Accuracy = [0.9620303756994405, 0.9577671196376233, 0.9772182254196643, 0.9806821209698907, 0.9852118305355716, 0.9444444444444444, 0.9605648814281907, 0.9876099120703438, 0.9826805222488676, 0.9762856381561418]
2022-01-26 22:41:59:INFO:Loss = [0.09677934532571077, 0.1035688766027303, 0.05549593510074078, 0.05729153852359847, 0.04100369643335802, 0.11985622567138995, 0.10305065411555747, 0.040049298945333184, 0.046852444230350135, 0.07013314559875217]
2022-01-26 22:41:59:INFO:-------------Training local models-------------
2022-01-26 22:45:43:INFO:-------------Aggregating local models-------------
2022-01-26 22:45:47:INFO:-------------Round number: 25-------------
2022-01-26 22:45:47:INFO:-------------Sending models-------------
2022-01-26 22:45:48:INFO:-------------Evaluating models-------------
2022-01-26 22:45:48:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:45:48:INFO:Accuracy = [0.9622968292033041, 0.9589661604050094, 0.9785504929389821, 0.9818811617372768, 0.9852118305355716, 0.9461763922195577, 0.9608313349320543, 0.9876099120703438, 0.9826805222488676, 0.9765520916600053]
2022-01-26 22:45:48:INFO:Loss = [0.09624140391722093, 0.1028059366146586, 0.05496079558700362, 0.05617055941987237, 0.040841738441655964, 0.11817812682733388, 0.10257982578490696, 0.039652876796355825, 0.04667479056520112, 0.06888393320368942]
2022-01-26 22:45:48:INFO:-------------Training local models-------------
2022-01-26 22:49:33:INFO:-------------Aggregating local models-------------
2022-01-26 22:49:37:INFO:-------------Round number: 26-------------
2022-01-26 22:49:37:INFO:-------------Sending models-------------
2022-01-26 22:49:38:INFO:-------------Evaluating models-------------
2022-01-26 22:49:38:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:49:38:INFO:Accuracy = [0.9626965094590993, 0.9593658406608047, 0.9784172661870504, 0.9820143884892086, 0.9850786037836398, 0.9476418864908074, 0.9606981081801226, 0.9878763655742073, 0.9825472954969358, 0.9764188649080735]
2022-01-26 22:49:38:INFO:Loss = [0.09566283583597904, 0.10211953036682292, 0.05448786798132385, 0.05534731872770692, 0.04070441565706513, 0.11651146326587718, 0.10215644723178922, 0.039354869444378444, 0.0464293332108787, 0.06807109619712753]
2022-01-26 22:49:38:INFO:-------------Training local models-------------
2022-01-26 22:53:21:INFO:-------------Aggregating local models-------------
2022-01-26 22:53:25:INFO:-------------Round number: 27-------------
2022-01-26 22:53:25:INFO:-------------Sending models-------------
2022-01-26 22:53:26:INFO:-------------Evaluating models-------------
2022-01-26 22:53:26:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:53:26:INFO:Accuracy = [0.9630961897148947, 0.960431654676259, 0.978683719690914, 0.9821476152411405, 0.9850786037836398, 0.9481747934985345, 0.9605648814281907, 0.988009592326139, 0.9825472954969358, 0.9764188649080735]
2022-01-26 22:53:26:INFO:Loss = [0.09530792746470348, 0.10162370809880254, 0.05404269192769802, 0.05458828076230242, 0.040587441381149315, 0.11487887913149586, 0.10202713216913936, 0.03906671068379477, 0.04636284720548291, 0.06734207103688805]
2022-01-26 22:53:26:INFO:-------------Training local models-------------
2022-01-26 22:57:11:INFO:-------------Aggregating local models-------------
2022-01-26 22:57:16:INFO:-------------Round number: 28-------------
2022-01-26 22:57:16:INFO:-------------Sending models-------------
2022-01-26 22:57:16:INFO:-------------Evaluating models-------------
2022-01-26 22:57:17:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:57:17:INFO:Accuracy = [0.9634958699706901, 0.961097788435918, 0.9792166266986411, 0.9816147082334132, 0.9850786037836398, 0.9492406075139888, 0.9605648814281907, 0.9881428190780709, 0.982414068745004, 0.9758859579003464]
2022-01-26 22:57:17:INFO:Loss = [0.09481871600264201, 0.10104502888228087, 0.053626841744772336, 0.05390741188085741, 0.040478744030293404, 0.11332496231700195, 0.10182126167406669, 0.03882831710074443, 0.04613322675451582, 0.06664949355954346]
2022-01-26 22:57:17:INFO:-------------Training local models-------------
2022-01-26 23:01:01:INFO:-------------Aggregating local models-------------
2022-01-26 23:01:06:INFO:-------------Round number: 29-------------
2022-01-26 23:01:06:INFO:-------------Sending models-------------
2022-01-26 23:01:06:INFO:-------------Evaluating models-------------
2022-01-26 23:01:07:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 23:01:07:INFO:Accuracy = [0.9638955502264854, 0.9621636024513722, 0.9798827604583, 0.9817479349853451, 0.9849453770317079, 0.9501731947775113, 0.9605648814281907, 0.9882760458300026, 0.9822808419930722, 0.9760191846522782]
2022-01-26 23:01:07:INFO:Loss = [0.09437446196421412, 0.10075398111580468, 0.053268444325756205, 0.05338043735273161, 0.04038808287418815, 0.11183664607862866, 0.1019543402966405, 0.038617960312309366, 0.04591434818716064, 0.06612872264009341]
2022-01-26 23:01:07:INFO:-------------Training local models-------------
2022-01-26 23:04:51:INFO:-------------Aggregating local models-------------
