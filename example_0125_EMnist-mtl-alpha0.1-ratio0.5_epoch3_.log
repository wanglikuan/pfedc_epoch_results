2022-01-25 21:17:22:INFO:-------------Round number: 0-------------
2022-01-25 21:17:22:INFO:-------------Sending models-------------
2022-01-25 21:17:23:INFO:-------------Evaluating models-------------
2022-01-25 21:17:24:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 21:17:24:INFO:Accuracy = [0.8909090909090909, 0.9545454545454546, 0.9, 0.9090909090909091, 0.8818181818181818, 0.1, 0.09090909090909091, 0.12727272727272726, 0.08181818181818182, 0.8636363636363636]
2022-01-25 21:17:24:INFO:Loss = [0.6607828552072699, 0.6483499537814748, 0.6659317932345651, 0.6574403367259286, 0.6621757144277746, 0.7392762736840681, 0.7426794252612374, 0.7391448904167522, 0.7449987904591994, 0.6712419098073786]
2022-01-25 21:17:24:INFO:-------------Training local models-------------
2022-01-25 21:22:06:INFO:-------------Aggregating local models-------------
2022-01-25 21:22:11:INFO:-------------Round number: 1-------------
2022-01-25 21:22:11:INFO:-------------Sending models-------------
2022-01-25 21:22:12:INFO:-------------Evaluating models-------------
2022-01-25 21:22:12:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 21:22:12:INFO:Accuracy = [0.8445454545454546, 0.918409090909091, 0.8345454545454546, 0.8768181818181818, 0.8197727272727273, 0.8359090909090909, 0.8625, 0.735909090909091, 0.8690909090909091, 0.7147727272727272]
2022-01-25 21:22:12:INFO:Loss = [0.4532714576206424, 0.49326856312426653, 0.5140246895226566, 0.47850850210948426, 0.5010635529729452, 0.4914291921664368, 0.5089778656986627, 0.5893587283112786, 0.4561284733089534, 0.6130105755545876]
2022-01-25 21:22:12:INFO:-------------Training local models-------------
2022-01-25 21:26:54:INFO:-------------Aggregating local models-------------
2022-01-25 21:27:00:INFO:-------------Round number: 2-------------
2022-01-25 21:27:00:INFO:-------------Sending models-------------
2022-01-25 21:27:00:INFO:-------------Evaluating models-------------
2022-01-25 21:27:01:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 21:27:01:INFO:Accuracy = [0.8188636363636363, 0.9243181818181818, 0.8481818181818181, 0.8811363636363636, 0.8186363636363636, 0.8775, 0.8854545454545455, 0.8029545454545455, 0.8863636363636364, 0.735909090909091]
2022-01-25 21:27:01:INFO:Loss = [0.45448774444785983, 0.3963601683351127, 0.4499969766559926, 0.41700670956210656, 0.46984099066731605, 0.38766988813877107, 0.41853380270979623, 0.5586898460306905, 0.37345425972545687, 0.5191187087785114]
2022-01-25 21:27:01:INFO:-------------Training local models-------------
2022-01-25 21:31:44:INFO:-------------Aggregating local models-------------
2022-01-25 21:31:49:INFO:-------------Round number: 3-------------
2022-01-25 21:31:49:INFO:-------------Sending models-------------
2022-01-25 21:31:50:INFO:-------------Evaluating models-------------
2022-01-25 21:31:50:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 21:31:50:INFO:Accuracy = [0.8179545454545455, 0.9268181818181818, 0.8545454545454545, 0.8818181818181818, 0.8195454545454546, 0.8927272727272727, 0.8822727272727273, 0.8311363636363637, 0.8988636363636363, 0.7684090909090909]
2022-01-25 21:31:50:INFO:Loss = [0.4780118701090528, 0.34686293822120534, 0.4334902486679229, 0.3841441881588914, 0.4752893958748742, 0.3498139192604206, 0.3864137255502018, 0.5610479235310446, 0.3409170524640517, 0.4737688329409469]
2022-01-25 21:31:50:INFO:-------------Training local models-------------
2022-01-25 21:36:32:INFO:-------------Aggregating local models-------------
2022-01-25 21:36:37:INFO:-------------Round number: 4-------------
2022-01-25 21:36:37:INFO:-------------Sending models-------------
2022-01-25 21:36:38:INFO:-------------Evaluating models-------------
2022-01-25 21:36:39:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 21:36:39:INFO:Accuracy = [0.8179545454545455, 0.9272727272727272, 0.8568181818181818, 0.8820454545454546, 0.8222727272727273, 0.8995454545454545, 0.8797727272727273, 0.8393181818181819, 0.9072727272727272, 0.785]
2022-01-25 21:36:39:INFO:Loss = [0.4891930917531929, 0.3220961986448277, 0.4281749645586718, 0.36351806748319754, 0.48071727587164126, 0.33502392075447873, 0.3744203489104455, 0.5700809523124587, 0.3243465521838516, 0.4573792143640193]
2022-01-25 21:36:39:INFO:-------------Training local models-------------
2022-01-25 21:41:21:INFO:-------------Aggregating local models-------------
2022-01-25 21:41:26:INFO:-------------Round number: 5-------------
2022-01-25 21:41:26:INFO:-------------Sending models-------------
2022-01-25 21:41:27:INFO:-------------Evaluating models-------------
2022-01-25 21:41:28:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 21:41:28:INFO:Accuracy = [0.8181818181818182, 0.9272727272727272, 0.8590909090909091, 0.885, 0.8236363636363636, 0.9027272727272727, 0.8638636363636364, 0.8429545454545454, 0.9104545454545454, 0.7854545454545454]
2022-01-25 21:41:28:INFO:Loss = [0.4926534137074751, 0.30740189690312203, 0.4244210102510723, 0.348584853163497, 0.4816708449443633, 0.328044562778351, 0.36912193919785996, 0.578061232089319, 0.3136595994572748, 0.45190618718889625]
2022-01-25 21:41:28:INFO:-------------Training local models-------------
2022-01-25 21:46:10:INFO:-------------Aggregating local models-------------
2022-01-25 21:46:15:INFO:-------------Round number: 6-------------
2022-01-25 21:46:15:INFO:-------------Sending models-------------
2022-01-25 21:46:15:INFO:-------------Evaluating models-------------
2022-01-25 21:46:16:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 21:46:16:INFO:Accuracy = [0.8181818181818182, 0.9272727272727272, 0.8593181818181819, 0.8886363636363637, 0.8259090909090909, 0.9068181818181819, 0.8570454545454546, 0.8452272727272727, 0.9118181818181819, 0.7888636363636363]
2022-01-25 21:46:16:INFO:Loss = [0.4930587842721831, 0.297126631108536, 0.42045058418403974, 0.336742047152736, 0.4798902632287619, 0.3239877747795121, 0.36650136949240486, 0.584173463056372, 0.3059746211627498, 0.44946303357454864]
2022-01-25 21:46:16:INFO:-------------Training local models-------------
2022-01-25 21:50:58:INFO:-------------Aggregating local models-------------
2022-01-25 21:51:04:INFO:-------------Round number: 7-------------
2022-01-25 21:51:04:INFO:-------------Sending models-------------
2022-01-25 21:51:04:INFO:-------------Evaluating models-------------
2022-01-25 21:51:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 21:51:05:INFO:Accuracy = [0.8181818181818182, 0.9272727272727272, 0.86, 0.8911363636363636, 0.8277272727272728, 0.9109090909090909, 0.8545454545454545, 0.8454545454545455, 0.9129545454545455, 0.7911363636363636]
2022-01-25 21:51:05:INFO:Loss = [0.4922195441915061, 0.28919431372460996, 0.4161685246931897, 0.3269679614342749, 0.4769587592010132, 0.3213186233050444, 0.365351725416258, 0.5889470118775286, 0.30016830970575525, 0.44754721517251295]
2022-01-25 21:51:05:INFO:-------------Training local models-------------
2022-01-25 21:55:47:INFO:-------------Aggregating local models-------------
2022-01-25 21:55:52:INFO:-------------Round number: 8-------------
2022-01-25 21:55:52:INFO:-------------Sending models-------------
2022-01-25 21:55:53:INFO:-------------Evaluating models-------------
2022-01-25 21:55:53:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 21:55:53:INFO:Accuracy = [0.8181818181818182, 0.9272727272727272, 0.860909090909091, 0.8952272727272728, 0.8288636363636364, 0.9104545454545454, 0.8536363636363636, 0.8454545454545455, 0.9122727272727272, 0.7913636363636364]
2022-01-25 21:55:53:INFO:Loss = [0.4908565363232893, 0.2827894304201684, 0.41170209700411015, 0.31872609026984056, 0.473672385416417, 0.31955001665363936, 0.36518090562048283, 0.5928180104206231, 0.29563343062023206, 0.4455134874209762]
2022-01-25 21:55:53:INFO:-------------Training local models-------------
2022-01-25 22:00:36:INFO:-------------Aggregating local models-------------
2022-01-25 22:00:41:INFO:-------------Round number: 9-------------
2022-01-25 22:00:41:INFO:-------------Sending models-------------
2022-01-25 22:00:42:INFO:-------------Evaluating models-------------
2022-01-25 22:00:43:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 22:00:43:INFO:Accuracy = [0.8181818181818182, 0.9272727272727272, 0.8627272727272727, 0.8977272727272727, 0.8290909090909091, 0.9104545454545454, 0.8540909090909091, 0.8454545454545455, 0.9111363636363636, 0.7915909090909091]
2022-01-25 22:00:43:INFO:Loss = [0.48924111377088014, 0.2774911961433562, 0.40716025122780014, 0.3116906095169146, 0.47034699631304566, 0.3184087948069315, 0.3656827616632323, 0.5960364720911127, 0.29197550414934414, 0.443333071698858]
2022-01-25 22:00:43:INFO:-------------Training local models-------------
2022-01-25 22:05:24:INFO:-------------Aggregating local models-------------
2022-01-25 22:05:30:INFO:-------------Round number: 10-------------
2022-01-25 22:05:30:INFO:-------------Sending models-------------
2022-01-25 22:05:30:INFO:-------------Evaluating models-------------
2022-01-25 22:05:31:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 22:05:31:INFO:Accuracy = [0.8181818181818182, 0.9272727272727272, 0.8634090909090909, 0.9002272727272728, 0.8302272727272727, 0.9106818181818181, 0.8543181818181819, 0.8454545454545455, 0.9104545454545454, 0.7940909090909091]
2022-01-25 22:05:31:INFO:Loss = [0.487507922321939, 0.2730596589517187, 0.40264210764064706, 0.3056499455081807, 0.4670891462084414, 0.31772308687002143, 0.36658799465830355, 0.5987276363821531, 0.2889226952292533, 0.44109058796682143]
2022-01-25 22:05:31:INFO:-------------Training local models-------------
2022-01-25 22:10:13:INFO:-------------Aggregating local models-------------
2022-01-25 22:10:19:INFO:-------------Round number: 11-------------
2022-01-25 22:10:19:INFO:-------------Sending models-------------
2022-01-25 22:10:19:INFO:-------------Evaluating models-------------
2022-01-25 22:10:20:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 22:10:20:INFO:Accuracy = [0.8181818181818182, 0.9277272727272727, 0.8645454545454545, 0.9027272727272727, 0.8320454545454545, 0.9109090909090909, 0.8547727272727272, 0.8454545454545455, 0.9090909090909091, 0.7954545454545454]
2022-01-25 22:10:20:INFO:Loss = [0.4857280709103427, 0.2693360811861401, 0.3982392378405414, 0.300450908894312, 0.46395273078444665, 0.317356144615703, 0.36770873899063605, 0.6010091910689053, 0.2863000370487994, 0.43885816195979716]
2022-01-25 22:10:20:INFO:-------------Training local models-------------
2022-01-25 22:15:02:INFO:-------------Aggregating local models-------------
2022-01-25 22:15:08:INFO:-------------Round number: 12-------------
2022-01-25 22:15:08:INFO:-------------Sending models-------------
2022-01-25 22:15:08:INFO:-------------Evaluating models-------------
2022-01-25 22:15:09:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 22:15:09:INFO:Accuracy = [0.8184090909090909, 0.9281818181818182, 0.8656818181818182, 0.9029545454545455, 0.8322727272727273, 0.9111363636363636, 0.8554545454545455, 0.8454545454545455, 0.9084090909090909, 0.7972727272727272]
2022-01-25 22:15:09:INFO:Loss = [0.4839612191034989, 0.26619010054167697, 0.39401908676055347, 0.2959809545046565, 0.4609675531656566, 0.3172268414488909, 0.3689403583718972, 0.6029754614457488, 0.28399193440140647, 0.4366644546516578]
2022-01-25 22:15:09:INFO:-------------Training local models-------------
2022-01-25 22:19:51:INFO:-------------Aggregating local models-------------
2022-01-25 22:19:56:INFO:-------------Round number: 13-------------
2022-01-25 22:19:56:INFO:-------------Sending models-------------
2022-01-25 22:19:57:INFO:-------------Evaluating models-------------
2022-01-25 22:19:57:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 22:19:57:INFO:Accuracy = [0.8188636363636363, 0.9295454545454546, 0.8663636363636363, 0.9034090909090909, 0.8329545454545455, 0.9115909090909091, 0.8563636363636363, 0.8454545454545455, 0.9081818181818182, 0.7995454545454546]
2022-01-25 22:19:57:INFO:Loss = [0.48222919097170236, 0.2635480614760044, 0.39003822776404296, 0.2921233828412369, 0.4581386010278948, 0.3172797411637889, 0.3702110344120725, 0.6047106317286803, 0.28191829340384256, 0.4345239184288816]
2022-01-25 22:19:57:INFO:-------------Training local models-------------
2022-01-25 22:24:40:INFO:-------------Aggregating local models-------------
2022-01-25 22:24:44:INFO:-------------Round number: 14-------------
2022-01-25 22:24:44:INFO:-------------Sending models-------------
2022-01-25 22:24:45:INFO:-------------Evaluating models-------------
2022-01-25 22:24:46:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 22:24:46:INFO:Accuracy = [0.8193181818181818, 0.9302272727272727, 0.865, 0.9045454545454545, 0.8331818181818181, 0.9118181818181819, 0.8568181818181818, 0.8454545454545455, 0.9077272727272727, 0.803409090909091]
2022-01-25 22:24:46:INFO:Loss = [0.48059146922632034, 0.26133366224609994, 0.3863342854406007, 0.28879440262363376, 0.45545694543345067, 0.31746889280409296, 0.371483939549547, 0.6062714450548149, 0.280018419879277, 0.4324499849314717]
2022-01-25 22:24:46:INFO:-------------Training local models-------------
2022-01-25 22:29:28:INFO:-------------Aggregating local models-------------
2022-01-25 22:29:33:INFO:-------------Round number: 15-------------
2022-01-25 22:29:33:INFO:-------------Sending models-------------
2022-01-25 22:29:34:INFO:-------------Evaluating models-------------
2022-01-25 22:29:34:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 22:29:34:INFO:Accuracy = [0.82, 0.9318181818181818, 0.8668181818181818, 0.9052272727272728, 0.8331818181818181, 0.9129545454545455, 0.8577272727272728, 0.8454545454545455, 0.9077272727272727, 0.8043181818181818]
2022-01-25 22:29:34:INFO:Loss = [0.47898804155093705, 0.25942530935968866, 0.3828993318729441, 0.28589472745502875, 0.4529326881906441, 0.31774170952002434, 0.37275139456826517, 0.6076279847332361, 0.27821739565856246, 0.4304206953214651]
2022-01-25 22:29:34:INFO:-------------Training local models-------------
2022-01-25 22:34:14:INFO:-------------Aggregating local models-------------
2022-01-25 22:34:19:INFO:-------------Round number: 16-------------
2022-01-25 22:34:19:INFO:-------------Sending models-------------
2022-01-25 22:34:20:INFO:-------------Evaluating models-------------
2022-01-25 22:34:20:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 22:34:20:INFO:Accuracy = [0.8209090909090909, 0.9325, 0.8672727272727273, 0.9063636363636364, 0.8325, 0.9129545454545455, 0.8572727272727273, 0.8454545454545455, 0.9081818181818182, 0.8063636363636364]
2022-01-25 22:34:20:INFO:Loss = [0.47744804829549553, 0.2577973283933137, 0.3797277558044615, 0.28336219383953987, 0.45054441605885087, 0.31810224079103633, 0.3740020027087832, 0.6088173064932396, 0.27652465186864983, 0.42846059095622463]
2022-01-25 22:34:20:INFO:-------------Training local models-------------
2022-01-25 22:38:57:INFO:-------------Aggregating local models-------------
2022-01-25 22:39:02:INFO:-------------Round number: 17-------------
2022-01-25 22:39:02:INFO:-------------Sending models-------------
2022-01-25 22:39:03:INFO:-------------Evaluating models-------------
2022-01-25 22:39:03:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 22:39:03:INFO:Accuracy = [0.8220454545454545, 0.9331818181818182, 0.8686363636363637, 0.9065909090909091, 0.8329545454545455, 0.9145454545454546, 0.8579545454545454, 0.8454545454545455, 0.9079545454545455, 0.8093181818181818]
2022-01-25 22:39:03:INFO:Loss = [0.4759804954561828, 0.2563853285381232, 0.3768098657146435, 0.2811401270414618, 0.4483147093793377, 0.31851005989169195, 0.37504885571966456, 0.6098362040007487, 0.2749588355623101, 0.4265815546524457]
2022-01-25 22:39:03:INFO:-------------Training local models-------------
2022-01-25 22:43:41:INFO:-------------Aggregating local models-------------
2022-01-25 22:43:46:INFO:-------------Round number: 18-------------
2022-01-25 22:43:46:INFO:-------------Sending models-------------
2022-01-25 22:43:46:INFO:-------------Evaluating models-------------
2022-01-25 22:43:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 22:43:47:INFO:Accuracy = [0.8227272727272728, 0.9334090909090909, 0.87, 0.9068181818181819, 0.8331818181818181, 0.9143181818181818, 0.8584090909090909, 0.8454545454545455, 0.9090909090909091, 0.8106818181818182]
2022-01-25 22:43:47:INFO:Loss = [0.4745724778013854, 0.25511532997585495, 0.37412892819636245, 0.2791682185922665, 0.4462026493782601, 0.31895194063386456, 0.3759757879676975, 0.6107168798144399, 0.27350230417743493, 0.42478915889197116]
2022-01-25 22:43:47:INFO:-------------Training local models-------------
2022-01-25 22:48:24:INFO:-------------Aggregating local models-------------
2022-01-25 22:48:29:INFO:-------------Round number: 19-------------
2022-01-25 22:48:29:INFO:-------------Sending models-------------
2022-01-25 22:48:29:INFO:-------------Evaluating models-------------
2022-01-25 22:48:30:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 22:48:30:INFO:Accuracy = [0.8238636363636364, 0.9338636363636363, 0.8736363636363637, 0.9065909090909091, 0.8334090909090909, 0.913409090909091, 0.8595454545454545, 0.8454545454545455, 0.9093181818181818, 0.8127272727272727]
2022-01-25 22:48:30:INFO:Loss = [0.47322030546122484, 0.25395740704526276, 0.3716771441363645, 0.2774078440990045, 0.44418477450328114, 0.31939372487408535, 0.3768303901613267, 0.6114524650662629, 0.2721134269345467, 0.423108969563195]
2022-01-25 22:48:30:INFO:-------------Training local models-------------
2022-01-25 22:53:08:INFO:-------------Aggregating local models-------------
2022-01-25 22:53:13:INFO:-------------Round number: 20-------------
2022-01-25 22:53:13:INFO:-------------Sending models-------------
2022-01-25 22:53:13:INFO:-------------Evaluating models-------------
2022-01-25 22:53:14:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 22:53:14:INFO:Accuracy = [0.8259090909090909, 0.9345454545454546, 0.8763636363636363, 0.9075, 0.8327272727272728, 0.9143181818181818, 0.8595454545454545, 0.8454545454545455, 0.9097727272727273, 0.8140909090909091]
2022-01-25 22:53:14:INFO:Loss = [0.4719163756097921, 0.25287038884972307, 0.3694364013319666, 0.27582975823262873, 0.44227314202792267, 0.31983184202743525, 0.3775782075879926, 0.6120477544715289, 0.2707860622618517, 0.42153888146223667]
2022-01-25 22:53:14:INFO:-------------Training local models-------------
2022-01-25 22:57:51:INFO:-------------Aggregating local models-------------
2022-01-25 22:57:56:INFO:-------------Round number: 21-------------
2022-01-25 22:57:56:INFO:-------------Sending models-------------
2022-01-25 22:57:57:INFO:-------------Evaluating models-------------
2022-01-25 22:57:57:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 22:57:57:INFO:Accuracy = [0.8284090909090909, 0.9345454545454546, 0.8768181818181818, 0.9063636363636364, 0.8343181818181818, 0.9145454545454546, 0.8615909090909091, 0.8454545454545455, 0.9104545454545454, 0.8145454545454546]
2022-01-25 22:57:57:INFO:Loss = [0.47067568945719607, 0.25182473351332274, 0.36739078185902063, 0.27440696523037994, 0.4404482096856968, 0.3202587610787966, 0.3782412699508396, 0.6125286480962214, 0.26952566162217406, 0.4201100078369068]
2022-01-25 22:57:57:INFO:-------------Training local models-------------
2022-01-25 23:02:35:INFO:-------------Aggregating local models-------------
2022-01-25 23:02:40:INFO:-------------Round number: 22-------------
2022-01-25 23:02:40:INFO:-------------Sending models-------------
2022-01-25 23:02:40:INFO:-------------Evaluating models-------------
2022-01-25 23:02:41:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 23:02:41:INFO:Accuracy = [0.8297727272727272, 0.9352272727272727, 0.8784090909090909, 0.9054545454545454, 0.8352272727272727, 0.9145454545454546, 0.8622727272727273, 0.8454545454545455, 0.9104545454545454, 0.815]
2022-01-25 23:02:41:INFO:Loss = [0.4694657098110342, 0.2508062597893348, 0.3655123815702444, 0.27310962353790685, 0.4386877177336084, 0.32066876468333333, 0.3788274987452579, 0.6129040316509252, 0.2683348573860712, 0.41883069137111306]
2022-01-25 23:02:41:INFO:-------------Training local models-------------
2022-01-25 23:07:17:INFO:-------------Aggregating local models-------------
2022-01-25 23:07:23:INFO:-------------Round number: 23-------------
2022-01-25 23:07:23:INFO:-------------Sending models-------------
2022-01-25 23:07:23:INFO:-------------Evaluating models-------------
2022-01-25 23:07:24:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 23:07:24:INFO:Accuracy = [0.8313636363636364, 0.9354545454545454, 0.8797727272727273, 0.905, 0.836590909090909, 0.9145454545454546, 0.8622727272727273, 0.8454545454545455, 0.9104545454545454, 0.8175]
2022-01-25 23:07:24:INFO:Loss = [0.4682938096378083, 0.24981128876944156, 0.3637948709286072, 0.27191273812098765, 0.4370154140305451, 0.32105382791593334, 0.3792967654087327, 0.6131784556666389, 0.2672164808366109, 0.4176862335785038]
2022-01-25 23:07:24:INFO:-------------Training local models-------------
2022-01-25 23:12:01:INFO:-------------Aggregating local models-------------
2022-01-25 23:12:06:INFO:-------------Round number: 24-------------
2022-01-25 23:12:06:INFO:-------------Sending models-------------
2022-01-25 23:12:07:INFO:-------------Evaluating models-------------
2022-01-25 23:12:08:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 23:12:08:INFO:Accuracy = [0.8327272727272728, 0.9359090909090909, 0.88, 0.9038636363636363, 0.8377272727272728, 0.9143181818181818, 0.8627272727272727, 0.8454545454545455, 0.9118181818181819, 0.8170454545454545]
2022-01-25 23:12:08:INFO:Loss = [0.46715374212521554, 0.24882012037560344, 0.36222149841910734, 0.27081318867646836, 0.43541906947397035, 0.3214311885520477, 0.379680656095628, 0.6133634545924989, 0.26614992558924394, 0.4166845810070465]
2022-01-25 23:12:08:INFO:-------------Training local models-------------
2022-01-25 23:16:45:INFO:-------------Aggregating local models-------------
2022-01-25 23:16:50:INFO:-------------Round number: 25-------------
2022-01-25 23:16:50:INFO:-------------Sending models-------------
2022-01-25 23:16:50:INFO:-------------Evaluating models-------------
2022-01-25 23:16:51:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 23:16:51:INFO:Accuracy = [0.8338636363636364, 0.9361363636363637, 0.8818181818181818, 0.9031818181818182, 0.8379545454545455, 0.9136363636363637, 0.8643181818181818, 0.845, 0.9118181818181819, 0.8190909090909091]
2022-01-25 23:16:51:INFO:Loss = [0.4660535152329513, 0.24782084856521, 0.3607746576414105, 0.26978417092256923, 0.43388323321546934, 0.32180087806191293, 0.37998532060935925, 0.6134556889533996, 0.2651357083454389, 0.4157954099990258]
2022-01-25 23:16:51:INFO:-------------Training local models-------------
2022-01-25 23:21:28:INFO:-------------Aggregating local models-------------
2022-01-25 23:21:33:INFO:-------------Round number: 26-------------
2022-01-25 23:21:33:INFO:-------------Sending models-------------
2022-01-25 23:21:34:INFO:-------------Evaluating models-------------
2022-01-25 23:21:35:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 23:21:35:INFO:Accuracy = [0.835, 0.9365909090909091, 0.8825, 0.9034090909090909, 0.8379545454545455, 0.9138636363636363, 0.8656818181818182, 0.8454545454545455, 0.9125, 0.8190909090909091]
2022-01-25 23:21:35:INFO:Loss = [0.46497204068847087, 0.24682013051986526, 0.3594332269043662, 0.2688285402265716, 0.4323867852016437, 0.3221458120335063, 0.3801938725011, 0.6134738976241682, 0.26417405995360405, 0.4150329296731136]
2022-01-25 23:21:35:INFO:-------------Training local models-------------
2022-01-25 23:26:11:INFO:-------------Aggregating local models-------------
2022-01-25 23:26:17:INFO:-------------Round number: 27-------------
2022-01-25 23:26:17:INFO:-------------Sending models-------------
2022-01-25 23:26:17:INFO:-------------Evaluating models-------------
2022-01-25 23:26:18:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 23:26:18:INFO:Accuracy = [0.8354545454545454, 0.9375, 0.8843181818181818, 0.9040909090909091, 0.8386363636363636, 0.9140909090909091, 0.8670454545454546, 0.8452272727272727, 0.9125, 0.8202272727272727]
2022-01-25 23:26:18:INFO:Loss = [0.46390737772823987, 0.24575132221533832, 0.3581802542522465, 0.26791589471130545, 0.4309291250268209, 0.32245786348781125, 0.3802946889910593, 0.6133687399433587, 0.26326948285303925, 0.4143766638103195]
2022-01-25 23:26:18:INFO:-------------Training local models-------------
2022-01-25 23:30:55:INFO:-------------Aggregating local models-------------
2022-01-25 23:31:00:INFO:-------------Round number: 28-------------
2022-01-25 23:31:00:INFO:-------------Sending models-------------
2022-01-25 23:31:01:INFO:-------------Evaluating models-------------
2022-01-25 23:31:01:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 23:31:01:INFO:Accuracy = [0.8375, 0.9379545454545455, 0.885, 0.9036363636363637, 0.8390909090909091, 0.9143181818181818, 0.8670454545454546, 0.8452272727272727, 0.913409090909091, 0.8229545454545455]
2022-01-25 23:31:01:INFO:Loss = [0.4628646878054662, 0.24471688186855647, 0.35702182244276626, 0.2670903353898955, 0.4295149689699015, 0.3227548768955537, 0.380309529106175, 0.613232332771771, 0.26241132054128685, 0.413811172593639]
2022-01-25 23:31:01:INFO:-------------Training local models-------------
2022-01-25 23:35:38:INFO:-------------Aggregating local models-------------
2022-01-25 23:35:44:INFO:-------------Round number: 29-------------
2022-01-25 23:35:44:INFO:-------------Sending models-------------
2022-01-25 23:35:44:INFO:-------------Evaluating models-------------
2022-01-25 23:35:45:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 23:35:45:INFO:Accuracy = [0.8386363636363636, 0.9379545454545455, 0.8865909090909091, 0.9034090909090909, 0.8395454545454546, 0.913409090909091, 0.8679545454545454, 0.8452272727272727, 0.9140909090909091, 0.8252272727272727]
2022-01-25 23:35:45:INFO:Loss = [0.46183551100336695, 0.24371617796873166, 0.35594448804622514, 0.26631580883192574, 0.42816198814014733, 0.3230503725988621, 0.38026673751989043, 0.6130566974466836, 0.26160327709406955, 0.41334232527085324]
2022-01-25 23:35:45:INFO:-------------Training local models-------------
2022-01-25 23:40:22:INFO:-------------Aggregating local models-------------
2022-01-25 23:40:27:INFO:-------------Round number: 30-------------
2022-01-25 23:40:27:INFO:-------------Sending models-------------
2022-01-25 23:40:28:INFO:-------------Evaluating models-------------
2022-01-25 23:40:28:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 23:40:28:INFO:Accuracy = [0.84, 0.9379545454545455, 0.8868181818181818, 0.9025, 0.8413636363636363, 0.913409090909091, 0.8681818181818182, 0.8459090909090909, 0.9140909090909091, 0.8254545454545454]
2022-01-25 23:40:28:INFO:Loss = [0.4608377686744048, 0.242740446745037, 0.35493662519041785, 0.26559304756281726, 0.4268327553571329, 0.32331957964290103, 0.38015902212778613, 0.6128522787359543, 0.2608466837015426, 0.41294601419517263]
2022-01-25 23:40:28:INFO:-------------Training local models-------------
2022-01-25 23:45:05:INFO:-------------Aggregating local models-------------
2022-01-25 23:45:10:INFO:-------------Round number: 31-------------
2022-01-25 23:45:10:INFO:-------------Sending models-------------
2022-01-25 23:45:10:INFO:-------------Evaluating models-------------
2022-01-25 23:45:11:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 23:45:11:INFO:Accuracy = [0.8413636363636363, 0.9386363636363636, 0.8884090909090909, 0.9025, 0.8415909090909091, 0.9138636363636363, 0.8695454545454545, 0.8468181818181818, 0.9145454545454546, 0.8268181818181818]
2022-01-25 23:45:11:INFO:Loss = [0.4598729675535155, 0.2417571151015264, 0.3539870458358729, 0.2649202181005173, 0.42553018833965656, 0.3235529221202755, 0.37998578985941345, 0.6126069779613648, 0.2601393499147062, 0.41261609123003756]
2022-01-25 23:45:11:INFO:-------------Training local models-------------
2022-01-25 23:49:48:INFO:-------------Aggregating local models-------------
2022-01-25 23:49:54:INFO:-------------Round number: 32-------------
2022-01-25 23:49:54:INFO:-------------Sending models-------------
2022-01-25 23:49:54:INFO:-------------Evaluating models-------------
2022-01-25 23:49:55:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 23:49:55:INFO:Accuracy = [0.8411363636363637, 0.9386363636363636, 0.8893181818181818, 0.9027272727272727, 0.8420454545454545, 0.9140909090909091, 0.8695454545454545, 0.8472727272727273, 0.9154545454545454, 0.8275]
2022-01-25 23:49:55:INFO:Loss = [0.45892526239834047, 0.24076334914107891, 0.3530930603706193, 0.2642849063257348, 0.42426331562455744, 0.3237500036336397, 0.3797369049036537, 0.6123074011993594, 0.2594676928224296, 0.41232771162705667]
2022-01-25 23:49:55:INFO:-------------Training local models-------------
2022-01-25 23:54:32:INFO:-------------Aggregating local models-------------
2022-01-25 23:54:37:INFO:-------------Round number: 33-------------
2022-01-25 23:54:37:INFO:-------------Sending models-------------
2022-01-25 23:54:37:INFO:-------------Evaluating models-------------
2022-01-25 23:54:38:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 23:54:38:INFO:Accuracy = [0.8420454545454545, 0.9386363636363636, 0.89, 0.9027272727272727, 0.8425, 0.9138636363636363, 0.87, 0.8465909090909091, 0.9163636363636364, 0.8286363636363636]
2022-01-25 23:54:38:INFO:Loss = [0.4580097564707764, 0.23976251168853857, 0.35224267057121983, 0.26368438564452595, 0.423035068631659, 0.3239257011626085, 0.3794227264440534, 0.6119762546150014, 0.25883977003025144, 0.41208849782653323]
2022-01-25 23:54:38:INFO:-------------Training local models-------------
2022-01-25 23:59:16:INFO:-------------Aggregating local models-------------
2022-01-25 23:59:21:INFO:-------------Round number: 34-------------
2022-01-25 23:59:21:INFO:-------------Sending models-------------
2022-01-25 23:59:21:INFO:-------------Evaluating models-------------
2022-01-25 23:59:22:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 23:59:22:INFO:Accuracy = [0.8434090909090909, 0.9388636363636363, 0.8906818181818181, 0.9031818181818182, 0.8434090909090909, 0.9138636363636363, 0.8711363636363636, 0.8470454545454545, 0.9165909090909091, 0.8297727272727272]
2022-01-25 23:59:22:INFO:Loss = [0.45713187196736477, 0.2387861190818843, 0.35143367848147383, 0.2631283779655033, 0.4218489282700995, 0.32409223059869624, 0.3790497127158398, 0.6116430633849549, 0.2582537903503345, 0.4118891323948364]
2022-01-25 23:59:22:INFO:-------------Training local models-------------
2022-01-26 00:03:59:INFO:-------------Aggregating local models-------------
2022-01-26 00:04:04:INFO:-------------Round number: 35-------------
2022-01-26 00:04:04:INFO:-------------Sending models-------------
2022-01-26 00:04:05:INFO:-------------Evaluating models-------------
2022-01-26 00:04:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 00:04:05:INFO:Accuracy = [0.8443181818181819, 0.9388636363636363, 0.8915909090909091, 0.9029545454545455, 0.8445454545454546, 0.9138636363636363, 0.8722727272727273, 0.8475, 0.9179545454545455, 0.8309090909090909]
2022-01-26 00:04:05:INFO:Loss = [0.4562908995303918, 0.2378109682817012, 0.35065139958804303, 0.26262056350718593, 0.42068790088206615, 0.3242374472669326, 0.3786337557248771, 0.6113024503744038, 0.2577051747801968, 0.41172643793873825]
2022-01-26 00:04:05:INFO:-------------Training local models-------------
2022-01-26 00:08:43:INFO:-------------Aggregating local models-------------
2022-01-26 00:08:48:INFO:-------------Round number: 36-------------
2022-01-26 00:08:48:INFO:-------------Sending models-------------
2022-01-26 00:08:48:INFO:-------------Evaluating models-------------
2022-01-26 00:08:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 00:08:49:INFO:Accuracy = [0.8461363636363637, 0.9388636363636363, 0.8922727272727272, 0.9031818181818182, 0.8470454545454545, 0.9140909090909091, 0.8731818181818182, 0.8477272727272728, 0.9188636363636363, 0.831590909090909]
2022-01-26 00:08:49:INFO:Loss = [0.4554727161112665, 0.23685559030960907, 0.34990751763318917, 0.2621617613302078, 0.419563514218581, 0.32438141895479267, 0.3781752314344472, 0.6109731407687915, 0.2571943456248846, 0.41159634928070854]
2022-01-26 00:08:49:INFO:-------------Training local models-------------
2022-01-26 00:13:26:INFO:-------------Aggregating local models-------------
2022-01-26 00:13:31:INFO:-------------Round number: 37-------------
2022-01-26 00:13:31:INFO:-------------Sending models-------------
2022-01-26 00:13:32:INFO:-------------Evaluating models-------------
2022-01-26 00:13:32:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 00:13:32:INFO:Accuracy = [0.8468181818181818, 0.9388636363636363, 0.8927272727272727, 0.9036363636363637, 0.8475, 0.9145454545454546, 0.8731818181818182, 0.8486363636363636, 0.9197727272727273, 0.8325]
2022-01-26 00:13:32:INFO:Loss = [0.4546693985726134, 0.23598005478058687, 0.3492075611286881, 0.2617841734074649, 0.41847314218069764, 0.32450925086476756, 0.37769099809335205, 0.6107102564620701, 0.2567212936029219, 0.4114964575379748]
2022-01-26 00:13:32:INFO:-------------Training local models-------------
2022-01-26 00:18:10:INFO:-------------Aggregating local models-------------
2022-01-26 00:18:15:INFO:-------------Round number: 38-------------
2022-01-26 00:18:15:INFO:-------------Sending models-------------
2022-01-26 00:18:15:INFO:-------------Evaluating models-------------
2022-01-26 00:18:16:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 00:18:16:INFO:Accuracy = [0.8481818181818181, 0.9390909090909091, 0.8931818181818182, 0.9031818181818182, 0.8479545454545454, 0.9143181818181818, 0.8736363636363637, 0.8488636363636364, 0.9206818181818182, 0.8338636363636364]
2022-01-26 00:18:16:INFO:Loss = [0.453907560959289, 0.23511507629247552, 0.3485341221083548, 0.26144954824439165, 0.4174220737890044, 0.324631427667654, 0.37716013515706764, 0.6104777532777834, 0.25628065174519593, 0.41142096784156323]
2022-01-26 00:18:16:INFO:-------------Training local models-------------
2022-01-26 00:22:53:INFO:-------------Aggregating local models-------------
2022-01-26 00:22:58:INFO:-------------Round number: 39-------------
2022-01-26 00:22:58:INFO:-------------Sending models-------------
2022-01-26 00:22:58:INFO:-------------Evaluating models-------------
2022-01-26 00:22:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 00:22:59:INFO:Accuracy = [0.8486363636363636, 0.9390909090909091, 0.8943181818181818, 0.9029545454545455, 0.8475, 0.9145454545454546, 0.8754545454545455, 0.8504545454545455, 0.9215909090909091, 0.8345454545454546]
2022-01-26 00:22:59:INFO:Loss = [0.4532761668881655, 0.23427726948760788, 0.34789157483239913, 0.26118450147015126, 0.41638652402960524, 0.3247631195297634, 0.3766053730981763, 0.6103087194041688, 0.25591161832350984, 0.4113586998989128]
2022-01-26 00:22:59:INFO:-------------Training local models-------------
2022-01-26 00:27:36:INFO:-------------Aggregating local models-------------
