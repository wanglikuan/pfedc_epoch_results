2022-01-25 12:14:20:INFO:-------------Round number: 0-------------
2022-01-25 12:14:20:INFO:-------------Sending models-------------
2022-01-25 12:14:21:INFO:-------------Evaluating models-------------
2022-01-25 12:14:21:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:14:21:INFO:Accuracy = [0.901010101010101, 0.8868686868686869, 0.896969696969697, 0.898989898989899, 0.901010101010101, 0.08888888888888889, 0.09494949494949495, 0.10303030303030303, 0.09696969696969697, 0.898989898989899]
2022-01-25 12:14:21:INFO:Loss = [0.6694116484637213, 0.653408883798002, 0.6615643211988488, 0.6542965058425461, 0.6641762230733428, 0.7379018910304465, 0.7407228308795678, 0.7419946313205391, 0.7473327146335081, 0.669854687109138]
2022-01-25 12:14:21:INFO:-------------Training local models-------------
2022-01-25 12:50:43:INFO:-------------Aggregating local models-------------
2022-01-25 12:50:46:INFO:-------------Round number: 1-------------
2022-01-25 12:50:46:INFO:-------------Sending models-------------
2022-01-25 12:50:46:INFO:-------------Evaluating models-------------
2022-01-25 12:50:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:50:47:INFO:Accuracy = [0.9606060606060606, 0.9474747474747475, 0.9040404040404041, 0.9030303030303031, 0.9585858585858585, 0.9393939393939394, 0.9191919191919192, 0.9267676767676768, 0.9222222222222223, 0.9202020202020202]
2022-01-25 12:50:47:INFO:Loss = [0.07412150737175699, 0.09611789464898822, 0.17915448514471827, 0.1730465033424388, 0.13213449725187432, 0.1426663027848164, 0.14094726834234528, 0.13287169091130674, 0.1564289048429334, 0.19168234281759294]
2022-01-25 12:50:47:INFO:-------------Training local models-------------
2022-01-25 13:29:14:INFO:-------------Aggregating local models-------------
2022-01-25 13:29:17:INFO:-------------Round number: 2-------------
2022-01-25 13:29:17:INFO:-------------Sending models-------------
2022-01-25 13:29:17:INFO:-------------Evaluating models-------------
2022-01-25 13:29:18:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:29:18:INFO:Accuracy = [0.9954545454545455, 0.9924242424242424, 0.9212121212121213, 0.9217171717171717, 0.9838383838383838, 0.9818181818181818, 0.9702020202020202, 0.9737373737373738, 0.954040404040404, 0.9393939393939394]
2022-01-25 13:29:18:INFO:Loss = [0.02715595775134532, 0.03697294542234335, 0.12853058065150186, 0.12488489859544018, 0.06436170053502517, 0.07112861371456852, 0.06702398646186633, 0.06140744043625844, 0.10549506691168062, 0.12468729018059682]
2022-01-25 13:29:18:INFO:-------------Training local models-------------
2022-01-25 14:07:37:INFO:-------------Aggregating local models-------------
2022-01-25 14:07:40:INFO:-------------Round number: 3-------------
2022-01-25 14:07:40:INFO:-------------Sending models-------------
2022-01-25 14:07:40:INFO:-------------Evaluating models-------------
2022-01-25 14:07:41:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:07:41:INFO:Accuracy = [1.0, 0.9984848484848485, 0.9424242424242424, 0.9444444444444444, 0.9944444444444445, 0.9934343434343434, 0.98989898989899, 0.9929292929292929, 0.9616161616161616, 0.9585858585858585]
2022-01-25 14:07:41:INFO:Loss = [0.013730380283033644, 0.018642090210006713, 0.09994641372474201, 0.09760881803075505, 0.037939401186598144, 0.0413122724464476, 0.041590268537813724, 0.03782075135022016, 0.08289496586878545, 0.09701936668916276]
2022-01-25 14:07:41:INFO:-------------Training local models-------------
2022-01-25 14:45:59:INFO:-------------Aggregating local models-------------
2022-01-25 14:46:01:INFO:-------------Round number: 4-------------
2022-01-25 14:46:02:INFO:-------------Sending models-------------
2022-01-25 14:46:02:INFO:-------------Evaluating models-------------
2022-01-25 14:46:03:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:46:03:INFO:Accuracy = [1.0, 1.0, 0.952020202020202, 0.9525252525252526, 0.9949494949494949, 0.9949494949494949, 0.9949494949494949, 0.9949494949494949, 0.9651515151515152, 0.9631313131313132]
2022-01-25 14:46:03:INFO:Loss = [0.008714925527462097, 0.01170983876473849, 0.08119606898069814, 0.07972609545914115, 0.02630306531741599, 0.028039630900655702, 0.028464212833616807, 0.025884794913975502, 0.06863973638784514, 0.08084327588275292]
2022-01-25 14:46:03:INFO:-------------Training local models-------------
2022-01-25 15:24:22:INFO:-------------Aggregating local models-------------
2022-01-25 15:24:24:INFO:-------------Round number: 5-------------
2022-01-25 15:24:24:INFO:-------------Sending models-------------
2022-01-25 15:24:25:INFO:-------------Evaluating models-------------
2022-01-25 15:24:25:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:24:25:INFO:Accuracy = [1.0, 1.0, 0.9631313131313132, 0.9646464646464646, 0.9954545454545455, 0.9959595959595959, 0.9959595959595959, 0.9974747474747475, 0.9717171717171718, 0.9651515151515152]
2022-01-25 15:24:25:INFO:Loss = [0.00624717500177212, 0.008329744423848972, 0.06788729534791947, 0.06722496440979556, 0.020052493816947757, 0.02102143357594902, 0.02108780402464397, 0.01937386743419197, 0.05846114540734267, 0.06905215837674643]
2022-01-25 15:24:25:INFO:-------------Training local models-------------
2022-01-25 16:02:42:INFO:-------------Aggregating local models-------------
2022-01-25 16:02:45:INFO:-------------Round number: 6-------------
2022-01-25 16:02:45:INFO:-------------Sending models-------------
2022-01-25 16:02:46:INFO:-------------Evaluating models-------------
2022-01-25 16:02:46:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 16:02:46:INFO:Accuracy = [1.0, 1.0, 0.9727272727272728, 0.9717171717171718, 0.9974747474747475, 0.9974747474747475, 0.9974747474747475, 0.9974747474747475, 0.9777777777777777, 0.9681818181818181]
2022-01-25 16:02:46:INFO:Loss = [0.004808638856018367, 0.006374936483152484, 0.058547091604115774, 0.058510082398711485, 0.01622274764759097, 0.016793561724544916, 0.016764818243164982, 0.015572002597154362, 0.05077779753610781, 0.059863839413373345]
2022-01-25 16:02:46:INFO:-------------Training local models-------------
2022-01-25 16:41:04:INFO:-------------Aggregating local models-------------
2022-01-25 16:41:07:INFO:-------------Round number: 7-------------
2022-01-25 16:41:07:INFO:-------------Sending models-------------
2022-01-25 16:41:08:INFO:-------------Evaluating models-------------
2022-01-25 16:41:08:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 16:41:08:INFO:Accuracy = [1.0, 1.0, 0.9762626262626263, 0.9747474747474747, 0.997979797979798, 0.9974747474747475, 0.996969696969697, 0.9974747474747475, 0.9828282828282828, 0.9762626262626263]
2022-01-25 16:41:08:INFO:Loss = [0.0038754298391245126, 0.005111878322886604, 0.052114336463787964, 0.05249522970846767, 0.013671614891614864, 0.014016257870896493, 0.014011818705102538, 0.013133747344795436, 0.04503698243823954, 0.05245431444501549]
2022-01-25 16:41:08:INFO:-------------Training local models-------------
2022-01-25 17:19:26:INFO:-------------Aggregating local models-------------
2022-01-25 17:19:29:INFO:-------------Round number: 8-------------
2022-01-25 17:19:29:INFO:-------------Sending models-------------
2022-01-25 17:19:30:INFO:-------------Evaluating models-------------
2022-01-25 17:19:30:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 17:19:30:INFO:Accuracy = [1.0, 1.0, 0.9782828282828283, 0.9782828282828283, 0.9984848484848485, 0.9984848484848485, 0.996969696969697, 0.9974747474747475, 0.9838383838383838, 0.9803030303030303]
2022-01-25 17:19:30:INFO:Loss = [0.0032266562336125655, 0.004236071741145523, 0.04759203074108974, 0.04823298277871359, 0.011872624314569155, 0.012079901988335856, 0.012114581438439964, 0.01143900504027966, 0.040852102865880965, 0.04657963647457449]
2022-01-25 17:19:30:INFO:-------------Training local models-------------
2022-01-25 17:57:47:INFO:-------------Aggregating local models-------------
2022-01-25 17:57:50:INFO:-------------Round number: 9-------------
2022-01-25 17:57:50:INFO:-------------Sending models-------------
2022-01-25 17:57:51:INFO:-------------Evaluating models-------------
2022-01-25 17:57:51:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 17:57:51:INFO:Accuracy = [1.0, 1.0, 0.9797979797979798, 0.9797979797979798, 0.998989898989899, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9858585858585859, 0.9828282828282828]
2022-01-25 17:57:51:INFO:Loss = [0.002753857360750606, 0.0035984376638997207, 0.04423450318384431, 0.04501887329073118, 0.0105417467866518, 0.010660673384435623, 0.01073329381428211, 0.010195497501858468, 0.03781735839530493, 0.04209704204930482]
2022-01-25 17:57:51:INFO:-------------Training local models-------------
2022-01-25 18:36:04:INFO:-------------Aggregating local models-------------
2022-01-25 18:36:07:INFO:-------------Round number: 10-------------
2022-01-25 18:36:07:INFO:-------------Sending models-------------
2022-01-25 18:36:07:INFO:-------------Evaluating models-------------
2022-01-25 18:36:08:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 18:36:08:INFO:Accuracy = [1.0, 1.0, 0.9813131313131314, 0.9813131313131314, 0.998989898989899, 0.9994949494949495, 0.9974747474747475, 0.9974747474747475, 0.9858585858585859, 0.9853535353535353]
2022-01-25 18:36:08:INFO:Loss = [0.002396178863956734, 0.0031162789216114565, 0.04160324391001139, 0.04246046068916313, 0.009525306744571844, 0.009587047933437684, 0.009684825180172791, 0.009245782571558421, 0.03551520928911744, 0.03868605257433808]
2022-01-25 18:36:08:INFO:-------------Training local models-------------
2022-01-25 19:14:18:INFO:-------------Aggregating local models-------------
2022-01-25 19:14:21:INFO:-------------Round number: 11-------------
2022-01-25 19:14:21:INFO:-------------Sending models-------------
2022-01-25 19:14:22:INFO:-------------Evaluating models-------------
2022-01-25 19:14:22:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 19:14:22:INFO:Accuracy = [1.0, 1.0, 0.9828282828282828, 0.9828282828282828, 0.9994949494949495, 0.9994949494949495, 0.9974747474747475, 0.9974747474747475, 0.9868686868686869, 0.9858585858585859]
2022-01-25 19:14:22:INFO:Loss = [0.00211792076619476, 0.002741169476351875, 0.03944550806053384, 0.040333414823919264, 0.008721728339378846, 0.008745092010301023, 0.008863415597722515, 0.00849887408789293, 0.03371986270441369, 0.03608399905927886]
2022-01-25 19:14:22:INFO:-------------Training local models-------------
2022-01-25 19:52:36:INFO:-------------Aggregating local models-------------
2022-01-25 19:52:39:INFO:-------------Round number: 12-------------
2022-01-25 19:52:39:INFO:-------------Sending models-------------
2022-01-25 19:52:39:INFO:-------------Evaluating models-------------
2022-01-25 19:52:40:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 19:52:40:INFO:Accuracy = [1.0, 1.0, 0.9838383838383838, 0.9838383838383838, 0.9994949494949495, 0.9994949494949495, 0.9974747474747475, 0.9974747474747475, 0.9873737373737373, 0.9878787878787879]
2022-01-25 19:52:40:INFO:Loss = [0.0018962843579826924, 0.0024425688695492967, 0.037640439051881344, 0.03853153570064501, 0.0080646472684895, 0.008062392499744999, 0.008201714048599837, 0.00789526291232735, 0.03229292151829415, 0.03408552396458525]
2022-01-25 19:52:40:INFO:-------------Training local models-------------
2022-01-25 20:30:56:INFO:-------------Aggregating local models-------------
2022-01-25 20:30:58:INFO:-------------Round number: 13-------------
2022-01-25 20:30:58:INFO:-------------Sending models-------------
2022-01-25 20:30:59:INFO:-------------Evaluating models-------------
2022-01-25 20:31:00:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 20:31:00:INFO:Accuracy = [1.0, 1.0, 0.9843434343434343, 0.9843434343434343, 0.9994949494949495, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9878787878787879, 0.9878787878787879]
2022-01-25 20:31:00:INFO:Loss = [0.0017172216056320448, 0.002201608460172517, 0.036103033898792214, 0.036986092716148104, 0.007520061341626452, 0.007499299960688928, 0.0076598105790602715, 0.007399670775784115, 0.031124967996036486, 0.03251361349557004]
2022-01-25 20:31:00:INFO:-------------Training local models-------------
2022-01-25 21:09:13:INFO:-------------Aggregating local models-------------
2022-01-25 21:09:16:INFO:-------------Round number: 14-------------
2022-01-25 21:09:16:INFO:-------------Sending models-------------
2022-01-25 21:09:17:INFO:-------------Evaluating models-------------
2022-01-25 21:09:17:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 21:09:17:INFO:Accuracy = [1.0, 1.0, 0.9853535353535353, 0.9838383838383838, 0.9994949494949495, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9878787878787879, 0.9878787878787879]
2022-01-25 21:09:17:INFO:Loss = [0.0015696733593505647, 0.0020031490597407675, 0.03477814138491845, 0.03564487908767449, 0.007063527770228437, 0.00702947273252857, 0.007206295388004028, 0.006983848334409295, 0.030194533888270873, 0.0312857325572016]
2022-01-25 21:09:17:INFO:-------------Training local models-------------
2022-01-25 21:47:24:INFO:-------------Aggregating local models-------------
2022-01-25 21:47:27:INFO:-------------Round number: 15-------------
2022-01-25 21:47:27:INFO:-------------Sending models-------------
2022-01-25 21:47:27:INFO:-------------Evaluating models-------------
2022-01-25 21:47:28:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 21:47:28:INFO:Accuracy = [1.0, 1.0, 0.9853535353535353, 0.9848484848484849, 0.9994949494949495, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9883838383838384, 0.9883838383838384]
2022-01-25 21:47:28:INFO:Loss = [0.0014463679313793721, 0.0018374017445221215, 0.03362062067311431, 0.034464363916685205, 0.006675498585261239, 0.00663266792534242, 0.006821333942030888, 0.006630083647854403, 0.029453524940831217, 0.03032615875638316]
2022-01-25 21:47:28:INFO:-------------Training local models-------------
2022-01-25 22:25:40:INFO:-------------Aggregating local models-------------
2022-01-25 22:25:43:INFO:-------------Round number: 16-------------
2022-01-25 22:25:43:INFO:-------------Sending models-------------
2022-01-25 22:25:44:INFO:-------------Evaluating models-------------
2022-01-25 22:25:44:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 22:25:44:INFO:Accuracy = [1.0, 1.0, 0.9858585858585859, 0.9853535353535353, 0.9994949494949495, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9878787878787879, 0.9893939393939394]
2022-01-25 22:25:44:INFO:Loss = [0.0013419781545411698, 0.0016971642312207471, 0.03261135033459104, 0.03342765151665854, 0.006343035252685888, 0.00629502542506456, 0.006489278764932562, 0.006324207054131701, 0.02883605829466442, 0.029550031152029987]
2022-01-25 22:25:44:INFO:-------------Training local models-------------
2022-01-25 23:03:58:INFO:-------------Aggregating local models-------------
2022-01-25 23:04:00:INFO:-------------Round number: 17-------------
2022-01-25 23:04:00:INFO:-------------Sending models-------------
2022-01-25 23:04:01:INFO:-------------Evaluating models-------------
2022-01-25 23:04:01:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 23:04:01:INFO:Accuracy = [1.0, 1.0, 0.9858585858585859, 0.9863636363636363, 0.9994949494949495, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9883838383838384, 0.98989898989899]
2022-01-25 23:04:01:INFO:Loss = [0.0012525602505260706, 0.0015773333659594893, 0.031712775096479386, 0.03250323507612609, 0.006057408958955108, 0.006006024104095155, 0.006201344515401882, 0.006058364585069193, 0.028296046085163864, 0.028889460017238192]
2022-01-25 23:04:02:INFO:-------------Training local models-------------
2022-01-25 23:42:14:INFO:-------------Aggregating local models-------------
2022-01-25 23:42:17:INFO:-------------Round number: 18-------------
2022-01-25 23:42:17:INFO:-------------Sending models-------------
2022-01-25 23:42:17:INFO:-------------Evaluating models-------------
2022-01-25 23:42:18:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 23:42:18:INFO:Accuracy = [1.0, 1.0, 0.9858585858585859, 0.9868686868686869, 0.9994949494949495, 0.998989898989899, 0.997979797979798, 0.9974747474747475, 0.9888888888888889, 0.98989898989899]
2022-01-25 23:42:18:INFO:Loss = [0.001175267895781541, 0.0014740251831803235, 0.03090588929709441, 0.03167371323395102, 0.005808057796222251, 0.005754362647789866, 0.005948758667705768, 0.005824115798157326, 0.02786036477081132, 0.02835830675110702]
2022-01-25 23:42:18:INFO:-------------Training local models-------------
2022-01-26 00:20:31:INFO:-------------Aggregating local models-------------
2022-01-26 00:20:34:INFO:-------------Round number: 19-------------
2022-01-26 00:20:34:INFO:-------------Sending models-------------
2022-01-26 00:20:34:INFO:-------------Evaluating models-------------
2022-01-26 00:20:35:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 00:20:35:INFO:Accuracy = [1.0, 1.0, 0.9863636363636363, 0.9868686868686869, 0.9994949494949495, 0.998989898989899, 0.997979797979798, 0.9974747474747475, 0.9893939393939394, 0.9893939393939394]
2022-01-26 00:20:35:INFO:Loss = [0.001107682198360433, 0.0013838488887583911, 0.03019134461483374, 0.03093543287539598, 0.005588324969758473, 0.005532925354187187, 0.005725229430093102, 0.00561604351188924, 0.027489754241792577, 0.027917476160405616]
2022-01-26 00:20:35:INFO:-------------Training local models-------------
2022-01-26 00:58:47:INFO:-------------Aggregating local models-------------
2022-01-26 00:58:50:INFO:-------------Round number: 20-------------
2022-01-26 00:58:50:INFO:-------------Sending models-------------
2022-01-26 00:58:51:INFO:-------------Evaluating models-------------
2022-01-26 00:58:51:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 00:58:51:INFO:Accuracy = [1.0, 1.0, 0.9863636363636363, 0.9873737373737373, 0.998989898989899, 0.998989898989899, 0.997979797979798, 0.9974747474747475, 0.98989898989899, 0.9893939393939394]
2022-01-26 00:58:51:INFO:Loss = [0.0010481967173006405, 0.0013045679952336635, 0.029559620046300073, 0.0302745211807357, 0.005395786501134298, 0.005338998837499395, 0.005525432502687145, 0.005429379316656839, 0.0271695482913176, 0.02754176054395705]
2022-01-26 00:58:51:INFO:-------------Training local models-------------
2022-01-26 01:32:48:INFO:-------------Aggregating local models-------------
2022-01-26 01:32:50:INFO:-------------Round number: 21-------------
2022-01-26 01:32:50:INFO:-------------Sending models-------------
2022-01-26 01:32:50:INFO:-------------Evaluating models-------------
2022-01-26 01:32:51:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 01:32:51:INFO:Accuracy = [1.0, 1.0, 0.9868686868686869, 0.9873737373737373, 0.998989898989899, 0.998989898989899, 0.997979797979798, 0.9974747474747475, 0.98989898989899, 0.9893939393939394]
2022-01-26 01:32:51:INFO:Loss = [0.000995529458275702, 0.001234485556668722, 0.028986513353091214, 0.029674836863852413, 0.0052257656480658695, 0.005168341062568344, 0.005346975442866685, 0.0052622356284737545, 0.026922704189766795, 0.027243164717146277]
2022-01-26 01:32:51:INFO:-------------Training local models-------------
2022-01-26 02:01:26:INFO:-------------Aggregating local models-------------
2022-01-26 02:01:28:INFO:-------------Round number: 22-------------
2022-01-26 02:01:28:INFO:-------------Sending models-------------
2022-01-26 02:01:28:INFO:-------------Evaluating models-------------
2022-01-26 02:01:28:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 02:01:28:INFO:Accuracy = [1.0, 1.0, 0.9873737373737373, 0.9873737373737373, 0.998989898989899, 0.998989898989899, 0.997979797979798, 0.9974747474747475, 0.98989898989899, 0.9888888888888889]
2022-01-26 02:01:28:INFO:Loss = [0.0009485690205606674, 0.0011721328544625049, 0.028470162667317618, 0.02913274673510111, 0.005073331523990327, 0.005016115754805276, 0.005186157609021374, 0.005111176980992443, 0.026730103740030448, 0.027004469084983218]
2022-01-26 02:01:28:INFO:-------------Training local models-------------
2022-01-26 02:30:03:INFO:-------------Aggregating local models-------------
2022-01-26 02:30:05:INFO:-------------Round number: 23-------------
2022-01-26 02:30:05:INFO:-------------Sending models-------------
2022-01-26 02:30:06:INFO:-------------Evaluating models-------------
2022-01-26 02:30:06:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 02:30:06:INFO:Accuracy = [1.0, 1.0, 0.9878787878787879, 0.9873737373737373, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9893939393939394, 0.9883838383838384]
2022-01-26 02:30:06:INFO:Loss = [0.0009065022035851731, 0.0011163795939699577, 0.02800259830369076, 0.028640636114371343, 0.004937232560236354, 0.004881102286019472, 0.005040062050521197, 0.004973571095777314, 0.026568793298043382, 0.026805144714675443]
2022-01-26 02:30:06:INFO:-------------Training local models-------------
2022-01-26 02:58:41:INFO:-------------Aggregating local models-------------
2022-01-26 02:58:43:INFO:-------------Round number: 24-------------
2022-01-26 02:58:43:INFO:-------------Sending models-------------
2022-01-26 02:58:43:INFO:-------------Evaluating models-------------
2022-01-26 02:58:44:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 02:58:44:INFO:Accuracy = [1.0, 1.0, 0.9878787878787879, 0.9878787878787879, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9883838383838384, 0.9888888888888889]
2022-01-26 02:58:44:INFO:Loss = [0.0008685080967625988, 0.0010661085165559075, 0.027582826013663592, 0.028194765039811363, 0.004815947681764197, 0.004761337287025967, 0.004906513230720649, 0.004847570579769319, 0.02643495056869105, 0.02663815393951687]
2022-01-26 02:58:44:INFO:-------------Training local models-------------
2022-01-26 03:19:11:INFO:-------------Aggregating local models-------------
2022-01-26 03:19:12:INFO:-------------Round number: 25-------------
2022-01-26 03:19:12:INFO:-------------Sending models-------------
2022-01-26 03:19:13:INFO:-------------Evaluating models-------------
2022-01-26 03:19:13:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 03:19:13:INFO:Accuracy = [1.0, 1.0, 0.9878787878787879, 0.9878787878787879, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9888888888888889, 0.9888888888888889]
2022-01-26 03:19:13:INFO:Loss = [0.0008341296597570887, 0.0010207265896138833, 0.02719312578036154, 0.027779458824057437, 0.004705925437527258, 0.0046520937561011794, 0.004784403238491822, 0.004732066569127397, 0.026328480567266378, 0.026499792756118096]
2022-01-26 03:19:13:INFO:-------------Training local models-------------
2022-01-26 03:38:14:INFO:-------------Aggregating local models-------------
2022-01-26 03:38:16:INFO:-------------Round number: 26-------------
2022-01-26 03:38:16:INFO:-------------Sending models-------------
2022-01-26 03:38:16:INFO:-------------Evaluating models-------------
2022-01-26 03:38:16:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 03:38:16:INFO:Accuracy = [1.0, 1.0, 0.9883838383838384, 0.9883838383838384, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9893939393939394, 0.9893939393939394]
2022-01-26 03:38:16:INFO:Loss = [0.0008029457779864033, 0.0009796487215249046, 0.026846154307948913, 0.02740675264182452, 0.004605293634695687, 0.004552472631994625, 0.004672327055353283, 0.004625849356965075, 0.026244030726714603, 0.026387933262293415]
2022-01-26 03:38:16:INFO:-------------Training local models-------------
2022-01-26 03:57:18:INFO:-------------Aggregating local models-------------
2022-01-26 03:57:19:INFO:-------------Round number: 27-------------
2022-01-26 03:57:19:INFO:-------------Sending models-------------
2022-01-26 03:57:20:INFO:-------------Evaluating models-------------
2022-01-26 03:57:20:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 03:57:20:INFO:Accuracy = [1.0, 1.0, 0.9883838383838384, 0.9883838383838384, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9893939393939394, 0.9893939393939394]
2022-01-26 03:57:20:INFO:Loss = [0.0007744876180588494, 0.0009422750900601827, 0.026527036528965587, 0.02706227778972706, 0.0045145228553126505, 0.004462407965409952, 0.004568883115482297, 0.0045274908870906625, 0.026182306629674013, 0.02630137919905158]
2022-01-26 03:57:20:INFO:-------------Training local models-------------
2022-01-26 04:16:22:INFO:-------------Aggregating local models-------------
2022-01-26 04:16:23:INFO:-------------Round number: 28-------------
2022-01-26 04:16:23:INFO:-------------Sending models-------------
2022-01-26 04:16:23:INFO:-------------Evaluating models-------------
2022-01-26 04:16:24:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 04:16:24:INFO:Accuracy = [1.0, 1.0, 0.9883838383838384, 0.9883838383838384, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9893939393939394, 0.98989898989899]
2022-01-26 04:16:24:INFO:Loss = [0.0007483594921080047, 0.0009080765214075471, 0.026239215410536455, 0.02674856874886925, 0.004430833941233971, 0.004379293928297667, 0.004473394020525956, 0.004436279279258143, 0.02613805638881942, 0.026236050964540812]
2022-01-26 04:16:24:INFO:-------------Training local models-------------
2022-01-26 04:35:25:INFO:-------------Aggregating local models-------------
2022-01-26 04:35:27:INFO:-------------Round number: 29-------------
2022-01-26 04:35:27:INFO:-------------Sending models-------------
2022-01-26 04:35:27:INFO:-------------Evaluating models-------------
2022-01-26 04:35:27:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 04:35:27:INFO:Accuracy = [1.0, 1.0, 0.9888888888888889, 0.9883838383838384, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.98989898989899, 0.9904040404040404]
2022-01-26 04:35:27:INFO:Loss = [0.0007244110790626945, 0.0008767887474213506, 0.025972661085618923, 0.026457398878499756, 0.004353762342268028, 0.004302479128045429, 0.004385628728770752, 0.004352299990243795, 0.02610290736617452, 0.026179674415118027]
2022-01-26 04:35:27:INFO:-------------Training local models-------------
2022-01-26 04:54:29:INFO:-------------Aggregating local models-------------
2022-01-26 04:54:30:INFO:-------------Round number: 30-------------
2022-01-26 04:54:30:INFO:-------------Sending models-------------
2022-01-26 04:54:31:INFO:-------------Evaluating models-------------
2022-01-26 04:54:31:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 04:54:31:INFO:Accuracy = [1.0, 1.0, 0.9888888888888889, 0.9883838383838384, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9893939393939394, 0.9904040404040404]
2022-01-26 04:54:31:INFO:Loss = [0.0007022412968746555, 0.0008479194547684106, 0.025710330289150832, 0.026172039137715975, 0.0042827325966911045, 0.004231676730955539, 0.004303850569066517, 0.004273966198697871, 0.026080195766024356, 0.026139060920556376]
2022-01-26 04:54:31:INFO:-------------Training local models-------------
2022-01-26 05:13:33:INFO:-------------Aggregating local models-------------
2022-01-26 05:13:34:INFO:-------------Round number: 31-------------
2022-01-26 05:13:34:INFO:-------------Sending models-------------
2022-01-26 05:13:34:INFO:-------------Evaluating models-------------
2022-01-26 05:13:35:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 05:13:35:INFO:Accuracy = [1.0, 1.0, 0.9888888888888889, 0.9883838383838384, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9893939393939394, 0.98989898989899]
2022-01-26 05:13:35:INFO:Loss = [0.0006816214320302477, 0.00082115450504808, 0.025468092485006668, 0.025911176329522865, 0.00421831256909457, 0.004167113875680823, 0.004227763829698638, 0.004200956374653389, 0.026060210809347808, 0.026103702869817186]
2022-01-26 05:13:35:INFO:-------------Training local models-------------
2022-01-26 05:32:36:INFO:-------------Aggregating local models-------------
2022-01-26 05:32:38:INFO:-------------Round number: 32-------------
2022-01-26 05:32:38:INFO:-------------Sending models-------------
2022-01-26 05:32:38:INFO:-------------Evaluating models-------------
2022-01-26 05:32:38:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 05:32:38:INFO:Accuracy = [1.0, 1.0, 0.9888888888888889, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.98989898989899, 0.98989898989899]
2022-01-26 05:32:38:INFO:Loss = [0.0006623919669161268, 0.0007962435493964497, 0.025250255175316594, 0.025678312249446476, 0.00416061271535551, 0.004108806955896352, 0.004156590349861051, 0.004132407564505073, 0.02605533403839585, 0.026084666989676535]
2022-01-26 05:32:38:INFO:-------------Training local models-------------
2022-01-26 05:51:01:INFO:-------------Aggregating local models-------------
2022-01-26 05:51:02:INFO:-------------Round number: 33-------------
2022-01-26 05:51:02:INFO:-------------Sending models-------------
2022-01-26 05:51:03:INFO:-------------Evaluating models-------------
2022-01-26 05:51:03:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 05:51:03:INFO:Accuracy = [1.0, 1.0, 0.9888888888888889, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9904040404040404, 0.98989898989899]
2022-01-26 05:51:03:INFO:Loss = [0.0006444413565086599, 0.0007730229200637721, 0.025044915899907393, 0.02545976520052338, 0.004108867045562709, 0.004056290136033586, 0.004090090617445998, 0.004068256051139524, 0.026049521885147673, 0.026064848045588764]
2022-01-26 05:51:03:INFO:-------------Training local models-------------
2022-01-26 06:10:03:INFO:-------------Aggregating local models-------------
2022-01-26 06:10:04:INFO:-------------Round number: 34-------------
2022-01-26 06:10:04:INFO:-------------Sending models-------------
2022-01-26 06:10:04:INFO:-------------Evaluating models-------------
2022-01-26 06:10:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 06:10:05:INFO:Accuracy = [1.0, 1.0, 0.9893939393939394, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9904040404040404, 0.9904040404040404]
2022-01-26 06:10:05:INFO:Loss = [0.0006276385121100707, 0.000751372362716174, 0.024857805300403796, 0.02526077182826129, 0.004060032525797057, 0.004006726512792132, 0.004027771972474199, 0.004008048991996438, 0.026048146091115904, 0.026050649599600354]
2022-01-26 06:10:05:INFO:-------------Training local models-------------
2022-01-26 06:29:04:INFO:-------------Aggregating local models-------------
2022-01-26 06:29:06:INFO:-------------Round number: 35-------------
2022-01-26 06:29:06:INFO:-------------Sending models-------------
2022-01-26 06:29:06:INFO:-------------Evaluating models-------------
2022-01-26 06:29:06:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 06:29:06:INFO:Accuracy = [1.0, 1.0, 0.98989898989899, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9904040404040404, 0.990909090909091]
2022-01-26 06:29:06:INFO:Loss = [0.0006119484226428081, 0.0007312072910942582, 0.02467694635179765, 0.02506800676652861, 0.004014009492416473, 0.0039597668255627275, 0.003969157775654913, 0.003951385078962079, 0.026042707723223944, 0.02603340160636766]
2022-01-26 06:29:06:INFO:-------------Training local models-------------
2022-01-26 06:48:07:INFO:-------------Aggregating local models-------------
2022-01-26 06:48:08:INFO:-------------Round number: 36-------------
2022-01-26 06:48:08:INFO:-------------Sending models-------------
2022-01-26 06:48:08:INFO:-------------Evaluating models-------------
2022-01-26 06:48:08:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 06:48:08:INFO:Accuracy = [1.0, 1.0, 0.98989898989899, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9904040404040404, 0.990909090909091]
2022-01-26 06:48:08:INFO:Loss = [0.0005972633844250613, 0.0007123768265092172, 0.024511933231817717, 0.024891372888413744, 0.00397185653694973, 0.003916625079079375, 0.003914072070515293, 0.0038981881340041215, 0.026041988932600436, 0.026022513008727842]
2022-01-26 06:48:08:INFO:-------------Training local models-------------
2022-01-26 07:07:08:INFO:-------------Aggregating local models-------------
2022-01-26 07:07:10:INFO:-------------Round number: 37-------------
2022-01-26 07:07:10:INFO:-------------Sending models-------------
2022-01-26 07:07:10:INFO:-------------Evaluating models-------------
2022-01-26 07:07:10:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 07:07:10:INFO:Accuracy = [1.0, 1.0, 0.98989898989899, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9904040404040404, 0.990909090909091]
2022-01-26 07:07:10:INFO:Loss = [0.0005834521638976781, 0.0006947143007092757, 0.024357168206478666, 0.0247270035657677, 0.0039292087697402975, 0.0038734083212708503, 0.0038619503850886665, 0.0038479172524639948, 0.026047545134269507, 0.02601868505450208]
2022-01-26 07:07:10:INFO:-------------Training local models-------------
2022-01-26 07:26:11:INFO:-------------Aggregating local models-------------
2022-01-26 07:26:12:INFO:-------------Round number: 38-------------
2022-01-26 07:26:12:INFO:-------------Sending models-------------
2022-01-26 07:26:12:INFO:-------------Evaluating models-------------
2022-01-26 07:26:13:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 07:26:13:INFO:Accuracy = [1.0, 1.0, 0.98989898989899, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.990909090909091]
2022-01-26 07:26:13:INFO:Loss = [0.0005704619284436128, 0.0006781750447753255, 0.024208023328019683, 0.024568159965496526, 0.003886182750581859, 0.0038302223522832996, 0.0038127642758763155, 0.0038004086462648835, 0.026055005985729466, 0.02601775564624845]
2022-01-26 07:26:13:INFO:-------------Training local models-------------
2022-01-26 07:45:12:INFO:-------------Aggregating local models-------------
2022-01-26 07:45:13:INFO:-------------Round number: 39-------------
2022-01-26 07:45:13:INFO:-------------Sending models-------------
2022-01-26 07:45:13:INFO:-------------Evaluating models-------------
2022-01-26 07:45:14:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 07:45:14:INFO:Accuracy = [1.0, 1.0, 0.98989898989899, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.990909090909091]
2022-01-26 07:45:14:INFO:Loss = [0.0005581676180104342, 0.0006625887305717422, 0.024065848716076508, 0.02441618125372182, 0.003846123949735575, 0.003789723817403637, 0.0037663275812170613, 0.003755456587567445, 0.02608149242065944, 0.026035973763743704]
2022-01-26 07:45:14:INFO:-------------Training local models-------------
2022-01-26 08:04:14:INFO:-------------Aggregating local models-------------
