2022-01-25 12:16:34:INFO:-------------Round number: 0-------------
2022-01-25 12:16:34:INFO:-------------Sending models-------------
2022-01-25 12:16:34:INFO:-------------Evaluating models-------------
2022-01-25 12:16:35:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:16:35:INFO:Accuracy = [0.8984360278876955, 0.8839268890145091, 0.8846806105144149, 0.9057848125117769, 0.9261352930092331, 0.0746184284906727, 0.11513095911060862, 0.10570944036178632, 0.09044657998869418, 0.8869417750141323]
2022-01-25 12:16:35:INFO:Loss = [0.6698315352150921, 0.6535867544269076, 0.6625111897674145, 0.6538707435928497, 0.6621472520726716, 0.7392828428455501, 0.7384982380980216, 0.7415181731063587, 0.7481898140251378, 0.6703967377585567]
2022-01-25 12:16:35:INFO:-------------Training local models-------------
2022-01-25 12:26:00:INFO:-------------Aggregating local models-------------
2022-01-25 12:26:05:INFO:-------------Round number: 1-------------
2022-01-25 12:26:05:INFO:-------------Sending models-------------
2022-01-25 12:26:05:INFO:-------------Evaluating models-------------
2022-01-25 12:26:06:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:26:06:INFO:Accuracy = [0.863576408517053, 0.8554739023930658, 0.8554739023930658, 0.8692293197663463, 0.8526474467684191, 0.8701714716412285, 0.8460523836442434, 0.8338044092707745, 0.875824382890522, 0.781232334652346]
2022-01-25 12:26:06:INFO:Loss = [0.42886869948963136, 0.405766389869183, 0.44017509718651776, 0.4093140250853513, 0.3802922882837429, 0.427524260629761, 0.47283508045560607, 0.469407391413451, 0.45423926758457595, 0.5335061026957157]
2022-01-25 12:26:06:INFO:-------------Training local models-------------
2022-01-25 12:35:57:INFO:-------------Aggregating local models-------------
2022-01-25 12:36:02:INFO:-------------Round number: 2-------------
2022-01-25 12:36:02:INFO:-------------Sending models-------------
2022-01-25 12:36:03:INFO:-------------Evaluating models-------------
2022-01-25 12:36:03:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:36:03:INFO:Accuracy = [0.8637648388920294, 0.8522705860184662, 0.8485019785189373, 0.8709251931411344, 0.861503674392312, 0.875824382890522, 0.8422837761447145, 0.8420953457697381, 0.8797814207650273, 0.8417184850197852]
2022-01-25 12:36:03:INFO:Loss = [0.4378532285555328, 0.3368833711334324, 0.4301842389626887, 0.371042474104393, 0.32575364561324344, 0.35690608773179056, 0.4563520341853267, 0.4118378934820204, 0.41757248008361536, 0.49021727184406866]
2022-01-25 12:36:03:INFO:-------------Training local models-------------
2022-01-25 12:45:54:INFO:-------------Aggregating local models-------------
2022-01-25 12:45:59:INFO:-------------Round number: 3-------------
2022-01-25 12:45:59:INFO:-------------Sending models-------------
2022-01-25 12:46:00:INFO:-------------Evaluating models-------------
2022-01-25 12:46:00:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:46:00:INFO:Accuracy = [0.8300358017712455, 0.8613152440173356, 0.849255700018843, 0.879216129640098, 0.872055775390993, 0.872055775390993, 0.8466176747691728, 0.8443565102694555, 0.8797814207650273, 0.8528358771433955]
2022-01-25 12:46:00:INFO:Loss = [0.4447561485944423, 0.30677560162741924, 0.4267883996274944, 0.3564381249070333, 0.2976828849649284, 0.3408626901848894, 0.45113344905262354, 0.37852934473468824, 0.4023832282382593, 0.48148663187287544]
2022-01-25 12:46:00:INFO:-------------Training local models-------------
2022-01-25 12:55:51:INFO:-------------Aggregating local models-------------
2022-01-25 12:55:56:INFO:-------------Round number: 4-------------
2022-01-25 12:55:56:INFO:-------------Sending models-------------
2022-01-25 12:55:57:INFO:-------------Evaluating models-------------
2022-01-25 12:55:58:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:55:58:INFO:Accuracy = [0.8175993970228, 0.861503674392312, 0.8537780290182777, 0.8944789900131901, 0.8841153193894856, 0.8697946108912756, 0.8577350668927831, 0.8462408140192199, 0.8797814207650273, 0.8543433201432071]
2022-01-25 12:55:58:INFO:Loss = [0.4487309899203151, 0.2954510432937933, 0.42435613858190807, 0.3483937702658343, 0.28412286230075673, 0.3395071351060629, 0.44920716679718015, 0.3587693523230224, 0.3965287845288615, 0.47775866787997184]
2022-01-25 12:55:58:INFO:-------------Training local models-------------
2022-01-25 13:05:49:INFO:-------------Aggregating local models-------------
2022-01-25 13:05:54:INFO:-------------Round number: 5-------------
2022-01-25 13:05:54:INFO:-------------Sending models-------------
2022-01-25 13:05:55:INFO:-------------Evaluating models-------------
2022-01-25 13:05:55:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:05:55:INFO:Accuracy = [0.8241944601469757, 0.8616921047672885, 0.8618805351422649, 0.9010740531373658, 0.8946674203881666, 0.8694177501413228, 0.8654607122668174, 0.8549086112681364, 0.8797814207650273, 0.8558507631430187]
2022-01-25 13:05:55:INFO:Loss = [0.4483979058682105, 0.2915594780240092, 0.4231985433441128, 0.3425414043146817, 0.27739103305117924, 0.34177336270901804, 0.44879487902426185, 0.3453900017211835, 0.39367316268119995, 0.4751199703554433]
2022-01-25 13:05:55:INFO:-------------Training local models-------------
2022-01-25 13:15:46:INFO:-------------Aggregating local models-------------
2022-01-25 13:15:51:INFO:-------------Round number: 6-------------
2022-01-25 13:15:51:INFO:-------------Sending models-------------
2022-01-25 13:15:51:INFO:-------------Evaluating models-------------
2022-01-25 13:15:52:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:15:52:INFO:Accuracy = [0.8298473713962691, 0.8624458262671942, 0.8724326361409459, 0.9005087620124365, 0.9039005087620124, 0.8690408893913699, 0.873751648765781, 0.8697946108912756, 0.8807235726399095, 0.8560391935179951]
2022-01-25 13:15:52:INFO:Loss = [0.44483134312280026, 0.2893636682397553, 0.42217486985675345, 0.3379651463442888, 0.2734871815084753, 0.3439296134781785, 0.44880558588009084, 0.3347894155530658, 0.3913053479719948, 0.4727758219984536]
2022-01-25 13:15:52:INFO:-------------Training local models-------------
2022-01-25 13:25:37:INFO:-------------Aggregating local models-------------
2022-01-25 13:25:42:INFO:-------------Round number: 7-------------
2022-01-25 13:25:42:INFO:-------------Sending models-------------
2022-01-25 13:25:43:INFO:-------------Evaluating models-------------
2022-01-25 13:25:43:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:25:43:INFO:Accuracy = [0.8351234218956096, 0.8647069907669116, 0.8833615978895798, 0.9023930657622009, 0.9120030148859997, 0.8701714716412285, 0.8816657245147917, 0.8859996231392501, 0.8814772941398153, 0.8567929150179009]
2022-01-25 13:25:43:INFO:Loss = [0.4393729840629517, 0.28716718855308515, 0.42069142505867696, 0.33433108631717484, 0.2706071391581883, 0.34480229506378074, 0.4486701446023791, 0.3255039989162168, 0.3888665536110661, 0.47043658285264]
2022-01-25 13:25:43:INFO:-------------Training local models-------------
2022-01-25 13:35:24:INFO:-------------Aggregating local models-------------
2022-01-25 13:35:30:INFO:-------------Round number: 8-------------
2022-01-25 13:35:30:INFO:-------------Sending models-------------
2022-01-25 13:35:30:INFO:-------------Evaluating models-------------
2022-01-25 13:35:31:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:35:31:INFO:Accuracy = [0.8443565102694555, 0.8690408893913699, 0.8880723572639909, 0.9035236480120595, 0.9184096476351988, 0.8709251931411344, 0.8856227623892972, 0.8991897493876013, 0.8827963067646505, 0.8569813453928773]
2022-01-25 13:35:31:INFO:Loss = [0.43293508177012713, 0.2846334187194757, 0.4187218617513944, 0.33137696470584616, 0.26799036320234415, 0.34435095449113545, 0.44834579390505075, 0.3169686567283193, 0.38618986282872053, 0.4680308842995024]
2022-01-25 13:35:31:INFO:-------------Training local models-------------
2022-01-25 13:45:12:INFO:-------------Aggregating local models-------------
2022-01-25 13:45:17:INFO:-------------Round number: 9-------------
2022-01-25 13:45:17:INFO:-------------Sending models-------------
2022-01-25 13:45:18:INFO:-------------Evaluating models-------------
2022-01-25 13:45:18:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:45:18:INFO:Accuracy = [0.8515168645185603, 0.8754475221405691, 0.8903335217637083, 0.9052195213868476, 0.9218013943847748, 0.8726210665159224, 0.8890145091388731, 0.9048426606368947, 0.8831731675146034, 0.8575466365178067]
2022-01-25 13:45:18:INFO:Loss = [0.4259675671919239, 0.28195643578459906, 0.41640107013530053, 0.3289326494074856, 0.26537069347394876, 0.3428165245167167, 0.44793754330410146, 0.309158811095273, 0.38326458682758696, 0.46554848252887243]
2022-01-25 13:45:18:INFO:-------------Training local models-------------
2022-01-25 13:54:59:INFO:-------------Aggregating local models-------------
2022-01-25 13:55:04:INFO:-------------Round number: 10-------------
2022-01-25 13:55:04:INFO:-------------Sending models-------------
2022-01-25 13:55:05:INFO:-------------Evaluating models-------------
2022-01-25 13:55:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:55:05:INFO:Accuracy = [0.8571697757678538, 0.8799698511400038, 0.8908988128886377, 0.9067269643866591, 0.9238741285095158, 0.8752590917655926, 0.8907103825136612, 0.9093649896363294, 0.8837384586395327, 0.8577350668927831]
2022-01-25 13:55:05:INFO:Loss = [0.4187374515324034, 0.2793259293822865, 0.41392896434908427, 0.3268679175218797, 0.2627290619241491, 0.3404642729057427, 0.44749824369160573, 0.3020560849623027, 0.3801257410231251, 0.46298081207783887]
2022-01-25 13:55:05:INFO:-------------Training local models-------------
2022-01-25 14:04:46:INFO:-------------Aggregating local models-------------
2022-01-25 14:04:51:INFO:-------------Round number: 11-------------
2022-01-25 14:04:51:INFO:-------------Sending models-------------
2022-01-25 14:04:52:INFO:-------------Evaluating models-------------
2022-01-25 14:04:52:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:04:52:INFO:Accuracy = [0.8622573958922178, 0.8867533446391558, 0.8910872432636141, 0.9078575466365179, 0.9263237233842095, 0.8767665347654042, 0.8912756736385905, 0.9121914452609761, 0.8835500282645562, 0.858111927642736]
2022-01-25 14:04:52:INFO:Loss = [0.4114364295829495, 0.276808146802788, 0.4114837764716232, 0.32508849771849097, 0.2601291348070468, 0.33745489122279093, 0.4469740527017954, 0.2957041045476535, 0.3768619732738306, 0.4602698158948879]
2022-01-25 14:04:52:INFO:-------------Training local models-------------
2022-01-25 14:14:33:INFO:-------------Aggregating local models-------------
2022-01-25 14:14:38:INFO:-------------Round number: 12-------------
2022-01-25 14:14:38:INFO:-------------Sending models-------------
2022-01-25 14:14:39:INFO:-------------Evaluating models-------------
2022-01-25 14:14:39:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:14:39:INFO:Accuracy = [0.8682871678914641, 0.8908988128886377, 0.8922178255134727, 0.9091765592613529, 0.9272658752590918, 0.8786508385151687, 0.891464104013567, 0.914264179385717, 0.8839268890145091, 0.858111927642736]
2022-01-25 14:14:39:INFO:Loss = [0.404184707463765, 0.27448132112544604, 0.40918540511886964, 0.32356170411795093, 0.2576299060484273, 0.3339702724462248, 0.4463205083347671, 0.29006604156429905, 0.37361633202311306, 0.4574571539646912]
2022-01-25 14:14:39:INFO:-------------Training local models-------------
2022-01-25 14:24:20:INFO:-------------Aggregating local models-------------
2022-01-25 14:24:25:INFO:-------------Round number: 13-------------
2022-01-25 14:24:25:INFO:-------------Sending models-------------
2022-01-25 14:24:25:INFO:-------------Evaluating models-------------
2022-01-25 14:24:26:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:24:26:INFO:Accuracy = [0.8729979272658752, 0.893159977388355, 0.8920293951384963, 0.9133220275108348, 0.9293386093838327, 0.8822310156397212, 0.893159977388355, 0.9169022046353872, 0.8841153193894856, 0.858111927642736]
2022-01-25 14:24:26:INFO:Loss = [0.39711358535519586, 0.2723438580030967, 0.40716538563017446, 0.3222490932113018, 0.25525935958972956, 0.33025937037855185, 0.44557256361653713, 0.28511608214976303, 0.3704700749962933, 0.4546069859438692]
2022-01-25 14:24:26:INFO:-------------Training local models-------------
2022-01-25 14:34:07:INFO:-------------Aggregating local models-------------
2022-01-25 14:34:12:INFO:-------------Round number: 14-------------
2022-01-25 14:34:12:INFO:-------------Sending models-------------
2022-01-25 14:34:13:INFO:-------------Evaluating models-------------
2022-01-25 14:34:13:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:34:13:INFO:Accuracy = [0.8767665347654042, 0.8978707367627662, 0.8922178255134727, 0.9148294705106463, 0.9310344827586207, 0.8835500282645562, 0.8937252685132844, 0.9201055210099868, 0.8846806105144149, 0.858111927642736]
2022-01-25 14:34:13:INFO:Loss = [0.39031030658147464, 0.27041432168505825, 0.40547404612391025, 0.32113966391642446, 0.2530826781794673, 0.32659083894039, 0.4448407636970297, 0.2808207202859517, 0.36763395180332614, 0.4518081886582926]
2022-01-25 14:34:13:INFO:-------------Training local models-------------
2022-01-25 14:43:54:INFO:-------------Aggregating local models-------------
2022-01-25 14:43:59:INFO:-------------Round number: 15-------------
2022-01-25 14:43:59:INFO:-------------Sending models-------------
2022-01-25 14:44:00:INFO:-------------Evaluating models-------------
2022-01-25 14:44:01:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:44:01:INFO:Accuracy = [0.8799698511400038, 0.9005087620124365, 0.893159977388355, 0.915960052760505, 0.9323534953834558, 0.8856227623892972, 0.8942905596382137, 0.9219898247597512, 0.8858111927642736, 0.8586772187676653]
2022-01-25 14:44:01:INFO:Loss = [0.38376514316701316, 0.26861349289305814, 0.40404874146842706, 0.32015770610087546, 0.2510867060947289, 0.3229748777316589, 0.4441298393561414, 0.27705281661268494, 0.3651454621371601, 0.4489923956409258]
2022-01-25 14:44:01:INFO:-------------Training local models-------------
2022-01-25 14:53:41:INFO:-------------Aggregating local models-------------
2022-01-25 14:53:46:INFO:-------------Round number: 16-------------
2022-01-25 14:53:46:INFO:-------------Sending models-------------
2022-01-25 14:53:47:INFO:-------------Evaluating models-------------
2022-01-25 14:53:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:53:47:INFO:Accuracy = [0.8824194460146976, 0.9023930657622009, 0.8941021292632373, 0.9161484831354815, 0.9334840776333145, 0.8871302053891087, 0.894855850763143, 0.9238741285095158, 0.8890145091388731, 0.8579234972677595]
2022-01-25 14:53:47:INFO:Loss = [0.3774675100113389, 0.2669372285937747, 0.4028224814639546, 0.31928427685289507, 0.24923675220723987, 0.319469578523958, 0.4433755091402165, 0.2737500918183367, 0.3630921780790391, 0.44616738510618975]
2022-01-25 14:53:47:INFO:-------------Training local models-------------
2022-01-25 15:03:28:INFO:-------------Aggregating local models-------------
2022-01-25 15:03:33:INFO:-------------Round number: 17-------------
2022-01-25 15:03:33:INFO:-------------Sending models-------------
2022-01-25 15:03:33:INFO:-------------Evaluating models-------------
2022-01-25 15:03:34:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:03:34:INFO:Accuracy = [0.8839268890145091, 0.9057848125117769, 0.8944789900131901, 0.9167137742604108, 0.9340493687582438, 0.8890145091388731, 0.8956095722630488, 0.9261352930092331, 0.8903335217637083, 0.8569813453928773]
2022-01-25 15:03:34:INFO:Loss = [0.37141809255672315, 0.2653663891849618, 0.4017508416245329, 0.3185178381836393, 0.2475152976284749, 0.3161060614782063, 0.4425741090712892, 0.27085315419596984, 0.3614775926052591, 0.44337158142131006]
2022-01-25 15:03:34:INFO:-------------Training local models-------------
2022-01-25 15:13:14:INFO:-------------Aggregating local models-------------
2022-01-25 15:13:20:INFO:-------------Round number: 18-------------
2022-01-25 15:13:20:INFO:-------------Sending models-------------
2022-01-25 15:13:20:INFO:-------------Evaluating models-------------
2022-01-25 15:13:21:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:13:21:INFO:Accuracy = [0.8856227623892972, 0.9074806858865649, 0.8957980026380252, 0.9163369135104579, 0.9357452421330319, 0.8907103825136612, 0.8957980026380252, 0.9268890145091389, 0.8908988128886377, 0.8571697757678538]
2022-01-25 15:13:21:INFO:Loss = [0.365649894251972, 0.26390395924871546, 0.4007932331938797, 0.3178126877656926, 0.2459262666661543, 0.3129077004075508, 0.4417404288157148, 0.26829997011580486, 0.3603179654787419, 0.4406189565606784]
2022-01-25 15:13:21:INFO:-------------Training local models-------------
2022-01-25 15:23:02:INFO:-------------Aggregating local models-------------
2022-01-25 15:23:07:INFO:-------------Round number: 19-------------
2022-01-25 15:23:07:INFO:-------------Sending models-------------
2022-01-25 15:23:07:INFO:-------------Evaluating models-------------
2022-01-25 15:23:08:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:23:08:INFO:Accuracy = [0.8873186357640852, 0.9089881288863765, 0.8961748633879781, 0.9174674957603166, 0.9361221028829847, 0.8920293951384963, 0.8967401545129075, 0.9272658752590918, 0.8924062558884492, 0.8566044846429245]
2022-01-25 15:23:08:INFO:Loss = [0.36014274896144405, 0.26254429055497347, 0.3999148750974633, 0.31714344735321426, 0.24444360686454472, 0.3098875516883334, 0.4408914954080846, 0.26603147505730185, 0.35955297872095743, 0.43791770093071125]
2022-01-25 15:23:08:INFO:-------------Training local models-------------
2022-01-25 15:32:48:INFO:-------------Aggregating local models-------------
2022-01-25 15:32:53:INFO:-------------Round number: 20-------------
2022-01-25 15:32:53:INFO:-------------Sending models-------------
2022-01-25 15:32:54:INFO:-------------Evaluating models-------------
2022-01-25 15:32:54:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:32:54:INFO:Accuracy = [0.8886376483889203, 0.9097418503862823, 0.8976823063877897, 0.9184096476351988, 0.9368758243828905, 0.8937252685132844, 0.896928584887884, 0.9270774448841154, 0.8935368381383079, 0.8577350668927831]
2022-01-25 15:32:54:INFO:Loss = [0.3548718305958871, 0.2613073329469152, 0.3991664777554969, 0.31652772567109766, 0.24307706357180273, 0.3070597490333059, 0.4400521164345795, 0.2640516898838815, 0.35911373080755843, 0.43533072531826017]
2022-01-25 15:32:54:INFO:-------------Training local models-------------
2022-01-25 15:42:35:INFO:-------------Aggregating local models-------------
2022-01-25 15:42:40:INFO:-------------Round number: 21-------------
2022-01-25 15:42:40:INFO:-------------Sending models-------------
2022-01-25 15:42:41:INFO:-------------Evaluating models-------------
2022-01-25 15:42:41:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:42:41:INFO:Accuracy = [0.8890145091388731, 0.9108724326361409, 0.8988128886376484, 0.9187865083851516, 0.9376295458827963, 0.8956095722630488, 0.8974938760128133, 0.9272658752590918, 0.8935368381383079, 0.8583003580177124]
2022-01-25 15:42:41:INFO:Loss = [0.3498492839963225, 0.2602072864137394, 0.3984457709677824, 0.31593045222551747, 0.2417798562104608, 0.3043525199759482, 0.43918725718059337, 0.2622969003656888, 0.358943260471595, 0.4328511460907419]
2022-01-25 15:42:41:INFO:-------------Training local models-------------
2022-01-25 15:52:22:INFO:-------------Aggregating local models-------------
2022-01-25 15:52:27:INFO:-------------Round number: 22-------------
2022-01-25 15:52:27:INFO:-------------Sending models-------------
2022-01-25 15:52:28:INFO:-------------Evaluating models-------------
2022-01-25 15:52:28:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:52:28:INFO:Accuracy = [0.8895798002638026, 0.9121914452609761, 0.8995666101375541, 0.9184096476351988, 0.9381948370077257, 0.8973054456378369, 0.8984360278876955, 0.928208027133974, 0.893159977388355, 0.8590540795176183]
2022-01-25 15:52:28:INFO:Loss = [0.3450583703592517, 0.2591829438082811, 0.3977304301900503, 0.315321640011828, 0.24053209301423348, 0.301789604661597, 0.43829639673980225, 0.2607285036071073, 0.35893576875365785, 0.4304782703865415]
2022-01-25 15:52:28:INFO:-------------Training local models-------------
2022-01-25 16:02:08:INFO:-------------Aggregating local models-------------
2022-01-25 16:02:14:INFO:-------------Round number: 23-------------
2022-01-25 16:02:14:INFO:-------------Sending models-------------
2022-01-25 16:02:14:INFO:-------------Evaluating models-------------
2022-01-25 16:02:15:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 16:02:15:INFO:Accuracy = [0.8908988128886377, 0.9123798756359525, 0.9005087620124365, 0.9185980780101752, 0.938760128132655, 0.8993781797625777, 0.8988128886376484, 0.9287733182589033, 0.8929715470133786, 0.8594309402675712]
2022-01-25 16:02:15:INFO:Loss = [0.3404977755794569, 0.2583133669277613, 0.39699605515783287, 0.3147283237394481, 0.23935357928179432, 0.2993526857471157, 0.4373788223691158, 0.2593492439768464, 0.3591510197824952, 0.42820906647937207]
2022-01-25 16:02:15:INFO:-------------Training local models-------------
2022-01-25 16:11:55:INFO:-------------Aggregating local models-------------
2022-01-25 16:12:01:INFO:-------------Round number: 24-------------
2022-01-25 16:12:01:INFO:-------------Sending models-------------
2022-01-25 16:12:01:INFO:-------------Evaluating models-------------
2022-01-25 16:12:02:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 16:12:02:INFO:Accuracy = [0.8916525343885434, 0.9131335971358583, 0.9014509138873187, 0.9191633691351045, 0.9389485585076315, 0.9008856227623893, 0.8993781797625777, 0.929903900508762, 0.8935368381383079, 0.8596193706425476]
2022-01-25 16:12:02:INFO:Loss = [0.33613409714685594, 0.25751146816223686, 0.39625408375465826, 0.3141230699141171, 0.238245450757793, 0.2970547359266087, 0.43643816561986415, 0.25811973084781936, 0.35943106333060926, 0.426062342331999]
2022-01-25 16:12:02:INFO:-------------Training local models-------------
2022-01-25 16:21:42:INFO:-------------Aggregating local models-------------
2022-01-25 16:21:47:INFO:-------------Round number: 25-------------
2022-01-25 16:21:47:INFO:-------------Sending models-------------
2022-01-25 16:21:48:INFO:-------------Evaluating models-------------
2022-01-25 16:21:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 16:21:49:INFO:Accuracy = [0.8916525343885434, 0.9133220275108348, 0.9010740531373658, 0.9191633691351045, 0.9391369888826079, 0.9022046353872244, 0.9001319012624835, 0.9293386093838327, 0.8937252685132844, 0.8613152440173356]
2022-01-25 16:21:49:INFO:Loss = [0.33195958812201953, 0.2567997365115391, 0.39546682177545317, 0.3135139785894069, 0.23718519280349729, 0.29483764924930095, 0.435493262654708, 0.25700838725438907, 0.3597600024883758, 0.4240260788386336]
2022-01-25 16:21:49:INFO:-------------Training local models-------------
2022-01-25 16:31:29:INFO:-------------Aggregating local models-------------
2022-01-25 16:31:34:INFO:-------------Round number: 26-------------
2022-01-25 16:31:34:INFO:-------------Sending models-------------
2022-01-25 16:31:35:INFO:-------------Evaluating models-------------
2022-01-25 16:31:35:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 16:31:35:INFO:Accuracy = [0.8920293951384963, 0.9135104578858112, 0.9016393442622951, 0.9191633691351045, 0.9397022800075372, 0.9029583568871302, 0.9001319012624835, 0.930280761258715, 0.8935368381383079, 0.8616921047672885]
2022-01-25 16:31:35:INFO:Loss = [0.3279602573997641, 0.25615895068982275, 0.39464907021137946, 0.31289895564384257, 0.23618550562337276, 0.29269925672277297, 0.4345372140353972, 0.25600937607923907, 0.3601126916290838, 0.4221119559273901]
2022-01-25 16:31:35:INFO:-------------Training local models-------------
2022-01-25 16:41:16:INFO:-------------Aggregating local models-------------
2022-01-25 16:41:21:INFO:-------------Round number: 27-------------
2022-01-25 16:41:21:INFO:-------------Sending models-------------
2022-01-25 16:41:21:INFO:-------------Evaluating models-------------
2022-01-25 16:41:22:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 16:41:22:INFO:Accuracy = [0.8922178255134727, 0.9138873186357641, 0.9023930657622009, 0.9193517995100811, 0.9400791407574901, 0.9039005087620124, 0.9006971923874129, 0.9306576220086678, 0.8929715470133786, 0.8630111173921237]
2022-01-25 16:41:22:INFO:Loss = [0.32413997735921674, 0.2555986300688901, 0.3938072585238727, 0.3122842560097256, 0.23526952780044433, 0.29066046478501595, 0.4335950969918389, 0.2551183841980584, 0.360473584877537, 0.4203103453235742]
2022-01-25 16:41:22:INFO:-------------Training local models-------------
2022-01-25 16:51:03:INFO:-------------Aggregating local models-------------
2022-01-25 16:51:08:INFO:-------------Round number: 28-------------
2022-01-25 16:51:08:INFO:-------------Sending models-------------
2022-01-25 16:51:08:INFO:-------------Evaluating models-------------
2022-01-25 16:51:09:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 16:51:09:INFO:Accuracy = [0.8925946862634256, 0.914264179385717, 0.9031467872621066, 0.9201055210099868, 0.940456001507443, 0.903712078387036, 0.9010740531373658, 0.9310344827586207, 0.8929715470133786, 0.8631995477671001]
2022-01-25 16:51:09:INFO:Loss = [0.3204697842999289, 0.2551168055856963, 0.39295225330174904, 0.31166254845468677, 0.23439161843426193, 0.2887005687482044, 0.4326548355958862, 0.25432168924506493, 0.36084647680276, 0.41864649956782984]
2022-01-25 16:51:09:INFO:-------------Training local models-------------
2022-01-25 17:00:50:INFO:-------------Aggregating local models-------------
2022-01-25 17:00:54:INFO:-------------Round number: 29-------------
2022-01-25 17:00:54:INFO:-------------Sending models-------------
2022-01-25 17:00:55:INFO:-------------Evaluating models-------------
2022-01-25 17:00:56:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 17:00:56:INFO:Accuracy = [0.8933484077633315, 0.9146410401356698, 0.9033352176370831, 0.9206708121349162, 0.9410212926323723, 0.9046542302619183, 0.9016393442622951, 0.9312229131335972, 0.891464104013567, 0.8643301300169587]
2022-01-25 17:00:56:INFO:Loss = [0.31694824197953775, 0.2546673507743687, 0.39207905662824155, 0.3110155280878667, 0.23357818856243767, 0.28683649910762093, 0.43171353848548916, 0.2536018499059562, 0.3611883935282694, 0.4170846019174445]
2022-01-25 17:00:56:INFO:-------------Training local models-------------
2022-01-25 17:10:36:INFO:-------------Aggregating local models-------------
2022-01-25 17:10:42:INFO:-------------Round number: 30-------------
2022-01-25 17:10:42:INFO:-------------Sending models-------------
2022-01-25 17:10:42:INFO:-------------Evaluating models-------------
2022-01-25 17:10:43:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 17:10:43:INFO:Accuracy = [0.8935368381383079, 0.9152063312605992, 0.9033352176370831, 0.9212361032598455, 0.9417750141322782, 0.905407951761824, 0.9023930657622009, 0.9312229131335972, 0.8908988128886377, 0.8652722818918409]
2022-01-25 17:10:43:INFO:Loss = [0.31357579590396567, 0.25426028306641146, 0.3911915145015744, 0.31034493550412606, 0.2327986374792214, 0.2850728569114917, 0.43078162233088646, 0.2529266821203023, 0.3615352313816876, 0.41560132992859034]
2022-01-25 17:10:43:INFO:-------------Training local models-------------
2022-01-25 17:20:23:INFO:-------------Aggregating local models-------------
2022-01-25 17:20:28:INFO:-------------Round number: 31-------------
2022-01-25 17:20:28:INFO:-------------Sending models-------------
2022-01-25 17:20:29:INFO:-------------Evaluating models-------------
2022-01-25 17:20:30:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 17:20:30:INFO:Accuracy = [0.8935368381383079, 0.9153947616355756, 0.9033352176370831, 0.9212361032598455, 0.9415865837573016, 0.9059732428867533, 0.9027699265121537, 0.930280761258715, 0.8907103825136612, 0.8656491426417938]
2022-01-25 17:20:30:INFO:Loss = [0.3103626296173327, 0.2538960785588616, 0.39029439781051767, 0.309658299092404, 0.2320506510899822, 0.28337709237963876, 0.4298641853764006, 0.2523117148756307, 0.3618458170966381, 0.4142072886284367]
2022-01-25 17:20:30:INFO:-------------Training local models-------------
2022-01-25 17:30:10:INFO:-------------Aggregating local models-------------
2022-01-25 17:30:15:INFO:-------------Round number: 32-------------
2022-01-25 17:30:15:INFO:-------------Sending models-------------
2022-01-25 17:30:15:INFO:-------------Evaluating models-------------
2022-01-25 17:30:16:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 17:30:16:INFO:Accuracy = [0.8937252685132844, 0.9150179008856227, 0.9040889391369888, 0.9212361032598455, 0.9417750141322782, 0.9061616732617298, 0.903712078387036, 0.9297154701337855, 0.8905219521386848, 0.8658375730167703]
2022-01-25 17:30:16:INFO:Loss = [0.3072848602975362, 0.2535706552715486, 0.3894245804054136, 0.3089621417080429, 0.23132525405186521, 0.28175888357894646, 0.4289570199059046, 0.25174794738715883, 0.362116727422737, 0.4129006442758481]
2022-01-25 17:30:16:INFO:-------------Training local models-------------
2022-01-25 17:39:57:INFO:-------------Aggregating local models-------------
2022-01-25 17:40:02:INFO:-------------Round number: 33-------------
2022-01-25 17:40:02:INFO:-------------Sending models-------------
2022-01-25 17:40:03:INFO:-------------Evaluating models-------------
2022-01-25 17:40:03:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 17:40:03:INFO:Accuracy = [0.8950442811381195, 0.9152063312605992, 0.9042773695119654, 0.9214245336348219, 0.9419634445072546, 0.9078575466365179, 0.9039005087620124, 0.9293386093838327, 0.8912756736385905, 0.866591294516676]
2022-01-25 17:40:03:INFO:Loss = [0.3043322976969396, 0.2532872028860439, 0.3885851192113445, 0.30824849866076276, 0.23066067344272967, 0.28019982141663646, 0.4280715127699002, 0.2512310262289601, 0.3623592224943548, 0.41167230455325315]
2022-01-25 17:40:03:INFO:-------------Training local models-------------
2022-01-25 17:49:44:INFO:-------------Aggregating local models-------------
2022-01-25 17:49:49:INFO:-------------Round number: 34-------------
2022-01-25 17:49:49:INFO:-------------Sending models-------------
2022-01-25 17:49:50:INFO:-------------Evaluating models-------------
2022-01-25 17:49:50:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 17:49:50:INFO:Accuracy = [0.8954211418880723, 0.915583192010552, 0.9040889391369888, 0.9221782551347277, 0.9419634445072546, 0.9084228377614472, 0.9044657998869418, 0.9297154701337855, 0.8912756736385905, 0.8667797248916526]
2022-01-25 17:49:50:INFO:Loss = [0.3015140776136501, 0.253027269196168, 0.38773293242381707, 0.30748552159257386, 0.23004035057469907, 0.2786947292705698, 0.4271813504166574, 0.2507475815297062, 0.3625735675634514, 0.4105295418034245]
2022-01-25 17:49:50:INFO:-------------Training local models-------------
2022-01-25 17:59:30:INFO:-------------Aggregating local models-------------
2022-01-25 17:59:36:INFO:-------------Round number: 35-------------
2022-01-25 17:59:36:INFO:-------------Sending models-------------
2022-01-25 17:59:36:INFO:-------------Evaluating models-------------
2022-01-25 17:59:37:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 17:59:37:INFO:Accuracy = [0.8963632937629545, 0.915960052760505, 0.9042773695119654, 0.9221782551347277, 0.9419634445072546, 0.9087996985114001, 0.9044657998869418, 0.9293386093838327, 0.8912756736385905, 0.8662144337667232]
2022-01-25 17:59:37:INFO:Loss = [0.2988317649760581, 0.2527885053137898, 0.38686150980173173, 0.30672116924419873, 0.2294593940866121, 0.27724308923989865, 0.4263060456566953, 0.2503071150818332, 0.36276535332921955, 0.409461685478513]
2022-01-25 17:59:37:INFO:-------------Training local models-------------
2022-01-25 18:09:13:INFO:-------------Aggregating local models-------------
2022-01-25 18:09:18:INFO:-------------Round number: 36-------------
2022-01-25 18:09:18:INFO:-------------Sending models-------------
2022-01-25 18:09:18:INFO:-------------Evaluating models-------------
2022-01-25 18:09:19:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 18:09:19:INFO:Accuracy = [0.896928584887884, 0.915960052760505, 0.9048426606368947, 0.9223666855097041, 0.9421518748822311, 0.9089881288863765, 0.9046542302619183, 0.9289617486338798, 0.891464104013567, 0.866968155266629]
2022-01-25 18:09:19:INFO:Loss = [0.2962516708013876, 0.25257463638960587, 0.3860000205896042, 0.30595092644153976, 0.22892218463343347, 0.27582685968103593, 0.42543001660122653, 0.24990039218389837, 0.3629222097057841, 0.40845791143843196]
2022-01-25 18:09:19:INFO:-------------Training local models-------------
2022-01-25 18:18:59:INFO:-------------Aggregating local models-------------
2022-01-25 18:19:05:INFO:-------------Round number: 37-------------
2022-01-25 18:19:05:INFO:-------------Sending models-------------
2022-01-25 18:19:05:INFO:-------------Evaluating models-------------
2022-01-25 18:19:06:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 18:19:06:INFO:Accuracy = [0.8990013190126248, 0.915960052760505, 0.9046542302619183, 0.9225551158846806, 0.9427171660071604, 0.9093649896363294, 0.9048426606368947, 0.9289617486338798, 0.8912756736385905, 0.8675334463915583]
2022-01-25 18:19:06:INFO:Loss = [0.2937777658091116, 0.252384361176363, 0.3851775110420252, 0.3051827675187797, 0.22841883628029555, 0.27444715093867594, 0.42459035713542864, 0.2495260956581184, 0.3630640921478411, 0.40753633249627835]
2022-01-25 18:19:06:INFO:-------------Training local models-------------
2022-01-25 18:28:46:INFO:-------------Aggregating local models-------------
2022-01-25 18:28:52:INFO:-------------Round number: 38-------------
2022-01-25 18:28:52:INFO:-------------Sending models-------------
2022-01-25 18:28:52:INFO:-------------Evaluating models-------------
2022-01-25 18:28:53:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 18:28:53:INFO:Accuracy = [0.9014509138873187, 0.915960052760505, 0.9046542302619183, 0.9234972677595629, 0.9430940267571133, 0.9091765592613529, 0.9046542302619183, 0.9283964575089504, 0.8910872432636141, 0.866968155266629]
2022-01-25 18:28:53:INFO:Loss = [0.2914218623944681, 0.2522190608836251, 0.38438096674193084, 0.30441925266205977, 0.2279534430961633, 0.2731062626112412, 0.42376675257206664, 0.2491779849992902, 0.3631721222922415, 0.40668936195788014]
2022-01-25 18:28:53:INFO:-------------Training local models-------------
2022-01-25 18:38:33:INFO:-------------Aggregating local models-------------
2022-01-25 18:38:38:INFO:-------------Round number: 39-------------
2022-01-25 18:38:38:INFO:-------------Sending models-------------
2022-01-25 18:38:38:INFO:-------------Evaluating models-------------
2022-01-25 18:38:39:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 18:38:39:INFO:Accuracy = [0.902016205012248, 0.9165253438854344, 0.905407951761824, 0.9234972677595629, 0.9436593178820426, 0.9087996985114001, 0.9057848125117769, 0.9287733182589033, 0.8910872432636141, 0.8680987375164877]
2022-01-25 18:38:39:INFO:Loss = [0.28917287862870306, 0.25206200290199177, 0.38362890739892036, 0.30365259653446697, 0.2275225914901246, 0.2718107656125817, 0.4229861882444551, 0.24884835967386662, 0.3632717035442291, 0.40591326001783246]
2022-01-25 18:38:39:INFO:-------------Training local models-------------
2022-01-25 18:48:20:INFO:-------------Aggregating local models-------------
