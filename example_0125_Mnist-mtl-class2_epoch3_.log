2022-01-25 12:08:17:INFO:-------------Round number: 0-------------
2022-01-25 12:08:17:INFO:-------------Sending models-------------
2022-01-25 12:08:17:INFO:-------------Evaluating models-------------
2022-01-25 12:08:18:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:08:18:INFO:Accuracy = [0.901010101010101, 0.8868686868686869, 0.896969696969697, 0.898989898989899, 0.901010101010101, 0.08888888888888889, 0.09494949494949495, 0.10303030303030303, 0.09696969696969697, 0.898989898989899]
2022-01-25 12:08:18:INFO:Loss = [0.6694116484637213, 0.653408883798002, 0.6615643211988488, 0.6542965058425461, 0.6641762230733428, 0.7379018910304465, 0.7407228308795678, 0.7419946313205391, 0.7473327146335081, 0.669854687109138]
2022-01-25 12:08:18:INFO:-------------Training local models-------------
2022-01-25 12:11:09:INFO:-------------Aggregating local models-------------
2022-01-25 12:11:10:INFO:-------------Round number: 1-------------
2022-01-25 12:11:10:INFO:-------------Sending models-------------
2022-01-25 12:11:10:INFO:-------------Evaluating models-------------
2022-01-25 12:11:10:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:11:10:INFO:Accuracy = [0.9242424242424242, 0.9151515151515152, 0.8984848484848484, 0.8974747474747474, 0.9101010101010101, 0.9085858585858586, 0.9050505050505051, 0.9035353535353535, 0.9202020202020202, 0.9030303030303031]
2022-01-25 12:11:10:INFO:Loss = [0.24461419163977333, 0.28937358158461823, 0.31482330987963714, 0.28370369254056405, 0.29360312792481946, 0.3178925497777233, 0.3099635318918812, 0.31586544801847954, 0.28704461422701827, 0.4120004442416959]
2022-01-25 12:11:10:INFO:-------------Training local models-------------
2022-01-25 12:14:02:INFO:-------------Aggregating local models-------------
2022-01-25 12:14:03:INFO:-------------Round number: 2-------------
2022-01-25 12:14:03:INFO:-------------Sending models-------------
2022-01-25 12:14:03:INFO:-------------Evaluating models-------------
2022-01-25 12:14:03:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:14:03:INFO:Accuracy = [0.9378787878787879, 0.9378787878787879, 0.897979797979798, 0.897979797979798, 0.9287878787878788, 0.9166666666666666, 0.9035353535353535, 0.9045454545454545, 0.9186868686868687, 0.9242424242424242]
2022-01-25 12:14:03:INFO:Loss = [0.12684895699030033, 0.16237926505590705, 0.22601696119145162, 0.21220852477414853, 0.19090755328070372, 0.20493463276876042, 0.2019938083708926, 0.19905715774029795, 0.19715921747535844, 0.26147748559120704]
2022-01-25 12:14:03:INFO:-------------Training local models-------------
2022-01-25 12:16:55:INFO:-------------Aggregating local models-------------
2022-01-25 12:16:56:INFO:-------------Round number: 3-------------
2022-01-25 12:16:56:INFO:-------------Sending models-------------
2022-01-25 12:16:56:INFO:-------------Evaluating models-------------
2022-01-25 12:16:56:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:16:56:INFO:Accuracy = [0.9515151515151515, 0.944949494949495, 0.9015151515151515, 0.9005050505050505, 0.951010101010101, 0.9308080808080809, 0.9131313131313131, 0.9212121212121213, 0.9217171717171717, 0.9202020202020202]
2022-01-25 12:16:56:INFO:Loss = [0.08367156582658715, 0.10797020757401532, 0.18803593423993636, 0.18094717127475604, 0.1435220092198708, 0.15451386893365646, 0.15364609190610923, 0.14636681592985612, 0.1643918038190653, 0.20371065423165383]
2022-01-25 12:16:56:INFO:-------------Training local models-------------
2022-01-25 12:19:48:INFO:-------------Aggregating local models-------------
2022-01-25 12:19:49:INFO:-------------Round number: 4-------------
2022-01-25 12:19:49:INFO:-------------Sending models-------------
2022-01-25 12:19:49:INFO:-------------Evaluating models-------------
2022-01-25 12:19:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:19:49:INFO:Accuracy = [0.9737373737373738, 0.9606060606060606, 0.9075757575757576, 0.9065656565656566, 0.9651515151515152, 0.955050505050505, 0.9333333333333333, 0.9419191919191919, 0.9262626262626262, 0.9207070707070707]
2022-01-25 12:19:49:INFO:Loss = [0.05994813483328361, 0.07867008852748897, 0.16538497944447128, 0.16019226563706374, 0.11377764157033667, 0.1237809080789289, 0.11985437910288874, 0.11131162295974038, 0.14265936356510572, 0.17307174870570313]
2022-01-25 12:19:49:INFO:-------------Training local models-------------
2022-01-25 12:22:41:INFO:-------------Aggregating local models-------------
2022-01-25 12:22:42:INFO:-------------Round number: 5-------------
2022-01-25 12:22:42:INFO:-------------Sending models-------------
2022-01-25 12:22:42:INFO:-------------Evaluating models-------------
2022-01-25 12:22:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:22:42:INFO:Accuracy = [0.9873737373737373, 0.9767676767676767, 0.9121212121212121, 0.9126262626262627, 0.9722222222222222, 0.9696969696969697, 0.955050505050505, 0.9585858585858585, 0.9419191919191919, 0.9227272727272727]
2022-01-25 12:22:42:INFO:Loss = [0.04415721096606417, 0.05903455876578304, 0.14952415833861163, 0.14496613558542895, 0.09146434138164469, 0.10050201100400752, 0.0946498296866805, 0.08695887946112156, 0.12573412358131722, 0.15123605651644556]
2022-01-25 12:22:42:INFO:-------------Training local models-------------
2022-01-25 12:25:34:INFO:-------------Aggregating local models-------------
2022-01-25 12:25:35:INFO:-------------Round number: 6-------------
2022-01-25 12:25:35:INFO:-------------Sending models-------------
2022-01-25 12:25:35:INFO:-------------Evaluating models-------------
2022-01-25 12:25:35:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:25:35:INFO:Accuracy = [0.9944444444444445, 0.9863636363636363, 0.9161616161616162, 0.9161616161616162, 0.9777777777777777, 0.9767676767676767, 0.9671717171717171, 0.9691919191919192, 0.951010101010101, 0.9282828282828283]
2022-01-25 12:25:35:INFO:Loss = [0.03337989250954118, 0.04518404139071759, 0.1369546442357306, 0.13287978696412256, 0.07450670001586203, 0.08232330423626917, 0.07704564742344158, 0.07062654729104705, 0.11282636092662943, 0.13446534259698703]
2022-01-25 12:25:35:INFO:-------------Training local models-------------
2022-01-25 12:28:27:INFO:-------------Aggregating local models-------------
2022-01-25 12:28:28:INFO:-------------Round number: 7-------------
2022-01-25 12:28:28:INFO:-------------Sending models-------------
2022-01-25 12:28:28:INFO:-------------Evaluating models-------------
2022-01-25 12:28:28:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:28:28:INFO:Accuracy = [0.9959595959595959, 0.9934343434343434, 0.9222222222222223, 0.9237373737373737, 0.9838383838383838, 0.9833333333333333, 0.9707070707070707, 0.9752525252525253, 0.9545454545454546, 0.9419191919191919]
2022-01-25 12:28:28:INFO:Loss = [0.025989622461334377, 0.03539317427838052, 0.1262787373009199, 0.12267801962755244, 0.06178730125415534, 0.06834754555626076, 0.0647447933372336, 0.059318584737995866, 0.10307688495177174, 0.12169111699637289]
2022-01-25 12:28:28:INFO:-------------Training local models-------------
2022-01-25 12:31:20:INFO:-------------Aggregating local models-------------
2022-01-25 12:31:21:INFO:-------------Round number: 8-------------
2022-01-25 12:31:21:INFO:-------------Sending models-------------
2022-01-25 12:31:21:INFO:-------------Evaluating models-------------
2022-01-25 12:31:21:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:31:21:INFO:Accuracy = [0.997979797979798, 0.9964646464646465, 0.9297979797979798, 0.9313131313131313, 0.9878787878787879, 0.9868686868686869, 0.9747474747474747, 0.9833333333333333, 0.9570707070707071, 0.9505050505050505]
2022-01-25 12:31:21:INFO:Loss = [0.020853099058913725, 0.028440155057445866, 0.11699329401364061, 0.11382547547956082, 0.05221785645022979, 0.05763277801269938, 0.05575742801937105, 0.051011139258208466, 0.09545388248089978, 0.11198596217342643]
2022-01-25 12:31:21:INFO:-------------Training local models-------------
2022-01-25 12:34:13:INFO:-------------Aggregating local models-------------
2022-01-25 12:34:13:INFO:-------------Round number: 9-------------
2022-01-25 12:34:13:INFO:-------------Sending models-------------
2022-01-25 12:34:14:INFO:-------------Evaluating models-------------
2022-01-25 12:34:14:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:34:14:INFO:Accuracy = [0.9984848484848485, 0.9974747474747475, 0.9358585858585858, 0.9388888888888889, 0.9924242424242424, 0.990909090909091, 0.9823232323232324, 0.9883838383838384, 0.9601010101010101, 0.9545454545454546]
2022-01-25 12:34:14:INFO:Loss = [0.01720217702401134, 0.023430493237589476, 0.10892635114958998, 0.10613110333565279, 0.0449449177930776, 0.04937648071920396, 0.048817343308326946, 0.04455549074624985, 0.08918103461663564, 0.10438926972876858]
2022-01-25 12:34:14:INFO:-------------Training local models-------------
2022-01-25 12:37:06:INFO:-------------Aggregating local models-------------
2022-01-25 12:37:06:INFO:-------------Round number: 10-------------
2022-01-25 12:37:06:INFO:-------------Sending models-------------
2022-01-25 12:37:06:INFO:-------------Evaluating models-------------
2022-01-25 12:37:06:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:37:06:INFO:Accuracy = [0.9994949494949495, 0.9984848484848485, 0.9419191919191919, 0.9434343434343434, 0.9944444444444445, 0.9934343434343434, 0.9888888888888889, 0.9919191919191919, 0.9611111111111111, 0.9585858585858585]
2022-01-25 12:37:06:INFO:Loss = [0.01453032296602473, 0.019740575714850554, 0.1018855993763539, 0.09939972612997423, 0.03932439652218653, 0.04295072728004236, 0.043194421037921045, 0.03931573850765349, 0.08380865617475891, 0.0981555818405468]
2022-01-25 12:37:06:INFO:-------------Training local models-------------
2022-01-25 12:39:59:INFO:-------------Aggregating local models-------------
2022-01-25 12:39:59:INFO:-------------Round number: 11-------------
2022-01-25 12:39:59:INFO:-------------Sending models-------------
2022-01-25 12:39:59:INFO:-------------Evaluating models-------------
2022-01-25 12:39:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:39:59:INFO:Accuracy = [1.0, 0.9984848484848485, 0.944949494949495, 0.946969696969697, 0.9944444444444445, 0.9939393939393939, 0.9919191919191919, 0.9934343434343434, 0.9626262626262626, 0.9595959595959596]
2022-01-25 12:39:59:INFO:Loss = [0.012517030405720244, 0.016954554562842606, 0.09570076130089501, 0.09347899033928483, 0.0349054296659141, 0.03788741708493843, 0.03850547027411974, 0.034977769555266464, 0.07908556555918737, 0.09279975787844659]
2022-01-25 12:39:59:INFO:-------------Training local models-------------
2022-01-25 12:42:51:INFO:-------------Aggregating local models-------------
2022-01-25 12:42:52:INFO:-------------Round number: 12-------------
2022-01-25 12:42:52:INFO:-------------Sending models-------------
2022-01-25 12:42:52:INFO:-------------Evaluating models-------------
2022-01-25 12:42:52:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:42:52:INFO:Accuracy = [1.0, 1.0, 0.947979797979798, 0.9489898989898989, 0.9949494949494949, 0.9944444444444445, 0.9934343434343434, 0.9939393939393939, 0.9626262626262626, 0.9616161616161616]
2022-01-25 12:42:52:INFO:Loss = [0.01095902914110209, 0.014799343327335505, 0.09020682088022398, 0.0882280560976748, 0.03136280340279542, 0.03383391765936988, 0.0345449635290101, 0.03135589805715059, 0.07486553284779986, 0.08804032841410413]
2022-01-25 12:42:52:INFO:-------------Training local models-------------
2022-01-25 12:45:44:INFO:-------------Aggregating local models-------------
2022-01-25 12:45:45:INFO:-------------Round number: 13-------------
2022-01-25 12:45:45:INFO:-------------Sending models-------------
2022-01-25 12:45:45:INFO:-------------Evaluating models-------------
2022-01-25 12:45:45:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:45:45:INFO:Accuracy = [1.0, 1.0, 0.951010101010101, 0.9505050505050505, 0.9949494949494949, 0.9949494949494949, 0.9939393939393939, 0.9944444444444445, 0.9636363636363636, 0.9626262626262626]
2022-01-25 12:45:45:INFO:Loss = [0.009723607508578536, 0.013093617140707052, 0.08526690384497128, 0.08352019329775229, 0.028464407550295664, 0.03052943766583345, 0.03118937184459135, 0.028324165979001642, 0.07108804842905786, 0.08376016422243074]
2022-01-25 12:45:45:INFO:-------------Training local models-------------
2022-01-25 12:48:37:INFO:-------------Aggregating local models-------------
2022-01-25 12:48:38:INFO:-------------Round number: 14-------------
2022-01-25 12:48:38:INFO:-------------Sending models-------------
2022-01-25 12:48:38:INFO:-------------Evaluating models-------------
2022-01-25 12:48:38:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:48:38:INFO:Accuracy = [1.0, 1.0, 0.952020202020202, 0.953030303030303, 0.9949494949494949, 0.9949494949494949, 0.9949494949494949, 0.9949494949494949, 0.9651515151515152, 0.9636363636363636]
2022-01-25 12:48:38:INFO:Loss = [0.008723281478836211, 0.011716207403323914, 0.08082449389639254, 0.07930737867743551, 0.026060527916015784, 0.02780101908173299, 0.02834553077374232, 0.025780938045566224, 0.06768394281881605, 0.07987021204816751]
2022-01-25 12:48:38:INFO:-------------Training local models-------------
2022-01-25 12:51:30:INFO:-------------Aggregating local models-------------
2022-01-25 12:51:31:INFO:-------------Round number: 15-------------
2022-01-25 12:51:31:INFO:-------------Sending models-------------
2022-01-25 12:51:31:INFO:-------------Evaluating models-------------
2022-01-25 12:51:31:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:51:31:INFO:Accuracy = [1.0, 1.0, 0.9535353535353536, 0.954040404040404, 0.9949494949494949, 0.9949494949494949, 0.9949494949494949, 0.9954545454545455, 0.9671717171717171, 0.9641414141414142]
2022-01-25 12:51:31:INFO:Loss = [0.00790032681652152, 0.010585790041350816, 0.0767963664398371, 0.07550507231834204, 0.024036390612382826, 0.025514242713894658, 0.025936122573535853, 0.023643311792561277, 0.0645987632438056, 0.07631777844252417]
2022-01-25 12:51:31:INFO:-------------Training local models-------------
2022-01-25 12:54:23:INFO:-------------Aggregating local models-------------
2022-01-25 12:54:23:INFO:-------------Round number: 16-------------
2022-01-25 12:54:23:INFO:-------------Sending models-------------
2022-01-25 12:54:24:INFO:-------------Evaluating models-------------
2022-01-25 12:54:24:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:54:24:INFO:Accuracy = [1.0, 1.0, 0.9580808080808081, 0.9585858585858585, 0.9949494949494949, 0.9954545454545455, 0.9954545454545455, 0.9959595959595959, 0.9712121212121212, 0.9646464646464646]
2022-01-25 12:54:24:INFO:Loss = [0.007212233043456864, 0.009643321625054626, 0.07311671342835362, 0.07204759419666994, 0.022312321435369674, 0.023575511144861023, 0.02388897471334503, 0.021836197301977656, 0.061783748488953204, 0.07305821975489674]
2022-01-25 12:54:24:INFO:-------------Training local models-------------
2022-01-25 12:57:16:INFO:-------------Aggregating local models-------------
2022-01-25 12:57:16:INFO:-------------Round number: 17-------------
2022-01-25 12:57:16:INFO:-------------Sending models-------------
2022-01-25 12:57:16:INFO:-------------Evaluating models-------------
2022-01-25 12:57:17:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 12:57:17:INFO:Accuracy = [1.0, 1.0, 0.9621212121212122, 0.9631313131313132, 0.9949494949494949, 0.9954545454545455, 0.9954545454545455, 0.9974747474747475, 0.9717171717171718, 0.9651515151515152]
2022-01-25 12:57:17:INFO:Loss = [0.00662960161906526, 0.008847402272842392, 0.06978115002672315, 0.06892272646301086, 0.020827828589920896, 0.021913223656531155, 0.02214286787572994, 0.020299392468954503, 0.059194042896581436, 0.07004344305658544]
2022-01-25 12:57:17:INFO:-------------Training local models-------------
2022-01-25 13:00:09:INFO:-------------Aggregating local models-------------
2022-01-25 13:00:09:INFO:-------------Round number: 18-------------
2022-01-25 13:00:09:INFO:-------------Sending models-------------
2022-01-25 13:00:09:INFO:-------------Evaluating models-------------
2022-01-25 13:00:09:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:00:09:INFO:Accuracy = [1.0, 1.0, 0.9646464646464646, 0.9661616161616161, 0.9959595959595959, 0.9964646464646465, 0.9964646464646465, 0.9974747474747475, 0.9737373737373738, 0.9656565656565657]
2022-01-25 13:00:09:INFO:Loss = [0.006130340900813051, 0.008166802733827316, 0.06676370635554618, 0.0661028735400348, 0.019536905269658268, 0.020474874767130287, 0.020643928782521123, 0.01898171842329597, 0.05681123092995176, 0.06725375849978217]
2022-01-25 13:00:09:INFO:-------------Training local models-------------
2022-01-25 13:03:01:INFO:-------------Aggregating local models-------------
2022-01-25 13:03:02:INFO:-------------Round number: 19-------------
2022-01-25 13:03:02:INFO:-------------Sending models-------------
2022-01-25 13:03:02:INFO:-------------Evaluating models-------------
2022-01-25 13:03:02:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:03:02:INFO:Accuracy = [1.0, 1.0, 0.9676767676767677, 0.9676767676767677, 0.996969696969697, 0.9964646464646465, 0.996969696969697, 0.9974747474747475, 0.9747474747474747, 0.9666666666666667]
2022-01-25 13:03:02:INFO:Loss = [0.005698576027726181, 0.007579246339196518, 0.06403968931762842, 0.06356073014650993, 0.018408808524948497, 0.01922331011523093, 0.019349236801446585, 0.017843216328750567, 0.054611668511496084, 0.06465853435376005]
2022-01-25 13:03:02:INFO:-------------Training local models-------------
2022-01-25 13:05:54:INFO:-------------Aggregating local models-------------
2022-01-25 13:05:55:INFO:-------------Round number: 20-------------
2022-01-25 13:05:55:INFO:-------------Sending models-------------
2022-01-25 13:05:55:INFO:-------------Evaluating models-------------
2022-01-25 13:05:55:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:05:55:INFO:Accuracy = [1.0, 1.0, 0.9691919191919192, 0.9691919191919192, 0.996969696969697, 0.996969696969697, 0.996969696969697, 0.996969696969697, 0.9772727272727273, 0.9681818181818181]
2022-01-25 13:05:55:INFO:Loss = [0.00532166855924203, 0.007067220349651479, 0.06159023799452251, 0.06127593687141221, 0.017413749430881875, 0.01812399180211783, 0.018223252026567053, 0.016853060647627725, 0.05257666670695839, 0.06222923111174646]
2022-01-25 13:05:55:INFO:-------------Training local models-------------
2022-01-25 13:08:47:INFO:-------------Aggregating local models-------------
2022-01-25 13:08:48:INFO:-------------Round number: 21-------------
2022-01-25 13:08:48:INFO:-------------Sending models-------------
2022-01-25 13:08:48:INFO:-------------Evaluating models-------------
2022-01-25 13:08:48:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:08:48:INFO:Accuracy = [1.0, 1.0, 0.9712121212121212, 0.9707070707070707, 0.9974747474747475, 0.996969696969697, 0.9974747474747475, 0.9974747474747475, 0.9777777777777777, 0.9681818181818181]
2022-01-25 13:08:48:INFO:Loss = [0.0049896786123163755, 0.0066170407342136545, 0.05938354157323825, 0.05921643809857102, 0.016528423085166118, 0.01715027346116117, 0.017236969516656098, 0.01598437247846941, 0.050703544366659095, 0.059954201479029676]
2022-01-25 13:08:48:INFO:-------------Training local models-------------
2022-01-25 13:11:40:INFO:-------------Aggregating local models-------------
2022-01-25 13:11:41:INFO:-------------Round number: 22-------------
2022-01-25 13:11:41:INFO:-------------Sending models-------------
2022-01-25 13:11:41:INFO:-------------Evaluating models-------------
2022-01-25 13:11:41:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:11:41:INFO:Accuracy = [1.0, 1.0, 0.9742424242424242, 0.9722222222222222, 0.997979797979798, 0.9974747474747475, 0.996969696969697, 0.9974747474747475, 0.9777777777777777, 0.9696969696969697]
2022-01-25 13:11:41:INFO:Loss = [0.004695509441874244, 0.006218594112439373, 0.05739518481262929, 0.05735944643609474, 0.01573875652287494, 0.016284865342995454, 0.016367696060530366, 0.01521731917290699, 0.04897851086265144, 0.05781911041701067]
2022-01-25 13:11:41:INFO:-------------Training local models-------------
2022-01-25 13:14:33:INFO:-------------Aggregating local models-------------
2022-01-25 13:14:34:INFO:-------------Round number: 23-------------
2022-01-25 13:14:34:INFO:-------------Sending models-------------
2022-01-25 13:14:34:INFO:-------------Evaluating models-------------
2022-01-25 13:14:34:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:14:34:INFO:Accuracy = [1.0, 1.0, 0.9742424242424242, 0.9737373737373738, 0.997979797979798, 0.9974747474747475, 0.996969696969697, 0.9974747474747475, 0.9803030303030303, 0.9722222222222222]
2022-01-25 13:14:34:INFO:Loss = [0.004433275469004958, 0.005863478007277173, 0.0556032139734739, 0.055686556083424196, 0.015031248800038487, 0.015511878190877862, 0.015596418064325752, 0.014535398286784355, 0.047390357997371915, 0.055809074370049394]
2022-01-25 13:14:34:INFO:-------------Training local models-------------
2022-01-25 13:17:26:INFO:-------------Aggregating local models-------------
2022-01-25 13:17:27:INFO:-------------Round number: 24-------------
2022-01-25 13:17:27:INFO:-------------Sending models-------------
2022-01-25 13:17:27:INFO:-------------Evaluating models-------------
2022-01-25 13:17:27:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:17:27:INFO:Accuracy = [1.0, 1.0, 0.9757575757575757, 0.9742424242424242, 0.997979797979798, 0.9974747474747475, 0.996969696969697, 0.9974747474747475, 0.9808080808080808, 0.9742424242424242]
2022-01-25 13:17:27:INFO:Loss = [0.004198145527216827, 0.005545363265426002, 0.05398148401834969, 0.054170120860112775, 0.014393587628258346, 0.014817343435571834, 0.01490742486341259, 0.01392469455504489, 0.04592892246770924, 0.053918458359501785]
2022-01-25 13:17:27:INFO:-------------Training local models-------------
2022-01-25 13:20:19:INFO:-------------Aggregating local models-------------
2022-01-25 13:20:19:INFO:-------------Round number: 25-------------
2022-01-25 13:20:19:INFO:-------------Sending models-------------
2022-01-25 13:20:19:INFO:-------------Evaluating models-------------
2022-01-25 13:20:20:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:20:20:INFO:Accuracy = [1.0, 1.0, 0.9767676767676767, 0.9747474747474747, 0.997979797979798, 0.9974747474747475, 0.996969696969697, 0.9974747474747475, 0.9828282828282828, 0.9772727272727273]
2022-01-25 13:20:20:INFO:Loss = [0.003986073936341034, 0.0052586160604889045, 0.05251419298621859, 0.05279495314929535, 0.013815962453108196, 0.014190122460172691, 0.014288057791859363, 0.013374492329515333, 0.04459173391150391, 0.05214679303759535]
2022-01-25 13:20:20:INFO:-------------Training local models-------------
2022-01-25 13:23:12:INFO:-------------Aggregating local models-------------
2022-01-25 13:23:12:INFO:-------------Round number: 26-------------
2022-01-25 13:23:12:INFO:-------------Sending models-------------
2022-01-25 13:23:12:INFO:-------------Evaluating models-------------
2022-01-25 13:23:12:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:23:12:INFO:Accuracy = [1.0, 1.0, 0.9767676767676767, 0.9752525252525253, 0.997979797979798, 0.9974747474747475, 0.996969696969697, 0.9974747474747475, 0.9838383838383838, 0.9787878787878788]
2022-01-25 13:23:12:INFO:Loss = [0.0037941598538762064, 0.004999338778225597, 0.05118128954873284, 0.051543420354963274, 0.0132914661945754, 0.01362231525442871, 0.013728650194043623, 0.012876463720088147, 0.04336590355146333, 0.05048631715214626]
2022-01-25 13:23:12:INFO:-------------Training local models-------------
2022-01-25 13:26:05:INFO:-------------Aggregating local models-------------
2022-01-25 13:26:05:INFO:-------------Round number: 27-------------
2022-01-25 13:26:05:INFO:-------------Sending models-------------
2022-01-25 13:26:05:INFO:-------------Evaluating models-------------
2022-01-25 13:26:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:26:05:INFO:Accuracy = [1.0, 1.0, 0.9777777777777777, 0.9762626262626263, 0.997979797979798, 0.997979797979798, 0.996969696969697, 0.9974747474747475, 0.9838383838383838, 0.9792929292929293]
2022-01-25 13:26:05:INFO:Loss = [0.003619458167896032, 0.004763500456950472, 0.049972411386716896, 0.05040770477215928, 0.012813246995431132, 0.013106182628682217, 0.013220734486969027, 0.012423363805224066, 0.04224143934627522, 0.04893120577956627]
2022-01-25 13:26:05:INFO:-------------Training local models-------------
2022-01-25 13:28:57:INFO:-------------Aggregating local models-------------
2022-01-25 13:28:58:INFO:-------------Round number: 28-------------
2022-01-25 13:28:58:INFO:-------------Sending models-------------
2022-01-25 13:28:58:INFO:-------------Evaluating models-------------
2022-01-25 13:28:58:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:28:58:INFO:Accuracy = [1.0, 1.0, 0.9777777777777777, 0.9772727272727273, 0.997979797979798, 0.997979797979798, 0.996969696969697, 0.9974747474747475, 0.9848484848484849, 0.9803030303030303]
2022-01-25 13:28:58:INFO:Loss = [0.0034602791935968626, 0.00454869976114644, 0.0488654036018727, 0.0493654771970401, 0.012375819337900582, 0.012635004947933891, 0.012757863347757269, 0.012009762185018667, 0.04121126237598329, 0.047480241346571035]
2022-01-25 13:28:58:INFO:-------------Training local models-------------
2022-01-25 13:31:50:INFO:-------------Aggregating local models-------------
2022-01-25 13:31:51:INFO:-------------Round number: 29-------------
2022-01-25 13:31:51:INFO:-------------Sending models-------------
2022-01-25 13:31:51:INFO:-------------Evaluating models-------------
2022-01-25 13:31:51:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:31:51:INFO:Accuracy = [1.0, 1.0, 0.9787878787878788, 0.9782828282828283, 0.997979797979798, 0.997979797979798, 0.996969696969697, 0.9974747474747475, 0.9848484848484849, 0.9808080808080808]
2022-01-25 13:31:51:INFO:Loss = [0.003314866782286595, 0.004352531166726046, 0.047850567960260305, 0.04840380233332381, 0.01197346862963509, 0.012202612366724284, 0.01233481863900758, 0.011631124073572191, 0.04026736453249921, 0.04613065687524134]
2022-01-25 13:31:51:INFO:-------------Training local models-------------
2022-01-25 13:34:43:INFO:-------------Aggregating local models-------------
2022-01-25 13:34:44:INFO:-------------Round number: 30-------------
2022-01-25 13:34:44:INFO:-------------Sending models-------------
2022-01-25 13:34:44:INFO:-------------Evaluating models-------------
2022-01-25 13:34:44:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:34:44:INFO:Accuracy = [1.0, 1.0, 0.9797979797979798, 0.9782828282828283, 0.998989898989899, 0.9984848484848485, 0.996969696969697, 0.9974747474747475, 0.9853535353535353, 0.9818181818181818]
2022-01-25 13:34:44:INFO:Loss = [0.003181081659891384, 0.0041721076972375745, 0.04691299155079336, 0.047514368495673136, 0.011602553358453506, 0.011805078897488802, 0.01194629285664173, 0.011282379507905019, 0.03940184489532692, 0.04487775238366054]
2022-01-25 13:34:44:INFO:-------------Training local models-------------
2022-01-25 13:37:36:INFO:-------------Aggregating local models-------------
2022-01-25 13:37:36:INFO:-------------Round number: 31-------------
2022-01-25 13:37:36:INFO:-------------Sending models-------------
2022-01-25 13:37:36:INFO:-------------Evaluating models-------------
2022-01-25 13:37:37:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:37:37:INFO:Accuracy = [1.0, 1.0, 0.9797979797979798, 0.9792929292929293, 0.998989898989899, 0.998989898989899, 0.996969696969697, 0.9974747474747475, 0.9858585858585859, 0.9818181818181818]
2022-01-25 13:37:37:INFO:Loss = [0.0030578284763385344, 0.004005894289576011, 0.04604699187321151, 0.04668992129813014, 0.011259104051927664, 0.011437883296501682, 0.01158845406698858, 0.010960675395905825, 0.038606922562324356, 0.04371472212515073]
2022-01-25 13:37:37:INFO:-------------Training local models-------------
2022-01-25 13:40:28:INFO:-------------Aggregating local models-------------
2022-01-25 13:40:29:INFO:-------------Round number: 32-------------
2022-01-25 13:40:29:INFO:-------------Sending models-------------
2022-01-25 13:40:29:INFO:-------------Evaluating models-------------
2022-01-25 13:40:29:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:40:29:INFO:Accuracy = [1.0, 1.0, 0.9797979797979798, 0.9797979797979798, 0.998989898989899, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9863636363636363, 0.9823232323232324]
2022-01-25 13:40:29:INFO:Loss = [0.0029440963801762063, 0.0038525576901391636, 0.04524215717108819, 0.04591829199327751, 0.010941643287390094, 0.011098906629128826, 0.011257964877821528, 0.010663133106719775, 0.03787172400750363, 0.0426307653704149]
2022-01-25 13:40:29:INFO:-------------Training local models-------------
2022-01-25 13:43:21:INFO:-------------Aggregating local models-------------
2022-01-25 13:43:22:INFO:-------------Round number: 33-------------
2022-01-25 13:43:22:INFO:-------------Sending models-------------
2022-01-25 13:43:22:INFO:-------------Evaluating models-------------
2022-01-25 13:43:22:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:43:22:INFO:Accuracy = [1.0, 1.0, 0.9803030303030303, 0.9808080808080808, 0.998989898989899, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9863636363636363, 0.9823232323232324]
2022-01-25 13:43:22:INFO:Loss = [0.002838724220069854, 0.0037104984775516016, 0.044493261174706866, 0.0451976519275643, 0.010647714726347299, 0.010785304987604665, 0.010951574086849554, 0.010386871002625375, 0.03719207145837535, 0.041624177443810195]
2022-01-25 13:43:22:INFO:-------------Training local models-------------
2022-01-25 13:46:13:INFO:-------------Aggregating local models-------------
2022-01-25 13:46:14:INFO:-------------Round number: 34-------------
2022-01-25 13:46:14:INFO:-------------Sending models-------------
2022-01-25 13:46:14:INFO:-------------Evaluating models-------------
2022-01-25 13:46:14:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:46:14:INFO:Accuracy = [1.0, 1.0, 0.9803030303030303, 0.9808080808080808, 0.998989898989899, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9863636363636363, 0.9828282828282828]
2022-01-25 13:46:14:INFO:Loss = [0.0027411558022699084, 0.0035789732153514503, 0.04379085991812359, 0.044517426531945035, 0.010374089533154737, 0.010494241839103668, 0.010667295033915317, 0.010130148260346191, 0.036563837011055166, 0.040691589623101106]
2022-01-25 13:46:14:INFO:-------------Training local models-------------
2022-01-25 13:49:06:INFO:-------------Aggregating local models-------------
2022-01-25 13:49:06:INFO:-------------Round number: 35-------------
2022-01-25 13:49:06:INFO:-------------Sending models-------------
2022-01-25 13:49:07:INFO:-------------Evaluating models-------------
2022-01-25 13:49:07:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:49:07:INFO:Accuracy = [1.0, 1.0, 0.9808080808080808, 0.9808080808080808, 0.998989898989899, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9863636363636363, 0.9838383838383838]
2022-01-25 13:49:07:INFO:Loss = [0.0026502015851843736, 0.0034563793149903757, 0.04313300337108567, 0.0438800545292833, 0.01011785743911686, 0.010222773381371893, 0.010402290305773013, 0.009890507063751974, 0.035977333613985626, 0.039822997196402275]
2022-01-25 13:49:07:INFO:-------------Training local models-------------
2022-01-25 13:51:58:INFO:-------------Aggregating local models-------------
2022-01-25 13:51:58:INFO:-------------Round number: 36-------------
2022-01-25 13:51:58:INFO:-------------Sending models-------------
2022-01-25 13:51:59:INFO:-------------Evaluating models-------------
2022-01-25 13:51:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:51:59:INFO:Accuracy = [1.0, 1.0, 0.9813131313131314, 0.9813131313131314, 0.998989898989899, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9863636363636363, 0.9843434343434343]
2022-01-25 13:51:59:INFO:Loss = [0.002565426388776019, 0.0033421460717400265, 0.042512502425336725, 0.043276065580537745, 0.00987925147460603, 0.009970177714267541, 0.010155058088356681, 0.009666615358465339, 0.035426978585460206, 0.03901148723530103]
2022-01-25 13:51:59:INFO:-------------Training local models-------------
2022-01-25 13:54:48:INFO:-------------Aggregating local models-------------
2022-01-25 13:54:49:INFO:-------------Round number: 37-------------
2022-01-25 13:54:49:INFO:-------------Sending models-------------
2022-01-25 13:54:49:INFO:-------------Evaluating models-------------
2022-01-25 13:54:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:54:49:INFO:Accuracy = [1.0, 1.0, 0.9818181818181818, 0.9813131313131314, 0.998989898989899, 0.9994949494949495, 0.9974747474747475, 0.9974747474747475, 0.9868686868686869, 0.9848484848484849]
2022-01-25 13:54:49:INFO:Loss = [0.002486266505832765, 0.003235465034297456, 0.04192756515029657, 0.04270623516065164, 0.00965537332522952, 0.009733690842433428, 0.009923856112671806, 0.009457004567296033, 0.03491793759438389, 0.03826055560035236]
2022-01-25 13:54:49:INFO:-------------Training local models-------------
2022-01-25 13:57:38:INFO:-------------Aggregating local models-------------
2022-01-25 13:57:39:INFO:-------------Round number: 38-------------
2022-01-25 13:57:39:INFO:-------------Sending models-------------
2022-01-25 13:57:39:INFO:-------------Evaluating models-------------
2022-01-25 13:57:39:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 13:57:39:INFO:Accuracy = [1.0, 1.0, 0.9818181818181818, 0.9823232323232324, 0.998989898989899, 0.9994949494949495, 0.9974747474747475, 0.9974747474747475, 0.9868686868686869, 0.9848484848484849]
2022-01-25 13:57:39:INFO:Loss = [0.002412176337531142, 0.0031356614041453783, 0.04137167424104509, 0.04216290427120288, 0.009445994165442317, 0.009512825519564701, 0.009707402611078431, 0.009260552687214152, 0.03443755425845427, 0.03755678369190645]
2022-01-25 13:57:39:INFO:-------------Training local models-------------
2022-01-25 14:00:28:INFO:-------------Aggregating local models-------------
2022-01-25 14:00:29:INFO:-------------Round number: 39-------------
2022-01-25 14:00:29:INFO:-------------Sending models-------------
2022-01-25 14:00:29:INFO:-------------Evaluating models-------------
2022-01-25 14:00:29:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:00:29:INFO:Accuracy = [1.0, 1.0, 0.9818181818181818, 0.9823232323232324, 0.998989898989899, 0.9994949494949495, 0.9974747474747475, 0.9974747474747475, 0.9873737373737373, 0.9848484848484849]
2022-01-25 14:00:29:INFO:Loss = [0.0023426756900270713, 0.0030420141115565925, 0.040845890281542035, 0.04164790521520472, 0.009248529714313183, 0.009304921287820424, 0.009503968534680999, 0.009075821342831301, 0.0339867476500101, 0.036899689826105996]
2022-01-25 14:00:29:INFO:-------------Training local models-------------
2022-01-25 14:03:19:INFO:-------------Aggregating local models-------------
