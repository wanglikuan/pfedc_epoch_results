2022-01-27 02:29:54:INFO:-------------Round number: 0-------------
2022-01-27 02:29:54:INFO:-------------Sending models-------------
2022-01-27 02:29:55:INFO:-------------Evaluating models-------------
2022-01-27 02:29:56:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:29:56:INFO:Accuracy = [0.8998401704848162, 0.09922749067661162, 0.1001598295151838, 0.09909429941395845, 0.8790623335109217, 0.8826584976025573, 0.10042621204049014, 0.09962706446457112, 0.8991742141715503, 0.8994405966968567]
2022-01-27 02:29:56:INFO:Loss = [0.6655192559204904, 0.7253744506381837, 0.7186372587511879, 0.7332048017370872, 0.6907839094490591, 0.6898970211844655, 0.7393671502267419, 0.7035915054535701, 0.6847794067370618, 0.638321891172998]
2022-01-27 02:29:56:INFO:-------------Training local models-------------
2022-01-27 02:37:34:INFO:-------------Aggregating local models-------------
2022-01-27 02:37:39:INFO:-------------Round number: 1-------------
2022-01-27 02:37:39:INFO:-------------Sending models-------------
2022-01-27 02:37:40:INFO:-------------Evaluating models-------------
2022-01-27 02:37:41:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:37:41:INFO:Accuracy = [0.8998401704848162, 0.9007725093233884, 0.8998401704848162, 0.9009057005860416, 0.898907831646244, 0.9011720831113479, 0.8995737879595098, 0.9003729355354289, 0.8991742141715503, 0.8994405966968567]
2022-01-27 02:37:41:INFO:Loss = [0.3311553117409785, 0.367660545865565, 0.3489033487408591, 0.36055744507637316, 0.32684359689167225, 0.38135060255470815, 0.38466912620940547, 0.375865492864562, 0.3701200242956617, 0.35494825181034756]
2022-01-27 02:37:41:INFO:-------------Training local models-------------
2022-01-27 02:45:20:INFO:-------------Aggregating local models-------------
2022-01-27 02:45:25:INFO:-------------Round number: 2-------------
2022-01-27 02:45:25:INFO:-------------Sending models-------------
2022-01-27 02:45:25:INFO:-------------Evaluating models-------------
2022-01-27 02:45:26:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:45:26:INFO:Accuracy = [0.8998401704848162, 0.9007725093233884, 0.8998401704848162, 0.9009057005860416, 0.898907831646244, 0.9011720831113479, 0.8995737879595098, 0.9003729355354289, 0.8991742141715503, 0.8994405966968567]
2022-01-27 02:45:26:INFO:Loss = [0.29053710309761793, 0.2913937180950051, 0.29437970859383134, 0.28455411040134326, 0.2743319744662494, 0.29285362744966864, 0.2919718224970057, 0.29215931409466805, 0.29034858375597206, 0.3025072135842967]
2022-01-27 02:45:26:INFO:-------------Training local models-------------
2022-01-27 02:53:05:INFO:-------------Aggregating local models-------------
2022-01-27 02:53:10:INFO:-------------Round number: 3-------------
2022-01-27 02:53:10:INFO:-------------Sending models-------------
2022-01-27 02:53:11:INFO:-------------Evaluating models-------------
2022-01-27 02:53:11:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:53:11:INFO:Accuracy = [0.8998401704848162, 0.9007725093233884, 0.8998401704848162, 0.9009057005860416, 0.898907831646244, 0.9011720831113479, 0.8995737879595098, 0.9003729355354289, 0.8991742141715503, 0.8994405966968567]
2022-01-27 02:53:11:INFO:Loss = [0.2884615629754631, 0.28889068987515254, 0.28708229459212875, 0.2798735740776663, 0.26752628438354836, 0.2828783854811423, 0.28730934324337404, 0.28266296676272246, 0.2837039596556458, 0.29916084254211134]
2022-01-27 02:53:11:INFO:-------------Training local models-------------
2022-01-27 03:00:51:INFO:-------------Aggregating local models-------------
2022-01-27 03:00:56:INFO:-------------Round number: 4-------------
2022-01-27 03:00:56:INFO:-------------Sending models-------------
2022-01-27 03:00:57:INFO:-------------Evaluating models-------------
2022-01-27 03:00:58:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 03:00:58:INFO:Accuracy = [0.8998401704848162, 0.9007725093233884, 0.9003729355354289, 0.9009057005860416, 0.8993074054342035, 0.9011720831113479, 0.8995737879595098, 0.9003729355354289, 0.8991742141715503, 0.8994405966968567]
2022-01-27 03:00:58:INFO:Loss = [0.28652381951452793, 0.28836843421077135, 0.2830119780460784, 0.27795994853661393, 0.26271031876556084, 0.2795030193752671, 0.2860175116105748, 0.27878192869971663, 0.2809176817079872, 0.29632801059524333]
2022-01-27 03:00:58:INFO:-------------Training local models-------------
2022-01-27 03:08:26:INFO:-------------Aggregating local models-------------
2022-01-27 03:08:31:INFO:-------------Round number: 5-------------
2022-01-27 03:08:31:INFO:-------------Sending models-------------
2022-01-27 03:08:31:INFO:-------------Evaluating models-------------
2022-01-27 03:08:32:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 03:08:32:INFO:Accuracy = [0.8998401704848162, 0.9007725093233884, 0.9034363345764518, 0.9009057005860416, 0.9013052743740011, 0.9011720831113479, 0.8995737879595098, 0.9003729355354289, 0.8991742141715503, 0.8994405966968567]
2022-01-27 03:08:32:INFO:Loss = [0.283611816052917, 0.287947343194177, 0.27824670075874064, 0.27652116089247536, 0.2573067617294273, 0.2774843444599193, 0.2846482170683212, 0.27637078548415894, 0.27895398708343205, 0.2926329209106554]
2022-01-27 03:08:32:INFO:-------------Training local models-------------
2022-01-27 03:15:56:INFO:-------------Aggregating local models-------------
2022-01-27 03:16:01:INFO:-------------Round number: 6-------------
2022-01-27 03:16:01:INFO:-------------Sending models-------------
2022-01-27 03:16:02:INFO:-------------Evaluating models-------------
2022-01-27 03:16:03:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 03:16:03:INFO:Accuracy = [0.8998401704848162, 0.9007725093233884, 0.9053010122535962, 0.9009057005860416, 0.904368673415024, 0.9011720831113479, 0.8995737879595098, 0.9003729355354289, 0.8991742141715503, 0.8994405966968567]
2022-01-27 03:16:03:INFO:Loss = [0.27968333395407374, 0.28729490625127985, 0.27221688920295595, 0.27521777951176446, 0.25129777668765907, 0.2758561156969964, 0.28295487621436904, 0.2744504552400042, 0.27728604408279733, 0.287852577457267]
2022-01-27 03:16:03:INFO:-------------Training local models-------------
2022-01-27 03:23:28:INFO:-------------Aggregating local models-------------
2022-01-27 03:23:33:INFO:-------------Round number: 7-------------
2022-01-27 03:23:33:INFO:-------------Sending models-------------
2022-01-27 03:23:33:INFO:-------------Evaluating models-------------
2022-01-27 03:23:34:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 03:23:34:INFO:Accuracy = [0.9009057005860416, 0.9007725093233884, 0.9066329248801278, 0.9009057005860416, 0.9058337773042089, 0.9011720831113479, 0.8995737879595098, 0.9003729355354289, 0.8991742141715503, 0.8999733617474693]
2022-01-27 03:23:34:INFO:Loss = [0.27500713888117145, 0.28630305412434437, 0.2653783502565279, 0.2740024332222308, 0.245564220215965, 0.2743392309655729, 0.28097599608447554, 0.2725996966404294, 0.27573682998590365, 0.2823497368648974]
2022-01-27 03:23:34:INFO:-------------Training local models-------------
2022-01-27 03:30:59:INFO:-------------Aggregating local models-------------
2022-01-27 03:31:04:INFO:-------------Round number: 8-------------
2022-01-27 03:31:04:INFO:-------------Sending models-------------
2022-01-27 03:31:04:INFO:-------------Evaluating models-------------
2022-01-27 03:31:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 03:31:05:INFO:Accuracy = [0.902770378263186, 0.9007725093233884, 0.9072988811933937, 0.9018380394246137, 0.9061001598295152, 0.9011720831113479, 0.8995737879595098, 0.9005061267980821, 0.8991742141715503, 0.9041022908897176]
2022-01-27 03:31:05:INFO:Loss = [0.2701666529896209, 0.28496463516229426, 0.2586477847991151, 0.27288487518454824, 0.24068530209582809, 0.27281757245350335, 0.27885149162586187, 0.2706678703961448, 0.2742798900054088, 0.27667412151506626]
2022-01-27 03:31:05:INFO:-------------Training local models-------------
2022-01-27 03:38:30:INFO:-------------Aggregating local models-------------
2022-01-27 03:38:35:INFO:-------------Round number: 9-------------
2022-01-27 03:38:35:INFO:-------------Sending models-------------
2022-01-27 03:38:35:INFO:-------------Evaluating models-------------
2022-01-27 03:38:36:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 03:38:36:INFO:Accuracy = [0.9034363345764518, 0.9007725093233884, 0.909829515183804, 0.9023708044752264, 0.9091635588705381, 0.9011720831113479, 0.899706979222163, 0.9007725093233884, 0.8991742141715503, 0.9061001598295152]
2022-01-27 03:38:36:INFO:Loss = [0.2656668148176684, 0.28341805522171204, 0.2523746128354299, 0.2718522592838313, 0.2366294589936366, 0.27133416704566565, 0.276724452481813, 0.2685833588369924, 0.2728215628182024, 0.27156664479422676]
2022-01-27 03:38:36:INFO:-------------Training local models-------------
2022-01-27 03:46:01:INFO:-------------Aggregating local models-------------
2022-01-27 03:46:06:INFO:-------------Round number: 10-------------
2022-01-27 03:46:06:INFO:-------------Sending models-------------
2022-01-27 03:46:07:INFO:-------------Evaluating models-------------
2022-01-27 03:46:07:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 03:46:07:INFO:Accuracy = [0.9068993074054342, 0.9007725093233884, 0.9118273841236015, 0.9015716568993074, 0.9087639850825786, 0.9011720831113479, 0.9002397442727758, 0.9007725093233884, 0.8991742141715503, 0.9066329248801278]
2022-01-27 03:46:07:INFO:Loss = [0.2618858325367096, 0.28177751711274873, 0.24675558440557935, 0.27089700187819665, 0.23321333584972578, 0.26997812428016993, 0.27457977471139816, 0.2663871488774187, 0.2712980197682048, 0.2671091081261968]
2022-01-27 03:46:07:INFO:-------------Training local models-------------
2022-01-27 03:53:32:INFO:-------------Aggregating local models-------------
2022-01-27 03:53:37:INFO:-------------Round number: 11-------------
2022-01-27 03:53:37:INFO:-------------Sending models-------------
2022-01-27 03:53:38:INFO:-------------Evaluating models-------------
2022-01-27 03:53:39:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 03:53:39:INFO:Accuracy = [0.9076984549813533, 0.9007725093233884, 0.9118273841236015, 0.9018380394246137, 0.9088971763452317, 0.9011720831113479, 0.9015716568993074, 0.9023708044752264, 0.898907831646244, 0.906766116142781]
2022-01-27 03:53:39:INFO:Loss = [0.2588518443122927, 0.28017503085665774, 0.2417287403796033, 0.2699136625454137, 0.23034017557035397, 0.2687720097551796, 0.27252816411204633, 0.26417678397787175, 0.26974656449240864, 0.26313607940489014]
2022-01-27 03:53:39:INFO:-------------Training local models-------------
2022-01-27 04:01:03:INFO:-------------Aggregating local models-------------
2022-01-27 04:01:08:INFO:-------------Round number: 12-------------
2022-01-27 04:01:08:INFO:-------------Sending models-------------
2022-01-27 04:01:08:INFO:-------------Evaluating models-------------
2022-01-27 04:01:09:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 04:01:09:INFO:Accuracy = [0.9078316462440064, 0.9015716568993074, 0.913825253063399, 0.9017048481619606, 0.9096963239211507, 0.9011720831113479, 0.9030367607884923, 0.9030367607884923, 0.8994405966968567, 0.9070324986680873]
2022-01-27 04:01:09:INFO:Loss = [0.25646570642351246, 0.27867871569165664, 0.23721079208893572, 0.26900841283910154, 0.22804494427357536, 0.26774579400720633, 0.2705568861485234, 0.2620268502578682, 0.26814199229637853, 0.25942687216806776]
2022-01-27 04:01:09:INFO:-------------Training local models-------------
2022-01-27 04:08:34:INFO:-------------Aggregating local models-------------
2022-01-27 04:08:39:INFO:-------------Round number: 13-------------
2022-01-27 04:08:39:INFO:-------------Sending models-------------
2022-01-27 04:08:40:INFO:-------------Evaluating models-------------
2022-01-27 04:08:40:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 04:08:40:INFO:Accuracy = [0.9061001598295152, 0.9014384656366542, 0.9150239744272776, 0.9013052743740011, 0.9090303676078849, 0.9011720831113479, 0.9034363345764518, 0.9047682472029834, 0.8998401704848162, 0.9078316462440064]
2022-01-27 04:08:40:INFO:Loss = [0.254439416249691, 0.277324228334871, 0.23316356530447763, 0.2681156299386464, 0.2262614732698131, 0.2668716624095345, 0.26867796548086004, 0.2598636807571116, 0.26649692228840954, 0.2559032276755057]
2022-01-27 04:08:40:INFO:-------------Training local models-------------
2022-01-27 04:16:06:INFO:-------------Aggregating local models-------------
2022-01-27 04:16:11:INFO:-------------Round number: 14-------------
2022-01-27 04:16:11:INFO:-------------Sending models-------------
2022-01-27 04:16:11:INFO:-------------Evaluating models-------------
2022-01-27 04:16:12:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 04:16:12:INFO:Accuracy = [0.905966968566862, 0.9019712306872669, 0.9159563132658498, 0.9011720831113479, 0.9104954714970698, 0.9011720831113479, 0.9041022908897176, 0.9063665423548215, 0.9010388918486947, 0.9078316462440064]
2022-01-27 04:16:12:INFO:Loss = [0.2528085312858168, 0.2760450007685863, 0.22941750956110787, 0.2672240028915615, 0.22477511379862333, 0.2660770075696882, 0.2668498608099617, 0.2578330017444499, 0.2648424589812962, 0.2524506486386664]
2022-01-27 04:16:12:INFO:-------------Training local models-------------
2022-01-27 04:23:36:INFO:-------------Aggregating local models-------------
2022-01-27 04:23:41:INFO:-------------Round number: 15-------------
2022-01-27 04:23:41:INFO:-------------Sending models-------------
2022-01-27 04:23:41:INFO:-------------Evaluating models-------------
2022-01-27 04:23:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 04:23:42:INFO:Accuracy = [0.9055673947789025, 0.9018380394246137, 0.9175546084176878, 0.9013052743740011, 0.9104954714970698, 0.9011720831113479, 0.9053010122535962, 0.9076984549813533, 0.9022376132125732, 0.9076984549813533]
2022-01-27 04:23:42:INFO:Loss = [0.2512749002479338, 0.2747312026091176, 0.22579023639681925, 0.2663310674774834, 0.22349372091735367, 0.26534849254897713, 0.2650502601010277, 0.2558299511486303, 0.26310762681154315, 0.2490025183506465]
2022-01-27 04:23:42:INFO:-------------Training local models-------------
2022-01-27 04:31:07:INFO:-------------Aggregating local models-------------
2022-01-27 04:31:12:INFO:-------------Round number: 16-------------
2022-01-27 04:31:12:INFO:-------------Sending models-------------
2022-01-27 04:31:13:INFO:-------------Evaluating models-------------
2022-01-27 04:31:13:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 04:31:13:INFO:Accuracy = [0.905167820990943, 0.9029035695258391, 0.9191529035695258, 0.9015716568993074, 0.9108950452850293, 0.9015716568993074, 0.9062333510921684, 0.9095631326584976, 0.9030367607884923, 0.9084976025572722]
2022-01-27 04:31:13:INFO:Loss = [0.24976797341371573, 0.27335359988060937, 0.2223200636410259, 0.26552725290853185, 0.22233984875139226, 0.26461844143150576, 0.263214937592353, 0.25389170043032017, 0.2613149403212875, 0.24568441717502884]
2022-01-27 04:31:13:INFO:-------------Training local models-------------
2022-01-27 04:38:38:INFO:-------------Aggregating local models-------------
2022-01-27 04:38:43:INFO:-------------Round number: 17-------------
2022-01-27 04:38:43:INFO:-------------Sending models-------------
2022-01-27 04:38:44:INFO:-------------Evaluating models-------------
2022-01-27 04:38:45:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 04:38:45:INFO:Accuracy = [0.9046350559403303, 0.9037027171017581, 0.919286094832179, 0.9017048481619606, 0.9110282365476825, 0.9019712306872669, 0.9066329248801278, 0.9104954714970698, 0.903569525839105, 0.9092967501331912]
2022-01-27 04:38:45:INFO:Loss = [0.24866684730331917, 0.2718791372196722, 0.21896577354016444, 0.2646888123164224, 0.22132710924529117, 0.2637544645450029, 0.2613300876949949, 0.2520575433848617, 0.2595154859818276, 0.2424361704916683]
2022-01-27 04:38:45:INFO:-------------Training local models-------------
2022-01-27 04:46:10:INFO:-------------Aggregating local models-------------
2022-01-27 04:46:15:INFO:-------------Round number: 18-------------
2022-01-27 04:46:15:INFO:-------------Sending models-------------
2022-01-27 04:46:15:INFO:-------------Evaluating models-------------
2022-01-27 04:46:16:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 04:46:16:INFO:Accuracy = [0.9046350559403303, 0.9039690996270645, 0.9207511987213639, 0.9019712306872669, 0.911427810335642, 0.9022376132125732, 0.9066329248801278, 0.9111614278103356, 0.9042354821523708, 0.9100958977091103]
2022-01-27 04:46:16:INFO:Loss = [0.24759108804317154, 0.270372587794097, 0.2158735177951548, 0.2638714365982666, 0.22037151973530453, 0.2627807998492397, 0.25947226238569476, 0.25032665143984645, 0.2577230691211174, 0.2393245212743669]
2022-01-27 04:46:16:INFO:-------------Training local models-------------
2022-01-27 04:53:41:INFO:-------------Aggregating local models-------------
2022-01-27 04:53:46:INFO:-------------Round number: 19-------------
2022-01-27 04:53:46:INFO:-------------Sending models-------------
2022-01-27 04:53:46:INFO:-------------Evaluating models-------------
2022-01-27 04:53:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 04:53:47:INFO:Accuracy = [0.9050346297282899, 0.904368673415024, 0.921683537559936, 0.9021044219499201, 0.9123601491742142, 0.9025039957378796, 0.9076984549813533, 0.911427810335642, 0.9050346297282899, 0.9111614278103356]
2022-01-27 04:53:47:INFO:Loss = [0.24660464882410044, 0.2688750015923471, 0.21293231437888768, 0.26310741110598407, 0.21935099733034055, 0.26170305284231377, 0.2576467825479897, 0.24857891794113263, 0.25582054343578675, 0.23613465644645448]
2022-01-27 04:53:47:INFO:-------------Training local models-------------
2022-01-27 05:01:12:INFO:-------------Aggregating local models-------------
2022-01-27 05:01:17:INFO:-------------Round number: 20-------------
2022-01-27 05:01:17:INFO:-------------Sending models-------------
2022-01-27 05:01:17:INFO:-------------Evaluating models-------------
2022-01-27 05:01:18:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 05:01:18:INFO:Accuracy = [0.9053010122535962, 0.9046350559403303, 0.9230154501864678, 0.9023708044752264, 0.9127597229621737, 0.9030367607884923, 0.9090303676078849, 0.9124933404368674, 0.9057005860415557, 0.9127597229621737]
2022-01-27 05:01:18:INFO:Loss = [0.24574457799353908, 0.2673864517868328, 0.21032385344204746, 0.26228373098032964, 0.21846062075558204, 0.2605858740372485, 0.2557867646398947, 0.24696901131819013, 0.2539231423015687, 0.2331660142149548]
2022-01-27 05:01:18:INFO:-------------Training local models-------------
2022-01-27 05:08:43:INFO:-------------Aggregating local models-------------
2022-01-27 05:08:48:INFO:-------------Round number: 21-------------
2022-01-27 05:08:48:INFO:-------------Sending models-------------
2022-01-27 05:08:48:INFO:-------------Evaluating models-------------
2022-01-27 05:08:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 05:08:49:INFO:Accuracy = [0.9054342035162494, 0.9054342035162494, 0.924746936600959, 0.902770378263186, 0.9134256792754395, 0.9037027171017581, 0.9100958977091103, 0.9126265316995205, 0.9062333510921684, 0.9135588705380927]
2022-01-27 05:08:49:INFO:Loss = [0.24521099004674193, 0.2659028611127245, 0.2078746544017586, 0.26152724492082424, 0.21762742159795612, 0.2594534852065654, 0.25399337955499957, 0.24554528153972693, 0.25188265651013936, 0.23032208401005225]
2022-01-27 05:08:49:INFO:-------------Training local models-------------
2022-01-27 05:16:14:INFO:-------------Aggregating local models-------------
2022-01-27 05:16:19:INFO:-------------Round number: 22-------------
2022-01-27 05:16:19:INFO:-------------Sending models-------------
2022-01-27 05:16:19:INFO:-------------Evaluating models-------------
2022-01-27 05:16:20:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 05:16:20:INFO:Accuracy = [0.905966968566862, 0.9055673947789025, 0.925546084176878, 0.9029035695258391, 0.9135588705380927, 0.9046350559403303, 0.9107618540223761, 0.9126265316995205, 0.9078316462440064, 0.9150239744272776]
2022-01-27 05:16:20:INFO:Loss = [0.24470040069463314, 0.2644630683548385, 0.20573160736427132, 0.26077545558969, 0.21678677521735706, 0.25838801189989136, 0.25218244733365297, 0.24429776271924933, 0.24984225990587114, 0.2276631540464526]
2022-01-27 05:16:20:INFO:-------------Training local models-------------
2022-01-27 05:23:45:INFO:-------------Aggregating local models-------------
2022-01-27 05:23:50:INFO:-------------Round number: 23-------------
2022-01-27 05:23:50:INFO:-------------Sending models-------------
2022-01-27 05:23:51:INFO:-------------Evaluating models-------------
2022-01-27 05:23:51:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 05:23:51:INFO:Accuracy = [0.9050346297282899, 0.9063665423548215, 0.925546084176878, 0.9042354821523708, 0.9139584443260522, 0.905966968566862, 0.9118273841236015, 0.9127597229621737, 0.9087639850825786, 0.9162226957911561]
2022-01-27 05:23:51:INFO:Loss = [0.2440395462626892, 0.263018178934318, 0.20376469292089971, 0.2600391046173219, 0.2159159430903673, 0.25738202153442585, 0.25038448087355053, 0.24322035802351438, 0.24781635373564845, 0.2251584725528876]
2022-01-27 05:23:51:INFO:-------------Training local models-------------
2022-01-27 05:31:16:INFO:-------------Aggregating local models-------------
2022-01-27 05:31:21:INFO:-------------Round number: 24-------------
2022-01-27 05:31:21:INFO:-------------Sending models-------------
2022-01-27 05:31:21:INFO:-------------Evaluating models-------------
2022-01-27 05:31:22:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 05:31:22:INFO:Accuracy = [0.9055673947789025, 0.9061001598295152, 0.9258124667021843, 0.9046350559403303, 0.9148907831646244, 0.9063665423548215, 0.9124933404368674, 0.9136920618007459, 0.9092967501331912, 0.917687799680341]
2022-01-27 05:31:22:INFO:Loss = [0.24381983882638927, 0.26154605685618365, 0.20192881199775872, 0.2592966034660487, 0.21523529106451394, 0.25638371673583804, 0.24861512878204145, 0.24222039332703033, 0.24580317030804202, 0.2227459200268406]
2022-01-27 05:31:22:INFO:-------------Training local models-------------
2022-01-27 05:38:48:INFO:-------------Aggregating local models-------------
2022-01-27 05:38:53:INFO:-------------Round number: 25-------------
2022-01-27 05:38:53:INFO:-------------Sending models-------------
2022-01-27 05:38:53:INFO:-------------Evaluating models-------------
2022-01-27 05:38:54:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 05:38:54:INFO:Accuracy = [0.905167820990943, 0.9063665423548215, 0.9262120404901438, 0.9047682472029834, 0.9160895045285029, 0.9066329248801278, 0.9128929142248269, 0.913825253063399, 0.9100958977091103, 0.9183537559936068]
2022-01-27 05:38:54:INFO:Loss = [0.24333654541956914, 0.2600739113396508, 0.20012653010788675, 0.2584497356596544, 0.21441422345956637, 0.2554787066172199, 0.24691393690409022, 0.24142642280094442, 0.2438516668870164, 0.22037870927823466]
2022-01-27 05:38:54:INFO:-------------Training local models-------------
2022-01-27 05:46:19:INFO:-------------Aggregating local models-------------
2022-01-27 05:46:24:INFO:-------------Round number: 26-------------
2022-01-27 05:46:24:INFO:-------------Sending models-------------
2022-01-27 05:46:24:INFO:-------------Evaluating models-------------
2022-01-27 05:46:25:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 05:46:25:INFO:Accuracy = [0.9058337773042089, 0.9080980287693128, 0.9268779968034097, 0.9053010122535962, 0.9158231220031966, 0.9064997336174747, 0.9139584443260522, 0.914624400639318, 0.9104954714970698, 0.9196856686201386]
2022-01-27 05:46:25:INFO:Loss = [0.24280497773918117, 0.25858628861966937, 0.19838798246567213, 0.2576065665344552, 0.21365969940351662, 0.254652156824515, 0.24531567775727223, 0.24077882531430095, 0.2419547555783588, 0.2182200781258739]
2022-01-27 05:46:25:INFO:-------------Training local models-------------
2022-01-27 05:53:50:INFO:-------------Aggregating local models-------------
2022-01-27 05:53:55:INFO:-------------Round number: 27-------------
2022-01-27 05:53:55:INFO:-------------Sending models-------------
2022-01-27 05:53:55:INFO:-------------Evaluating models-------------
2022-01-27 05:53:56:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 05:53:56:INFO:Accuracy = [0.905966968566862, 0.9084976025572722, 0.9274107618540224, 0.9053010122535962, 0.9162226957911561, 0.906766116142781, 0.914624400639318, 0.9147575919019713, 0.9104954714970698, 0.9210175812466702]
2022-01-27 05:53:56:INFO:Loss = [0.24207882757199908, 0.25717099362495227, 0.19671424885901145, 0.2567523493413739, 0.21285960181648747, 0.25392410566273144, 0.24384739991678367, 0.24038733468484902, 0.24015273809081691, 0.21608709784092647]
2022-01-27 05:53:56:INFO:-------------Training local models-------------
2022-01-27 06:01:21:INFO:-------------Aggregating local models-------------
2022-01-27 06:01:26:INFO:-------------Round number: 28-------------
2022-01-27 06:01:26:INFO:-------------Sending models-------------
2022-01-27 06:01:26:INFO:-------------Evaluating models-------------
2022-01-27 06:01:27:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 06:01:27:INFO:Accuracy = [0.9068993074054342, 0.9096963239211507, 0.9280767181672882, 0.9055673947789025, 0.9163558870538092, 0.9074320724560468, 0.9147575919019713, 0.9147575919019713, 0.9108950452850293, 0.9223494938732019]
2022-01-27 06:01:27:INFO:Loss = [0.24153701416139883, 0.25578289714681535, 0.19521184141619144, 0.2558487190948834, 0.21211312931082094, 0.2532760358088564, 0.24251889257622833, 0.23987360790289838, 0.23843054275425846, 0.21419847485215884]
2022-01-27 06:01:27:INFO:-------------Training local models-------------
2022-01-27 06:08:52:INFO:-------------Aggregating local models-------------
2022-01-27 06:08:57:INFO:-------------Round number: 29-------------
2022-01-27 06:08:57:INFO:-------------Sending models-------------
2022-01-27 06:08:58:INFO:-------------Evaluating models-------------
2022-01-27 06:08:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 06:08:59:INFO:Accuracy = [0.9070324986680873, 0.9103622802344167, 0.9278103356419819, 0.9063665423548215, 0.9167554608417687, 0.9075652637187, 0.9155567394778903, 0.9151571656899308, 0.9115610015982951, 0.9228822589238146]
2022-01-27 06:08:59:INFO:Loss = [0.24127732111924052, 0.2545195050349132, 0.19389362553195094, 0.2549439941327896, 0.21132849373211032, 0.25271037697011073, 0.24138838914359464, 0.23951278513984456, 0.23677137123592512, 0.2123619965180858]
2022-01-27 06:08:59:INFO:-------------Training local models-------------
2022-01-27 06:16:23:INFO:-------------Aggregating local models-------------
