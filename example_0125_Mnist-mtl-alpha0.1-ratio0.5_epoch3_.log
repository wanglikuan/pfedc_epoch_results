2022-01-25 14:33:40:INFO:-------------Round number: 0-------------
2022-01-25 14:33:40:INFO:-------------Sending models-------------
2022-01-25 14:33:40:INFO:-------------Evaluating models-------------
2022-01-25 14:33:41:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:33:41:INFO:Accuracy = [0.8984360278876955, 0.8839268890145091, 0.8846806105144149, 0.9057848125117769, 0.9261352930092331, 0.0746184284906727, 0.11513095911060862, 0.10570944036178632, 0.09044657998869418, 0.8869417750141323]
2022-01-25 14:33:41:INFO:Loss = [0.6698315352150921, 0.6535867544269076, 0.6625111897674145, 0.6538707435928497, 0.6621472520726716, 0.7392828428455501, 0.7384982380980216, 0.7415181731063587, 0.7481898140251378, 0.6703967377585567]
2022-01-25 14:33:41:INFO:-------------Training local models-------------
2022-01-25 14:34:24:INFO:-------------Aggregating local models-------------
2022-01-25 14:34:25:INFO:-------------Round number: 1-------------
2022-01-25 14:34:25:INFO:-------------Sending models-------------
2022-01-25 14:34:25:INFO:-------------Evaluating models-------------
2022-01-25 14:34:26:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:34:26:INFO:Accuracy = [0.8315432447710571, 0.8654607122668174, 0.858111927642736, 0.8679103071415112, 0.8752590917655926, 0.7539099302807613, 0.7569248162803844, 0.6986998304126625, 0.8194837007725645, 0.6566798567929151]
2022-01-25 14:34:26:INFO:Loss = [0.5023840137720332, 0.5405867760135827, 0.547953840083314, 0.5234522761565403, 0.5219802235465322, 0.5997369474153499, 0.5900457559702018, 0.5989007102706371, 0.5613045549469073, 0.6649671794668708]
2022-01-25 14:34:26:INFO:-------------Training local models-------------
2022-01-25 14:35:09:INFO:-------------Aggregating local models-------------
2022-01-25 14:35:10:INFO:-------------Round number: 2-------------
2022-01-25 14:35:10:INFO:-------------Sending models-------------
2022-01-25 14:35:10:INFO:-------------Evaluating models-------------
2022-01-25 14:35:11:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:35:11:INFO:Accuracy = [0.8545317505181835, 0.8594309402675712, 0.8633879781420765, 0.8713020538910873, 0.8566044846429245, 0.8437912191445262, 0.8322969662709628, 0.8094968908988129, 0.8607499528924063, 0.7365743357829282]
2022-01-25 14:35:11:INFO:Loss = [0.43863562801271955, 0.4625207224423117, 0.47371069633491253, 0.4496924125538363, 0.4344846669297412, 0.5010636379815595, 0.50935237540944, 0.5168620052438392, 0.4894316056632706, 0.591612338093191]
2022-01-25 14:35:11:INFO:-------------Training local models-------------
2022-01-25 14:35:54:INFO:-------------Aggregating local models-------------
2022-01-25 14:35:55:INFO:-------------Round number: 3-------------
2022-01-25 14:35:55:INFO:-------------Sending models-------------
2022-01-25 14:35:56:INFO:-------------Evaluating models-------------
2022-01-25 14:35:56:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:35:56:INFO:Accuracy = [0.8622573958922178, 0.8567929150179009, 0.8594309402675712, 0.8694177501413228, 0.8535895986433013, 0.866968155266629, 0.8485019785189373, 0.83192010552101, 0.8739400791407574, 0.7710570944036179]
2022-01-25 14:35:56:INFO:Loss = [0.42886791213650544, 0.4173393050871687, 0.4450070358453407, 0.41678319881954995, 0.39018360625819815, 0.44233705324092915, 0.47829499450307433, 0.47857936569834375, 0.4608208896718261, 0.5442985843327258]
2022-01-25 14:35:56:INFO:-------------Training local models-------------
2022-01-25 14:36:40:INFO:-------------Aggregating local models-------------
2022-01-25 14:36:41:INFO:-------------Round number: 4-------------
2022-01-25 14:36:41:INFO:-------------Sending models-------------
2022-01-25 14:36:41:INFO:-------------Evaluating models-------------
2022-01-25 14:36:41:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:36:41:INFO:Accuracy = [0.8652722818918409, 0.8522705860184662, 0.8520821556434898, 0.8722442057659695, 0.8535895986433013, 0.8731863576408517, 0.8415300546448088, 0.8356887130205389, 0.8784624081401922, 0.800263802524967]
2022-01-25 14:36:41:INFO:Loss = [0.4301320538635499, 0.38734432136341973, 0.4349125752196387, 0.3984140740219305, 0.3656208862920664, 0.4055349164178575, 0.4663459877338768, 0.455242573953456, 0.44428105095434045, 0.5181310078140052]
2022-01-25 14:36:41:INFO:-------------Training local models-------------
2022-01-25 14:37:25:INFO:-------------Aggregating local models-------------
2022-01-25 14:37:26:INFO:-------------Round number: 5-------------
2022-01-25 14:37:26:INFO:-------------Sending models-------------
2022-01-25 14:37:26:INFO:-------------Evaluating models-------------
2022-01-25 14:37:26:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:37:26:INFO:Accuracy = [0.8662144337667232, 0.847936687394008, 0.8498209911437724, 0.8718673450160166, 0.8556623327680422, 0.8754475221405691, 0.8419069153947616, 0.8390804597701149, 0.879216129640098, 0.8257019031467873]
2022-01-25 14:37:26:INFO:Loss = [0.43301495219262665, 0.3651320633069748, 0.4318060270072417, 0.3860135440577249, 0.34860894015413013, 0.38161119992106124, 0.4611534568194573, 0.4374787210493322, 0.43254214134390195, 0.5031100269206976]
2022-01-25 14:37:26:INFO:-------------Training local models-------------
2022-01-25 14:38:10:INFO:-------------Aggregating local models-------------
2022-01-25 14:38:11:INFO:-------------Round number: 6-------------
2022-01-25 14:38:11:INFO:-------------Sending models-------------
2022-01-25 14:38:11:INFO:-------------Evaluating models-------------
2022-01-25 14:38:11:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:38:11:INFO:Accuracy = [0.8652722818918409, 0.8483135481439608, 0.8488788392688902, 0.8718673450160166, 0.8590540795176183, 0.8763896740154513, 0.8422837761447145, 0.840776333144903, 0.8797814207650273, 0.8366308648954212]
2022-01-25 14:38:11:INFO:Loss = [0.43576427238498644, 0.34782980280184767, 0.43079427123913516, 0.3769636856234436, 0.33487827068032244, 0.36589553216424886, 0.4581641479400068, 0.42255594558674797, 0.423493873968507, 0.4944096554870241]
2022-01-25 14:38:11:INFO:-------------Training local models-------------
2022-01-25 14:38:55:INFO:-------------Aggregating local models-------------
2022-01-25 14:38:56:INFO:-------------Round number: 7-------------
2022-01-25 14:38:56:INFO:-------------Sending models-------------
2022-01-25 14:38:56:INFO:-------------Evaluating models-------------
2022-01-25 14:38:56:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:38:56:INFO:Accuracy = [0.8630111173921237, 0.8535895986433013, 0.8483135481439608, 0.8701714716412285, 0.8616921047672885, 0.8746938006406633, 0.842472206519691, 0.8426606368946674, 0.8797814207650273, 0.8432259280195967]
2022-01-25 14:38:56:INFO:Loss = [0.4381618390318876, 0.3341410259137273, 0.43006996160581223, 0.3702330222107303, 0.32330041493646994, 0.3555627098327721, 0.4558930014635134, 0.4097387873172263, 0.4163764988450221, 0.48915479597127526]
2022-01-25 14:38:56:INFO:-------------Training local models-------------
2022-01-25 14:39:40:INFO:-------------Aggregating local models-------------
2022-01-25 14:39:41:INFO:-------------Round number: 8-------------
2022-01-25 14:39:41:INFO:-------------Sending models-------------
2022-01-25 14:39:41:INFO:-------------Evaluating models-------------
2022-01-25 14:39:41:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:39:41:INFO:Accuracy = [0.856416054267948, 0.8566044846429245, 0.8483135481439608, 0.872055775390993, 0.8641416996419823, 0.873751648765781, 0.8430374976446203, 0.8430374976446203, 0.8797814207650273, 0.8477482570190314]
2022-01-25 14:39:41:INFO:Loss = [0.4402814407080773, 0.3233283171621514, 0.42919624534324835, 0.36515758185613556, 0.31361171005687527, 0.348827403349532, 0.45401163126228106, 0.3987438205418298, 0.41083369563053435, 0.4857880986173324]
2022-01-25 14:39:41:INFO:-------------Training local models-------------
2022-01-25 14:40:25:INFO:-------------Aggregating local models-------------
2022-01-25 14:40:26:INFO:-------------Round number: 9-------------
2022-01-25 14:40:26:INFO:-------------Sending models-------------
2022-01-25 14:40:26:INFO:-------------Evaluating models-------------
2022-01-25 14:40:26:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:40:26:INFO:Accuracy = [0.847559826644055, 0.8601846617674769, 0.8486904088939137, 0.874128509515734, 0.8671565856416055, 0.8728094968908988, 0.8436027887695496, 0.8439796495195026, 0.8797814207650273, 0.8505747126436781]
2022-01-25 14:40:26:INFO:Loss = [0.44221249813321345, 0.3148764605744122, 0.4282042259518538, 0.361213745094628, 0.3056446321426015, 0.3444970253725479, 0.4525132147054428, 0.38939530517788723, 0.40659464130257766, 0.48348388588678953]
2022-01-25 14:40:26:INFO:-------------Training local models-------------
2022-01-25 14:41:10:INFO:-------------Aggregating local models-------------
2022-01-25 14:41:11:INFO:-------------Round number: 10-------------
2022-01-25 14:41:11:INFO:-------------Sending models-------------
2022-01-25 14:41:11:INFO:-------------Evaluating models-------------
2022-01-25 14:41:11:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:41:11:INFO:Accuracy = [0.8362540041454682, 0.861503674392312, 0.8490672696438666, 0.8760128132654984, 0.8703599020162051, 0.8716789146410401, 0.8454870925193141, 0.8443565102694555, 0.8797814207650273, 0.8524590163934426]
2022-01-25 14:41:11:INFO:Loss = [0.4439773552601626, 0.3083822510900323, 0.42720422199482405, 0.3580368033641697, 0.2991673913261367, 0.3418160024739062, 0.4513542271928698, 0.3814453077887748, 0.40339021631489314, 0.48178428585464017]
2022-01-25 14:41:11:INFO:-------------Training local models-------------
2022-01-25 14:41:55:INFO:-------------Aggregating local models-------------
2022-01-25 14:41:56:INFO:-------------Round number: 11-------------
2022-01-25 14:41:56:INFO:-------------Sending models-------------
2022-01-25 14:41:56:INFO:-------------Evaluating models-------------
2022-01-25 14:41:56:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:41:56:INFO:Accuracy = [0.8243828905219521, 0.8613152440173356, 0.8498209911437724, 0.8816657245147917, 0.8748822310156397, 0.8718673450160166, 0.8481251177689844, 0.8447333710194084, 0.8797814207650273, 0.8534011682683249]
2022-01-25 14:41:56:INFO:Loss = [0.44554297091635564, 0.303479760633499, 0.4263130051483277, 0.3553906683823217, 0.29394449926621474, 0.3403030048825222, 0.4504720906739125, 0.3746670228721329, 0.400972062763264, 0.4804460330762212]
2022-01-25 14:41:56:INFO:-------------Training local models-------------
2022-01-25 14:42:40:INFO:-------------Aggregating local models-------------
2022-01-25 14:42:41:INFO:-------------Round number: 12-------------
2022-01-25 14:42:41:INFO:-------------Sending models-------------
2022-01-25 14:42:41:INFO:-------------Evaluating models-------------
2022-01-25 14:42:41:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:42:41:INFO:Accuracy = [0.821368004522329, 0.8618805351422649, 0.8511400037686075, 0.8859996231392501, 0.8775202562653099, 0.8707367627661579, 0.850951573393631, 0.8447333710194084, 0.8797814207650273, 0.8539664593932542]
2022-01-25 14:42:41:INFO:Loss = [0.4468375559769352, 0.2998412697030565, 0.4255590430927321, 0.35310776275508027, 0.2897334290338536, 0.33960277673972455, 0.44982747779378185, 0.3688400661244122, 0.3991381429151242, 0.4793458873894264]
2022-01-25 14:42:41:INFO:-------------Training local models-------------
2022-01-25 14:43:25:INFO:-------------Aggregating local models-------------
2022-01-25 14:43:26:INFO:-------------Round number: 13-------------
2022-01-25 14:43:26:INFO:-------------Sending models-------------
2022-01-25 14:43:26:INFO:-------------Evaluating models-------------
2022-01-25 14:43:26:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:43:26:INFO:Accuracy = [0.8183531185227059, 0.8616921047672885, 0.8528358771433955, 0.8916525343885434, 0.8814772941398153, 0.8701714716412285, 0.8539664593932542, 0.8454870925193141, 0.8797814207650273, 0.8541548897682306]
2022-01-25 14:43:26:INFO:Loss = [0.4478227569537726, 0.29717526111708975, 0.42496052559479913, 0.3510815165703546, 0.28632333599859633, 0.3394731659333734, 0.4493567085215432, 0.3637696479276786, 0.3977376245196406, 0.47841107143366096]
2022-01-25 14:43:26:INFO:-------------Training local models-------------
2022-01-25 14:44:10:INFO:-------------Aggregating local models-------------
2022-01-25 14:44:11:INFO:-------------Round number: 14-------------
2022-01-25 14:44:11:INFO:-------------Sending models-------------
2022-01-25 14:44:11:INFO:-------------Evaluating models-------------
2022-01-25 14:44:11:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:44:11:INFO:Accuracy = [0.8175993970228, 0.8616921047672885, 0.8537780290182777, 0.8937252685132844, 0.8844921801394384, 0.8697946108912756, 0.8577350668927831, 0.8464292443941963, 0.8797814207650273, 0.8547201808931599]
2022-01-25 14:44:11:INFO:Loss = [0.44846586635592844, 0.29522646582029605, 0.42449940260177166, 0.34924790907643466, 0.2835431224363378, 0.33971732684442874, 0.4490274761080256, 0.35929276553243755, 0.39664301297011245, 0.477584144588934]
2022-01-25 14:44:11:INFO:-------------Training local models-------------
2022-01-25 14:44:55:INFO:-------------Aggregating local models-------------
2022-01-25 14:44:56:INFO:-------------Round number: 15-------------
2022-01-25 14:44:56:INFO:-------------Sending models-------------
2022-01-25 14:44:56:INFO:-------------Evaluating models-------------
2022-01-25 14:44:57:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:44:57:INFO:Accuracy = [0.8191068400226117, 0.861503674392312, 0.8558507631430187, 0.8957980026380252, 0.8876954965140381, 0.8692293197663463, 0.8605615225174298, 0.8488788392688902, 0.8797814207650273, 0.8549086112681364]
2022-01-25 14:44:57:INFO:Loss = [0.448763502409602, 0.29380026030069384, 0.4241285487290911, 0.3475757081011412, 0.2812566972572029, 0.340175732395773, 0.44880598489390255, 0.355287934417998, 0.39575095082193945, 0.476826677520045]
2022-01-25 14:44:57:INFO:-------------Training local models-------------
2022-01-25 14:45:40:INFO:-------------Aggregating local models-------------
2022-01-25 14:45:41:INFO:-------------Round number: 16-------------
2022-01-25 14:45:41:INFO:-------------Sending models-------------
2022-01-25 14:45:41:INFO:-------------Evaluating models-------------
2022-01-25 14:45:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:45:42:INFO:Accuracy = [0.821368004522329, 0.8616921047672885, 0.8588656491426417, 0.8974938760128133, 0.8899566610137554, 0.8692293197663463, 0.8620689655172413, 0.8500094215187488, 0.8797814207650273, 0.8556623327680422]
2022-01-25 14:45:42:INFO:Loss = [0.4487481016314455, 0.2927351671670089, 0.4238240644890294, 0.3460380457113886, 0.2793657855344917, 0.3407559811651976, 0.44867096478300245, 0.3516659139621661, 0.39499114667073687, 0.47611663768684626]
2022-01-25 14:45:42:INFO:-------------Training local models-------------
2022-01-25 14:46:25:INFO:-------------Aggregating local models-------------
2022-01-25 14:46:26:INFO:-------------Round number: 17-------------
2022-01-25 14:46:26:INFO:-------------Sending models-------------
2022-01-25 14:46:27:INFO:-------------Evaluating models-------------
2022-01-25 14:46:27:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:46:27:INFO:Accuracy = [0.8228754475221406, 0.8616921047672885, 0.8603730921424534, 0.8991897493876013, 0.893159977388355, 0.8688524590163934, 0.8641416996419823, 0.8515168645185603, 0.8797814207650273, 0.8556623327680422]
2022-01-25 14:46:27:INFO:Loss = [0.44844143675656545, 0.2918986331362439, 0.42356785862561475, 0.34460920217286056, 0.2777787453846559, 0.3413924503132956, 0.4486004653548573, 0.348347028911139, 0.39430559827513195, 0.47544530039224636]
2022-01-25 14:46:27:INFO:-------------Training local models-------------
2022-01-25 14:47:10:INFO:-------------Aggregating local models-------------
2022-01-25 14:47:11:INFO:-------------Round number: 18-------------
2022-01-25 14:47:11:INFO:-------------Sending models-------------
2022-01-25 14:47:12:INFO:-------------Evaluating models-------------
2022-01-25 14:47:12:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:47:12:INFO:Accuracy = [0.8245713208969286, 0.8618805351422649, 0.8622573958922178, 0.8991897493876013, 0.896551724137931, 0.8692293197663463, 0.8671565856416055, 0.8552854720180894, 0.8799698511400038, 0.8558507631430187]
2022-01-25 14:47:12:INFO:Loss = [0.44788711692753386, 0.2912070519961761, 0.4233396135035703, 0.3432817188162123, 0.27642509304808316, 0.34203979938361384, 0.44857335542820903, 0.3452687588709789, 0.3936663294723547, 0.474807727376825]
2022-01-25 14:47:12:INFO:-------------Training local models-------------
2022-01-25 14:47:56:INFO:-------------Aggregating local models-------------
2022-01-25 14:47:57:INFO:-------------Round number: 19-------------
2022-01-25 14:47:57:INFO:-------------Sending models-------------
2022-01-25 14:47:57:INFO:-------------Evaluating models-------------
2022-01-25 14:47:57:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:47:57:INFO:Accuracy = [0.8255134727718109, 0.8618805351422649, 0.8648954211418881, 0.899943470887507, 0.8991897493876013, 0.8692293197663463, 0.8688524590163934, 0.8586772187676653, 0.8801582815149802, 0.8560391935179951]
2022-01-25 14:47:57:INFO:Loss = [0.4471283837537049, 0.29060011475713055, 0.4231149250934006, 0.3420481611638475, 0.275262699088286, 0.3426631509054565, 0.448576116575806, 0.3423814100219228, 0.3930538518949469, 0.4741936578820364]
2022-01-25 14:47:57:INFO:-------------Training local models-------------
2022-01-25 14:48:41:INFO:-------------Aggregating local models-------------
2022-01-25 14:48:42:INFO:-------------Round number: 20-------------
2022-01-25 14:48:42:INFO:-------------Sending models-------------
2022-01-25 14:48:42:INFO:-------------Evaluating models-------------
2022-01-25 14:48:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:48:42:INFO:Accuracy = [0.8273977765215753, 0.8622573958922178, 0.8671565856416055, 0.8993781797625777, 0.9012624835123422, 0.8694177501413228, 0.8709251931411344, 0.8622573958922178, 0.8801582815149802, 0.8560391935179951]
2022-01-25 14:48:42:INFO:Loss = [0.44619328508860606, 0.2900412197508036, 0.42286965527206893, 0.3408947875516165, 0.274232932957567, 0.34322228076279343, 0.44858307167717465, 0.3396413109191299, 0.39245850326805226, 0.4735907648314673]
2022-01-25 14:48:42:INFO:-------------Training local models-------------
2022-01-25 14:49:26:INFO:-------------Aggregating local models-------------
2022-01-25 14:49:27:INFO:-------------Round number: 21-------------
2022-01-25 14:49:27:INFO:-------------Sending models-------------
2022-01-25 14:49:27:INFO:-------------Evaluating models-------------
2022-01-25 14:49:27:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:49:27:INFO:Accuracy = [0.8289052195213868, 0.8624458262671942, 0.8701714716412285, 0.8993781797625777, 0.9035236480120595, 0.8694177501413228, 0.8728094968908988, 0.8664028641416996, 0.8805351422649331, 0.8560391935179951]
2022-01-25 14:49:27:INFO:Loss = [0.44511624471081673, 0.28949484910008877, 0.422595300913592, 0.3398256276640111, 0.27331165964686227, 0.34369549033270114, 0.44857762397237266, 0.3370188812918986, 0.3918498895772992, 0.47298763652849996]
2022-01-25 14:49:27:INFO:-------------Training local models-------------
2022-01-25 14:50:11:INFO:-------------Aggregating local models-------------
2022-01-25 14:50:12:INFO:-------------Round number: 22-------------
2022-01-25 14:50:12:INFO:-------------Sending models-------------
2022-01-25 14:50:12:INFO:-------------Evaluating models-------------
2022-01-25 14:50:12:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:50:12:INFO:Accuracy = [0.8309779536461278, 0.8628226870171471, 0.8733747880158281, 0.8997550405125306, 0.905407951761824, 0.868664028641417, 0.8769549651403806, 0.8697946108912756, 0.8807235726399095, 0.8560391935179951]
2022-01-25 14:50:12:INFO:Loss = [0.4439150698520984, 0.28897392011861966, 0.42228324058238753, 0.33883857060563743, 0.2724760421522589, 0.34407219051997473, 0.4485681064225788, 0.33454482152261156, 0.39125429236543574, 0.47238917491860816]
2022-01-25 14:50:12:INFO:-------------Training local models-------------
2022-01-25 14:50:56:INFO:-------------Aggregating local models-------------
2022-01-25 14:50:57:INFO:-------------Round number: 23-------------
2022-01-25 14:50:57:INFO:-------------Sending models-------------
2022-01-25 14:50:57:INFO:-------------Evaluating models-------------
2022-01-25 14:50:57:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:50:57:INFO:Accuracy = [0.8315432447710571, 0.863576408517053, 0.8767665347654042, 0.8997550405125306, 0.9084228377614472, 0.868664028641417, 0.8778971170152629, 0.8724326361409459, 0.8807235726399095, 0.8562276238929716]
2022-01-25 14:50:57:INFO:Loss = [0.4426031672187679, 0.28844058015874274, 0.42194555388055094, 0.3379046097793094, 0.2716969925464623, 0.34435175525709644, 0.44854867372652, 0.3321400985220396, 0.3906542322807362, 0.4717940619587056]
2022-01-25 14:50:57:INFO:-------------Training local models-------------
2022-01-25 14:51:41:INFO:-------------Aggregating local models-------------
2022-01-25 14:51:42:INFO:-------------Round number: 24-------------
2022-01-25 14:51:42:INFO:-------------Sending models-------------
2022-01-25 14:51:42:INFO:-------------Evaluating models-------------
2022-01-25 14:51:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:51:42:INFO:Accuracy = [0.8324853966459393, 0.8639532692670059, 0.8794045600150744, 0.90032033163746, 0.9099302807612587, 0.8692293197663463, 0.8797814207650273, 0.877143395515357, 0.8812888637648388, 0.8566044846429245]
2022-01-25 14:51:42:INFO:Loss = [0.44120064713039797, 0.287887271662889, 0.4215843339036239, 0.3370265821744752, 0.27096648530957634, 0.3445554624256522, 0.4485153024780155, 0.3298168346394931, 0.3900473332414251, 0.4712044470334562]
2022-01-25 14:51:42:INFO:-------------Training local models-------------
2022-01-25 14:52:26:INFO:-------------Aggregating local models-------------
2022-01-25 14:52:27:INFO:-------------Round number: 25-------------
2022-01-25 14:52:27:INFO:-------------Sending models-------------
2022-01-25 14:52:27:INFO:-------------Evaluating models-------------
2022-01-25 14:52:27:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:52:27:INFO:Accuracy = [0.8345581307706802, 0.8641416996419823, 0.8822310156397212, 0.9008856227623893, 0.9116261541360468, 0.8699830412662521, 0.8812888637648388, 0.8820425852647447, 0.8814772941398153, 0.8567929150179009]
2022-01-25 14:52:27:INFO:Loss = [0.43973718133922796, 0.2873091513362689, 0.4212058514142253, 0.33620190662509125, 0.2702655626644033, 0.34468389705530017, 0.44847841265614685, 0.32756057460995053, 0.38943557201601536, 0.47062240009090284]
2022-01-25 14:52:27:INFO:-------------Training local models-------------
2022-01-25 14:53:11:INFO:-------------Aggregating local models-------------
2022-01-25 14:53:12:INFO:-------------Round number: 26-------------
2022-01-25 14:53:12:INFO:-------------Sending models-------------
2022-01-25 14:53:12:INFO:-------------Evaluating models-------------
2022-01-25 14:53:12:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:53:12:INFO:Accuracy = [0.8366308648954212, 0.8650838515168645, 0.884303749764462, 0.9010740531373658, 0.9131335971358583, 0.8707367627661579, 0.8824194460146976, 0.8854343320143208, 0.8814772941398153, 0.8567929150179009]
2022-01-25 14:53:12:INFO:Loss = [0.4382306979481064, 0.2867162062896025, 0.4207821732662202, 0.33543165238871253, 0.2695916604361184, 0.3447241069318522, 0.4484331560466282, 0.3253698671617534, 0.3888171888501016, 0.4700368288554327]
2022-01-25 14:53:12:INFO:-------------Training local models-------------
2022-01-25 14:53:56:INFO:-------------Aggregating local models-------------
2022-01-25 14:53:57:INFO:-------------Round number: 27-------------
2022-01-25 14:53:57:INFO:-------------Sending models-------------
2022-01-25 14:53:57:INFO:-------------Evaluating models-------------
2022-01-25 14:53:57:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:53:57:INFO:Accuracy = [0.8385151686451856, 0.8660260033917467, 0.8854343320143208, 0.9014509138873187, 0.9150179008856227, 0.8707367627661579, 0.8833615978895798, 0.8892029395138497, 0.8818541548897683, 0.8569813453928773]
2022-01-25 14:53:57:INFO:Loss = [0.436676031789585, 0.2861042984599452, 0.42033376097057906, 0.3347035265046912, 0.2689321763880269, 0.34467168274753757, 0.4483694944243186, 0.32323095756799647, 0.388177294956559, 0.46944216126812977]
2022-01-25 14:53:57:INFO:-------------Training local models-------------
2022-01-25 14:54:41:INFO:-------------Aggregating local models-------------
2022-01-25 14:54:42:INFO:-------------Round number: 28-------------
2022-01-25 14:54:42:INFO:-------------Sending models-------------
2022-01-25 14:54:42:INFO:-------------Evaluating models-------------
2022-01-25 14:54:43:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:54:43:INFO:Accuracy = [0.8413416242698323, 0.8673450160165819, 0.8861880535142265, 0.9016393442622951, 0.9163369135104579, 0.8707367627661579, 0.884303749764462, 0.8935368381383079, 0.8822310156397212, 0.8569813453928773]
2022-01-25 14:54:43:INFO:Loss = [0.43508271268150916, 0.2854772909553051, 0.4198564381631899, 0.3340149684796864, 0.26828316182347545, 0.3445492898053394, 0.4482904614325959, 0.3211499633104887, 0.3875281791909201, 0.46885304662139443]
2022-01-25 14:54:43:INFO:-------------Training local models-------------
2022-01-25 14:55:26:INFO:-------------Aggregating local models-------------
2022-01-25 14:55:27:INFO:-------------Round number: 29-------------
2022-01-25 14:55:27:INFO:-------------Sending models-------------
2022-01-25 14:55:28:INFO:-------------Evaluating models-------------
2022-01-25 14:55:28:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:55:28:INFO:Accuracy = [0.8437912191445262, 0.8684755982664405, 0.8875070661390616, 0.9022046353872244, 0.9180327868852459, 0.8709251931411344, 0.8856227623892972, 0.8959864330130017, 0.882607876389674, 0.8569813453928773]
2022-01-25 14:55:28:INFO:Loss = [0.4334646031697108, 0.284842846237561, 0.4193659297718216, 0.3333641166608979, 0.26764438103168725, 0.3443574103533264, 0.4482116402629714, 0.31912733964454076, 0.3868711371698147, 0.4682674919355458]
2022-01-25 14:55:28:INFO:-------------Training local models-------------
2022-01-25 14:56:12:INFO:-------------Aggregating local models-------------
2022-01-25 14:56:12:INFO:-------------Round number: 30-------------
2022-01-25 14:56:12:INFO:-------------Sending models-------------
2022-01-25 14:56:13:INFO:-------------Evaluating models-------------
2022-01-25 14:56:13:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:56:13:INFO:Accuracy = [0.845863953269267, 0.8697946108912756, 0.8882607876389674, 0.9023930657622009, 0.9191633691351045, 0.8713020538910873, 0.8867533446391558, 0.8986244582626719, 0.8827963067646505, 0.8569813453928773]
2022-01-25 14:56:13:INFO:Loss = [0.4318283476221375, 0.2842067313824177, 0.41885676130219673, 0.3327490566182981, 0.2670088989650009, 0.34410712345898475, 0.4481278149783471, 0.317162195386844, 0.3862086135677945, 0.4676791376732423]
2022-01-25 14:56:13:INFO:-------------Training local models-------------
2022-01-25 14:56:57:INFO:-------------Aggregating local models-------------
2022-01-25 14:56:58:INFO:-------------Round number: 31-------------
2022-01-25 14:56:58:INFO:-------------Sending models-------------
2022-01-25 14:56:58:INFO:-------------Evaluating models-------------
2022-01-25 14:56:58:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:56:58:INFO:Accuracy = [0.8466176747691728, 0.8716789146410401, 0.8884492180139438, 0.9023930657622009, 0.9206708121349162, 0.8714904842660637, 0.8878839268890145, 0.90032033163746, 0.8827963067646505, 0.8573582061428302]
2022-01-25 14:56:58:INFO:Loss = [0.4301783085858794, 0.28357025119662477, 0.4183288707908289, 0.3321665712522207, 0.2663745574791083, 0.3437895667585659, 0.44804518001619287, 0.3152537960168227, 0.3855361019574035, 0.4670870594500608]
2022-01-25 14:56:58:INFO:-------------Training local models-------------
2022-01-25 14:57:42:INFO:-------------Aggregating local models-------------
2022-01-25 14:57:43:INFO:-------------Round number: 32-------------
2022-01-25 14:57:43:INFO:-------------Sending models-------------
2022-01-25 14:57:43:INFO:-------------Evaluating models-------------
2022-01-25 14:57:43:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:57:43:INFO:Accuracy = [0.8490672696438666, 0.8731863576408517, 0.8892029395138497, 0.9031467872621066, 0.9208592425098926, 0.8714904842660637, 0.8880723572639909, 0.9012624835123422, 0.8829847371396269, 0.8573582061428302]
2022-01-25 14:57:43:INFO:Loss = [0.42851560594498567, 0.2829300252160156, 0.4177860958198407, 0.33161510385193677, 0.2657457280770288, 0.34342286775556546, 0.44796163571551156, 0.31339826915312324, 0.38484971625513664, 0.4664974080699029]
2022-01-25 14:57:43:INFO:-------------Training local models-------------
2022-01-25 14:58:27:INFO:-------------Aggregating local models-------------
2022-01-25 14:58:28:INFO:-------------Round number: 33-------------
2022-01-25 14:58:28:INFO:-------------Sending models-------------
2022-01-25 14:58:28:INFO:-------------Evaluating models-------------
2022-01-25 14:58:28:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:58:28:INFO:Accuracy = [0.850951573393631, 0.8743169398907104, 0.8892029395138497, 0.9035236480120595, 0.9218013943847748, 0.872055775390993, 0.8884492180139438, 0.9029583568871302, 0.8831731675146034, 0.8575466365178067]
2022-01-25 14:58:28:INFO:Loss = [0.426845850298008, 0.2822874142848763, 0.4172284978698372, 0.33109659167310296, 0.26512359798452334, 0.34300160604111946, 0.44787161840824014, 0.3115884089374847, 0.38414903641218173, 0.4659051931997021]
2022-01-25 14:58:28:INFO:-------------Training local models-------------
2022-01-25 14:59:12:INFO:-------------Aggregating local models-------------
2022-01-25 14:59:13:INFO:-------------Round number: 34-------------
2022-01-25 14:59:13:INFO:-------------Sending models-------------
2022-01-25 14:59:13:INFO:-------------Evaluating models-------------
2022-01-25 14:59:13:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:59:13:INFO:Accuracy = [0.853024307518372, 0.875824382890522, 0.8895798002638026, 0.9040889391369888, 0.9225551158846806, 0.8726210665159224, 0.8890145091388731, 0.9031467872621066, 0.8831731675146034, 0.8575466365178067]
2022-01-25 14:59:13:INFO:Loss = [0.4251756411153189, 0.28165951571696224, 0.41666380215770704, 0.3305983348374338, 0.2644997463990754, 0.3425356090016697, 0.44777928712618625, 0.30983148183308074, 0.38344644218704216, 0.4653201021285826]
2022-01-25 14:59:13:INFO:-------------Training local models-------------
2022-01-25 14:59:57:INFO:-------------Aggregating local models-------------
2022-01-25 14:59:58:INFO:-------------Round number: 35-------------
2022-01-25 14:59:58:INFO:-------------Sending models-------------
2022-01-25 14:59:58:INFO:-------------Evaluating models-------------
2022-01-25 14:59:58:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 14:59:58:INFO:Accuracy = [0.8535895986433013, 0.8773318258903335, 0.8905219521386848, 0.9040889391369888, 0.9225551158846806, 0.8733747880158281, 0.889768230638779, 0.9057848125117769, 0.8831731675146034, 0.8575466365178067]
2022-01-25 14:59:58:INFO:Loss = [0.4235024195139786, 0.28104662373053485, 0.4160925819487115, 0.33012825536315876, 0.2638830500449773, 0.34203101695386756, 0.447690791211161, 0.30812684556142295, 0.382742041807535, 0.4647317290714894]
2022-01-25 14:59:58:INFO:-------------Training local models-------------
2022-01-25 15:00:42:INFO:-------------Aggregating local models-------------
2022-01-25 15:00:43:INFO:-------------Round number: 36-------------
2022-01-25 15:00:43:INFO:-------------Sending models-------------
2022-01-25 15:00:43:INFO:-------------Evaluating models-------------
2022-01-25 15:00:43:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:00:43:INFO:Accuracy = [0.8552854720180894, 0.8782739777652158, 0.8899566610137554, 0.903712078387036, 0.92312040700961, 0.8745053702656869, 0.8899566610137554, 0.9074806858865649, 0.8833615978895798, 0.8575466365178067]
2022-01-25 15:00:43:INFO:Loss = [0.42182856995525253, 0.2804355188089068, 0.41552889410259203, 0.32967459543952354, 0.2632662362847, 0.341500692760608, 0.44760376699288124, 0.30647271544478544, 0.382030246345403, 0.46414489692006144]
2022-01-25 15:00:43:INFO:-------------Training local models-------------
2022-01-25 15:01:27:INFO:-------------Aggregating local models-------------
2022-01-25 15:01:28:INFO:-------------Round number: 37-------------
2022-01-25 15:01:28:INFO:-------------Sending models-------------
2022-01-25 15:01:28:INFO:-------------Evaluating models-------------
2022-01-25 15:01:28:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:01:28:INFO:Accuracy = [0.8566044846429245, 0.8794045600150744, 0.8905219521386848, 0.9040889391369888, 0.9236856981345393, 0.8748822310156397, 0.8901450913887319, 0.9082344073864707, 0.8833615978895798, 0.8575466365178067]
2022-01-25 15:01:28:INFO:Loss = [0.4201637266576632, 0.2798309548373561, 0.41497602222552876, 0.329241195820491, 0.26265851004040497, 0.3409427463520383, 0.4475201526597958, 0.304875561329544, 0.38131581608970994, 0.4635561774518156]
2022-01-25 15:01:28:INFO:-------------Training local models-------------
2022-01-25 15:02:12:INFO:-------------Aggregating local models-------------
2022-01-25 15:02:13:INFO:-------------Round number: 38-------------
2022-01-25 15:02:13:INFO:-------------Sending models-------------
2022-01-25 15:02:13:INFO:-------------Evaluating models-------------
2022-01-25 15:02:13:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:02:13:INFO:Accuracy = [0.8573582061428302, 0.8795929903900509, 0.8908988128886377, 0.9050310910118711, 0.9244394196344451, 0.8750706613906162, 0.8907103825136612, 0.9087996985114001, 0.8835500282645562, 0.8577350668927831]
2022-01-25 15:02:13:INFO:Loss = [0.4185061409288932, 0.2792316330110699, 0.4144217211846622, 0.3288292786430596, 0.2620576133215191, 0.340352746180301, 0.44743467593426595, 0.30332591787303265, 0.3806002853611861, 0.46296789034331876]
2022-01-25 15:02:13:INFO:-------------Training local models-------------
2022-01-25 15:02:57:INFO:-------------Aggregating local models-------------
2022-01-25 15:02:58:INFO:-------------Round number: 39-------------
2022-01-25 15:02:58:INFO:-------------Sending models-------------
2022-01-25 15:02:58:INFO:-------------Evaluating models-------------
2022-01-25 15:02:58:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-25 15:02:58:INFO:Accuracy = [0.8583003580177124, 0.8812888637648388, 0.8907103825136612, 0.9057848125117769, 0.9246278500094215, 0.8752590917655926, 0.8908988128886377, 0.9087996985114001, 0.8837384586395327, 0.8579234972677595]
2022-01-25 15:02:58:INFO:Loss = [0.41685517068630035, 0.27864379500072617, 0.41387125397926194, 0.32843434924177917, 0.2614629623408059, 0.3397294948140673, 0.4473419998728921, 0.3018303219688897, 0.3798818214186351, 0.4623696105596379]
2022-01-25 15:02:58:INFO:-------------Training local models-------------
2022-01-25 15:03:42:INFO:-------------Aggregating local models-------------
